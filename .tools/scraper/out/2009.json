[{"href":"http://spinoff.nasa.gov/Spinoff2009/hm_1.html","text":"Image-Capture Devices Extend Medicine’s Reach","image":"http://spinoff.nasa.gov/Spinoff2009/images/Mediphan-2.jpg","story":"\n  \n    \n      \n      \n      \n      \n    \n    Health and Medicine\n    \n      Originating Technology/NASA Contribution\n  \n    In spring 2008, Dr. Scott Dulchavsky diagnosed high-altitude pulmonary edema in a climber over 20,000 feet up the slope of Mount Everest. Dulchavsky made the diagnosis from his office in Detroit, half a world away. The story behind this long-distance medical achievement begins with a seemingly unrelated fact: There is no X-ray machine on the International Space Station (ISS).\n    \n    On the ISS, diagnosing an injury or other medical issue can be problematic; bulky medical imaging devices like X-ray, CAT, or MRI machines are too large and heavy for costly transportation into space. And while crew medical officers receive some diagnostic training, the nearest doctors and fully equipped hospitals are 250 miles away on Earth. Future astronauts on long-term Moon or Mars expeditions will face even greater challenges.  \n  \n    \n    \n      \n        \n                      Remote ultrasound procedures provide for medical diagnoses to areas as far-flung as Mount Everest (above) and the International Space Station (right)—miles from professional medical personnel.\n      \n    \n  \n  The ISS does have an ultrasound machine—at \n    \n    168 pounds, much smaller than its imaging technology counterparts—installed as part of the Human Research Facility for experiments on the effects of microgravity on human health. During medical use, the ultrasound machine’s hand-held transducer emits high-frequency sound waves that partially reflect at points of differing density, such as between soft tissue and bone. The machine’s computer translates the echoes into a two- or three-dimensional video representation. On Earth, ultrasound is commonly used for imaging fetus development, abdominal conditions like gallstones, and blood flow in patients with arterial disease. Unconventional applications, like diagnosing broken bones or collapsed lungs, were not explored given the ready availability of X-ray and MRI machines in hospitals and the high density differences of bone and air, which completely reflect the ultrasound waves and prevent clear images of deeper tissue.\n    \n    That changed in 2000, when NASA approached Dulchavsky, chair of the Department of Surgery at Henry Ford Hospital in Detroit, to make ultrasound a more versatile diagnostic technique and to adapt it \n    for remote use on the ISS. Dulchavsky tested new ultrasound applications and found that, in many cases, such as with collapsed lungs, the technique worked better than X-ray imaging. He became lead investigator for the Advanced Diagnostic Ultrasound in Microgravity (ADUM) experiment, a collaborative effort between Johnson Space Center, Henry Ford Hospital, and Wyle Laboratories Inc. in Houston. \n    \n    Aided by Onboard Proficiency Enhancer (OPE) software, cue cards, and direct communication with doctors on Earth, ISS crewmembers with only minimal ultrasound training (about 3 hours as opposed to about 500 hours for a professional) used non-traditional ultrasound techniques pioneered by Dulchavsky’s team for imaging of a wide range of body parts. These novel ultrasound techniques can evaluate infections in the teeth or sinus cavities or judge the effects of space flight on the central nervous system by measuring changes in the diameter of the eye’s optic nerve sheath as a gauge of pressure around the brain. Experts on the ground received diagnostic-quality images from the ISS through satellite downlink, demonstrating the effectiveness of ultrasound as a multipurpose, remote diagnostic tool in space. \n    \n    Partnership\n    \n    In keeping with NASA’s mandate to translate space technologies into applications for terrestrial use, Henry Ford Hospital doctors and Wyle engineers worked to find ways to overcome a major obstacle to bringing the ADUM-developed remote ultrasound procedures down to Earth: There were no cost-effective, technologically viable methods for sending ultrasound scans over long distances without a loss of image quality. \n    \n    “We have a great satellite hookup and a big telemedical network at NASA, but we don’t have these for common terrestrial use,” says Dulchavsky. \n    \n    To overcome this problem, they collaborated with Epiphan Systems Inc., a computer-imaging industry leader headquartered in Canada with offices in Springfield, New Jersey. The cooperation resulted in the formation of Mediphan, a remote medical diagnostics technology company. Mediphan drew on NASA expertise to adapt Epiphan’s video-streaming innovations into a practical solution. \n    \n    Product Outcome\n    \n    Mediphan has developed and commercialized two tools for terrestrial telemedical use. \n    \n    DistanceDoc, an external video frame grabber, makes use of Epiphan’s video graphics array (VGA) capture technology to take diagnostic-quality and Digital Imaging and Communications in Medicine (DICOM) standard stills or video from the ultrasound monitor (or any other medical device with a video display, such as an electrocardiogram or ventilator). It then allows the ultrasound operator to transmit the images securely over the Internet in real time and at near-original resolution. The second tool, MedRecorder, is a similar device that captures diagnostic-quality and DICOM imaging, then stores and archives it for later reference, like an external hard drive.\n    \n    Each device plugs into the VGA port of any standard ultrasound machine and then connects to a computer by a universal serial bus (USB) 2.0. A non-physician can, with minimal technical know-how, install Mediphan’s technology and use it to send medical imaging for consultation with experts. Coupled with the highly portable General Electric LOGIQ laptop ultrasound machine and the NASA-developed OPE instructional software now modified for broader use, even the medically inexperienced can consult with distant doctors to diagnose medical issues when and where they occur. \n    \n    “Immediacy in point of care is essential,” says Dulchavsky. “We can now have non-skilled individuals onsite doing what traditionally only highly skilled individuals are able to do.” \n    \n  \n  \n    \n    \n      \n    \n    \n                Mediphan’s MedRecorder and DistanceDoc devices enable the remote ultrasound techniques developed for space to be employed on Earth. By capturing, transmitting, and storing diagnostic-quality ultrasound imagery and video, the devices allow doctors to diagnose injuries and other conditions while not in the same room, building, or even hemisphere as their patients. \n    \n  \n  The applications of remote ultrasound diagnostic capabilities are widespread and increasing. The major professional sports teams in Detroit are all using the ultrasound procedure, OPE software, and Mediphan devices for immediate locker-room diagnoses of injuries that happen during practice and games. Olympians at the 2006 Winter Olympic Games in Torino, Italy, benefitted from the telemedical procedure, as did athletes at last year’s Summer Olympic Games in Beijing, China. Currently, the procedure is used for day-to-day oversight of Olympians in training facilities across the United States. It also allows trainers to establish baseline evaluations of athletes’ body structures, making for easier recognition of damage due to injury. More than 345 musculoskeletal ultrasound examinations have been performed on Olympians and professional athletes so far, a number of these with remote guidance.\n      \n    The technology is also helping improve education, allowing a medical student on duty to share diagnostic information with an attending doctor elsewhere. The MedRecorder offers medical students the ability to archive personal portfolios documenting proficiency in diagnostic techniques and provides an affordable way to store and maintain records. \n    \n    Meanwhile, the United Nations Millennium Project, which has among its goals improved maternal care in underserved areas, plans to use the telemedical procedure in developing countries. Dulchavsky and NASA engineers are currently working to create a highly versatile, environmentally robust device that could serve as a kind of information node connecting patients in remote areas to distant experts via Mediphan technology. Then, Dulchavsky says, “we could utilize the techniques and technologies that we developed for use on the ISS to diagnose a wide variety of medical issues, such as traumatic injury, problematic pregnancies, and certain infectious diseases.”\n    \n    Last year, working at a distance with a NASA team in the Mars-like environment of Devon Island in northern Canada, Dulchavsky performed the first-ever remote guidance of a simulated appendectomy. One day, the same technique may be used to do the real thing in a village in Madagascar, on the slope of Everest, or on Mars itself.\n    \n    \n    DistanceDoc™ and MedRecorder™ are trademarks of Mediphan. \n    LOGIQ® is a registered trademark of General Electric Company.\n    \n    \n    \n    \n      \n      \n      \n      \n    \n  \n                      "},{"href":"http://spinoff.nasa.gov/Spinoff2009/hm_2.html","text":"Medical Devices Assess, Treat Balance Disorders","image":"http://spinoff.nasa.gov/Spinoff2009/images/NeuroCom-2.jpg","story":"\n                      \n  \n    \n    \n    \n    \n  \n  Health and Medicine\n  \n  Originating Technology/NASA Contribution \n  \n                        You may have heard the phrase “as difficult as walking and chewing gum” as a joking way of referring to something that is not difficult \n                        at all. Just walking, however, is not all that simple—physiologically speaking. Even standing upright is an undertaking requiring the complex cooperation of multiple motor and sensory systems including vision, the inner ear, somatosensation (sensation from the skin), and proprioception (the sense of the body’s parts in relation to each other). The compromised performance of any of these elements can lead to a balance disorder, which in some form affects nearly half of Americans at least once in their lifetimes, from the elderly, to those with neurological or vestibular (inner ear) dysfunction, to athletes with musculoskeletal injuries, to astronauts returning from space. \n                        \n                      \n                      \n                        \n                        \n                          \n                        \n                        \n                                                      The effects of space flight on astronauts’ ability to balance has long been a focus \n                                of NASA research. This 1964 photo shows a NASA scientist testing astronaut \n                          John Glenn’s inner ear balance mechanism by running cool water into his ear and measuring the effect on Glenn’s eye motions.\n                        \n                      \n                      Readjusting to Earth’s gravity has a significant impact on an astronaut’s ability to balance, a result of the brain switching to a different “model” for interpreting sensory input in normal gravity versus weightlessness. While acclimating, astronauts can experience headaches, motion sickness, and problems with perception. To help ease the transition and study the effects of weightlessness on the body, NASA has conducted many investigations into post-flight balance control, realizing this research can help treat patients with balance disorders on Earth as well. \n                        \n                        In the 1960s, the NASA-sponsored Man Vehicle Laboratory at the Massachusetts Institute of Technology (MIT) studied the effects of prolonged space flight on astronauts. The lab’s work intrigued MIT doctoral candidate Lewis Nashner, who began conducting NASA-funded research on human movement and balance under the supervision of Dr. Larry Young in the MIT Department of Aeronautics and Astronautics. In 1982, Nashner’s work resulted in a noninvasive clinical technique for assessing the cooperative systems that allow the body to balance, commonly referred to as computerized dynamic posturography (CDP). CDP employs a series of dynamic protocols to isolate and assess balance function deficiencies. The technology was based on Nashner’s novel, engineering-inspired concept of balance as an adaptable collaboration between multiple sensory and motor systems. CDP proved useful not only for examining astronauts, but for anyone suffering from balance problems. Today, CDP is the standard medical tool for objectively evaluating balance control. \n                        \n                        Partnership \n                        \n                        In 1984, Nashner founded NeuroCom International Inc., headquartered in Clackamas, Oregon, and continued his research to refine the clinical role of CDP. Within \n                        2 years, the company had developed the EquiTest, the first commercially available CDP device. NASA has employed NeuroCom’s CDP systems for its research and continues to use EquiTest for the routine evaluation and balance rehabilitation of its astronauts at Kennedy Space Center and Johnson Space Center. NeuroCom’s EquiTest and Balance Master systems—the latter created based on CDP concepts to meet increasing demand from physical therapists—were first featured in Spinoff 1996.\n                        \n                        “When I joined NeuroCom in 1988, the concepts of a systems approach to balance and vestibular rehabilitation were basically unknowns,” says Jon F. Peters, Ph.D., NeuroCom’s vice president and general manager. “Researchers were keen on the ideas, but it wasn’t common practice. Out of Dr. Nashner’s work grew a whole new approach for looking at these problems.”\n                        \n                        Product Outcome\n                        \n                      \n                      \n                        \n                          \n                        \n                      \n                      NeuroCom now has over 2,000 systems in use around the world in a variety of medical fields including neurology, geriatrics, otolaryngology (ear, nose, and throat specialists), orthopedics, and sports medicine. \n                        \n                        Under the Balance Manager concept, NeuroCom’s products are cast into two broad categories: systems based on either dynamic or fixed force plate technology. NeuroCom’s dynamic models, which include EquiTest, SMART EquiTest, SMART Balance Master, and PRO Balance Master, offer the ability to control the support surface as well as the visual surround. The patient stands on the system’s dynamic force plate, a platform that shifts while recording the vertical forces applied by the feet as the patient attempts to maintain balance. Supported by a safety harness to prevent falls, the patient faces into the booth’s three-sided visual surround, which also tilts to test the visual component of the patient’s balance mechanisms. The system provides comprehensive reports that identify sensory and motor impairments and allow for comparison to normal data for the patient’s age range. The information gathered can be teased apart, says Peters, to help understand where the patient’s balance problems lie. The same system can then be used in a biofeedback mode (a video screen provides visual biofeedback), retraining sensory and motor systems to regain balance control.\n                        NeuroCom’s fixed force plate models include the Balance Master and Basic Balance Master systems, which have a physical therapy focus and help identify specific daily performance issues and possible underlying sensory and motor impairments affecting balance. A stroke patient, for example, can be examined using a fixed force plate system to see what movements (getting up from a chair, for example) are contributing most to the patient’s difficulty. After therapists identify the problem, they can then use visual biofeedback to help the patient learn new cues to perform tasks more safely. \n                      \n                      \n                        \n                        \n                          \n                        \n                        \n                                                      Developed from balance assessment research supported with NASA funding, NeuroCom’s systems provide a versatile range of balance analysis and therapy options.\n                        \n                      \n                      All of NeuroCom’s systems can be enhanced with optional protocols and capabilities. Among these is the inVision package, which measures changes in a patient’s visual acuity as a function of balance and head motion. The electromyography option analyzes the response of a patient’s gastrocnemius and tibialis muscles (both located in the lower leg) to unexpected external balance challenges. The NeuroGames package provides video games like Solitaire and NeuroPong that offer a fun way to rehabilitate balance control. Patients play the games on a Balance Master or SMART EquiTest system by shifting their center of gravity to control the action.\n                        The versatility of the technology is essential; even patients with the same diagnosis, like Parkinson’s disease, can suffer from different balance impairments with different immediate causes. The same applies to the elderly. While about one-third of Americans over 65 experience falls each year according to the National Safety Council, the impairments that lead to these falls vary. The balance analysis and therapy offered by NeuroCom’s NASA-developed technology can help reduce the Centers for Disease Control and Prevention’s estimate of over \n                        $19 billion spent each year to treat fall-related injuries.\n                        \n                        The company continues to push its technology into new clinical realms, says Peters. “Applications have gone well beyond patients with vertigo and dizziness,” he notes. The company is exploring the relationship between balance disorders and cognitive issues like learning problems and attention deficit disorder. Peters says NeuroCom looks to sources like NASA as “guideposts\n                        for our efforts.”\n                        \n                        “Because NASA has to deal with the complex problems of flying people in space,” he says, “their research tends to be more applied and closer to what we need to take hold of and put into general medical practice.”\n                        \n                        NeuroCom®, Balance Manager®, EquiTest®, SMART EquiTest®, SMART Balance Master®, PRO Balance Master®, Balance Master®, and Basic Balance Master® are registered trademarks of NeuroCom International Inc. \n                        inVision™, NeuroGames™, and NeuroPong™ are trademarks of NeuroCom International Inc.\n                        \n                        \n                        \n                        \n                          \n                          \n                          \n                          \n                        \n                      \n                    "},{"href":"http://spinoff.nasa.gov/Spinoff2009/hm_3.html","text":"NASA Bioreactors Advance Disease Treatments","image":"http://spinoff.nasa.gov/Spinoff2009/images/Regenetech-2.jpg","story":"\n      \n                      Health and Medicine\n                      \n                      Originating Technology/NASA Contribution \n                        \n                        The International Space Station (ISS) is falling. This is no threat to the astronauts onboard, however, because falling is part of the ISS staying \n                        in orbit. \n                        \n                        The absence of gravity beyond the Earth’s atmosphere is actually an illusion; at the ISS’s orbital altitude of approximately 250 miles above the surface, the planet’s gravitational pull is only 12-percent weaker than on the ground. Gravity is constantly pulling the ISS back to Earth, but the space station is also constantly traveling at nearly 18,000 miles per hour. This means that, even though the ISS is falling toward Earth, it is moving sideways fast enough to continually miss impacting the planet. The balance between the force of gravity and the ISS’s motion creates a stable orbit, and the fact that the ISS and everything in it—including the astronauts—are falling at an equal rate creates the condition of weightlessness called microgravity.\n                        \n                \n\n                        \n                        \n                          \n                        \n                        \n                          \n                              Cells grown in microgravity (A) tend to become more spherical than those grown on Earth (B). This demonstrates that tissues can grow and differentiate into distinct structures in microgravity. NASA’s rotating wall bioreactor simulates weightlessness to mimic this effect on Earth. \n                          \n                        \n                      \n                      The constant falling of objects in orbit is not only an important principle in space, but it is also a key element of a revolutionary NASA technology here on Earth that may soon help cure medical ailments from heart disease to diabetes. \n                        \n                        In the mid-1980s, NASA researchers at Johnson Space Center were investigating the effects of long-term microgravity on human tissues. At the time, the Agency’s shuttle fleet was grounded following the 1986 Space Shuttle Challenger disaster, and researchers had no access to the microgravity conditions of space. To provide a method for recreating such conditions on Earth, Johnson’s David Wolf, Tinh Trinh, and Ray Schwarz developed that same year a horizontal, rotating device—called a rotating wall bioreactor—that allowed the growth of human cells in simulated weightlessness. Previously, cell cultures on Earth could only be grown two-dimensionally in Petri dishes, because gravity would cause the multiplying cells to sink within their growth medium. These cells do not look or function like real human cells, which grow three-dimensionally in the body. Experiments conducted by Johnson scientist Dr. Thomas Goodwin proved that the NASA bioreactor could successfully cultivate cells using simulated microgravity, resulting in three-dimensional tissues that more closely approximate those in the body. Further experiments conducted on space shuttle missions and by Wolf as an astronaut on the Mir space station demonstrated that the bioreactor’s effects were even further expanded in space, resulting in remarkable levels of tissue formation.\n                        \n                        While the bioreactor may one day culture red blood cells for injured astronauts or single-celled organisms like algae as food or oxygen producers for a Mars colony, the technology’s cell growth capability offers significant opportunities for terrestrial medical research right now. A small Texas company is taking advantage of the NASA technology to advance promising treatment applications for diseases both common and obscure.\n                        \n                        Partnership\n                        \n                        In 2002, Houston-based biotechnology firm Regenetech Inc. (then called BioCell Innovations) acquired the licenses for the NASA bioreactor and a number of related patents for use in the burgeoning field of adult stem cell research. (Unlike ethically controversial embryonic stem cells, adult stem cells are harvested from sources such as blood and bone marrow.) Employing a novel business model that takes advantage of sponsored research agreements with major medical institutions like the University of Texas M.D. Anderson Cancer Center in Houston, Regenetech was able to begin testing and adapting the bioreactor’s capabilities for use with human stem cells with a first year budget of only $100,000. A NASA Space Act Agreement that saw the company share resources with Goodwin at Johnson, as well as additional licensing agreements between the company and the Agency, enabled Regenetech to further complement the bioreactor with its own proprietary improvements. \n                        \n                        Product Outcome\n                        \n                        Regenetech has built upon its licensed NASA technology to create a thriving intellectual property business that is providing researchers with the tools to make adult stem cell therapy viable for the public. \n                        \n                        Adult stem cells are found in some types of body tissue. These cells are multipotent, meaning they can differentiate into a specific range of specialized cells. This makes them appealing possibilities for treating diseases—the stem cells differentiate into healthy replacements for sick or damaged cells. Blood stem cells, for example, can transform into red blood cells, white blood cells, and platelets; these cells could provide a potential treatment for blood diseases like sickle cell anemia. \n                        \n                        One of the richest sources of adult stem cells is bone marrow. \n                        \n                        “There are about 70 different conditions and diseases where bone marrow stem cells have been used to regenerate tissue or treat disease,” says Donnie Rudd, Regenetech’s chief scientist and director of intellectual property. Stem cells can be harvested from a patient’s bone marrow through a procedure called bone marrow apheresis—a process that like any medical procedure carries some level of risk. The problem with alternative methods of adult stem cell harvest is getting enough of the cells to have therapeutic value, which is where Regenetech’s Intrifuge cellXpansion technology comes to bear. \n                        \n                      \n                      \n                        \n                        \n                          \n                        \n                        \n                          \n                              Regenetech scientists examine the company’s bioreactors. Licensed from NASA, the bioreactor technology allows for rapid, healthy cell growth, providing for a quicker, cheaper source of adult stem cells for therapy and medical research. \n                          \n                        \n                      \n                      “We can take a sample of peripheral blood from a patient’s arm, separate the stem cells, put that into our improved NASA bioreactor, and then multiply the cells to a therapeutic level without all the trauma of bone marrow apheresis,” says Rudd.\n                        \n                      \n                      Regenetech’s Intrifuge rotating wall bioreactor cradles a soup can-sized, rotating chamber that is used to expand, or multiply, harvested stem cells. The cell sample, contained in a growth fluid, is placed in the rotating chamber equipped with a membrane for oxygenation and gas exchange. As the chamber rotates, the cells are suspended in a constant state of falling—similar to an object in space orbit. This condition is enabled by a rotating inner wall that reduces shear from the nutrient fluid. In this simulated weightlessness, the cells do not get damaged and die from bouncing off the sides of the chamber. They multiply rapidly (50–200 times in size in as few as 6 days) into healthy populations, providing a quicker and cheaper source of stem cells for therapy or medical research. Regenetech’s cellXpansion process is being tested for further enhancement by a NASA-developed electromagnetic coil that surrounds the canister and which NASA developed to stimulate nerve cell growth. The coil, also patented by the NASA bioreactor development team and licensed by Regenetech, produces time varying electromagnetic conditions.\n                        \n                        Regenetech started producing revenue only 5 years after its founding, and since acquiring the original NASA licenses, it has developed over 300 of its own patents and patent applications and has licensed out its technologies on a global scale. The company generates its revenue through research partnerships and licensing its patents to stem cell researchers in pursuit of treatments for everything from heart disease to diabetes to liver cirrhosis. It is currently engaged in sponsored research agreements with major universities to develop stem cell therapy for type 1 diabetes, study blood stem cells, and create stem cell veterinary orthopedic treatments using the company’s Intrifuge cellXpansion technology.\n                        \n                        Through an agreement with NASA, Regenetech is also able to offer significant help to researchers pursuing treatments of rare diseases that affect less than 200,000 people in the United States and thus do not offer enough return on drug development investment. NASA allows the company to charge as little as $1,000 to $10,000 to license its NASA-developed technologies to researchers of such rare diseases.\n                        \n                      “Our relationship with NASA has allowed us to get this technology out into the field for those diseases that otherwise might never be treated,” says Rudd.\n                      Intrifuge™ and cellXpansion™ are trademarks of Regenetech Inc.\n                          \n                          \n                          \n      \n                            \n                            \n                            \n                            \n                            \n                      \n                    "},{"href":"http://spinoff.nasa.gov/Spinoff2009/hm_4.html","text":"Robotics Algorithms Provide Nutritional Guidelines","image":"http://spinoff.nasa.gov/Spinoff2009/images/Vitabot-3.jpg","story":"Health and Medicine\n                      \n                      Originating Technology/NASA Contribution \n                      \n                      On July 5, 1997, a small robot emerged from its lander like an insect from an egg, crawling out onto the rocky surface of Mars. About the size of a child’s wagon, NASA’s Sojourner robot was the first successful rover mission to the Red Planet. For 83 sols (Martian days, typically about 40 minutes longer than Earth days), Sojourner—largely remote controlled by NASA operators on Earth—transmitted photos and data unlike any previously collected. \n                \n      \n                        \n                        \n                          \n                        \n                        \n                                                      Developing NASA’s Ranger Neutral Buoyancy Vehicle provided Joe Graves with the robotics experience he used to create the online nutritional program Vitabot. \n                        \n                \n                      Sojourner was perhaps the crowning achievement of the NASA Space Telerobotics Program, an Agency initiative designed to push the limits of robotics in space. Telerobotics—devices that merge the autonomy of robotics with the direct human control of teleoperators—was already a part of NASA’s efforts; probes like the Viking landers that preceded Sojourner on Mars, for example, were telerobotic applications. The Space Telerobotics Program, a collaboration between Ames Research Center, Johnson Space Center, Jet Propulsion Laboratory (JPL), and multiple universities, focused on developing remote-controlled robotics for three main purposes: on-orbit assembly and servicing, science payload tending, and planetary surface robotics. The overarching goal was to create robots that could be guided to build structures in space, monitor scientific experiments, and, like Sojourner, scout distant planets in advance of human explorers. \n                        \n                        While telerobotics remains a significant aspect of NASA’s efforts—as evidenced by the currently operating Spirit and Opportunity Mars rovers, the Hubble Space Telescope, and many others—the Space Telerobotics Program was dissolved and redistributed within the Agency the same year as Sojourner’s success. The program produced a host of remarkable technologies and surprising inspirations, including one that is changing the way people eat. \n                        \n                        Partnership\n                        \n                        The Space Systems Laboratory (SSL), focusing on space robotics, artificial intelligence, and space simulation, was originally founded at Boston’s Massachusetts Institute of Technology in 1976. The lab conducted experiments on large-scale space structure assemblies and telerobotics using Marshall Space Flight Center’s Neutral Buoyancy Simulator, a water tank used to mimic conditions in space (NASA’s neutral buoyancy facility is now located at Johnson). Along with Marshall, SSL spearheaded the 1985 Experimental Assembly of Structures in Extravehicular Activities (EASE) experiment, which studied astronaut proficiency in assembling structures during spacewalks, as well as possible building and maintenance techniques. The success of the EASE experiment boosted interest in telerobotic applications for construction in space. In 1990, SSL moved to the University of Maryland, College Park, where it built a Neutral Buoyancy Research Facility—a 50-foot-diameter, 25-foot-deep water tank—that became the site of one of the Space Telerobotics Program’s major projects: the Ranger Telerobotic Flight Experiment. \n                        \n                      \n                      \n                        \n                          \n                        \n                      \n                      Funded through what was then the Telerobotics Intercenter Working Group, part of the NASA Headquarters Office of Space Sciences (now the Science Mission Directorate), Ranger was SSL’s effort to produce a free-flying robot capable of assisting astronauts with tasks such as structural repairs, assembly, and on-orbit refueling. The lab developed a test robot for underwater operation—the Ranger Neutral Buoyancy Vehicle (NBV). \n                        \n                        “Ranger was designed to easily transition from water to space,” says Joe Graves, who as a master’s and later PhD candidate served as a lead engineer for Ranger NBV. “The robot was not necessarily designed to replace astronauts. We were trying to determine how a robot could be helpful to human operations.” \n                        \n                        Though Ranger NBV is no longer part of an official NASA program, Graves has moved on to a new project, one that leverages the telerobotics experience he developed from the Ranger program to help revolutionize an entirely different field: nutrition. \n                        \n                        Product Outcome\n                        \n                        In 2003, Graves founded Vitabot, an online nutrition company headquartered in Beltsville, Maryland, that uses some of the same robotics and computer science concepts that he developed for the Ranger NBV—in this case, to offer a product that helps customers determine and maintain their ideal diet. Graves hit on the idea when he noticed the disconnect between the vast amounts of nutritional data available to the public and how that data is actually used. He noted that the U.S. Department of Agriculture (USDA) offers complete breakdowns of what composes various foods—far beyond what is offered on food labels—and that the Institute of Medicine, a nonprofit division of the National Academies of Science, publishes reports that gather research from around the world to determine nutritional needs. \n                        \n                        “On one end, you have the USDA putting out exactly what’s in food, and on the other you have the Institute of Medicine putting out the nutrition you should have,” says Graves. The problem he saw was that the public had no convenient way to make use of this information. “If I could think of one field in which the data and the application of the data are so incredibly removed from each other, it would be nutrition,” he says. \n                        \n                      \n                      \n                        \n                        \n                          \n                        \n                        \n                          Vitabot uses robotics algorithms to help users take advantage of vast amounts of detailed nutritional data and develop balanced meal plans. \n                        \n                      \n                      Graves realized this challenge was similar to one he faced with the Ranger NBV. The robot has more than 20 computers controlling different joints, navigation systems, and thrusters, all requiring complex data to manipulate. “We had this enormously intricate system with all these equations to position the arms and all these controllers to manipulate the arm positions, but as the human operator, I don’t want to think about all that,” he says. “I just want to reach out and grab something.” For the Ranger NBV, the solution was to create intelligent software to mediate between the operator and the robotics data. Graves saw the same idea could work for nutrition.\n                        \n                        “Vitabot uses the exact same style of algorithms that we developed between the robot and the operator,” says Graves. The result is an easy-to-use online program that allows users to set health goals like desired weight and then plan balanced meals using a food database featuring tens of thousands of choices. Available through corporate wellness programs and health clubs, Vitabot centers around an interactive report card that grades how food choices measure up to users’ nutritional needs in a wide range of categories including calories, fat, electrolytes, minerals, and vitamins. Users can build complete menus of favorite foods that also match their nutritional needs, allowing them to make real, individually tailored use of the previously overwhelming quantities of available nutritional data. Vitabot’s algorithms guide the users’ choices to help them get complete nutritional balance. The resulting balanced menus are then shared through Vitabot’s Ultimate Mealplan Project, where other users can then modify and improve these menus, guided by Vitabot’s suggestions. “This creates a massive group experiment where individuals, guided by their own personal tastes and the requirements of the Institute of Medicine, are mapping out an enormous space of carefully balanced meal plans,” says Graves.\n                        \n                        Though the focus of Vitabot is on balanced nutrition and not weight loss, the latter is often a result of the former, Graves says. The company now counts the likes of HBO and Warner Bros. among its nearly 1,000 company clients and has experienced over 1,500-percent growth in the health club industry in the last year, with major chains like Gold’s Gym offering Vitabot to its members. Recently, the U.S. Air Force has started using Vitabot at several of its bases.\n                        \n                        Graves credits Vitabot’s unusual origins for much of its success; most nutritional planning systems do not come out of a space program, he says. \n                        \n                      “It’s a different paradigm that has created a different solution.”\n                      \n                      Vitabot® is a registered trademark of the Vitabot Network.\n                        The Ultimate Mealplan Project™ is a trademark of the Vitabot Network.\n                        HBO® is a registered trademark of Home Box Office Inc.\n                        Warner Bros.® is a registered trademark of Time Warner Inc.\n                      Gold’s Gym® is a registered trademark of Gold’s Gym International Inc.\n                      \n                      \n                        \n                        \n                          \n                          \n                          \n                          \n                        \n                      \n              "},{"href":"http://spinoff.nasa.gov/Spinoff2009/hm_5.html","text":" ‘Anti-Gravity’ Treadmills Speed Rehabilitation","image":"http://spinoff.nasa.gov/Spinoff2009/images/OriginatingTech-Option1.jpg","story":"\n  \n    \n      \n      \n      \n      \n    \n    Health and Medicine\n    \n    Originating Technology/NASA Contribution\n    \n    On Earth, gravity can cause a lot of stress to a person’s bones and muscles, whether the stress is caused by running a marathon or simply climbing a staircase. However, in space, the lack of gravity can also cause problems for astronauts’ bodies. NASA is seeking ways to combat these problems, and the solutions are finding application here on Earth.\n    \n  \n  \n    \n    \n      \n    \n    \n      In space, in order to prevent bone loss and muscle atrophy, astronauts exercise on treadmills equipped with a loading harness.\n    \n  \n  While he was studying the biomechanics of exercise, Ames Research Center scientist Robert Whalen proposed using differential air pressure in space to mimic the Earth’s gravity to prevent bone loss and muscle deterioration. As a National Research Council post-doctoral Fellow at Ames from 1988 to 1989, Whalen helped develop effective exercise regimens for NASA’s astronauts, and when Whalen’s fellowship ended, NASA hired Whalen to a full-time research position.\n      \n    In his research, Whalen developed the hypothesis that musculoskeletal maintenance in space requires Earth-equivalent functional loading (or weighting), which is loading bones and muscles with activities and force levels in space similar to daily activity on Earth. In space, most bone loss and muscle atrophy occur in the lower body. Whalen explains, “On Earth, our most significant musculoskeletal loading―particularly of the lower body―occurs during normal upright activities, such as standing, walking, and stepping off a curb.” These various activities impart different levels of musculoskeletal loading, which keep our leg muscles able to support our weight. \n    \n    Astronauts do not have these types of functional activities in space and must replace them with treadmill exercise using a loading harness to hold the astronaut in place on the treadmill. However, the treadmill loading harness is uncomfortable and prevents astronauts from exercising normally and with the same intensity as on Earth. Whalen suggested using air pressure as an effective way of applying a high force, equal to body weight, to astronauts during treadmill exercise to replace the harness system. \n    \n    Partnership\n    \n    After patenting his gravity differential technology in 1992, Whalen licensed his patent in 2005 to a private company to help rehabilitate patients needing support as they learned (or re-learned) to stand, walk, and run. Based in Menlo Park, California, Alter-G Inc. adapted the technology for athletic and medical uses here on Earth in the form of a specialized treadmill called the G-Trainer. This rehabilitation device applies air pressure to a patient’s lower body in order to unload weight, which reduces the stress placed on the lower body during rehabilitation. \n    \n    Whalen explains the G-Trainer evolved directly from his original idea of using air pressure for the opposite effect—to add weight to an astronaut’s body during treadmill exercise in the low gravity of space. A variety of patients—whether suffering from brain injury, neurological disorders, athletic injuries, or other stresses on the joints such as arthritis or morbid obesity—now use the NASA-derived technology in physical therapy. \n    \n    Product Outcome\n    \n    Lars Barfod, Alter-G’s president and CEO, says that rehabilitation clinics are a major market for the G-Trainer, and he notes that the G-Trainer has been a successful option in military hospitals for orthopedic and neurological uses, including helping patients rehabilitate after traumatic brain injury to transition from ambulatory assistive devices to independent movement. Someone who is recovering from a brain injury can re-learn proper balance and gait while getting as much physical support from the G-Trainer as needed.\n    \n    According to Barfod, another market for the G-Trainer is professional athletic teams and athletic departments at universities, which use the G-Trainer to help athletes recover from stress injuries. Many teams in the National Basketball Association (NBA), the National Football League (NFL), and the National Collegiate Athletic Association (NCAA) have G-Trainers. \n    \n  \n  \n    \n    \n      \n    \n    \n      After the patient’s lower body is sealed in an airtight enclosure, the system performs a calibration, adjusting to the person’s size and weight. If a patient desires more unloading—more weightlessness—a button is simply pressed on a touch screen, and the air pressure increases, lifting the body, reducing strain, and further minimizing impact on the legs.\n    \n  \n  Whatever the cause of an injury, rehabilitation can be painful, and patients often alter their gait, stride length, or body position to over-compensate for the pain. The G-Trainer reduces the effect of gravity and weight, which makes it more comfortable for a patient to focus on a normal, correct gait instead of worrying about more injury and pain. This allows patients to develop good habits and condition their muscles while their bodies are still healing. The G-Trainer is comfortable like water training, but offers more realistic support of the lower limbs in their free-swing phase, allowing the legs to swing more normally than they would in water. Precision is another advantage the G-Trainer offers over water rehabilitation.\n      \n    The ability to change the amount of patient support precisely and incrementally is a major advantage the G-Trainer offers over other rehabilitation devices and methods, such as harness systems and water training. Like an ordinary treadmill, the G-Trainer stores information and allows for incremental adjustments to the workout, such as increasing incline or speed. It also allows for incremental adjustment to the air pressure, which controls the amount of weight lifted from the patient. Depending on what users specify, the air pressure system can reduce body weight in 1-percent increments—useful to fine-tune treatment with improvement—to as much as an 80-percent reduction, for instance, for a patient who weighs 160 pounds but can only support 32 pounds \n    of weight. \n    \n    The comfort of the G-Trainer is an improvement over harness systems, Barfod explains, because the support remains constant, even when the system is supporting a high percentage of weight or a patient weighing several hundred pounds. Conversely, harness systems chafe and can become uncomfortable quickly, especially if a patient is obese or needs a larger percentage of weight lifted. In a harness system, there is typically no reliable, precise method to change or record the amount of weight on a weak or injured limb and no digital readout to keep patient and trainer informed.\n    \n    In order for the G-Trainer to control air pressure effectively, users first have to don specifically designed shorts, which attach to a waist-level enclosure. This enclosure—in essence a large airtight bag that surrounds the patient’s lower body and the running platform—attaches to the treadmill system. After the patient’s lower body is sealed in the enclosure, the system performs a calibration, adjusting to the person’s size and weight. Then, the patient chooses a running speed, incline amount, and decides what percent weight should be removed. If a patient desires more unloading—more weightlessness—a button is simply pressed on a touch screen, and the air pressure increases, lifting the body, reducing strain, and further minimizing impact on \n    the legs. \n    \n    After the U.S. Food and Drug Administration (FDA) cleared the G-Trainer for medical use in January 2008, studies at major hospitals and universities began to assess G-Trainer’s effectiveness for patients with cardiovascular complications, lower-limb arthritis, ankle fractures, and mobility issues associated with Parkinson’s disease. Alter-G is also considering developing the G-Trainer for other patients, including children with cerebral palsy or other disorders that interfere with the ability to walk. \n    \n    Meanwhile, the company is working hard on making the product more affordable. “By doing that, we think the G-Trainer will become a standard of care in rehabilitation,” Barfod says.\n    \n    \n  \n  G-Trainer™ is a trademark of Alter-G Inc.\n    \n    \n    \n    \n      \n      \n      \n      \n      \n  \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/hm_6.html","text":"Crew Management Processes Revitalize Patient Care","image":"http://spinoff.nasa.gov/Spinoff2009/images/Flight-Simulator.jpg","story":"\n  \n    \n      \n      \n      \n      \n    \n    Health and Medicine\n    \n    Originating Technology/NASA Contribution\n    \n    In January 2009, birds struck the engines of US Airways Flight 1549 and forced an emergency landing into the Hudson River. Everyone on board survived, and the crew was lauded for remaining calm under pressure and keeping passengers safe. The pilot, Captain Chesley Sullenberger, is a former U.S. Air Force pilot, trained in Crew (or cockpit) Resource Management (CRM) which originated at NASA in 1979. Even before they knew they had an emergency, the crew was using specific training for safe and effective operations: all parts of key NASA CRM methods required by US Airways since 1995. \n    \n  \n  \n    \n    \n      \n    \n    \n      Astronauts and pilots receive line oriented flight training (LOFT) in simulators, such as the one shown here. LOFT prepares crews for both routine and hazardous situations through highly realistic simulations. \n    \n  \n  In June 1979, John Lauber in the Aviation Safety Research office at Ames Research Center chaired a workshop that presented formal studies and discussions on human error in aviation. The workshop, Resource Management on the Flight Deck, presented research from over a dozen commercial and military pilots, university researchers, as well as Ames employee Hugh Patrick “H.P.” Ruffell Smith, whose data showed human error was the primary cause of aviation accidents. \n      \n    Lauber and Ruffell Smith suggested that these human errors were caused by failures on a variety of levels: interpersonal communications, inadequate leadership, failure to prioritize and delegate, preoccupations with minor mechanical problems, and lack of situational awareness, which is the ability to recognize warning signs and anticipate potential danger. Another problem the researchers discovered was a failure to use available resources, including maps, navigation equipment, or others’ expertise.\n    \n    Initially referred to as simply Resource Management, the proposed solutions evolved into CRM, a series of management techniques geared at reducing human error and improving safety through effective coordination of all resources. These skills, which can be improved through mock situations and simulations, include effective teamwork, meaningful communication, task coordination through checklists, and situational awareness. \n    \n    In order to keep workflows predictable and as error-free as possible, CRM advocates using simple checklists to coordinate both tasks and communications among crewmembers. Without clear, predictable steps, disasters have occurred when captains assumed co-pilots had handled a seemingly minor problem, such as a malfunctioning light on an instrument panel. With CRM, crewmembers are taught to make no assumptions, but to follow printed checklists, communicate clearly, and maintain constant awareness.\n    \n    In CRM, everyone learns to articulate a discrepancy between what is happening and what should be happening—a moment in which one’s training in situational awareness becomes critical. Untrained operators may not notice this discrepancy, or may ignore it, which can lead to a serious situation, mistake, or fatality. CRM techniques include clearly expressing concerns and problems, after which everyone commits to a solution. While this may sound like common sense, the 1979 research showed that subordinates regularly hesitated to correct their supervisors out of a traditional—but sometimes dangerous—respect for authority. \n    \n    Ruffell Smith also suggested a CRM-related program now known as Line Oriented Flight Training (LOFT), in which crews fly complete, realistic missions in simulators. In debriefings after the simulations, crew and instructors discuss, in detail, what areas need more training.\n    \n    The Federal Aviation Administration (FAA), the military, several commercial airlines, and of course NASA, use NASA’s CRM and LOFT to prepare flight crews—like that of US Airways Flight 1549—for both routine and hazardous situations. \n    \n    Partnership\n    \n    Cardiologist Drew Gaffney flew as a payload specialist in 1991 on STS-40, the first Spacelab mission dedicated to biomedical studies. On the mission, he worked with fellow physician and astronaut Rhea Seddon. Seddon became an astronaut in August 1979 and ultimately spent 722 hours in space, acting as a mission specialist on STS-51D (1985) and STS-40, and then as payload commander on STS-58 (1993). NASA prepared Seddon and Gaffney for both routine and emergency situations in their missions through extensive CRM skill training and LOFT simulations. In 2005, Seddon and Gaffney collaborated with two former FedEx Corporation CRM trainers and U.S. Navy top gun pilots, Steve Harden and Alan Mullen, to found LifeWings Partners LLC, based in Memphis. The LifeWings founders had realized the medical industry was a natural fit for NASA’s CRM and could benefit from techniques that helped crews function in stressful, fast-paced environments.\n    \n    Product Outcome\n    \n    Situational awareness, peer monitoring, simulation training, and procedural checklists have long been a part of NASA’s astronaut training, and the LifeWings partners discovered the need for these same tools in medicine. In medicine like with space missions, Gaffney explains, “There was a lot of routine, but a lot of stress. Decisions were high-consequence.” As a result, LifeWings designed an approach to help hospitals use the same cockpit training and tools that had been so useful in making commercial aviation safe and reliable. LifeWings provides customized, in-depth CRM training to health care teams, which begins with onsite evaluations and focus groups, progresses with customized realistic simulations and extensive training in CRM techniques, and concludes with team assessments and interviews.\n    \n  \n  \n    \n    \n      \n    \n    \n      Rhea Seddon became an astronaut in August 1979 and ultimately spent 722 hours in space, acting as a mission specialist on STS-51D (1985) and STS-40 (1991), and then as payload commander on STS-58 (1993). In this image, Seddon performs cardiovascular experiments as part of the biomedical studies on STS-40’s Spacelab mission.\n    \n  \n  One skill that LifeWings stresses in its training is situational awareness. Doctors, nurses, and other hospital staff learn to notice subtle changes in their surroundings and to check in regularly with teammates. Gaffney explains that the LifeWings CRM training helps “create a culture that is psychologically and administratively safe,” so that any employee can spot and report potential hazards without fear. Everyone shares responsibility for patient safety, and having team accountability works far more effectively than individual accountability alone. \n      \n    This ongoing peer monitoring helps eliminate costly (and sometimes dangerous) medical mistakes, such as duplicating the administration of a drug, because everyone is aware of what a teammate is (or is not) doing. Gaffney says, “Because of their CRM training, if there is any confusion, everyone is expected to speak up and raise a concern,” intervening with clearly stated questions or observations. Using good CRM, another teammate or the team leader acknowledges the question and responds; the added information and teamwork protect the patient from avoidable errors. Eventually, this cycle becomes routine and part of the culture, resulting in significant reduction in medical errors. \n    \n  \n  \n    \n      \n    \n  \n  LifeWings uses simulations to evaluate new clients and see how their health care teams respond to different stressful situations, such as staff or room shortages, procedural bottlenecks, and various patient emergencies. These simulations help LifeWings identify focus areas for training or re-training, enabling the company to improve efficiency in both emergencies and routine procedures, such as getting a patient’s results from a hospital laboratory or reducing waiting times. Health care teams, like astronaut crews, benefit from rehearsing responses to realistic situations, and after being trained in CRM, the crews are better able to follow proper procedures, regardless of the situation. \n      \n    Research published in January 2009 in The New England Journal of Medicine describes how doctors using a simple checklist before surgery were able to reduce post-surgical deaths by more than 36 percent. According to LifeWings president Steve Harden, when hospitals follow the LifeWings CRM training, they have seen major improvements, such as in risk-adjusted patient mortality. Harden explains, “We’ve seen decreases from 1.2 to 0.68,” in observed to expected deaths, indicating an almost 50-percent improvement.\n    \n    Focus group interviews performed by LifeWings indicated medical staff felt, after CRM training, they had better teamwork, less waste, greater efficiency, and better overall patient outcomes. The LifeWings data showed 51-percent improvement in operating room turnaround, 40-percent decrease in post-operative infections, and vast improvements in team members’ willingness to speak out about possible problems and advocate for patient safety. Hospital administrators also note that the LifeWings CRM training seems to improve employee satisfaction, reduce patient stays and time in routine procedures, and reduce employee turnover.\n    \n    In its first operating year of 2005, LifeWings had sales of close to $500,000. Since 2007, sales have remained close to $3 million, despite a struggling U.S. economy. Since 2005, LifeWings has brought its CRM training to over 90 health care organizations.\n    \n    \n    LifeWingsSM is a service mark of LifeWings Partners LLC.\n    \n    \n    \n    \n      \n      \n      \n      \n    \n  \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/hm_7.html","text":"Hubble Systems Optimize Busy Hospital Schedules","image":"http://spinoff.nasa.gov/Spinoff2009/images/STS125-HSTRepair.jpg","story":"\n  \n    \n      \n      \n      \n      \n    \n    Health and Medicine\n    \n    Originating Technology/NASA Contribution \n    \n  \n  \n    \n    \n      \n    \n    \n      A team of engineers at the Space Telescope Science Institute developed software to manage time-consuming tasks for the Hubble Space Telescope, launched in 1990 and shown here during its last servicing mission in May 2009. The scheduling technology is now used in software that helps hospitals reclaim unused capacity.\n    \n  \n  Beginning in 1985, a team of engineers at the Space Telescope Science Institute in Baltimore began developing software to manage various time-consuming tasks for the Hubble Space Telescope, launched in 1990. In the early phases of development, the complexity of scheduling different tasks became clear when the engineers realized Hubble’s power restrictions. \n      \n    When it first became operational, Hubble functioned under a variety of scheduling restraints. For example, in order to conserve energy, it could have only two scientific instruments operating at one time. This was further complicated by the length of time it took to move the instruments into position. Changing Hubble’s orientation to a new target, or slewing, was a slow process, moving only 90 degrees per hour. Likewise, the instruments themselves could take up to 24 hours to shift from standby to operative modes. Further complicating the schedule was the fact that certain tasks only operated during specific times, needing protection from (or exposure to) direct sunlight, or requiring specific angles, locations, or other conditions. \n    \n    In order to compensate for these scheduling constraints, Hubble’s software team designed a knowledge-based system that worked around these scheduling conflicts using a variety of methods, such as backward and forward chaining—“If X is a near-infrared spectrometer, then X operates only when facing away from the Sun”—logical arguments used to design computer systems and software.\n    \n    Partnership\n    \n    One of the team members who worked on Hubble, NASA computer scientist Don Rosenthal, helped develop the scheduling system, refining the algorithms in the programming and consequently increasing the telescope’s efficiency. After working on Hubble, Rosenthal acquired intellectual property rights to the scheduling technology. He then ran the artificial intelligence application group at Ames Research Center, where he developed programming for the Mars Exploration Rovers, the Pioneer spacecraft, and a system for human space flight. \n    \n    Rosenthal went on to co-found Menlo Park, California’s Allocade Inc. in 2004, and is now chief technical officer of the company and chair of the board of directors. Using Rosenthal’s experience with Hubble’s software, Allocade created its On-Cue software suite, which optimizes ever-changing hospital schedules. \n    \n    Product Outcome\n    \n    On-Cue is a software solution that enables hospitals to reclaim their unused capacity. The system helps hospital departments handle dynamic rescheduling issues by allocating resources and managing disruptions in real time for inpatient and outpatient imaging procedures. In the past, staff made these time-consuming adjustments through numerous phone calls, whiteboards, handwritten notes, and faxes, which caused delays and frustration for both patients and staff. \n    \n    By automating the rescheduling process, Allocade helps hospitals manage frequent changes more efficiently, which can reduce operating costs and wait times. The emergency, transport, and radiology departments have immediate access to the latest schedules, and the system alerts staff to pending tasks with instant messages and other visual cues. When there is an unexpected flood of emergency procedures, for instance, the system can reallocate staff and resources, telling a transport member to keep a scheduled patient comfortable in her room until later, and freeing up transport for unexpected emergent cases.\n    \n    In order to reschedule radiology procedures, On-Cue pulls data from and synchronizes with a facility’s radiology information, picture archiving, and communication systems. It can then direct patient data to the best resource, automatically rescheduling procedures and having information readily available for use and analysis. The system displays live updates on monitors in high-traffic areas, which allows staff to track patient status and procedures quickly. On-Cue, which is compatible with standard personal computers and existing intranets, also provides the ability to balance loads between different machines, and makes specific recommen­dations when rescheduling, taking into consideration various department and hospital policies and constraints. As a result, hospitals can manage staff and patient flow far more efficiently, which increases satisfaction and profit.\n    \n  \n  \n    \n    \n      \n    \n    \n      On-Cue helps hospital departments handle dynamic rescheduling issues by allocating resources and managing disruptions in real time for inpatient and outpatient imaging procedures. By automating the rescheduling process, the software can reduce operating costs and wait times.\n        \n        Image courtesy of Allocade Inc.\n    \n  \n  Allocade offers the On-Cue system in three modules: the On-Cue Navigator Optimization Engine, On-Cue Communicator, and On-Cue Aviator Workstation Software Client. As the core technology in the On-Cue solution, Navigator is the optimizer that adjusts to new schedules as needs arise. Communicator, meanwhile, is in charge of collecting and displaying information to clinical areas and updating displays in real time, enabling staff to make decisions on patient care efficiently. Aviator tracks all resources, connecting information from the other two modules in a snapshot view. Allocade can also adjust the On-Cue system to specific workflow preferences and can pull data from existing feeds. \n      \n    One of the first customers for Allocade’s system was the California Pacific Medical Center (CPMC) in San Francisco. Prior to adopting the On-Cue software, CPMC had 2 weeks of backlog in its computerized tomography (CT) department. Schedules changed constantly, and staff began to realize that traditional tracking methods simply wasted too much time. The radiology department was thrown into chaos when the inevitable emergency procedures would take precedence over scheduled procedures, and other departments had no way of efficiently tracking changes to their patients’ visits to radiology.\n    \n    CPMC adopted the On-Cue software for beta testing in 2006. The medical center soon reported noticeable improvements to efficiency, including a 12-percent increase in procedure volume, 35-percent reduction in staff overtime, and significant reductions in backlog and technician phone time. Allocade began shipping the full commercial version of On-Cue for CT departments in January 2008, and now offers versions for both outpatient and inpatient magnetic resonance imaging (MRI), ultrasound, interventional radiology, nuclear medicine, positron emission tomography (PET), radiography, radiography-fluoroscopy, and mammography. Customers can buy the software for just a few departments or as a software suite for an entire radiology department. \n    \n    In 2009, Pennsylvania’s Harrisburg Hospital became the first medical center on the East Coast to adopt On-Cue.\n    \n    On-Cue™ is a trademark of Allocade Inc.\n    \n    \n    \n    \n      \n      \n      \n      \n    \n  \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/hm_8.html","text":"Web-Based Programs Assess Cognitive Fitness ","image":"http://spinoff.nasa.gov/Spinoff2009/images/Criteria_1.jpg","story":"\n\n  \n    \n    \n    \n    \n  \n  Health and Medicine\n  \n\n\n  \n  \n    \n  \n  \n    The MiniCog Rapid Assessment Battery (MRAB) measures the ability to sustain attention and vigilance, as well as the ability to divide one’s attention. A test subject’s aptitude in these areas correlates with fitness to perform attention-demanding tasks.\n  \n\nOriginating Technology/NASA Contribution\n    \n  Astronauts, pilots, air traffic controllers, truck drivers, shift workers, and mountain climbers have something in common: All are at risk for impaired cognitive abilities due to stress or sleep deprivation. Whether in space or on Earth, stress and sleep loss can cause a reduction in certain cognitive abilities, such as working memory, reaction time, and problem solving. Because mission safety and success depend on being able to think clearly and function well, NASA began exploring a small, portable way for astronauts to monitor themselves and their cognitive fitness while in space, especially on future missions to Mars that will require extended periods in stressful environments. \n  \n  Partnership\n  \n  The National Space Biomedical Research Institute (NSBRI), based in Houston and funded by NASA, leads a science and technology program to develop solutions to the health-related problems and physical and psychological challenges men and women face on long-duration space flights. The research results and medical technologies developed often have impact for conditions experienced on Earth.\n  \n  In 2001, the NSBRI began funding research by Harvard University researcher, Dr. Stephen Kosslyn, now dean of social sciences, and research assistant, Jennifer Shephard. The project included the development of cognitive task scripting and administration software for personal digital assistants (PDAs) and an accompanying set of portable cognitive fitness tests, the MiniCog Rapid Assessment Battery (MRAB).\n  \n  The test battery, which Kosslyn refers to as “a blood-pressure cuff for the mind,” assesses nine different cognitive functions and is intended to gauge the effects of stress-related deficits, such as fatigue, on astronauts as well as professionals on Earth. The original hand-held MRAB enabled someone to test his or her own alertness quickly and easily; depending on the assessment, users might realize they should take a nap or drink coffee instead of proceeding with any sort of risky or complex activity. In 2003 and 2004, in collaboration with the NSBRI, Mount Everest climbers self-administered the MRAB on Palm PDAs to test themselves for cognitive deficits in the oxygen-poor higher altitudes.\n  \n\n\n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    The MRAB consists of nine short Web-based exercises that measure a person’s information-processing functions. Subtests measure the subject’s ability to focus while ignoring irrelevant information. The tests also measure working memory, mental rotation, verbal reasoning, and perceptual reaction time.\n  \n\nHarvard owns the software copyright, and a patent is pending. Although NSBRI funding ended for the MRAB in 2007, a California company now is using the battery in Web-based employment tests. In 2005, Drs. Josh Millet, Eric Loken, and David Sherman founded Criteria Corporation, based in Los Angeles. Now the company’s chief research scientist, Loken knew of Kosslyn’s research from his own experiences at Harvard and recommended the MRAB to Millet, a fellow Harvard graduate and Criteria’s CEO. After hearing about the MRAB, Criteria decided to license it from Harvard and adapted a Web-based version of it for delivery in 2006. \n    \n    Product Outcome\n    \n  Criteria offers subscription-based employment testing, and the MRAB is included in the company’s HireSelect subscription service along with about 15 other tests. The MRAB can be used not only for pre-employment testing but also for repeated administrations to measure day-to-day fluctuations of mental functioning. Unlike other aptitude tests, such as traditional college assessment exams, the MRAB focuses less on verbal skills and more on working memory, concentration, and problem-solving; testing involves tasks such as recognizing patterns within time limits and reacting accurately to information while attention is divided.\n  \n  The MRAB consists of nine short Web-based exercises that measure a person’s information-processing functions. It takes about 25 minutes to complete, and users are instructed that final scores will be based on both speed and accuracy. Subtests measure the subject’s ability to focus while ignoring irrelevant information: Users are required, for instance, to rapidly indicate the number of digits in “6666” by pressing “4” rather than “6,” the numeral that is actually repeating. Other subtests measure working memory, functioning similarly to the game Concentration, quizzing the user on where or when a numeral appeared on the screen. Mental rotation, the ability to identify whether shapes are flipped versus merely rotated, is a problem-solving skill that MRAB tests, as is verbal reasoning, assessed by asking users whether a series of statements are logically connected. Perceptual reaction time is a subtest that requires a user to press keys corresponding to red-flashing numerals as quickly as possible. The MRAB also measures the ability to sustain attention and vigilance, as well as the converse ability to divide one’s attention. \n  \n  A test subject’s aptitude in these areas correlates, Millet says, with fitness to perform attention-demanding tasks. “The MRAB is based on neuroscientific research that focuses on understanding the brain as an information processing unit. Because the MRAB measures mental fitness, attention, and concentration, it’s gotten significant traction in the transportation and logistics industries as a tool to help select drivers,” he says. It can also be used after a candidate is hired; truck drivers or pilots can self-test their alertness before beginning long trips. Millet, however, sees the potential for wider applicability in other industries: “For example, things like divided attention, focus, and concentration would be very helpful in someone who is screening bags and doing surveillance at the airport.” \n  \n  Although Kosslyn and the Harvard team have no current plans for pursuing additional development of the MRAB, Millet says Criteria probably will investigate additional applications for the software with Kosslyn’s advice on product direction and development as a member of the company’s scientific advisory board. “We certainly have a number of validity studies in progress to explore new applications of the MRAB, specifically with respect to job performance,” Millet says.\n  \n  Palm® is a registered trademark of Palm Inc. \n  HireSelect® is a registered trademark of Criteria Corporation.                      \n  \n  \n  \n  \n    \n    \n    \n    \n  \n\n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/hm_9.html","text":"Electrolyte Concentrates Treat Dehydration","image":"http://spinoff.nasa.gov/Spinoff2009/images/Wellness-Brands_1.jpg","story":"\n  \n    \n      \n      \n      \n      \n    \n    Health and Medicine\n    \n    Originating Technology/NASA Contribution \n    \n    For astronauts returning to Earth, adjusting to full gravity can be just as demanding as any of the challenges they faced in space. While readjusting to Earth’s gravitational pull, astronauts can experience difficulties moving and balancing, headaches, nausea, and even fainting spells. \n    \n  \n  \n    \n    \n      \n    \n    \n      Vigorous exercise while in space is one measure astronauts can take, along with hydration efforts, to help mitigate difficulties adjusting to Earth’s gravity upon return from long-term missions. \n    \n  \n  While the exact reasons for this latter effect are still unknown, the tendency for astronauts to experience orthostatic intolerance—dizziness, lightheadedness, and fainting among other symptoms—arises from the effects of microgravity on the body’s circulatory and balance systems. On Earth, gravity pulls the body’s blood and other fluids toward the feet, creating higher blood pressure in the feet than in the brain or around the heart. In space, however, the lack of gravity results in greater than normal amounts of fluid shifting to the upper body and head. One outcome is that the body mistakenly thinks there are excess fluids that need eliminating; as a result, astronaut blood plasma levels can decrease by about 12 percent in space, and their total body water drops \n    \n    2–3 percent. (Under normal conditions, about two-thirds of the body’s water is contained inside cells, while the rest is found outside of cells; much of this latter amount is blood plasma.) Astronauts thus return to Earth in a state of dehydration and low blood volume—one possible factor leading to the orthostatic intolerance that troubles as many as 80 percent of astronauts following long-term space missions.\n    \n    To help address this concern, astronauts traditionally tried to rehydrate before and after landing by taking salt tablets with water. (Sodium helps regulate extracellular fluid volume.) This method, though, proved inconvenient and unpleasant for the astronauts, as well as impractical in space where water supplies are limited. The high levels of sodium in the tablets could even lead to greater dehydration if not managed carefully.\n    \n    After years of extensive Agency research and testing, Ames Research Center physiologist Dr. John Greenleaf developed and patented a better alternative: an electrolyte concentrate composed of a specific ratio of sodium chloride and sodium citrate. The isotonic formula, containing optimal proportions of water and salts for absorption into the body, provides for fast, easy, and effective rehydration in amounts practical for use in space. Astronauts currently use the patented formula on missions. \n    \n    “We developed this product to perform optimally under the most extreme conditions. The health of our highly trained astronauts was paramount,” says Greenleaf, now retired from NASA. “With all that Americans and the Government have invested in the Space Program and our astronauts, this is one clear way to protect and maximize that investment.” The value of Greenleaf’s electrolyte formula is not limited to countering the effects of microgravity, however. Thanks to a NASA partnership, he says, the public will now benefit from this research. \n    \n    Partnership\n    \n    In early 2009, Boulder, Colorado-based Wellness Brands Inc. exclusively licensed the concentrated electrolyte formula from Ames. David Belaga, the company’s president and CEO with more than 15 years of experience in licensing and technology transfer, built the startup Wellness Brands around the NASA innovation after discovering the licensing opportunity while researching the Agency’s patent databases. The electrolyte formula fit Belaga’s interest in a NASA technology with consumer market applications, and his familiarity with the endurance athletes attracted to Colorado’s high-altitude conditions for training made the partnership an “immediately intriguing opportunity.” \n    \n    “As is typical, NASA put their scientists on developing a superior technology, in this case to relieve and prevent the ravages of dehydration,” Belaga says. “NASA spent about 15 years working through various combinations to get to the optimal formula.”\n    \n    Product Outcome\n    \n    That formula is now available to the public as the liquid electrolyte concentrate called The Right Stuff. Packaged in single-serving, 16.5 milliliter recyclable plastic vials, the Wellness Brands concentrate contains the original sodium chloride and sodium citrate blend, along with a small amount of sucralose sweetener and citric acid to counter the saltiness of the electrolytes. Available in citrus blend, wild berry, or unflavored varieties, The Right Stuff is added to water or any training beverage to significantly enhance rehydration. \n    \n  \n  \n    \n    \n      \n    \n    \n      A NASA-developed and tested electrolyte concentrate formula, The Right Stuff has been demonstrated to boost athlete endurance.\n    \n  \n  The effectiveness of The Right Stuff is backed by extensive NASA testing, says Belaga. “Every human has receptors throughout the body, both intracellular and extracellular, that ensure the balance of hydration in the body,” he explains. Whether you are an astronaut returning to Earth, an Olympian, or in training for your first marathon, human physiology and its needs and challenges remain the same, he says. Dehydration can cause tiredness, headaches, muscle cramps, decreased blood pressure, dizziness, and fainting. Severe dehydration can lead to delirium, unconsciousness, and even death. Athletes training for long periods or in hot conditions must constantly resupply the water they lose through sweating and breathing, and Belaga notes that rigorous NASA testing has shown that the electrolyte formula of The Right Stuff is ideal for meeting this need. \n      \n    “NASA scientists compared this formula to water, to carbohydrate-based sports drinks, to hybrid drinks with extra sugars and glycogens, and this product beat them all,” Belaga says. The researchers determined that the quantities of carbohydrates found in most common sports drinks may actually impede the body’s ability to absorb the rehydrating electrolytes. The Right Stuff contains no carbohydrates, caffeine, or sugar, and Belaga cites one study that demonstrated the product not only effectively rehydrated users, but it also led to a 20-percent increase in endurance.\n    \n    “More endurance means superior performance,” Belaga says.\n    \n    Wellness Brands is in discussions with college and professional sports teams and will start stocking specialty sporting goods retailers with The Right Stuff this year. The company is targeting elite athletes and endurance sport enthusiasts as its initial consumers, but notes that its NASA-developed formula is the “right stuff” for everyone. \n    \n    “Since it works so well for astronauts, imagine what it will do for elite athletes,” says Belaga. “If it works for the elite athletes, imagine what it could do for the average person.”\n    \n    Not only athletes will benefit from the electrolyte formula. Under the exclusive NASA license, Wellness Brands plans to expand with other products for situations when proper hydration is critical. Dehydration, for example, is a problem for airline passengers on long-distance flights during which water is lost in the dry air of the pressurized airplane cabins. Dehydration is also a factor in jet lag and altitude sickness, and can be a deadly outcome of various diseases that cause diarrhea and vomiting, such as cholera, and conditions like heat stroke. \n    \n    The formula’s NASA origins position The Right Stuff to make an immediate market impact and start providing its benefits to the public, says Belaga. \n    \n    “It’s a great asset to have this technology come out of NASA,” he says. “Its credibility with the American populace is almost incalculable.”\n    \n    The Right Stuff™ is a trademark of Wellness Brands Inc.\n    \n    \n    \n    \n      \n      \n      \n      \n    \n  \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/t_1.html","text":"Tools Lighten Designs, Maintain Structural Integrity","image":"http://spinoff.nasa.gov/Spinoff2009/images/HyperSizer.jpg","story":"\n            \n                      Transportation\n                      \n                      Originating Technology/NASA Contribution\n                      \nWhile working on designs for a new high-speed aircraft, a group of software engineers at NASA’s Langley Research Center developed a program that helps create lighter weight vehicles, while still maintaining strength and structural integrity. Part of the National Aerospace Plane project, the software was necessary to allow designers to easily experiment with new materials and structures, trying a variety of different options for building what would have been the world’s fastest aircraft, the X-30—capable of taking off from an airport in Washington, DC, accelerating to over 20 times the speed of sound, and landing in Tokyo in under \n                      2 hours.\n                      \nIn an aircraft like the X-30, what President Ronald Reagan said could potentially be the next “Orient Express,” the benefits realized by weight reduction become critical, while the demands placed on the vehicle’s structure are greatly magnified. Weight reduction translates directly into fuel savings, increased payload, and greater flight range, but that kind of speed places an incredible strain on an aircraft.\n\nNamed “ST-SIZE” and developed over the course of several years from 1988 to 1995, the software NASA developed for solving this issue allowed for weight reduction through optimizing use of composite materials—helping designers quickly and easily experiment with the full range of effects that individual parts composed of varied and nontraditional materials would have on the vehicle. \n\nPartnership\n\nWhile the Agency had long been known for bringing its cutting-edge technologies to the public sector in the forms of commercial spinoffs, it was not until 1996 that NASA had ever licensed software to a private company. In that year, the National Aerospace Plane project came to an end, unrealized, but with many technologies ready to be applied to new missions and additional aerospace research. It was then that Langley’s Craig Collier licensed the ST-SIZE software he had helped develop for the X-30 and struck out on his own to bring the software to the broader market. \n\nAs Collier explains, the company founders knew “NASA would again need the capabilities, but in a commercially robust software package, so it made sense to step up the development for the purpose of making it better so that customers like NASA would want to use it.”\n\nThe company he formed, Collier Research Corporation, of Hampton, Virginia, wrote a more capable and robust code based on the ST-SIZE software and now markets it under the name HyperSizer. It has been used in everything from designing next-generation cargo containers, to airframes, rocket engines, ship hulls, and train bodies. Most recently, it was adopted by Bombardier Inc. for design and analysis of the new all-composite Learjet 85. With over 300 companies, projects, and divisions using the software and sales topping $4 million a year, the small software startup has been expanding rapidly in recent years.\n\nAs Collier originally intended, the technology has also taken a spin back into NASA, where it is now being used to analyze designs for NASA’s newest space vehicles. “In the beginning,” Collier says, “it was a scenario where we were taking NASA technology and applying it to industry, but we have been able to work with industry to understand new details and issues and then take these lessons learned from industry and build capabilities. NASA now benefits from these newfound capabilities in designing hardware and making components.” \n\nAfter years of modifications and updates through \n                      applying the software to work on high profile projects with Langley, Marshall Space Flight Center, Glenn Research Center, Ames Research Center, Lockheed Martin Corporation, Boeing, Gulfstream, Scaled Composites, Goodrich, Bombardier, and the Air Force Research Laboratory, the company received several \n                      Small Business Innovation Research (SBIR) contracts to apply HyperSizer to nearly all aspects of the new Orion crew exploration vehicle design. The company is now also fundamentally involved in the development of both the Ares I and Ares V launch vehicles. \n                      \nCollier cites the NASA-licensed technology as helping the company gain audience with new customers, but says that it is really the continued partnership with the Space Agency that has kept the company competitive. “Just the association has gotten the foot in the door,” he explains, “but that only goes so far. The other thing is to be able to demonstrate that it is good technology and to do that we have continued to stay in step with NASA’s technology. It keeps us on the cutting edge.”\n\nProduct Outcome\n\n            \n            \n  \n  \n    \n  \n  \n    HyperSizer is being used to help design the new Orion crew exploration vehicle composite crew module.\n  \n\n            The company has added features to the program, making it more user-friendly and adaptable to different projects. Now, aerospace industry designers and airframe stress analysts use HyperSizer for examining the structural integrity of new designs using both traditional metallic materials, such as aluminum and steel, and more advanced materials, such as composite laminates. \n                \n              HyperSizer software is not another computer-aided design or finite element analysis (FEA) program. It is an integration of aerospace structural design best practices with modern structural vehicle analysis software. The program integrates with the user’s current design software, allowing analyses of new configurations for weight, potential buckling of panels, crippling of posts, the durability of joints, and overall composite strength, including damage tolerance and temperature variables. Rather than being a new program, it is a complementary analysis software suite divided into three distinct products that share and build upon the same database. The three products, HyperSizer Material Manager, HyperSizer Basic, and HyperSizer Pro are available as a suite or can be used individually. One feature they all share, though, is that the software blends seamlessly with standard design software and uses a familiar Windows interface. \n  \n              The use of a Windows platform was one of the first risks the company took in developing HyperSizer. In the 1990s, when this product was first being developed, most design software was Unix-based and ran on very expensive workstations. Company founders made the early decision to write and code for the Windows platform, gambling correctly that the future was in the personal computing platform and widespread acceptance of Windows within the engineering community. Another gamble was investing in developing composite material technology early on, and that decision was similarly validated by the increasing acceptance of composite materials within the aerospace industry and the growing need for the NASA-derived software suite. \n  \n              The simplest of the three products, HyperSizer Material Manager, eases the design process by offering an easy-to-use materials database with interactive graphics depicting different metals, foams, honeycomb structures, ply tapes, and fabrics. The software allows users to create composite laminates from these various materials using standard Windows copy and paste functions. The software will then analyze the materials and structures using a variety of composite failure theories, as well as preliminary analysis for stiffness, thermal behavior, and structural strength. The software also creates graphs for display of variables with temperature dependencies, failure envelopes, and stress/strain profiles. \n  \n              HyperSizer Basic includes all of the features and capabilities of the Material Manager, but adds additional analysis for 50 different panel and beam concepts, as well as the ability to analyze other combinations of materials and structures. HyperSizer Pro includes all the features of HyperSizer Basic, but adds full vehicle design analysis. It works with FEA programs for system-level analysis and automatic finite element model resizing, and it generates stress report results for documenting complete vehicle structural design details.\n  \n              The software continues to mature, and its capabilities grow. When it was first developed at NASA, it was primarily employed for lightweight designs but was not considered a final design tool. It is now being used for final designs on larger projects. Companies are using HyperSizer to gain certification for flight readiness with the Federal Aviation Administration. Customers, including NASA, are placing a lot of trust in the answers it generates.\n  \n              HyperSizer Material Manager™, HyperSizer Basic™, and HyperSizer Pro™ are trademarks of Collier Research Corporation.\n              Windows® is a registered trademark of Microsoft Corporation. \n              Unix® is a registered trademark of The Open Group.\n  \n  \n  \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/t_2.html","text":"Insulating Foams Save Money, Increase Safety","image":"http://spinoff.nasa.gov/Spinoff2009/images/Invention_icon.jpg","story":"\n            \n                      Transportation\n                      \n                      Originating Technology/NASA Contribution\n                      \n                      Researchers at the Advanced Materials and Processing Branch at Langley Research Center created a superior polyimide foam as insulation for reusable cryogenic propellant tanks on the space shuttle. At the time, the foam insulation on the tanks had a limited lifetime: one launch, which did not suit NASA’s need for reusable launch systems. \n                      \n                      The foam on the shuttle’s external tanks needed to insulate the super-cooled liquid propellant, preventing ice from forming on the tanks and surrounding areas and posing catastrophic risk from debris during launch. The insulation also needed to be able to withstand the high temperatures that the tanks would experience during ignition and launch. The researchers named their new foam TEEK. \n                      \n                      A partnership with a small business in Florida improved the chemical structure of the NASA-developed foam, leading to a new product, FPF-44 with commercial applications in the boat-building business, as well as further applications within the Space Program. The partnership also earned NASA scientists, Roberto J. Cano, Brian J. Jensen, and Erik S. Weiser, as well as their industry counterpart, Juan Miguel Vazquez, the coveted designation of “NASA Commercial Invention of the Year.”\n                      \n                      Partnership\n                      \n                      A small Hialeah, Florida-based business, PolyuMAC Inc., was looking for advanced foams to use in the customized manufacturing of acoustical and thermal insulation. PolyuMAC is a state-of-the-art manufacturer of foams for use in the marine industry. One of the company’s customers had requested newer, advanced materials for use on U.S. Navy ships. The goal, then, was to find an advanced, insulating material—lighter weight, manufacturable in-house, easy to work with, increased insulating capabilities, and affordable. The hunt was on for better foam.\n                      \n                \n            \n                  \n                  \n                    \n                  \n                  \n                    Engineers at Langley Research Center developed insulating foam for the space shuttle’s external fuel tanks.\n                  \n                  \n                      During this search, Juan Miguel Vazquez, new product development lead as well as founder and president \n                      of PolyuMAC, came across information about the TEEK foam developed at Langley. Vazquez read about \n                      TEEK and contacted Langley for samples and technical data sheets.\n                      \n                      He reviewed the materials and began his own testing, investigating the foam’s properties. He determined, however, that TEEK was not the right density for his needed applications, and furthermore, producing the material in the large quantities he needed would have been cost-prohibitive. Rather than dismiss the endeavor altogether, though, he contacted the inventors and asked for help tweaking the TEEK chemistry to bring it more in line with his company’s needs. They agreed, and he licensed the foam from NASA to begin the modifications. After multiple visits between the company’s laboratory and the NASA field center, the researchers had made the foam lighter in weight and cheaper to produce. They named this new generation of foam FPF-44, and the patent is now held by the three Langley scientists and Vazquez. NASA tested FPF-44 at the White Sands Test Facility, a rocket test site in the dunes of New Mexico operated by the Johnson Space Center. There, scientists simulated launch facility conditions to test for ice mitigation on the liquid oxygen feedline on the space shuttle’s external fuel tank. The specific goal was to prove that FPF-44 was a viable option for addressing a chief safety concern—a gap between the liquid oxygen feedline and the external tank support brackets, which is exposed to cryogenic temperatures, allowing moisture to collect on the oxygen tank and turn to ice. During tanking, de-tanking, and launch, the feedline articulates, opening and closing the small gap. The insulation needed to be flexible to allow for the articulation of the exposed metal parts to prevent ice from forming. The Langley-PolyuMAC team thermal-formed the foam into the exact shape needed for that gap, with added flexibility to keep it in place and prevent damage when the feedline moved. The success of this test makes it a candidate for future shuttle applications and insulation on next-generation space vehicles. The NASA-PolyuMAC team is continuing to collaborate on the foam, trying to further reduce density while maintaining its insulating properties. Future applications could include the next generation of commercial aircraft. Commercial aircraft, which currently use fiberglass as an acoustic sound absorber, could perhaps benefit from the next-generation foam, since it has improved handle-ability while providing the same—if not improved—insulating qualities. The test will be if the scientists can lower the density of the foam enough to make it a compelling alternative and if they can develop manufacturing processes capable of accommodating the scale and quantity necessary to infiltrate the large commercial aircraft industry. \n                      \n                      Product Outcome \n                      \n                      \n                      \n                        \n                        \n                          \n                        \n                        \n                          The commercial Polyshield foam is flexible, flame-retardant, and provides excellent thermal and acoustical insulating properties.\n                        \n                      \n                      Commercial production of the joint NASA-PolyuMAC foam began in summer 2007, with the company marketing the foam under the trade name Polyshield. The commercialized version offers the same qualities as the NASA next-generation, high performance, flexible polyimide foam, and shows promise for use on watercraft, aircraft, spacecraft, electronics and electrical products, automobiles and automotive products, recreation equipment, and building and construction materials. \n                        \n                      Consumers appreciate its flame retardant qualities, thermal insulation and acoustic insulation factors, and the weight reduction it provides, but the chief advantage Polyshield has over the TEEK foam is that it is roughly one-fifth the cost to manufacture. The durable polyimide foam is formed at room temperature and then cured using large microwaves, which reduces costs and increases the company’s production rates. The finished product can be flexible or rigid, structural or non-structural, and is always highly durable. This affordable insulating foam can also be applied to gaskets and seals, vibration damping pads, spacers in adhesives and sealants, extenders, and flow-leveling aids. \n                      \n                      The products provide excellent insulation for sound, cryogenics, and heat, and can be used for fire protection. In fact, one of the chief advantages of this material is that, while it holds at very high temperatures, if it does burn, it will not produce smoke or harmful byproducts, a critical concern on boats, submarines, airplanes, and other contained environments. \n                      \n                      While the company has the capacity to thermal-form the material into any shape required by clients, it typically provides sheets of the foam to customers, who then cut and shape it as needed for their specific applications. The user can then cover it with various cloths. PolyuMAC will, on demand, make specially fitted shapes, and densities can be tailored according to the intended use.\n                      \n                      \n                      \n                      \n                      \n                        \n                        \n                        \n                        \n                      \n                      \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/t_3.html","text":"Polyimide Resins Resist Extreme Temperatures","image":"http://spinoff.nasa.gov/Spinoff2009/images/R-D_thumb.jpg","story":"\n             \n              Transportation\n              \n              Originating Technology/NASA Contribution\n              \n            \n            \n                  \n                  \n                    \n                    Dr. Ruth Pater of Langley Research Center developed RP-46, a polyimide resin capable of withstanding the high temperatures of aerospace applications.\n                  \n                  \n                      Spacecraft and aerospace engines share a common threat: high temperature. The temperatures experienced during atmospheric reentry can reach over \n                      2,000 °F, and the temperatures in rocket engines can reach well over 5,000 °F. \n                      \n                      To combat the high temperatures in aerospace applications, Dr. Ruth Pater of Langley Research Center developed RP-46, a polyimide resin capable of withstanding the most brutal temperatures. The composite material can push the service temperature to the limits of organic materials. \n                      \n                      Designed as an environmentally friendly alternative to other high-temperature resins, the RP-46 polyimide resin system was awarded a 1992 “R&D 100” award, named a “2001 NASA Technology of the Year,” and later, due to its success as a spinoff technology, “2004 NASA Commercial Invention of the Year.” The technology’s commercial success also led to its winning the Langley’s “Paul F. Holloway Technology Transfer Award” as well as “Richard T. Whitcom Aerospace Technology Transfer Award” both for 2004. RP-46 is relatively inexpensive and it can be readily processed for use as an adhesive, composite, resin molding, coating, foam, or film. Its composite materials can be used in temperatures ranging from minus 150 °F to 2,300 °F. No other organic materials are known to be capable of such wide range and extreme high-temperature applications.\n                      \n                      \n                      \n                        \n                        \n                          \n                        \n                        \n                          The temperatures in rocket engines can reach well over \n                          5,000 °F.\n                        \n                      \n                      In addition to answering the call for environmentally conscious high-temperature materials, RP-46 provides a slew of additional advantages: It is extremely lightweight (less than half the weight of aluminum), chemical and moisture resistant, strong, and flexible.\n                        \n                      Pater also developed a similar technology, RP-50, using many of the same methods she used with RP-46, and very similar in composition to RP-46 in terms of its thermal capacity and chemical construction, but it has different applications, as this material is a coating as opposed to a buildable composite. \n                      \n                      A NASA license for use of this material outside of the Space Agency as well as additional government-funded testing proved that RP-46 is even more exceptional than originally thought. \n                      \n                      Partnership\n                      \n                      Unitech LLC, of Hampton, Virginia, is an advanced materials solutions provider specializing in advanced materials technology, engineering, manufacturing, research and development, and prototyping services. In 2001, Unitech received a nonexclusive license from NASA for commercialization of the cost-effective, weight- and space-saving high-temperature material RP-46 and the RP-50 coating. \n                      \n                      Using the NASA-developed technology, Unitech applied for a Small Business Innovation Research (SBIR) contract with the U.S. Navy to develop insulation for an all-electric ship that was under consideration. One of the considerations the Navy had was the need for an extremely fire-resistant material. While initial NASA testing had proven that RP-46 could withstand temperatures in the range of 700 °F, the Navy was looking for a material that could withstand anywhere from 8,000 to 250,000 volts of electricity. Under this Navy SBIR, independent testing showed that RP-46 could withstand temperatures up to 2,300 °F. This discovery made it \n                      ideal for use in the original Navy application, but also opened up the possibility that the material could be used in future applications, like in high-voltage insulation for high-rise buildings, where great amounts of power run long distances. \n                      \n                      Product Outcome\n                      \n                      Unitech now commercially manufactures RP-46, the high-temperature polyimide resin matrix system, and RP-50, the high-temperature polyimide coating. In addition to the host of technical specifications that make RP-46 an incredible invention, one of the key features that makes RP-46 so appealing commercially is its versatility; the polyimide can be used as a molding, adhesive, coating, composite matrix resin, foam, or film. It is available as a liquid for prepreg of carbon, glass, or quartz fabric; or as a powder for compression molding. Although specifically designed for the Space Program, industry uses abound.\n                      \n                      \n                      \n                        \n                        \n                          \n                        \n                        \n                          Unitech LLC received a license from NASA for commercialization of the cost-effective, weight- and space-saving high-temperature material.\n                        \n                      \n                      The traditional use of RP-46 is to impregnate fibers (such as glass, carbon, Kevlar, etc.) with the resin to produce rolls of fabric that can then be cut and shaped. These pieces, which are then heat and pressure cured, can be used in a traditional lay-up to make a structural part. Users employ this method for creating any number of pieces, primarily for use in high-temperature aerospace applications. It can serve as a composite material for thermal skins on aircraft and spacecraft and sees many uses in aerospace engines and exhaust duct systems, where the material is prized for its light weight, durability, and temperature resistance. Similar applications include the high-speed motor sports industry, where the company has already seen interest from NASCAR, Formula One, and motorcycle racing groups. \n                                              \n                      Parts built from RP-46 are also finding use in rocket nose cones, where in addition to the light weight and temperature resistance, the dielectric, insulating properties are prized. Rocket nose cones often experience a great deal of heat while also carrying sensitive electronics. The nose cone of a missile, for example, may contain that weapon’s guidance system, so RP-46 would be able to provide the temperature resistance as well as be able to butt against the electronics without risk. \n                      \n                      RP-46 can also be used as a molding material. In this application, rather than using the prepregged fabrics, a customer would receive a powder form of the resin and then, depending on the intended use, employ various additives and fillers to create the desired composition. The material comes heated and staged but not completely cured. Once the customer mixes the powder, it is then compression-molded into the specific part. So far, one \n                      of the most common uses of this method has been to create bearings for high-temperature industry uses. Another application is in creating grinding wheels. The wheels use RP-46 to bond industrial diamonds in place for grinding extremely hard materials. Grinding wheels made from this material last longer and work longer at higher temperatures.\n                      \n                      RP-50 is a coating material that shares many of the same qualities as RP-46, but would not be used for structural applications or making parts. Uses include high-temperature electrical insulation and flexible circuitry, where its electrical and thermal insulating properties are well-suited.\n                      \n                      Kevlar® is a registered trademark of E. I. du Pont de Nemours and Company.\n                      \n                      \n                      \n                      \n                        \n                        \n                        \n                        \n                      \n                      \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/t_4.html","text":"Sensors Locate Radio Interference","image":"http://spinoff.nasa.gov/Spinoff2009/images/Soneticom-1-.jpg","story":"\n            Transportation\n                      \n                      Originating Technology/NASA Contribution\n                      \n                      While many air travelers are accustomed to rules against electronic devices during takeoff and landing, they might not be aware that these devices are banned because they can cause electromagnetic interference (EMI) with navigation equipment. Because similar problems can occur near launch sites for space missions, NASA began investigating technologies for tracking this interference in order to protect sensitive mission instrumentation. This electronic encroachment is partly due to a myriad of modern communication devices in the marketplace, but unfortunately could also be due to intentional and malicious transmissions. Uninterrupted communication between range activities, mission control, and the flight deck is critical to human safety and mission security, so NASA worked with a company that develops custom communication systems to design a system for locating sources of radio interference. \n                      \n                      Partnership\n                      \n                \n            \n                  \n                  \n                    \n                  \n                  \n                    The Space Shuttle Atlantis (foreground) and the Space Shuttle Endeavour (background) at Kennedy Space Center. Securing launches against radio interference has been one of the goals of Soneticom Inc.\n                  \n                  \n                      In 2005, Kennedy Space Center awarded a Phase I Small Business Innovation Research (SBIR) contract to Soneticom Inc., in West Melbourne, Florida. Recognizing the inability of existing tools to locate radio interference, the company developed a network of sensors to locate EMI sources, controlled by algorithms and receivers the company also developed under the contract. With a follow-on Phase II agreement in 2006, the company continued to develop the algorithms and receivers that were then integrated with software for data collection and analysis in the company’s Lynx Location System (LLS).\n                        \n                      In 2009, Soneticom began collaborating with the Federal Aviation Administration (FAA) to install and test the LLS at its field test center in New Jersey in preparation for deploying the LLS at commercial airports. The FAA reports that each year there are many cases of inadvertent interference and intentional disruptions of cockpit to tower communications at major airports. With a Phase III SBIR contract, Soneticom also plans to begin testing a new field strength mapping feature for the LLS in the near future.\n                      \n                      Product Outcome\n                      \n                      Soneticom’s LLS is an EMI precision geolocation system with two major components: the Control Station, a software package that runs on a laptop; and multiple compact, rugged, unattended processing sensors, which rely on the NASA-funded receiver components. The software collects data from each sensor in order to compute the location of the interfering emitter. The sensors can be mounted with existing infrastructure for power and wireless communications, or Soneticom can provide an independent power system on a tripod with battery or solar power options. \n                      \n                      \n                      \n                        \n                        \n                          \n                        \n                        \n                          Soneticom’s Lynx Location System is an electromagnetic interference geolocation system that relies on NASA-derived receiver components.\n                        \n                      \n                      Before locating interference, the LLS establishes a baseline by capturing and averaging radio frequency (RF) readings. Ron Cobb, Soneticom’s vice president of advanced communications systems, explains that the company deploys three or more sensors to an area, whereupon the system confirms receipt of a signal from the software. After the Control Station confirms communication from the sensors, it compares this baseline with real-time data to locate interference in a process called radio interferometry (RI), which uses NASA-developed algorithms to cross-correlate a fringe pattern produced when multiple antennas are tuned to a specific frequency. \n                        \n                      Using another algorithm called time difference of arrival (TDOA), which was also developed under the NASA SBIR, Cobb says the system locates disruptive signals down to small footprints, or “dots on a map.” The system then begins to differentiate between harmless radio traffic, such as from a recreational boater, and an intentional threat. The LLS begins alerting users to unusual activity on the RF spectrum, including changes in radiated power, signal strength, and EMI levels. \n                      \n                      Dwayne Free, senior systems engineer at Soneticom, says that one of the applications of the LLS system will be keeping runway (and launch) operations free from radio frequency interference. Because uninterrupted communication between crews in the tower (or mission control) and in the cockpit is critical to safety, the threat mitigation system could secure communications before flight, while a vehicle waits for takeoff.\n                      \n                      NASA and the FAA are not the only government agencies interested in locating (and preventing) security threats from radio interference. Other agencies and security firms that need to monitor anomalous RF emissions have purchased Soneticom’s LLS. The company has had a number of sales to private customers, all interested in preventing electronic encroachment, and although some frequencies differ between industries and organizations, the technology and processes are the same. Soneticom hopes to add the U.S. Air Force to its list of customers, seeing an easy transfer of the LLS to the Air Force’s launch needs at Cape Canaveral and Vandenberg Air Force Base. Another potential customer is the Federal Communications Commission, which could use the LLS to enforce radio frequency licenses.\n                      \n                      Plans for the LLS and Soneticom’s related RI/TDOA services include adapting the technology into smaller tracking devices, both for objects and for people, in an approach called cooperative tracking. An RI/TDOA personnel tracking device could track individuals in high-security or high-risk locations; astronauts, military personnel, firefighters, miners, and other individuals at risk could wear small beacons that would track their locations for their safety, and could also identify individuals without proper access. Security personnel and military forces approaching an area of operations could use RF tracking to secure an area from physical intrusion, not just radio interference. The system could also monitor and secure radio traffic during demolition explosions at construction sites. In 2009, Soneticom hopes to complete an enhanced mapping product, the EMI Image, which will be compatible with the LLS and has been developed with NASA SBIR funding. \n                      \n                      Parsippany, New Jersey’s DRS Technologies, a supplier of integrated products to military forces and intelligence agencies, announced with Soneticom in May that DRS has agreed to acquire the Florida company.\n                      \n                      \n                      \n                      \n                        \n                        \n                        \n                        \n                      \n                      \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/t_5.html","text":"Surface Operations Systems Improve Airport Efficiency","image":"http://spinoff.nasa.gov/Spinoff2009/images/Chicago-ATC-tower.jpg","story":"\n            Transportation\n                        \n                      Originating Technology/NASA Contribution\n                      \n  As part of its research to make air travel safer, NASA began collaborating with the Federal Aviation Administration (FAA) in 2005 to develop what are now called surface traffic management systems (STMS). Both agencies have expressed a need to gather and organize data on airport surface operations, the management of all airport vehicle activities on or near runways, including the movement of aircraft, baggage vans, fuel trucks, catering vehicles, security personnel, and any other ground traffic. STMS continuously record data to determine the position of aircraft using a transponder signal, GPS onboard the aircraft, or primary radar. These surface surveillance systems, which report locations every second for thousands of air and ground vehicles, generate massive amounts of data, making gathering and analyzing this information difficult. To record and help analyze airport operations data with the eventual goal of automating airport ground traffic, NASA sought assistance from private industry.\n  \n  Partnership\n  \n            \n            \n    \n    \n      \n    \n    \n      The Aviation Systems Division at Ames Research Center has contributed to surface automation research by helping to develop surface traffic management systems, which are decision-support tools designed to aid surface traffic planning.\n    \n  \n            In 2005, Mosaic ATM Inc., of Leesburg, Virginia, developed the Surface Operations Data Analysis and Adaptation (SODAA) tool with funding from Ames Research Center through the Small Business Innovation Research (SBIR) program. In essence, says Chris Brinton, Mosaic ATM’s president and a former Ames employee, “SODAA is an off-line support tool that can be used to analyze how well the airport surface operation is working, and to help in redesigning procedures and decision-making processes to improve airport operations.” Mosaic ATM continued its work with a Phase II SBIR in 2006. \n                  \n              After identifying what NASA, the FAA, and the aviation industry required, Mosaic ATM built and then systematically improved upon a prototype for SODAA. These improvements included advanced query, visualization, and data analysis capabilities to allow researchers to pinpoint trends and correlations in vast amounts of recorded airport operations data. Now widely used, SODAA has two main capabilities: supporting analysis of surface operations and developing STMS adaptation data, which provide airport configuration parameters for STMS. Mosaic ATM designers have also made a special effort to reduce the time needed to build STMS \n              adaptation data sets, with options that include predefined functions.\n              \n              Product Outcome\n              \n              Mosaic ATM’s SODAA helps airports and carriers avoid the significant costs of aviation delays by providing analysis tools to help refine and improve airport operational procedures. Even a small airstrip manages numerous variables for each aircraft and ground vehicle, and collecting data 24 hours a day on hundreds of different vehicles and situations can become unwieldy quickly. Working with current airport surface surveillance systems, SODAA manages these large amounts of data, revealing where slowdowns or irregularities occur. \n              \n              SODAA presents this data in a graphical user interface (GUI), allowing for immediate, useful interpretation, such as when changes in the flight schedules at the airport cause inefficiencies. Using the GUI, users can define queries—and areas of concern—which SODAA can plot on a map, display in a graph or a table, or export to other software. SODAA pulls raw airport data and STMS log files into its database, and then flags data that may be \n              of interest.\n              \n                      \n            \n    \n    \n      \n    \n    \n      In 2005, Mosaic ATM Inc. developed Surface Operations Data Analysis and Adaptation (SODAA), an off-line support tool for analyzing and improving airport surface operations.\n    \n  \n            SODAA imports data after receiving updates from the STMS, which allows for post-operations analysis for a variety of uses: long-term airport planning, highly accurate operations billing, assessing noise abatement issues, and routine management of ground traffic. Based on the data it collects, SODAA identifies busy runway crossings and choke points, calculates waiting times and taxi times, and determines how frequently and for what duration taxiways and runways are used. The software analyzes these runway assignments, flight profiles, and taxi routes in order to help managers make key decisions and be alert to potential or recurring slowdowns; SODAA displays key factors like proximity to a conflict point, such as a bottlenecked runway, taxiway, or ramp area. SODAA can then create new scenarios for departure and arrival traffic by using customized management strategies. Airport planners can also adapt the tool to suit different needs and conditions, such as a taxiway that cannot be used on certain dates due to construction.\n                  \n              In addition to inefficiencies, the SODAA tool can also help analysts recognize possible safety concerns, such as a particular driver who regularly follows the wrong route. By preventing or catching a surface deviation early, an analyst or airport manager may help avoid a costly or dangerous delay. User-friendly graphics also allow users to view these vehicle paths, and to drill down to see more specific information and statistics, such as how closely and regularly a vehicle is adhering to its assigned route, and how often it is out of compliance. \n              \n              In order to create detailed views of the various airport operation levels, the software uses statistical correlation, clustering, and modeling in its data analysis. Brinton explains that these analytical techniques allow information about the airport operation to be automatically derived by SODAA and provided to the user. “For example,” Brinton says, “if flights parked at one concourse experience more delays than flights parked at other concourses, SODAA will identify this correlation and display it to the user.” This analysis depends on the collection of large amounts of surface data from STMS to identify consistent characteristics. \n              \n              Customers such as air traffic specialists, airline managers, and airport authorities use SODAA to improve operations efficiency and to help make long-term planning decisions at airports. Brinton explains, “The significant costs of aviation delays and the opportunity to reduce such delays through this effort result in a strong market for the SODAA technology.” Currently, Mosaic ATM continues the commercialization and development of SODAA under a Phase III SBIR contract.\n              \n              \n              \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/t_6.html","text":"Nontoxic Resins Advance Aerospace Manufacturing ","image":"http://spinoff.nasa.gov/Spinoff2009/images/Invention_icon.jpg","story":"\n            \n              Transportation\n                  \n                                  Originating Technology/NASA Contribution\n                  \n                      \n            \n    \n    \n      \n    \n    \n      PETI-330 is the first resin created specifically for high-temperature composites formed with resin transfer molding and resin infusion. Offering processability, toughness, and high-temperature performance, the resin has a low-melt viscosity and, when cured, a high glass transition temperature.\n    \n  \n            In the late 1980s, scientists and engineers at Langley Research Center began to develop technology for future commercial supersonic air travel, which could reduce travel time across the Pacific or Atlantic Ocean to less than half the time possible with modern subsonic jets. Although British Airways and Air France offered high-speed travel across the Atlantic on the Aérospatiale-BAC Concorde aircraft at speeds of about 1,350 miles per hour (Mach 2.05, or 2.05 times the speed of sound, depending on altitude), NASA hoped to develop quieter, more fuel-efficient, faster supersonic jets that would travel at Mach 2.4 and carry up to 300 passengers, 3 times the number on Concorde. Supported by a team of U.S. aerospace companies, the Agency’s High-Speed Research (HSR) program began to explore the possibility of making these supersonic passenger jets a reality.\n                  \n              For the new jets, the HSR program needed a structural material with higher temperature capability than Concorde’s aluminum alloy, which would not tolerate the aerodynamic heating at higher altitudes at sustained speeds above Mach 2.2. Because wind friction can cause the outer surface of an aircraft to reach a temperature of 177 °C (350 °F) at Mach 2.4, the HSR team investigated new materials that retained their mechanical integrity at 177 °C for 60,000 hours—the anticipated service life of a commercial supersonic aircraft. \n  \n  Partnership\n  \n              Chemicals manufacturer Ube Industries Ltd., based in Ube City, Japan, has its North American headquarters, Ube America Inc., in New York. At the same time that Ube was seeking applications for a unique monomer (a small molecule that can be used as a building block for advanced high-performance polymers), Langley scientists Dr. John Connell, Paul Hergenrother (now retired), and Dr. Joseph G. Smith, Jr. were investigating these chemical building blocks that could impart specific physical, thermal, and mechanical properties into high-temperature polymers for the HSR program. Ultimately, NASA was seeking a partner in private industry that could provide materials and manufacturing capability for a high-temperature resin that met the property requirements for structural applications on supersonic aircraft. A colleague from the Japanese Aerospace Exploration Agency (JAXA), Dr. Rikio Yokota, introduced the two teams, and they formed an informal collaboration in which Ube provided a unique monomer to the Langley researchers for chemical evaluation. “We used Ube’s monomer to prepare over 50 resin formulations, measured properties, and honed in on the best performing material,” says Connell. \n  \n              The monomer was a byproduct from the synthesis of another chemical used in the microelectronics industry. However, Connell explains, “This unique monomer was difficult and expensive to synthesize directly, so we collaborated with Ube to obtain the monomer and to investigate the effect of this monomer on polyimide matrix resins.” Although the HSR program was phased out in 1999, the Agency continued development with Connell’s team at Langley, who recognized that this material might fill a need in aerospace manufacturing for a high-temperature resin that could be easily processed. \n  \n              Connell also credits Dr. Jim Criss, Jr., of M&P Technologies Inc., a small company in Marietta, Georgia, for refining the resin infusion (RI) and resin transfer molding (RTM) manufacturing processes for use with this high-temperature resin system. RTM is a standard process in aerospace manufacturing, traditionally for lower-temperature resin systems, such as epoxies. “As we were developing the resin system, he was developing the equipment and process for RTM, which at the time did not exist for high-temperature resins,” says Connell. \n  \n              This polyimide matrix resin was named PETI-330, for its phenylethynyl-terminated imide and glass transition temperature of 330 °C. PETI-330 met the team’s requirements for a substance that performed well at high temperatures and had the unique capability to be processed into composites by RTM and RI processes. \n  \n              Langley issued Ube America a non-exclusive license in 2004 for the manufacture of PETI-330, and according to Stewart Bain, product director of aerospace materials at Ube, the license was strategic for the company, which wanted to have a larger aerospace role for its specialty and chemicals division.\n  \n              Based on the sales to date and the potential of PETI-330, NASA awarded the Langley team the “Commercial Invention of the Year” award for 2008. Connell believes the NASA award will help with the ongoing transfer to the commercial marketplace: “Ideally it will provide more visibility for the material and help further its progression into aerospace-related products.”\n  \n  Product Outcome\n  \n              The aerospace industry fabricates composites through non-autoclave techniques such as RTM, RI, vacuum-assisted RTM, and conventional autoclave processes using pre-impregnated material (prepreg). PETI-330 is the first resin created specifically for high-temperature composites formed with RTM and RI. Offering processability, toughness, and high-temperature performance, the resin has a low-melt viscosity and, when cured, a high glass transition temperature. These properties typically oppose each other, but are both highly desirable in manufacturing. \n  \n            \n            \n  \n  \n    \n  \n  \n    PETI-330 was used in resin transfer molding to fabricate this F-frame. Composite manufacturing is simpler and faster with PETI-330, because it needs only a one-step curing process.\n  \n\n            Bain explains that the composite manufacturing process is far simpler and faster using PETI-330 than competing materials because Ube’s resin only requires a one-step curing process. “The resin is heated to 288 °C and then de-gassed,” he explains. “Then it is injected into a mold, the temperature is increased to 371 °C, and left for an hour and subsequently cooled. You then have your part.” Curing cycles for other resins can have as many as 15 steps, Bain explains, and can take 24 hours. Because PETI-330 has low-melt viscosity, it is able to penetrate large area carbon fiber molds (preforms) without changing flow characteristics—an important characteristic for resins during this process. Connell says, “The low-melt viscosity gives us that advantage in the processing.” Machining of the composite is also possible after molding, thus enabling the precise manufacture of a variety of shapes and sizes. \n                \n              Another advantage PETI-330 offers, Bain says, is strength with a lower weight than metal alloys, which enables the resin to replace them—particularly titanium alloys—in many components. Consequently, the resin can reduce the weight of high-temperature parts. Because of its strength and toughness, the cured resin (and composites) also resists microcracks that often result from frequent expansions and contractions with temperature fluctuations. Bain explains that when heat is combined with humidity in extended operation, a part tends \n              to degrade much more quickly, but PETI-330 tends to maintain its strength even in these conditions. This can make PETI-330 especially useful for aerospace applications, where components must be both lightweight and resistant to cracks and damage from temperature swings. \n  \n              One important feature of the PETI-330 that Connell and Bain are particularly proud of is its safety. Whereas traditional approaches use toxic monomers, the new resin is “completely nontoxic,” says Bain. Other high-temperature resin matrix composites, he says, contain unreacted aromatic diamines, such as 4,4’-diaminodiphenylmethane (called MDA), many of which are carcinogenic and require special handling and dedicated facilities to protect workers. He says, “PETI-330 is guaranteed not to contain unreacted aromatic diamines, which is an important feature when you consider the health of the workers who are handling the material.” The diamines used in PETI-330 are fully reacted into the resin, Connell says. Consequently, it is stable and has a long shelf life. Neither specialized protective equipment nor dedicated facilities are required for PETI-330, which can help reduce costs.\n  \n              Because of the resin’s high-temperature performance and processability, Connell says, the NASA resin is well suited for use in and around jet engines (including inlet frames, insulation, nacelles, air ducts, and compressor vanes) where temperatures may reach 260–288 °C (500–550 °F) and remain at high temperatures for thousands of hours. Recently, Ube began collaborating with Boeing Aerospace for high-temperature applications on commercial aircraft. The resin is also under evaluation by a number of other aerospace companies for applications that may take advantage of PETI-330’s unique qualities.\n              \n              \n              \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ps_1.html","text":"Sensors Provide Early Warning of Biological Threats","image":"http://spinoff.nasa.gov/Spinoff2009/images/Early-Warning-1.jpg","story":"\n      Public Safety\n        \n                            Originating Technology/NASA Contribution \n                  \n          \n      \n    \n    \n      \n    \n    \n      Containing millions of carbon nanotubes, the NASA biosensor can alert inspectors to minute amounts of potentially dangerous organic contaminants.\n    \n  \n      The Centers for Disease Control and Prevention (CDC) estimates there are between 4 and \n        11 million cases of acute gastrointestinal illnesses in the United States each year—caused by pathogens in public drinking water. The bacteria Escherichia coli (E. coli) and Salmonella have within the past few years contaminated spinach and tomato supplies, leading to nationwide health scares. Elsewhere, waterborne diseases are devastating populations in developing countries like Zimbabwe, where a cholera epidemic erupted in 2008 and claimed over 4,000 lives. \n        \n        Scientists have found an unexpected source of inspiration in the effort to prevent similar disasters: the search for life on Mars. The possibility of life on the Red Planet has been a subject of popular and scientific fascination since the 19th century. While Martian meteorites have turned up controversial hints of organic activity, and NASA’s exploratory efforts have delivered important discoveries related to potential life—the presence of water ice, and plumes of methane in Mars’s atmosphere—direct evidence of organisms on our closest planetary relative has yet to be found. \n        \n          \n      \n    \n      \n    \n  \n      In order to help detect biological traces on Mars, scientists at Ames Research Center began work on an ultrasensitive biosensor in 2002. The chief components of the sensor are carbon nanotubes, which are the major focus of research at the Center for Nanotechnology at Ames—the U.S. Government’s largest nanotechnology research group and one of the largest in the world. Tubes of graphite about 1/50,000th the diameter of a human hair, carbon nanotubes can be grown up to several millimeters in length and display remarkable properties. They possess extreme tensile strength (the equivalent of a cable 1 millimeter in diameter supporting nearly 14,000 pounds) and are excellent conductors of heat \n        and electricity. \n        \n        It is the nanotubes’ electrical properties that Ames researchers employed in creating the biosensor. The sensor contains a bioreceptor made of nanotubes tipped with single strands of nucleic acid of waterborne pathogens, such as E. coli and Cryptosporidium. When the probe strand contacts a matching strand from the environment, it binds into a double helix, releasing a faint electrical charge that the nanotube conducts to the sensor’s transducer, signaling the presence of the specific pathogens found in the water. Because the sensor contains millions of nanotubes, it is highly sensitive to even minute amounts of its target substance. Tiny, requiring little energy and no laboratory expertise, the sensor is ideal for use in space and, as it turns out, on Earth as well.\n        \n        Partnership\n        \n        “Carbon nanotubes are the wonder material of nanotechnology,” says Neil Gordon, president of Early Warning Inc., based in Troy, New York. “The opportunity was ripe to put that technology into a product.” Gordon encountered the director of the Center for Nanotechnology, Meyya Meyyappan, at a number of industry conferences, and the two discussed the possible terrestrial applications of NASA’s biosensor. In 2007, Early Warning exclusively licensed the biosensor from Ames and entered into a Space Act Agreement \n        to support further, joint development of the sensor through 2012.\n        \n        Product Outcome\n        \n        Early Warning initially developed a working version of the NASA biosensor calibrated to detect the bacteria strain E. coli O157:H7, known to cause acute gastrointestinal illness. It also detects indicator E. coli, commonly used in water testing. In the process, the company worked out a method for placing multiple sensors on a single wafer, allowing for mass production and cost-effective testing. In April, at the 2009 American Water Works Association “Water Security Congress,” Early Warning launched its commercial Biohazard Water Analyzer, which builds upon the licensed NASA biosensor and can be configured to test for a suite of waterborne pathogens including \n        E. coli, Cryptosporidium, Giardia, and other bacteria, viruses, and parasitic protozoa. The analyzer uses \n        a biomolecule concentrator—an Early Warning invention—to reduce a 10-liter water sample to 1 milliliter in about 45 minutes. The concentrated sample is then processed and fed to the biosensor. The entire process takes about 2 hours, a drastic improvement over typical laboratory-based water sampling, which can take several days to a week. The sensor operates in the field via a wired or wireless network and without the need for a laboratory or technicians, allowing for rapid, on-the-fly detection and treatment of potentially dangerous organic contaminants.\n        \n          \n      \n    \n    \n      \n    \n    \n      Early Warning’s analyzer feeds a concentrated water sample to its biosensor, providing rapid pathogen detection.\n    \n  \n      “The sensor is incredibly sensitive and specific to \n        the type of pathogen it is calibrated to detect in the water,” says Gordon. “Instead of just detecting coliforms in the water that may or may not indicate the presence of pathogens, we will know if there are infectious strains of Salmonella, E. coli, or Giardia that could sicken \n        or even kill vulnerable people if consumed.” (Coliform bacteria levels typically indicate water and food \n        sanitation quality.)\n        \n        The water analyzer has multiple applications, notes Gordon. Early Warning’s system can monitor recreational water quality at beaches and lakes, which can be contaminated by animal feces, farming activities, and infectious pathogens in human waste. Agricultural companies may use the analyzer to test feed water for cattle, and food and beverage companies may employ the sensor to ensure the purity of water used in their products. Health care organizations have expressed interest in using the analyzer to test water from showers and other potential sources of pathogens like Legionella, which causes the flu-like Legionnaires’ disease.\n  \n        Early Warning and Kansas State University, in Manhattan, Kansas, are collaborating on sensor enhancements such as improving the safety of imported produce. Since the skins of fruits and vegetables are potential sites of dangerous pathogens, inspectors could collect water sprayed on the produce and, using the analyzer, know within a few hours whether a particular shipment is contaminated. Last year, Kansas State was selected as the home for the U.S. Department of Homeland Security’s new National Bio and Agro-Defense Facility, which could also benefit Early Warning. \n  \n        “We’re eager to show how the private sector, government agencies, and academia can work together to evolve this platform into products that benefit our citizens,” says Gordon. With an aging U.S. water and wastewater infrastructure, increasingly severe weather systems, global travel and food imports affecting the proliferation of disease-causing organisms, and more than 1 billion people worldwide without access to safe water (according to the World Health Organization), the fruits of this partnership may be more necessary than ever.\n        \n        \n        \n          \n          \n          \n          \n        \n      \n    "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ps_2.html","text":" Robots Save Soldiers’ Lives Overseas","image":"http://spinoff.nasa.gov/Spinoff2009/images/Marbot.jpg","story":"\n            Public Safety\n                      \n                      Originating Technology/NASA Contribution\n                  \n    NASA intends to return people to the Moon, but this time to stay. Future plans include living quarters, scientific laboratories, a permanent lunar community, and a training ground for a future mission to Mars. Ahead of these first 21st century boots on the Moon, though, the Space Agency needs to make sure a couple of things are in place, including one thing that most of us here on Earth have begun to accept as a necessary part of any human existence: the Internet. \n    \n            \n            \n      \n      \n        \n      \n      \n        The Multi-function Agile Remote Control Robot (MARCbot) pictured here on display at WIRED NextFest, an annual showcase of innovative technologies transforming the world, is a tele-operated reconnaissance robot developed to identify explosives from a safe distance. \n      \n    \n            NASA is designing a mobile communications platform so that a planned series of scouting robots can communicate with one another, astronauts on the Moon, and mission controllers on Earth. These robot scouts will initially serve as beacons to help triangulate coordinates, including potential landing sites. They will also carry simple science experiments for studying the new locale, taking dust measurements, profiles of local geochemistry, and astronomical readings. \n                  \n              Once in place, though, NASA wants these scouts to begin acting as relay points for a wireless communications network—essentially putting the Internet on the Moon. This network, while essential for NASA’s own purposes, will also eliminate many compatibility issues for communicating with international partners who join us on the lunar surface. With each nation designing its own space hardware, universal wireless communications reduce the difficulties of connecting communications equipment. \n              \n              Working toward this goal, engineers at Marshall Space Flight Center, as part of the Science Mission Directorate’s Self-Aware Surface Network project, are designing a prototype of a communications network which will enable sensor-webs, data sharing, communications, and navigation on the Moon’s surface. \n              \n              As an unexpected early benefit of this NASA research, the U.S. Army received a souped-up reconnaissance tool that is now being deployed to keep soldiers safer in \n              war zones. \n              \n              Partnership\n              \n              Huntsville, Alabama-based Marshall engineers provided their counterparts at the Army’s nearby Redstone Arsenal with unexpected design upgrades for one of its remotely operated reconnaissance robots. The Multi-function Agile Remote Control Robot (MARCbot) is a device that the Army has been deploying to Iraq since 2004 to help soldiers search out and identify improvised explosive devices (IEDs). It was developed for the Army by an engineering consulting firm, Exponent Inc., headquartered in Menlo Park, California, with 19 offices across \n              \n              the country and representing over 90 scientific and technical disciplines. \n              \n              NASA became involved with the project, not just because of the proximity to Redstone or because both the Space Agency and the Army are actively engaged in studying how best to integrate and coordinate humans and robots to do some of the hardest jobs in the universe. Rather, NASA saw the low-cost MARCbots being tested and bought two from its neighbor to test its mobile communications platform. \n              \n                    \n            \n      \n      \n        \n      \n      \n        The MARCbot received multiple upgrades from engineers at NASA’s Marshall Space Flight Center, and hundreds have now been deployed by the U.S. military overseas to help soldiers identify improvised explosive devices.\n      \n    \n    While tinkering with the devices, the Marshall engineers made a few design changes, making the robot simpler and faster while adding myriad capabilities. They essentially gutted the device and replaced all of its electronics, upgrading from an analog camera to a digital setup, encrypting the controllers and video transmission, as well as significantly increasing the range and adding communications abilities. Despite all of these upgrades, they also managed to simplify the design, providing more plug-and-play sensors and replacing some of the complex electronics with more trouble-free, low-cost components.\n        \n      When they demonstrated the modified robot to its former owners, the Army was impressed and wanted these design changes reproduced in future models. The Huntsville-based Von Braun Center for Science and Innovation, a local NASA-affiliated nonprofit, helped coordinate this partnership, which involved the transfer of intellectual property between two large government agencies and the contracting of two private companies to carry out the work on a third company’s existing product. Schafer Corporation, also in Huntsville, had designed the control system for the updated robot, and Applied Geo Technologies Inc. (AGT), a tribally-owned corporation in Choctaw, Mississippi, was given the task of manufacturing the modified Exponent MARCbots. \n      \n      AGT is currently producing 40 new systems per month, upgrading the original Exponent product to make the MARCbot IV-N, the “N” designating its NASA roots. It has completed over 300 of these units, all of which are on their way overseas for active duty. They are also producing a kit so that already-deployed units can be upgraded in the field. \n      \n      Product Outcome \n      \n      According to the U.S. Department of Defense, IEDs have been responsible for approximately half of all U.S. and coalition force casualties and combat injuries in Iraq.\n      \n      These devices disrupt supply convoys, destroy assets, and have been credited with killing or maiming thousands of soldiers. The MARCbot is a remotely operated reconnaissance robot specifically developed to identify IEDs and maintaining a safe distance—allowing a soldier to assess whether an object is a potential IED while avoiding close (and perhaps dangerous) physical proximity. It is used to hunt down threats to soldiers by allowing a suspected IED to be examined remotely.\n      \n      The small-wheeled robot is easy to use. It operates with a standard laptop using Windows software and is operated with a common video game controller. In fact, when looking for components, the NASA engineers actually stopped by a series of local pawn shops and purchased used video game controllers, knowing that these parts were readily-accessible, cheap, and most importantly, would be used intuitively by the average young soldier. Although it operates much like a remote-controlled toy car, this robot has features not found under the Christmas tree: It is several times more rugged than even the most robust toy and comes equipped with a video camera, GPS, compass, and an articulated arm. Once it travels so far, it also has way-finding features, so the operator can instruct the robot to find its own way back, following a memorized path.\n      \n      Reports have come back from the battlefield of soldiers giving their MARCbots names, honorary medals and ranks, and mourning their loss in combat.\n      \n      Currently, one user operates a single MARCbot IV-N, but future plans are to have one operator oversee a fleet of semi-autonomous robots in order to gain complete situational awareness. Future plans also include adding radiation sensors and plume detection for dirty bomb cleanup and mitigation.\n      \n      Windows® is a registered trademark of Microsoft Corporation. \n      \n        \n      \n        \n        \n        \n        \n      \n    \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ps_3.html","text":"Apollo-Era Life Rafts Save Hundreds of Sailors","image":"http://spinoff.nasa.gov/Spinoff2009/images/a11splash.jpg","story":"\n            Public Safety\n              \n              Originating Technology/NASA Contribution\n              \n            \n            \n                  \n                  \n                    \n                  \n                  \n                    Apollo astronauts and a Navy frogman in biological isolation garments await pickup from a helicopter.\n                  \n                  \n                      The space shuttle is unique among spacecraft in that it glides back to Earth and lands like an airplane, usually touching ground near where it launched at Kennedy Space Center, but sometimes, in poor weather, gliding into the back-up landing site at Dryden Flight Research Center and then catching a ride back to the Cape on the back of a modified Boeing 747. Before NASA began flying the shuttle, though, astronauts had a longer, more involved trip back to base after a mission. Their capsule, called the command module, would plunge through the atmosphere before releasing a series of parachutes that would slow the craft enough for it to land on the water without too significant of an impact. Called a splashdown, this type of landing put the astronauts out in the ocean, where a specially designated U.S. Navy ship would then deploy a helicopter to retrieve the space travelers. Waiting for the rescue, the astronauts would release a highly visible marker dye into the water, then leave the command module and climb aboard a life raft. \n                        \n                      These early space pioneers had traveled thousands of miles and then landed safely back on Earth. The journey’s end was in sight, but they had one more obstacle. The rotor downdraft from the helicopter coming to retrieve them, reaching sometimes as much as 100 knots per hour, was enough to flip a typical flat-bottomed life raft. \n                      \n                      Not willing to be thwarted after coming so far, NASA engineers began devising a solution. They knew they needed a highly stable inflatable raft capable of riding out the rough winds, and the solution was to make use of the most abundant resource available: water. Engineers at NASA’s Johnson Space Center went to work designing and patenting a hydrodynamically stabilized ballast system that would prevent a life raft from tipping in choppy seas and fierce winds. \n                      \n                      Partnership\n                      \n                      While NASA was working on its rescue raft designs, inventor Jim Givens was similarly at work, designing a canopied raft with a hemispheric ballast chamber capable of withstanding the strongest winds and waves. Givens patented his similar system and then obtained an exclusive license for the patented NASA system. \n                      \n                      Givens Marine Survival Co. Inc., of Tiverton, Rhode Island, now manufactures and markets the rescue rafts—under the name Givens Buoy Life Raft—in a variety of sizes and models for everything from sailboats to larger ocean-going vessels. \n                      \n                      To date, Givens has sold several thousand of the ballasted inflatable life rafts, and this space-age technology is credited with saving the lives of over 450 seamen.\n                      \n                      Product Outcome\n                      \n                      \n                      \n                        \n                        \n                          \n                          Givens Marine Survival Co. Inc. licensed the self-righting life raft design from NASA and has since crafted thousands of the life-saving rafts.\n                        \n                      \n                      The Givens raft, like the NASA design, relies upon a heavy, water-filled ballast. A flapper valve allows large amounts of water—hundreds of gallons—to enter the hemispheric chamber. This water provides the ballast that keeps the center of gravity constant, much like the thousands of pounds of lead keel used to stabilize sailboats. This design makes the raft nearly impossible to capsize. If, however, a large wave breaks over the top of the life raft, carrying it upside down, it is designed to somersault and right itself, the momentum of the water in the ballast chamber continuing across the top of the canopy and leveling it upright again. While not the most comfortable sensation, this feature is what keeps crews alive and out of the water.\n                        \n                      With a typical, flat-bottomed life raft, there is little or no ballast and no momentum to help a capsized craft right itself. An inverted life raft begins to fill with seawater, increasing exponentially the risks of hypothermia or drowning. Righting the raft involves the disoriented occupants leaving the craft and attempting the procedure from outside, a task that could result in dangerous exposure to the elements and sailors being swept away. \n                      \n                      It is not just strong winds and waves that flip the typical inflatable life raft, though. Something as simple as someone trying to climb aboard, or occupants shifting inside, could flip a standard life raft. The Givens-designed valve system, however, employs multiple stabilizers to accommodate for boarders and shifting of occupants as well as varying wave angles and swells. \n                      \n                      \n                      \n                        \n                        \n                          \n                        \n                        \n                          Available in a variety of sizes, the Givens Buoy Life Raft can be used on small sailboats or large fishing vessels and fully self-inflates in under 12 seconds. \n                        \n                      \n                      Both the Navy and U.S. Coast Guard have tested the Givens Buoy Life Raft. Coast Guard testing, as part of its routine testing of all available certified marine safety gear, demonstrated that the raft could not be capsized by rough seas or strong winds. The testing included simulated rescue hoists from Coast Guard rescue helicopters, simulated hurricane force winds from a C-130 aircraft slipstream, drift tests, weight distribution and stability tests, and “at-sea” testing. In each instance, the Givens life raft withstood the most brutal of punishments. \n                        \n                      Testing, no matter how well-designed, can never really account for all of the variables that could happen at sea, so it is the testimonials from people whose lives have been saved by these rafts that really speak to their ruggedness. In 1980, the lives of four sailors were saved by a Givens life raft. It was August and the four men were caught in the middle of Hurricane Allen, at that time the second worst storm ever recorded on the Atlantic. With winds gusting to 190 knots per hour, their 30-ton ketch capsized, and the crew sought refuge in their Givens Buoy Life Raft. The four men rode 35-foot waves over the next 42 hours before being rescued, with the raft at times being submerged under several feet of water, flipping, and then righting itself. As Bob Harvey, one of the survivors tells, “We didn’t feel comfortable, but we did feel secure.”\n                      \n                      The standard Givens Buoy Life Raft comes equipped with water-activated lights, an automatically inflated canopy, a system for capturing rainwater, insulated floors, and an automatic inflation system.\n                      \n                      \n                      \n                      \n                        \n                        \n                        \n                        \n                      \n                      \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ps_4.html","text":"Circuits Enhance Scientific Instruments and Safety Devices ","image":"http://spinoff.nasa.gov/Spinoff2009/images/Virginia-Diodes-.jpg","story":"\n            Public Safety\n              \n                                  Originating Technology/NASA Contribution\n                  \n                      \n            \n    \n    \n      \n      Virginia Diodes Inc. (VDI) has found commercial success with its high-frequency integrated diodes, which are key components in VDI’s vector network analyzer (VNA) extenders.\n    \n  \n            Since its founding in 1958, NASA has pioneered the use of different frequencies on the electromagnetic spectrum—including X-ray, microwave, and infrared wavelengths—to gather information about distant celestial bodies. During the 1962 Mariner 2 mission, NASA used microwave radiometers that operated in the range of 15–23 gigahertz (GHz) to assess the surface temperature of Venus and to determine the percentage of water vapor in its atmosphere. \n                  \n              Today, there is another area on the spectrum proving uniquely useful to scientists: the terahertz (THz) range, spanning from about 100 GHz–10,000 GHz. (1 THz equals approximately 1,000 GHz.) Terahertz frequencies span the lesser-known gap on the electromagnetic spectrum between microwave radiation and infrared (and visible) light, falling within the spectral range where most simple molecules resonate. This molecular resonance makes terahertz particularly useful for chemical spectroscopy and the remote sensing of specific molecules. In the 1990s, NASA began using frequencies above \n              \n              300 GHz (more than an order of magnitude higher than the instrumentation on Mariner 2) to perform spectral analysis of molecular clouds and planetary atmospheres. Instruments using these higher frequencies have included the Microwave Limb Sounder (MLS) on the Upper Atmosphere Research Satellite (UARS), deployed from 1991–2001, and the Microwave Instrument for the Rosetta Orbiter (MIRO), launched in 2004. With UARS-MLS, NASA used advanced terahertz receivers to measure the emission signatures from atmospheric molecules, providing researchers with valuable data about the changes in the Earth’s protective ozone layer. MIRO, set to rendezvous with the comet 67P Churyumov-Gerasimenko in 2014, will use terahertz instrumentation to analyze the comet’s dust and gasses. \n              \n                      \n            \n    \n    \n      \n    \n    \n      VDI’s VNA extenders enable engineers to create and test products in the terahertz range. Products that use terahertz span a variety of areas in research, manufacturing, and security monitoring.\n    \n  \n            Although NASA has been a driving force behind the development of terahertz technology, scientific equipment for terahertz research—including transmitters, receivers, and basic test and measurement equipment—is not widely available, making scientific experiments in this range between traditional electronics and quantum photonics more costly and greatly limiting commercial development in the field. Given NASA’s interest in studying distant bodies in space as well as in improving life on Earth, the Agency has collaborated with private industry to develop terahertz technologies. \n                  \n                          Partnership \n                  \n              In the early 1980s, University of Virginia professor Thomas Crowe and research scientist William Bishop worked with NASA to develop high-frequency diodes for UARS-MLS instrumentation. In 1996, Bishop and Crowe founded Virginia Diodes Inc. (VDI), based in Charlottesville, Virginia. A few years later, the company began developing and selling terahertz components and subsystems, with a mission to make the terahertz region of the electromagnetic spectrum as useful for scientific, military, and commercial applications as the microwave and infrared frequency bands have become. \n              \n              As a subcontractor on a 1999 Phase I Small Business Innovation Research (SBIR) contract from the Goddard Space Flight Center, VDI collaboratively developed three state-of-the-art frequency multipliers with output center frequencies of 182 GHz, 250 GHz, and 384 GHz. Building on these early successes with concurrent Phase II SBIR contracts from Goddard and the Jet Propulsion Laboratory in 2001, VDI developed a highly compact \n              870 GHz receiver and a compact frequency tunable source for frequencies at 1.5 THz. \n  \n              Today Goddard uses these VDI technologies in the airborne Conical Scanning Submillimeter-wave Imaging Radiometer to make airborne measurements of ice crystals as proof of concept for the next generation of spaceborne instruments for Earth and space exploration. In addition to its continuing collaboration with NASA to develop terahertz technology for current and future missions, VDI has found commercial success with its terahertz components and testing equipment, particularly its integrated diode circuits, which are key components in VDI’s vector network analyzer (VNA) extenders. \n  \n  Product Outcome\n  \n              Because of the unique characteristics of terahertz radiation—such as its ability to image items hidden behind common materials (such as clothing), and to detect and identify a wide range of chemicals—there is a growing demand for terahertz components for a variety of systems. Applications include security imaging systems to detect concealed items, hazardous chemical and biological-agents detectors, plasma diagnostic instruments, and industrial process monitors. In order to create these new products, engineers need components that can operate in the terahertz range, such as high-frequency mixers and multipliers, amplifiers that operate in terahertz frequencies, and advanced testing equipment like VNAs. \n  \n            \n            \n  \n  \n    \n  \n  \n    New security imaging products use the VDI diodes to detect passive terahertz waves, which can reveal images hidden behind common materials. The image on the left, returned from the security system, shows a gun hidden under the man’s jacket.\n  \n\n            VDI’s advanced integrated diode circuits have increased the frequency range of VNAs (and VNA extenders) by an order of magnitude, from 100 GHz to 1,000 GHZ (1 THz). The company’s extenders now expand the range of current commercial 4-port VNAs to the 780–850 GHz range while maintaining high dynamic range (80 decibels). “The frequency multipliers and frequency mixers are the key technology,” says Crowe, now VDI’s president. “They have diode circuits that were primarily developed under the SBIRs.” Crowe also states that VDI’s advantage in the VNA extender field is the company’s ability “to make very efficient and cost effective mixers and multipliers that work all the way to 1 THz and beyond.” These VNA extenders allow engineers to design systems and make measurements that were scarcely possible only 5 years ago.\n                \n              While most customers—including many universities—come to VDI for components for high-frequency test systems, Crowe expects VDI’s terahertz-ready VNA extenders and diodes will spur the development for many other research instruments and commercial products, including security imaging systems. One security system currently using terahertz components from VDI is ThruVision’s T5000 Imaging System, now in use at some international airports. Because terahertz radiation is a shorter wavelength than radio or microwave frequencies, a terahertz scan of a person displays hidden objects with higher spatial resolution. It also can detect a greater variety of materials, including metals, wood, ceramics, and plastics. Terahertz photons also have very low energy and, unlike X-rays, terahertz radiation is non-ionizing and not considered to be harmful to people. In fact, terahertz imaging systems like the T5000 can be totally passive, detecting only the terahertz energy that is naturally emitted by the subject. \n  \n            \n            \n  \n    \n  \n\n            These imaging systems are possible only because of developments in terahertz components and test equipment, and Crowe expects demand to increase noticeably in the coming years as VDI’s terahertz components improve. VDI’s goals include increasing the dynamic range to greater than 100 decibels throughout the entire frequency range, and extending the modular systems to greater than 1 THz. Transmitter power will improve as more power inevitably becomes available from broadband amplifiers. VDI also expects continued improvement of the multipliers, particularly near the band edges. \n                \n              According to Crowe, VDI has grown to over 30 full-time employees and continues to grow at 30 percent per year, growth he credits to the company’s successful commercialization of terahertz products developed under the NASA contracts. The company has over 200 customers in over two dozen countries, including major university and government research laboratories.\n  \n  \n  \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ps_5.html","text":"Tough Textiles Protect Payloads and Public Safety Officers ","image":"http://spinoff.nasa.gov/Spinoff2009/images/Mars-lander-Crash-bags.jpg","story":"\n            Public Safety\n              \n              Originating Technology/NASA Contribution\n              \n            \n            \n                  \n                  \n                    \n                  \n                  \n                    The Mars Pathfinder’s airbags incorporated multiple layers (up to four, depending on the location of the airbag) of lightweight fabric. When Pathfinder landed on Mars, the vehicle and its delicate payload were protected by 24 inflated spheres woven by Warwick Mills Inc.\n                  \n                  \n                      Special textiles have been mission-critical components for successful space missions since the early years of NASA’s first parachutes and space suits in the late 1950s. One of the Agency’s more recognizable uses for textiles, the Mars Pathfinder airbags, provided a cushioned, instrument-friendly landing in 1997. This same technology also successfully protected the Mars Exploration Rovers when they landed on the Red Planet in 2004. \n                        \n    These were not the ordinary airbags found in automobiles. Because the success of the missions depended on the payloads remaining undamaged, NASA had specific, exacting requirements for the airbag design. A lightweight fabric that could maintain inflation was required, but that fabric would have to be tough enough to withstand extreme temperatures (both in space and in the Martian atmosphere). The fabric balloons would have to inflate after passing through the atmosphere and then maintain inflation during impact on the rocky, sharp, and unpredictable Martian terrain. In July 1997, when the Mars Pathfinder landed on Mars, 24 interconnected, inflated spheres protected the vehicle and its delicate payload as the craft bounced 15 times after an initial impact speed of 18 meters per second (40 mph). \n    \n    Partnership\n    \n    In order to create Pathfinder’s mission-critical airbags, NASA’s Jet Propulsion Laboratory (JPL) collaborated with Frederica, Delaware’s ILC Dover, which solicited a bid from New Ipswich, New Hampshire’s Warwick Mills Inc. to weave the textiles. Founded in 1888, Warwick Mills has a long history in weaving textiles and a long history with NASA as well, having woven fabrics for reentry parachutes and the Apollo recovery floats in the 1960s. The company began developing high-performance flexible composites in 1991 in order to address needs in the military, industrial, marine, and aerospace markets.\n    \n    According to John Cronin, one of Warwick’s public safety equipment program managers, the company was one of the first weavers of Vectran, a liquid-crystal polyester fiber noted for its strength as well as its resistance to impact and abrasion. After receiving a request from JPL to weave a lightweight and yet strong fabric for the Mars airbags, Warwick, in collaboration with the engineering team at ILC Dover, decided to use a blend of coated Vectran fibers, due to Vectran’s strength and reliability in cold temperatures. Warwick’s team also engineered a process to apply thin coatings to the woven Vectran, which added strength while remaining lightweight.\n    \n                      \n                \n      \n      \n        \n      \n      \n        Available in the TurtleSkin line are puncture-resistant and needle-resistant clothing, such as these gloves. The TurtleSkin products are in use by various law enforcement groups around the world.\n      \n    \n                      After Warwick wove the fabric, the completed airbag prototypes first underwent tests at ILC Dover and then at Glenn Research Center’s Plum Brook Station Space Power Facility in a simulated Martian atmosphere. According to Chuck Sandy, chief engineer at ILC Dover, “Warwick provided valuable insight to the team as a number of iterations of candidate materials (different weaves, weights, and layup combinations) were fabricated and subjected to customized rock impingement testing at ILC.” During this testing, the JPL team discovered that the most effective design would incorporate multiple layers (up to four, depending on the location of the airbag) of lightweight fabric. The outer layers could tear and absorb more energy from impact while protecting the inner layers. \n                        \n    Charlie Howland, Warwick’s chief engineer and CEO, explains that the collaborative design and testing with NASA and ILC Dover yielded several benefits for Warwick, including new enthusiasm for design possibilities. “What this project provided for us was this innovative spark,” he says. “This was able to really get our engineering staff excited and looking at high-performance fibers that were emerging.” In addition, the company also learned new techniques for improving the fiber’s tear resistance and refining test methods. \n    \n    Warwick also benefited enormously from learning how to weave textiles in new ways and incorporate coatings. “What makes Warwick Mills unique,” Howland says, “is our patented weaving and finishing technique, which we developed for the Mars airbags.”\n    \n    Product Outcome\n    \n    From the late 1800s until the early 1990s, Warwick’s core business was weaving textiles. Today, however, the company is known primarily as an engineering firm with a range of manufacturing capabilities. In its TurtleSkin line, Warwick Mills offers protective apparel and safety products, using similar weaving techniques the company used in developing the Mars airbags and applying different composites and laminates to fabric. “From the knowledge and engineering experience we gained while working on the airbags,” Cronin says, “we were able to develop high-performance protective products for public safety.” \n    \n                      \n                \n      \n      \n        \n      \n      \n        Using a tight weaving technique, Warwick Mills created SoftPlate body armor, which offers flexibility, comfort, and armor concealment.\n      \n    \n                      Many of the company’s products are based on the company’s uniquely tight weaving technique, Cronin says. “We have made a series of modifications to high-speed rapier looms to control warp yarn tension and support extremely high weaving forces.” The result, Howland adds, is that the fabric has the tightest weave possible. To penetrate TurtleSkin fabrics, sharp objects must actually break the fibers, rather than simply push them to the side. Howland notes that in protective applications, this allows the creation of significantly lighter and more flexible fabric than had previously been possible. \n                        \n    The TurtleSkin products offer resistance from a variety of forces, and include ballistic-resistant body armor, stab-resistant body armor, and puncture-resistant clothing. According to Cronin, the body armor uses a tightly woven blend of Vectran, Dyneema, and Twaron to protect the wearer from knife injuries (in stab armor and cell extraction vests) and blunt impact and firearms (in the SoftPlate body armor). Cronin explains that the tight weave in the stab- and spike-resistant fabrics is the critical element for protection from various weapons: “When you stitch a button on your shirt, you don’t actually make a hole in the fabric; the tip of the needle simply gets between the weave and spreads the fibers apart momentarily so you can drag the thread through. With TurtleSkin, the fibers don’t shift.” Because the fibers do not shift, weapons or bullets are far less able to separate the fibers and pierce the skin.\n    \n    Using this tight weaving technique, Warwick Mills also created Metal Flex Armor (MFA), and SoftPlate body armor. MFA offers stab protection from ice picks, hypodermic needles, and knives, and is a composite of hard steel elements laminated to Twaron woven fabric. This flexible laminate offers protection comparable with rigid steel plates in other body armor products, but with higher mobility and comfort. Over 50,000 MFA vests have sold. Like the MFA, the SoftPlate body armor offers flexibility, comfort, and armor concealment, but is designed to defeat handgun bullets (instead of piercing weapons). The manufacturing process for both of these laminates combines the tightly woven fabric with proprietary coating and finishing techniques developed during the NASA collaboration.\n    \n    Public safety and military customers now benefiting from the TurtleSkin products include the United States Marine Corps, the New York State Department of Corrections, the Federal Bureau of Prisons, and police departments throughout the United States. The products are also in use by civilian law enforcement groups throughout the world including agencies in the Netherlands, Korea, and Peru. \n    \n    Warwick Mills continues to reap new benefits from its NASA collaboration as it plans to offer a new TurtleSkin product soon: flexible ballistic vests that resist rifle rounds. Like the MFA line, this new technology “combines the benefits of ceramic and high-performance textiles that are direct descendants of the Mars bags,” says Cronin.\n    \n    Vectran® is a registered trademark of Kuraray Co. Ltd. \n    TurtleSkin® is a registered trademark of Warwick Mills Inc.\n    Dyneema® is a registered trademark of Royal DSM N.V.\n    Twaron® is a registered trademark of Teijin Twaron USA Inc.\n    SoftPlate™ is a trademark of Warwick Mills Inc.\n    Kevlar® is a registered trademark of E. I. du Pont de Nemours and Company.\n    Spectra® is a registered trademark of Honeywell International Inc.\n    \n    \n    \n                      \n                        \n                        \n                        \n                        \n                      \n                      \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ch_1.html","text":"Forecasting Tools Point to Fishing Hotspots","image":"http://spinoff.nasa.gov/Spinoff2009/images/WorldWinds_1.jpg","story":"\n                      Consumer, Home, and \n                      Recreation\n                                              \n                      Originating Technology/NASA Contribution \n                        \n                        Sport fishing is an uncertain pastime. Some days the fish are biting; others, not. But for captains of charter fishing boats and recreational fishermen making the most of a day off from work, returning without a catch is more than just a disappointment—it can have a financial impact as well, from wasted gas to frustrated clients taking their business elsewhere. Thanks to an evolving commercial partnership, oceanic data gathered by NASA satellites is now helping take the guesswork out of finding fishing hotspots. \n                        \n                      \n          \n                        \n                        \n                          \n                        \n                        \n                          FishBytes, featuring a database of 18 fish species, uses sea surface temperature and chlorophyll levels measured by NASA satellites to help anglers locate the best areas for their favorite catches. \n                        \n                      \n                      In 1997, NASA launched the first of more than \n                        20 satellites that now comprise the Earth Observing System (EOS). EOS was designed to provide space-based measurements and imagery of Earth’s surface and atmosphere to help scientists understand climate change and humans’ role in it on a long-term, global scale. However, NASA soon realized that the EOS was making unique observations of weather and the ocean, as well.\n                        \n                        In 2002, NASA established the Short-term Prediction Research and Transition Center (SPoRT) at Marshall Space Flight Center to facilitate the use of real-time EOS measurements for short-term weather forecasting—the prediction of weather on a scale of hours, rather than days or weeks. SPoRT uses EOS and other satellite data to provide a suite of NASA products to address challenging forecast issues such as visibility reduction due to clouds and fog at night; the timing and location of severe weather; flood potential due to runoff from snow melt; and the prediction of cloud cover, temperature changes, and precipitation in coastal regions associated with sea breeze fronts. SPoRT repackages the satellite data into useful formats and shares it, along with other tools like forecast models, with government entities like the National Oceanic and Atmospheric Administration (NOAA) and the National Weather Service, as well \n                        as private sector organizations like television’s The Weather Channel.\n                        \n                        “We don’t just throw data over the fence,” says Dr. Gary Jedlovec, SPoRT’s principal investigator. “We work closely with these end users to understand what their forecast problems are and then match our data capabilities to their forecast problems.” \n                        \n                        Partnership\n                        \n                        WorldWinds Inc., a private weather forecasting company based in Slidell, Louisiana, approached SPoRT in 2006 seeking use of the program’s oceanic data. WorldWinds has an extensive history of NASA partnership; it was originally a part of User Systems Enterprises Inc., developed from founder and former Jet Propulsion Laboratory scientist Walt McCandless’s Phase I and II Small Business Innovation Research (SBIR) contracts with Stennis Space Center in the early 1990s. (McCandless used his SBIR research to help address the lack of atmospheric and meteorological data over the open ocean, using radar backscatter off the water to determine wind speeds.) WorldWinds was established from User Systems’ Stennis office in 2000. Beginning in 2003, the company conducted Phase I and II SBIR research on high-resolution, radar-based digital elevation models to determine accurate storm surge predictions.\n                        \n                      \n                      \n                        \n                          \n                        \n                      \n                      WorldWinds, which gathers weather and oceanic information from multiple sources and packages it into publicly useable products, was impressed by SPoRT’s data capabilities related to sea surface temperature (SST) and chlorophyll, \n                        \n                        the light-absorbing, energy-producing material found in plants like tiny, oceanic phytoplankton. SPoRT had developed an algorithm that compensates \n                        for holes in SST data caused by cloud cover that interferes with satellite readings. WorldWinds was interested \n                        in utilizing SPoRT’s SST capacities and developing a similar cloud-hole compensating algorithm for chlorophyll data. The company entered into a cooperative agreement with SPoRT to produce the algorithm, which was recently completed.\n                        \n                        “WorldWinds is what I call a value-added forecaster,” Jedlovec says. “They take some of these basic building blocks that NASA is providing and create tailored products for a specific end user in the commercial sector.”\n                        \n                        Product Outcome\n                        \n                        WorldWinds was featured in Spinoff 2002 with an eponymous weather forecasting product that utilized NASA satellite data for weather forecasting accurate to 1 kilometer. Since then, the company has expanded its product capabilities. In 2006, Baron Services Inc.—a Huntsville, Alabama weather solutions company that also evolved from a NASA partnership and was featured in Spinoff 1993—approached WorldWinds to develop a fisherman’s dream: a method of forecasting favorable conditions for certain fish populations. The result, which incorporates SPoRT SST and chlorophyll data, \n                        is FishBytes. \n                      \n                      \n                        \n                        \n                          \n                        \n                        \n                          FishBytes draws on chlorophyll data like that from NASA’s Aqua satellite, used to generate this composite map.\n                        \n                      \n                      FishBytes guides fishing enthusiasts to areas most likely to be populated by target species. The system operates using two main components. First, it features a current database of 18 pelagic fish species popular with anglers, including tuna, mahi-mahi, sailfish, marlin, and tarpon. The database contains information such as known SST and salinity preferences for each species, as well as the fish’s favored proximity to land, depth ranges, and attraction to underwater geological features. \n                        \n                        Second, the system gathers environmental information from a range of sources, including SPoRT, and compares these numbers to its fish preferences database. The results are remarkably accurate predictions of specific fish population locations within a 2-kilometer range. \n                        \n                        “We’ve had great feedback from people saying FishBytes works even better than they expected,” says Elizabeth Valenti, WorldWinds president. “The fishermen love it.”\n                        \n                        The key to the system’s effectiveness, says Valenti, is its ability to detect the lines between temperature and chlorophyll differences in the ocean. FishBytes uses a proprietary edge-detection algorithm to determine where these edges occur. “Fish tend to congregate at these chlorophyll or SST lines,” says Valenti. “We use other data to make our predictions, but these two characteristics seem to be the most important.” Small fish are attracted to areas high in chlorophyll-containing phytoplankton, a source of food; these fish in turn attract the larger species that anglers like to target. \n                        \n                        WorldWinds sends the FishBytes data to the WxWorx division of Baron Services, which then broadcasts the service as part of XM WX Satellite Weather’s Master Mariner package, which also includes WorldWinds weather data that enables anglers to track storms as well as fishing hotspots. XM WX is part of XM Satellite Radio, the Nation’s leading satellite radio service. So far, Valenti says, XM WX has about 8,500 subscribers receiving FishBytes data on XM Satellite GPS devices. \n                        \n                        Besides its effectiveness at pinpointing fish hangouts, FishBytes has significant range; while most current fish forecasting systems are limited to small regions, Valenti notes, FishBytes covers the Atlantic, Caribbean, and Gulf of Mexico (with coverage of the Pacific coming soon). The XM Satellite footprint reaches 600 miles offshore in all directions from the continental United States. \n                        \n                        WorldWinds plans to expand its database of fish species, helping anglers save gas and time tracking down their favorite catches, all with the continued partnership of NASA.\n                        \n                      “As a taxpayer, you see millions of dollars being invested in NASA, and technology transfer programs like SPoRT help people realize benefits from the tax dollars used to fund this research,” says Valenti. “It’s something that they deserve.”\n                      \n                      The Weather Channel® is a registered trademark of The Weather Channel Inc.\n                        FishBytes™ and WxWorx™ are trademarks of Baron Services Inc.\n                        XM WX Satellite Weather® is a registered trademark of XM Satellite Radio Inc.\n                        \n                        \n                        \n                        \n                          \n                          \n                          \n                          \n                        \n                      \n                      "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ch_2.html","text":"Air Purifiers Eliminate Pathogens, Preserve Food","image":"http://spinoff.nasa.gov/Spinoff2009/images/0300225.jpg","story":"\n            Consumer, Home, and \n                      Recreation\n                      \n                      Originating Technology/NASA Contribution\n                  \n    In order for NASA astronauts to explore the solar system, they will need to travel not just as pioneers but as settlers, learning to live off the land. Current mission needs have NASA scientists exploring ways to extract oxygen from the lunar soil and potable water from human wastes. One of the basic goals, however, will be for pioneering space travelers to learn to grow and manage their own crops. This requires the development of space-age greenhouses where astronaut farmers can experiment with harvesting large-scale food crops. \n    \n            \n            \n      \n      \n        \n      \n      \n        Dr. Weijia Zhou (left), director of the Wisconsin Center for Space Automation and Robotics at the University of Wisconsin-Madison, inspects soybeans grown in the plant growth unit aboard the International Space Station (ISS). Coating technology used inside the miniature plant greenhouse removes ethylene, a chemical produced by plant leaves that can cause plants to mature too quickly. \n      \n    \n            In the 1990s, researchers at the Wisconsin Center for Space Automation and Robotics, a NASA research partnership center at the University of Wisconsin in Madison, sponsored by Marshall Space Flight Center’s Space Product Development program, produced an ethylene reduction device for a plant growth unit. Ethylene is a naturally occurring, odorless, colorless gas given off by plants that hastens the ripening of fruits and the aging of flowers, encouraging decay. Comprised of carbon and hydrogen, in closed growing environments, like on a spacecraft or in a terrestrial greenhouse, ethylene builds up quickly and plants mature too fast. Removing ethylene, therefore, is important to preserving crops not just in space, but also on Earth, where grocers and florists have an interest in reducing the gas that ultimately shortens the shelf life of their products. \n                  \n              The ethylene reduction device, also called the ethylene “scrubber,” draws air through tubes coated in thin layers of titanium dioxide (TiO2). The insides of the tubes are exposed to ultraviolet light, which creates a simple chemical reaction, converting the ethylene (C22H4) into trace amounts of water (H2O) and carbon dioxide (CO2), both of which are actually good for plants. \n              \n              The ethylene scrubber first launched aboard Space Shuttle Columbia mission STS-73 in 1995, where onboard the spacecraft the device was used successfully to preserve a crop of potato seedlings. Subsequent evolutions of the technology were flown aboard numerous International Space Station (ISS) expeditions.\n              \n              Partnership\n              \n              KES Science & Technology Inc., a Kennesaw, Georgia-based company specializing in sustaining perishable foods, licensed the ethylene scrubbing technology from the University of Wisconsin (Spinoff 2001 and 2002). KES partnered with Akida Holdings, of Jacksonville, Florida, which now markets the NASA-developed technology as AiroCide. According to the company, it is the only air purifier that completely destroys airborne bacteria, mold, fungi, mycotoxins, viruses, volatile organic compounds (like ethylene), and odors. What’s more, the device has no filters that need changing and produce no harmful byproducts, such as the ozone created by some filtration systems. \n              \n              Now in widespread use, the device is still helping preserve fresh foods, but has also seen applications in the medical and dental fields as well as in killing airborne pathogens, including anthrax and dust mites. One of the most recent applications of this NASA technology now available is in a new line of home refrigerators. Other companies have begun looking at using the device for treating whole house systems. \n              \n              Product Outcome\n              \n              KES and Akida categorize the AiroCide customer-base into three distinct fields: food preservation, health care, and private spaces. As Marc Anderson of the University of Wisconsin explains, “One of the great uses of this device is for removing ethylene, but it really cleans any organic material from the air, including odors, bacteria, volatile organic compounds of all sorts, and will even remove inorganics, like sulfur compounds.” \n              \n                    \n            \n      \n      \n        \n      \n      \n        Now in widespread use, the ethylene-removal technology developed for the ISS is still helping preserve fresh foods and has also seen applications in the medical and dental fields, as well as in killing airborne pathogens, including anthrax and dust mites.\n      \n    \n            Food preservation customers include supermarkets like Whole Foods; produce distribution facilities like those operated by Del Monte; food processing plants; wineries; distilleries; restaurants; and large floral shops. Reeves Floral, an AiroCide user, reported 92-percent reductions in airborne mold and a 58-percent drop in airborne bacteria levels in just the first 24 hours it had the units operating in its floral storage warehouse. The AiroCide units can be used in walk-in coolers to preserve freshness of produce during storage and transport, to increase safety in food preparation areas, to kill bacterial contaminants in flowers (botrytis), and to protect against spoilage \n              and contaminants.\n              \n              AiroCide has seen new consumer applications in food preservation. The technology is now incorporated into a line of refrigerators, high-end consumer models that preserve freshness and reduce food waste. The refrigerator recycles the air every 20 minutes, reducing odors, viruses, and bacteria, as well as eliminating the presence of veggie-wilting ethylene. \n              \n              The same technology has also seen use in remote regions of the world, where harsh environments and underdeveloped infrastructure complicate food storage and distribution. AiroCide units have currently been deployed to India and the Gulf Cooperation Council, which includes the countries of Bahrain, Kuwait, Quatar, Oman, Saudi Arabia, and the United Arab Emirates. \n              \n              In these areas, where refrigerated trucks carry groceries from rural farmland to towns miles away, the AiroCide unit preserves freshness and prevents food spoilage. The units are also found in food storage facilities, preventing mold growth and the spread of disease. \n              \n              In the health care arena, AiroCide units have been incorporated into doctors’ clinics and operating rooms, as well as in waiting areas, an oft overlooked location rife with germs and bacteria like respiratory influenza or mycobacterium tuberculosis and frequented by people with compromised immune systems. Operating rooms are similarly prone to germ and bacteria infiltration. The rooms are cleaned and sanitized initially, but the incoming doctors, equipment, and even the patients contaminate the air. With AiroCide units mounted in the ceiling, an operating room becomes safer for all inhabitants, as harmful bacteria like methicillin-resistant Staphylococcus aureus (MRSA) and vancomycin-resistant Enterococcus, and the fungi Penicillium and Aspergillus are removed from the air. In addition to eliminating virtually all known airborne germs and diseases, the technology reduces the burden on high-efficiency particulate air (HEPA) filters and laminar flow environments. These same air-cleaning properties have also been applied to neonatal wards. \n              \n              In addition to preserving produce and maintaining healthy air in medical settings, the AiroCide units have been adapted for use in everyday living environments. In hotels, for example, the units eliminate mold, mildew, germs, and unwanted odors. These same features are also useful in offices, where illnesses caused by airborne organisms can lower productivity. In homes, the AiroCide units help eliminate the growth of mold and fungi as well as eliminate allergens like pet dander and dust mites.\n              \n              AiroCide® is a registered trademark of KesAir Technologies LLC. \n                \n                \n                \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ch_3.html","text":"Fabrics Protect Sensitive Skin from UV Rays","image":"http://spinoff.nasa.gov/Spinoff2009/images/spf_1.jpg","story":"\n            Consumer, Home, and \n                      Recreation\n                        \n                      Originating Technology/NASA Contribution\n                  \n    Beginning in 1968, NASA began researching garments to help astronauts stay cool. The Agency designed the Apollo space suits to use battery-powered pumps to circulate cool water through channels in the inner layers of the garments. This led to commercial cooling vests for patients with heat control disorders (first featured in Spinoff 1979) and for workers in heat stress occupations (featured in Spinoff 1982). \n    \n            \n            \n      \n      \n        \n      \n      \n        A team from Johnson Space Center worked with Solar Protective Factory Inc. (SPF) to create cool suits that enable sun-sensitive patients to play outdoors.\n      \n    \n            Space suits not only keep astronauts cool, but also use multiple layers of heavy fabric to block the Sun’s ultraviolet (UV) rays from burning the skin. The first commercial cool suits had been designed primarily to keep patients cool, but were not designed specifically to block UV rays.\n                  \n              In 1997, late Johnson Space Center engineer Robert Dotts, assistant director of Technology Transfer and Commercialization, headed a team to continue the research from the first generation of cool suits after receiving a request for help from a family with two children suffering from life-threatening sun sensitivities. In order to both prevent the Sun’s light from damaging their skin and also to keep the patients cool, Dotts hoped to develop UV-blocking technology in a fabric that—unlike in a bulky space suit—could remain comfortable, light, and breathable in the sun and heat. Dotts, engineers Dominic Del Rosso and Evelyne Orndoff, and NASA physician Smith Johnston discussed requirements, identified materials, and then began testing fabrics from private industry at NASA’s White Sands Test Facility.\n              \n              Partnership\n              \n              In the summer of 1997, Dotts contacted Terry Breese, president of Solar Protective Factory Inc. (SPF), a Madison, Wisconsin-based company that had been developing commercial UV-resistant fabrics since 1989. “Dr. Dotts was very concerned about the manufacturing standards and testing methods we employed to measure ultraviolet transmittance,” Breese says, remembering when NASA first contacted his company to request fabrics for testing. \n              \n              With NASA’s input, SPF developed its “Solarpro-tiferous” process, which enhances fabric reflectivity and UV absorption with special chemical treatments added during the dying process. In this process, SPF uses charcoal, coconut, and titanium in its fabrics to reflect UV rays or to help transfer UV light into heat, which then disperses quickly. Dotts and NASA engineers provided SPF with feedback on fiber structure during development, suggesting combinations of high-loft synthetic fibers and spandex blends to keep the fabric as tightly knit as possible while also being comfortable, breathable, moisture-wicking, and reflective. Too much elasticity, the engineers explained, would allow too much UV light through when the fabric stretched. The team determined the optimal amount of spandex in the suits was 8–9 percent when blended with a high-loft nylon thread. Because of the life-threatening sensitivity of these patients to light or heat, the Johnson team required the fabric, according to Breese, “to perform at the highest possible protection level and still be comfortable.”\n              \n              The prototypes for the second generation of protective cool suits consisted of a hat, gloves, socks, pants, scarf, goggles, and jacket—truly covering the wearer from head-to-toe—that incorporated the earlier built-in water channels under layers of UV-blocking fabric, thereby protecting patients with both light and heat sensitivities.\n              \n              Del Rosso, the cooling system specialist on the project, explains that the Johnson team used NASA’s research and experience in cooling astronauts to adapt the cool suits for the young, sun-sensitive patients. These improved cool suits were far lighter than the first generation of cool suits from a decade before, enabling pediatric patients to play outdoors in sunlight for the first time. The new prototypes still used two layers of garments like before, but now the UV-blocking outer fabric was far lighter and more breathable.\n              \n              In subsequent versions of the suit, the team replaced the water tubing with simple pockets that held refrigerated gel packs. These gel packs were not as effective at keeping patients cool, but they were far less costly and less cumbersome than the tubing, which had required a motorized pump attached to a belt. The gel packs also allowed young patients more freedom of movement than the tubing, adding a level of independence to their new outdoor activities.\n              \n              NASA helped SPF further enhance the suits’ safety by using lapped seams with non-overlying stitch lines, which prevent light from entering through seams. According to Del Rosso, this lap stitching is used in some NASA pressure garments to prevent stitch holes from compromising suits’ protective qualities.\n              \n              After deciding on the fabric blend and overall suit design, the Johnson team collaborated with SPF and the Hypohidrotic Ectodermal Dysplasia (HED) Foundation (later called the Sarah Moody Foundation), in Hampton, Virginia, to provide over 1,000 suits to patients with severe light sensitivities and heat disorders. These disorders include the namesake HED, a lack of sweat glands that can lead to severe and sometimes fatal heat exhaustion; Xeroderma Pigmentosum, in which the DNA cannot repair ordinary skin damage caused by sun exposure; and polymorphic light reaction syndrome (PLRS), severe skin blistering caused by exposure to ordinary sunlight. Patients with neurological pain caused by neuropathy and multiple sclerosis also benefit from the cooling effects of the suits. \n              \n              In the fall of 1997, Breese, Del Rosso, Dotts, and Johnston accompanied PLRS patients Ryan and Kyle Richards as the boys experienced their first time in the Florida sun, on a family trip to Walt Disney World that would not have been possible without the cool suits. Calling the trip one of the highlights of his life, Breese is proud of having worked with NASA to design the UV-blocking fabric and looks forward to future collaboration. “If it weren’t for NASA’s development of their space suits with the cooling vest technology,” Breese says, “none of this project could have happened.” \n              \n              Product Outcome\n              \n              In 2009, SPF’s 20th year in business, ordinary beachgoers are now benefiting from the NASA and SPF partnership. The UV-blocking fabric, first used to help protect the most sensitive patients from damaging sun and heat, is now being used in swimwear and clothing for the public. \n              \n                    \n            \n      \n      \n        \n      \n      \n        SPF uses UV-blocking fabrics it developed with NASA in its Aquaweave and Solarknit product lines. The apparel blocks at least 98 percent of ultraviolet rays, in part due to special stitching and SPF’s Solarprotiferous process, which enhances fabric reflectivity and UV absorption by applying charcoal, coconut, and titanium in a finishing process.\n      \n    \n            SPF categorizes its UV-blocking fabrics into two main categories: Solarweave and Solarknit, which include lines of woven or knit fabrics, respectively. The NASA fabric is incorporated into the Solarknit products, which have more stretch while still providing UV protection. The NASA collaboration, Breese says, allowed them to create a comfortable fabric that has the benefits of both the UV-blocking ability of a knit and the breathability and elasticity of a weave. \n                  \n              Breese reports that customers feel cooler in the SPF clothing, which he attributes to its NASA-tested fabric. “The type of fibers we use, along with highly controlled knitting and weaving techniques, create a denser shade under the fabric that enhances the cooling effect,” he says. \n              \n              SPF’s newest sun-protective fabric, Aquaweave, uses the NASA-derived Solarprotiferous technology to provide better skin protection at the beach or pool than ordinary swimwear. In order to produce the UV-protective swimsuits, SPF added chlorine resistance and more elasticity to the original NASA-derived UV-blocking fabric. The apparel blocks at least 98 percent of UV rays, a feature that lasts for at least 40 machine washings. In addition to swimwear, SPF also offers a full line of machine-washable sun-protective clothing, which uses the NASA fabric. “Our partnership with NASA has helped us develop all levels of sun-protective apparel,” Breese says. Whether the fabric is worn by sun-sensitive patients, or just by sunbathers, the technology from NASA’s original space suits is now protecting more than just astronauts.\n              \n              Solarweave®, Solarknit®, Aquaweave®, and SPF® are registered trademarks of Solar Protective Factory Inc.\n              Walt Disney World® is a registered trademark of The Walt Disney Company.\n                \n                \n                \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ch_4.html","text":"Phase Change Fabrics Control Temperature","image":"http://spinoff.nasa.gov/Spinoff2009/images/HOF-Medal.jpg","story":"\n            \n                Consumer, Home, and \n                  Recreation\n                  \n                  \n                          Originating Technology/NASA Contribution\n                  \n              Since designing the first space suits in the 1950s, NASA has been interested in developing materials to keep astronauts comfortable and cool. In order to protect an astronaut from the extreme temperatures in space, engineers at Johnson Space Center created liquid-cooled garments that run water in small channels throughout the suit in what is called an active control system. However, in the 1980s, NASA began to investigate passive control strategies—fabric that could control temperature without pumped liquids—building on work by the U.S. Air Force. \n              \n              Phase change materials (PCMs) control temperature swings in textiles using passive control strategies. These PCMs change state at different temperatures, such \n              as when wax melts and reforms as it heats up and cools off. In 1987, Johnson began actively seeking collaboration with private industry to develop PCMs for space suits and particularly for use in astronaut gloves during extravehicular activities. \n              \n              Partnership\n              \n              Triangle Research and Development Corporation (TRDC), of Research Triangle Park, North Carolina, participated in two Phase I Small Business Innovation Research (SBIR) contracts in 1987 and 1988 with Johnson to assist in the creation of phase change materials for NASA. Prior to these contracts, the company demonstrated the value of manufacturing textiles containing microencapsulated phase change materials (mPCMs) for the Air Force. \n              \n              Boulder, Colorado-based Gateway Technologies Inc. (first featured in Spinoff 1997) then acquired the exclusive patent rights for incorporating phase-change technology in commercial fibers and fabrics from TRDC. In 1997, Gateway Technologies changed its name to Outlast Technologies Inc. and incorporated the mPCMs, which the company calls Thermocules, into all of its products. These mPCMs are now integrated into textiles and onto garments to provide greater comfort and temperature control for consumers in bedding, medical supplies, outdoor gear, and a full line of apparel for both ordinary and extreme conditions.\n              \n              Product Outcome\n              \n              With over 20 patents in fabric technologies, Outlast is a leader in creating new applications and products for mPCMs. The company regularly announces new products, which include active, casual, and nighttime apparel for men and women, as well as leather jackets, gloves, and winter sporting apparel from dozens of company partners in the United States and around the world. Some of these well-known partners include the Burton Corporation, the Timberland Company, Dillard’s Inc., Eddie Bauer Inc., Jos A. Bank Clothiers Inc., and Marks & Spencer PLC. \n              \n                    \n            \n      \n      \n        \n          \n        \n      \n      \n        Outlast Technologies Inc. incorporates microencapsulated phase change materials (mPCMs) into all of its products, including automobile seat covers, bedding products, and a full line of apparel for both ordinary and extreme conditions. These mPCMs provide greater comfort by trapping and then releasing stored heat as needed.\n                    \n          Images courtesy of Outlast Technologies Inc. \n      \n    \n            The Outlast Thermocules react to temperature fluctuations, with the encapsulated materials changing from liquid to solid and vice-versa as they release or absorb excess heat, depending on the environment. This feature allows Thermocules to be used in a variety of clothing and consumer goods to maintain more comfortable, slow-changing temperatures near the body. Thermocules are incorporated into or onto fibers, fabrics, and finished garments. \n                  \n              Since creating its first process with the Thermocules, Outlast has added new techniques for applying the temperature-controlling technology to different fabrics. Initially, Outlast only offered its products in acrylic fiber as well as coating the technology onto fabrics through a process called matrix coating technology (MCT), but the company has since added three new ways to offer this temperature-regulating benefit: Outlast matrix infusion coating (MIC), Outlast infusion technology, and Outlast viscose fiber.\n              \n              In 2006, in partnership with fiber manufacturer Kelheim Fibres GmbH, Outlast announced its manufactured cellulosic viscose, similar in texture to rayon or silk. This lightweight, easy-to-clean material enables temperature control in delicate garments, including blouses, intimate apparel, dresses, and sleepwear. Outlast has also used viscose to complete its line of bedding products by offering viscose sheets, which, when used with Outlast’s existing line of bedding products already in the market, offer consumers new control over temperature fluctuations during sleep, simply through the fabrics around them. New Outlast brand nightshirts, made with a cotton viscose blend, may also help mitigate discomfort from night sweats.\n              \n              Most of the bedding products offered by Outlast are created with the original MCT process, which allows for the most loading of Thermocules. Fabrics using this process tend be stiffer and heavier and less ideal for soft items worn close to the skin, but the benefits of having more Thermocules are especially noticeable in car seat covers, outerwear (including jackets, hats, and shoes), rugged outdoor clothing (including winter boots), and bedding (including mattress pads, blankets, duvets, and pillows). \n              \n              In 2008, Outlast revealed its new MIC process to help improve the temperature-adapting qualities of natural fiber products and its mattress products, and to expand the types of fabric offering Thermocules in general. The MIC process, in essence, screenprints an advanced formulation of microscopic Thermocules onto flat fabrics, providing manufacturers a more affordable method of adding temperature regulation to existing fabric prior to garment construction. Previous coatings were often too heavy for next-to-skin applications, but this new process is lightweight, and according to Outlast technical director Mark Hartmann, “It gives the temperature-regulation benefits of Outlast technology needed for next-to-skin applications and the wicking capabilities of polyester.” It is especially useful for woven fabrics like cotton and polyester for polo shirts and sleepwear. Some of the brands offering apparel in this line are Reebok and Marks & Spencer. In spring 2008, Outlast announced this technology would be incorporated in the COCOON MummyLiner sleeping bag product by Design Salt USA; the MIC process allows these liners to be breathable and have wicking abilities, while keeping the sleeper comfortable in the outdoors. \n              \n              The Outlast infusion technology, also initiated in 2008, is a spray process created for finished apparel such as t-shirts, socks, underwear, and shirts, and is not for thick or layered products. This technology offers manufacturers an easy way to apply Outlast technology to existing apparel without changing texture. \n              \n              Outlast has seen success in its phase change products, increasing its sales by 400 percent from 2002 to 2008, and the company announces new products regularly. CEO Greg Roda says the company’s research and development team is regularly “innovating and developing new applications” for the phase-change technology. Other new products are motorcycle apparel, snowboarding boots, and wheelchair seat cushions and covers, which keep skin drier and cooler to prevent pressure ulcers (also called bedsores). \n              \n              “Outlast is proud to be in the Space Technology Hall of Fame, which recognizes life-changing technologies emerging from America’s space program,” says Roda. He concludes, “The relationship with NASA gives us credibility within our various market segments to develop products that bring comfort to people on Earth.”\n              \n              Outlast Infusion™ is a trademark of Outlast Technologies Inc. \n              Thermocules® is a registered trademark of Outlast Technologies Inc.\n              COCOON MummyLiner™ is a trademark of Design Salt USA.\n                \n                \n                \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ch_5.html","text":"Tiny Devices Project Sharp, Colorful Images","image":"http://spinoff.nasa.gov/Spinoff2009/images/displaytech_3.jpg","story":"\n            Consumer, Home, and \n                      Recreation\n                      \n                      Originating Technology/NASA Contribution\n                  \n    Johnson Space Center, NASA’s center for the design of systems for human space flight, began developing high-resolution visual displays in the 1990s for telepresence, which uses virtual reality technology to immerse an operator into the environment of a robot in another location. Telepresence is used by several industries when virtual immersion in an environment is a safer option, including remote training exercises and virtual prototyping, as well as remote monitoring of hazardous environments. Microdisplay panels, the tiny screens that comprise the visual displays for telepresence, are also used in some electronic viewfinders for digital video and still cameras. \n    \n    Partnership\n    \n            \n            \n      \n      \n        \n        Ferroelectric liquid-crystal-on-silicon (FLCOS) panels need a smooth and shiny wafer top surface, which is possible with chemical mechanical planarization (CMP), a special technique of polishing semiconductor wafers to allow more metal layers—and smoother integrated-circuit surfaces. \n              \n              Image courtesy of Displaytech Inc. and Micron Technology Inc.\n      \n    \n            In 1993, Johnson Space Center granted a Small Business Innovation Research (SBIR) contract to Displaytech Inc., based in Longmont, Colorado, and recently acquired by Micron Technology Inc., of Boise, Idaho. Under Phase I of this contract, Displaytech began developing miniature high-resolution displays based on its ferroelectric liquid-crystal-on-silicon (FLCOS) technology. Displaytech proposed that pixels could be made small enough to fit a complete high-resolution panel onto a single integrated circuit. \n                  \n              Displaytech first determined how to make a panel that could reproduce grayscale using only standard complementary metal-oxide-semiconductor (CMOS) logic circuitry, which just recognizes binary values (such as a “0” for black and a “1” for white) and was not well suited for subtle shades of gray. Dr. Mark Handschy, Displaytech’s chief technology officer, explains the company perfected time-based grayscale techniques in a Phase II follow-on NASA contract: “Because our ferroelectric liquid crystal material can switch faster than the eye can follow, a sequence of displayed black and white images is averaged by the eye into a single grayscale image.” \n              \n              For FLCOS panels to work well, Handschy explains, they need a smooth and shiny wafer top surface. Without this, the pixel mirrors form in the last metal layer on the semiconductor wafer, scatter, and then absorb light, resulting in a dim appearance. “The Phase II of our NASA SBIR came at a very opportune time,” Handschy says. “We were able to have an SXGA [super-extended video graphics array] CMOS backplane we’d designed under the NASA project using one of the first commercially available CMP silicon processes.” Chemical mechanical planarization (CMP) is a special technique of polishing semiconductor wafers to allow more metal layers—and smoother integrated-circuit surfaces—and was one of the factors that led to Displaytech’s success. \n              \n              Another important development during the mid-1990s was the introduction of efficient blue light-emitting diodes (LEDs). Displaytech took these bright blue LEDs and combined them with red and green LEDs to illuminate its panels, rapidly sequencing through the color LEDs to create the illusion of different hues as they reflect off the panels. “In this SBIR program, we developed grayscale and color for microdisplay panels,” Handschy says, “And that was a first for us. We’ve since leveraged that into a line of products.”\n              \n              Product Outcome\n              \n                    \n            \n      \n      \n        \n        Displaytech Inc. uses its FLCOS technology to apply active matrix displays to a tiny silicon chip, with a final product smaller than a thumbnail. A thin layer of fast-switching liquid crystal material allows the circuitry to drive reflective pixels on the surface of the chip.\n          \n          Image courtesy of Displaytech Inc. and Micron Technology Inc.\n      \n    \n            Displaytech uses its FLCOS technology to apply active matrix displays (individual switching elements) to a tiny silicon chip, with a final product smaller than a thumbnail. These silicon chips are essentially encased \n              in a glass window, Handschy says. “There’s this thin layer of fast-switching liquid crystal material which allows \n              \n              that circuitry to drive reflective pixels on the surface of the chip.” \n              The company’s first microdisplay panels were used in electronic viewfinders in camcorders and digital still cameras. Since 1990, Displaytech has shipped over 20 million microdisplays to some of the world’s largest consumer electronics companies, including JVC America, the Eastman Kodak Company, Olympus Corporation, Hitachi Ltd., Konica Minolta Holdings Inc., Kyocera Communications Inc., and the Hewlett-Packard Company.\n              \n              Handschy says the company’s LightView products, “which all have NASA heritage,” are now being used in a new product: pocket projectors, or “pico” projectors. \n              (A pico is a metric unit smaller than a nano.) Until recently, images and videos displayed on media players and cell phones were constrained by tiny, hard-to-see screens, making it difficult to share images, such as for a business presentation. \n              \n              Currently, these pico projectors are sold as separate “accessory projectors” for existing hand-held devices, and attach via a universal serial bus cable. (Future media players and cellular phones will incorporate the pico projectors in their design and will not need any attachments for projection.) In these tiny devices, high-brightness LEDs shine through the microdisplays, magnifying the tiny images into large, colorful, sharp images 50 inches across, projected onto walls or screens large enough for groups of people to view together.\n              \n                    \n            \n      \n      \n        \n        Displaytech Inc. uses its FLCOS technology to apply active matrix displays to a tiny silicon chip, with a final product smaller than a thumbnail. A thin layer of fast-switching liquid crystal material allows the circuitry to drive reflective pixels on the surface of the chip.\n      \n      \n        \n         \n      \n    \n            Handschy says the microdisplays are the company’s most popular products, whether for camera viewfinders or the new projectors. Currently, camcorders and digital cameras comprise the main market for Displaytech’s microdisplays, but pico projectors are soon expected to dominate the company’s sales. \n                  \n              “We hope to sell a lot more in the new market of pico projectors,” Handschy says. Displaytech customer 3M currently incorporates the microdisplay in its Micro Professional Projector, an accessory projector that weighs only 5.6 ounces and is sold in major office suppliers and electronics retailers. Displaytech believes sales of pico projectors may exceed $1.1 billion within 5 years. Today, the company’s research and development is funded primarily from product revenue, but Handschy says Displaytech is still open to more contracts or collaborations with NASA.\n              \n              In May 2009, Displaytech and Micron Technology Inc. announced Micron’s acquisition of Displaytech to broaden its semiconductor offerings, including products for pico projectors.\n              \n              Displaytech® is a registered trademark of Micron Technology Inc.\n              LightView™ is a trademark of Micron Technology Inc.\n                \n                \n                \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/er_1.html","text":"Star-Mapping Tools Enable Tracking of Endangered Animals","image":"http://spinoff.nasa.gov/Spinoff2009/images/Animal_Tracking_2.jpg","story":"\n            Environmental and \t\t\t\tAgricultural Resources\n                      \n                      Originating Technology/NASA Contribution\n                      \n                      Try this: Print out a lower-case letter “o” in Times New Roman, 10-point font. Now hold the paper at arm’s length. Viewed from this distance, the area inside the “o” is approximately equal to the area observed in the Hubble Ultra Deep Field, an image taken by the Hubble Space Telescope. Within that space—only one thirteen-millionth of the sky’s total area—Hubble revealed approximately 10,000 galaxies, each containing billions of stars. The observable universe as a whole contains some 80 billion galaxies and anywhere between 30 and 70 billion trillion stars.\n                      \n                \n            \n                  \n                  \n                    \n                  \n                  \n                    Researchers at the University of Central Florida track polar bears by using the bears’ unique whisker spot patterns to match photographs taken by researchers and tourists.\n                  \n                  \n                      In order to map the intimidating fields of stars Hubble—among other sensitive telescopes—would uncover following its launch in 1990, astronomers needed a powerful tool for comparing and matching star configurations within the telescope’s collected images. In 1986, Princeton University physics professor Edward J. Groth, supported by the Hubble Space Telescope program, invented a pattern-matching algorithm that addressed the challenge. The Groth algorithm forms triangles between every possible triplet of stars in an image (each star’s position being represented by an x-y coordinate pair). It then compares the triangles’ measurements to those in other images, determining any matches. Because certain properties of a triangle do not change if the triangle is rotated or altered in size, the algorithm allows astronomers to effectively map star locations using images of different magnification and orientation.\n                        \n                      The Groth algorithm was incorporated into the Space Telescope Science Data Analysis System (STSDAS), a software suite for calibrating, analyzing, and reducing data gathered by Hubble. An updated version of the algorithm is still part of STSDAS, which is available to the public from the Space Telescope Science Institute, a NASA partner located in Baltimore, involved with management of Hubble and the currently under-development James Webb Space Telescope. \n                      \n                      Partnership\n                      \n                      In 2002, Portland, Oregon, software programmer and technical writer Jason Holmberg had a rare encounter with a whale shark while scuba diving in the Red Sea. Growing to lengths of up to 40 feet, the filter-feeding whale shark is the world’s largest—and among its least understood—fish species. It is also listed as vulnerable to extinction by the International Union for Conservation of Nature. Fascinated, Holmberg began toying with ideas to help improve methods for tracking the unusual fish. (Physically tagging the sharks for satellite tracking proves inefficient because the tags are frequently lost or rendered inoperative within weeks or a few months; with plastic visual tags, less than 1 percent are spotted again after tagging.) Holmberg eventually teamed­ with marine biologist Brad Norman, founder of the Perth, Australia, nonprofit ECOCEAN, which studies the whale sharks that migrate annually through Western Australia’s Ningaloo Marine Park. Norman had been tracking the Ningaloo sharks by photographing and identifying each shark from the distinctive white spots on its skin, a marker as unique as fingerprints are in humans. The process was a tedious one; Norman had to examine and compare all photos by eye. \n                      \n                      For help conceiving a computer-based tracking system, Holmberg turned to friend Dr. Zaven Arzoumanian, an astrophysicist with Universities Space Research Association on contract at Goddard Space Flight Center, who contributed to the undertaking as a side project independent of his NASA duties. The pair were contemplating the challenge of identifying whale sharks in an automated way when they encountered the Groth algorithm, which provided an ideal basis for creating a pattern-matching program using shark spots instead of stars in the universe. (Fittingly, the whale shark’s name in Madagascar, “marokintana,” means “many stars,” while “geger lintang,” its Javanese name, means “stars in the back.”) Holmberg and Arzoumanian modified the algorithm, applying a technique called blob extraction to pinpoint single-color pixel groups—a useful tweak since the whale shark’s spots are larger and more irregular \n                      in shape than stars in photographs. They also introduced rotation correction and contrast enhancement elements to clarify photos, compensate for perspective issues (the sharks are rarely photographed in perfect profile), and take into account 3-D qualities not present in space images. \n                      \n                      “What we did in practice was make a very precise algorithm a little less precise,” says Arzoumanian. Since its completion in 2005, the modified Groth algorithm has proven to be highly effective: When a match between photographs is made, the algorithm ranks the correct shark as the first of all possible matches more than \n                      90 percent of the time.\n                      \n                      Product Outcome\n                      \n                      Holmberg built a database system around the algorithm that allows anyone, from researchers to tourists, to submit whale shark photographs for comparison and identification online. Called the ECOCEAN Whale Shark Photo-identification Library, the system has been used by ECOCEAN to collect images of over 1,600 whale sharks so far, providing a continuing data span that is helping researchers to learn more about the life histories and migration patterns of the elusive fish, as well as the status of the whale shark’s threatened population. \n                      \n                      \n                      \n                        \n                        \n                          \n                        \n                        \n                          Thanks to a modified NASA algorithm, the general public can now help marine biologists track rare species like whale sharks. \n                        \n                      \n                      “We’re getting reliable population models, and we’re challenging a lot of previous conceptions about whale sharks,” says Holmberg, who notes that findings indicate the sharks may not be as massively migratory as once thought, nor may their numbers be declining, at least at Ningaloo Marine Park, as with most shark species. Photographs are now streaming into the ECOCEAN database from places as diverse as California, Mozambique, Belize, Honduras, and the Maldives. Holmberg credits this to the impact of ecotourism and the “citizen scientist,” the average person contributing valuable scientific information. \n                        \n                      “The general public collects a lot of data,” he says. “We’re talking about an animal considered to be rare, maybe a couple of hundred documented sightings in all of history. Now, just this year, we’ll get over 2,400.” Holmberg is now working on a simplified version of the software for easier use by individual researchers studying other species. \n                      \n                      The successful application of the modified Groth algorithm has attracted significant attention from scientific circles. Last year, researchers at the University of Central Florida (UCF), in Orlando, adapted the whale shark algorithm as part of a package for tracking polar bears. A threatened species in the United States, polar bears can be tracked using their own individually unique trait: the whisker spots on their muzzles. UCF researchers are compiling a database of photographs with the help of tourists visiting Churchill, Canada, a popular destination for polar bear enthusiasts. The polar bear population at Churchill has been declining dramatically, according to the Canadian Wildlife Service.\n                      \n                      “This virtual mark-recapture capability allows people who are going to an ecotourism environment to have a positive effect on the animals. They all become our field assistants in a way,” says Jane Waterman, associate professor of biology and one of the principal investigators of the polar bear project. The database will provide an essential resource for understanding bear behavior and monitoring the bear population as the species suffers the effects of global warming.\n                      \n                      The polar bear library is only the most recent application of the pattern-matching algorithm. “We’ve had lots of people approach us from various animal-tracking communities,” says Arzoumanian. California researchers are considering adapting the algorithm to track Mola mola, the ocean sunfish that frequents the waters off the Galápagos Islands. And the Megafishes Project, a collaboration between the National Geographic Society and the World Wildlife Fund, may apply it to track giant Eurasian trout in Mongolia. In theory, the algorithm can be applied to track any animal with unique spotting that does not change as it ages. \n                      \n                      “There’s a groundswell of data we’re getting,” says Holmberg, “and it all goes back to the algorithm Edward Groth wrote years ago.”\n                      \n                      \n                      \n                      \n                        \n                        \n                        \n                        \n                      \n                      \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/er_2.html","text":"Nanofiber Filters Eliminate Contaminants","image":"http://spinoff.nasa.gov/Spinoff2009/images/R-D_thumb.jpg","story":"\n        \n                      Environmental and \t\t\t\tAgricultural Resources\n                      \n                      Originating Technology/NASA Contribution\n                  \n    Water, an increasingly precious commodity on Earth, has always been priceless in space; but “priceless” is a figure of speech—water in space does have a price, and it is an expensive one. A single gallon of water costs over $83,000 to launch just into low-Earth orbit. Despite recent NASA innovations that allow astronauts to derive potable water from their own sweat and urine and technologies that may one day extract water from buried glaciers on Mars, the availability of water in space is not likely to exceed its necessity. This means methods for recycling and purifying water remain a top concern for the Space Program. \n    \n    Partnership\n      \n      \n      \n        \n      \n    \n    \n      \n      \n        \n        The NanoCeram water filter’s nanoalumina fibers are shown here capturing fumed silica particles of a similar size to viruses.\n      \n    \n    NASA’s Johnson Space Center awarded Argonide Corporation, a nanomaterials company, headquartered in Sanford, Florida, a Phase I Small Business Innovation Research (SBIR) contract in 2000 and a Phase II SBIR contract in 2002. Argonide had developed unique filtration media with the potential to revolutionize water purification and provide methods for sanitizing recycled water in space. Working toward a basic tool for water recirculation during long-term space flight, Argonide used its Phase I research to build on its proprietary technology, initially developing laboratory filter discs and syringes. During Phase II, it researched and tested the nanofiber media’s virus filtration properties and its ability to absorb DNA and RNA. Argonide also developed NanoCeram cartridges providing superior purification for drinking water applications. The NanoCeram water filter was an R&D Magazine “R&D 100” award-winning technology in 2002 and was inducted into the Space Foundation’s Space Technology Hall of Fame in 2005. \n        \n      The special ingredients of Argonide’s nonwoven filtration media are nanoalumina fibers made up of the mineral boehmite. The NanoCeram fibers—each 2 nanometers in diameter and 200–300 nanometers in length (for comparison, a sheet of paper is roughly 100,000 nanometers thick)—are attached to microglass strands. The result looks like nanosize mascara brushes. With a surface area of as much as 500 square meters per gram, the fibers produce an electropositive charge when water flows through them. Many impurities carry a slight negative charge and are thus absorbed by the nanoalumina. A single layer of the resulting media, though it has a pore size of about 2 microns, is capable of removing greater than 99.99 percent of 0.025 micron particles, thanks to this property. (Three layers remove up to 99.9999 percent.) Some of the many impurities the filter media remove are bacteria, viruses, cysts, organic debris, parasites, and dissolved and particulate metals such as iron and lead. Its large pore size relative to the particles it eliminates means the filter achieves the grail of filtration media: high flow with high dirt-holding capacity and low pressure drop.\n      \n    \n    \n      \n      \n        \n        The filtration capabilities of these NanoCeram PAC cartridges are enhanced by powdered activated carbon. The Disruptor media can retain virtually any nanopowder, adapting to remove specific contaminants from water.\n      \n    \n    “Our NASA-funded research provided us with information, know-how, and techniques that enabled us to develop our current technology,” says Fred Tepper, Argonide’s founder and president. \n        \n        Product Outcome\n        \n      Since Argonide’s nanoalumina filtration media was first featured in Spinoff 2004, its production has expanded, thanks to a licensing agreement that has resulted in a host of new applications and recognitions. In 2006, the company exclusively licensed the filter media to Ahlstrom Corporation, a leading specialty paper and nonwoven roll goods manufacturer, headquartered in Finland, with multiple plants and offices in the United States. Ahlstrom began mass-producing and globally promoting the technology under the name Disruptor. \n      \n      Ahlstrom’s large-scale production capabilities gave Argonide access to mass quantities of the nanofiber roll media for large-scale production of its NanoCeram filter cartridges. It scaled up the size of its cartridges, ultimately producing 4½-inch-diameter by 40-inch-longcartridges, which \n      according to Tepper allowed Argonide to move beyond the retail market and into the industrial and municipal sectors. \n      \n      In mid-2007, Argonide’s new NanoCeram filters caught the eye of major automobile manufacturer Toyota. Concerned with reducing the size of its U.S. plants’ “water footprint”—the amount of water the plants consume—the company had committed to scaling back its water use during manufacturing from the Toyota-standard \n      900 gallons per car to 300 gallons. In order to purify recycled water, Toyota uses reverse osmosis (RO) membranes, which tend to foul easily, even with the use of standard prefilters. Toyota was using prefilters that let through too many RO-membrane-fouling particles; in one plant, this required the expensive membranes to be replaced every 2 to 3 months. Since utilizing the NanoCeram cartridges as prefilters in that plant, the RO membranes have yet to require cleaning or replacement. Toyota has also used NanoCeram filters to cleanse the roughly 16 miles of chill water pipes in a typical plant. The filters have solved a long-standing corrosion problem by removing its cause: iron oxide and the bacteria that feeds on it. \n      \n    \n    \n      \n      \n        \n        Argonide’s SBIR-developed NanoCeram filters are already yielding significant benefits for industrial water filtration and may soon do the same for municipal water supplies.\n      \n    \n    Argonide’s filtration media continues to evolve. Ahlstrom is now producing the nanoalumina media with a new component: powdered activated carbon (PAC), which is retained by the nanofibers and enhances the media’s filtration abilities even further. The Disruptor PAC media, which Argonide uses to create its NanoCeram PAC cartridges, has been certified for the purification of drinking water by NSF International, a nonprofit, nongovernmental group that certifies products for public health and safety. Tepper notes that the nanoalumina media can retain virtually any nanopowder desired, meaning it can be adapted to remove specific contaminants from water. \n        \n      That kind of efficiency and versatility has the nanofiber media poised to be a major player in a number of burgeoning applications. Tepper expects that, by 2011, the U.S. Environmental Protection Agency (EPA) will require municipalities to monitor their water for viruses. (Currently, only bacteria monitoring is required, though Tepper says viruses cause roughly 50 percent of waterborne gastrointestinal illnesses.) The EPA has expressed satisfaction with the NanoCeram filter as a virus sample collector in such a monitoring capacity. In addition, “The desalination business is growing by leaps and bounds,” says Tepper, who points out that the RO membranes used in extracting fresh water from our planet’s oceans will benefit, like Toyota’s, from NanoCeram prefilters that remove the cellular material that causes membrane biofouling. And, he notes, all municipal water ultimately will be RO treated as well, providing another opportunity for Argonide and NASA to benefit Earth’s water supplies.\n      \n      NanoCeram® is a registered trademark of Argonide Corporation.\n      Disruptor™ is a trademark of Ahlstrom Corporation. \n      \n      \n      \n      \n        \n        \n        \n        \n      \n    \n    "},{"href":"http://spinoff.nasa.gov/Spinoff2009/er_3.html","text":"Modeling Innovations Advance Wind Energy Industry","image":"http://spinoff.nasa.gov/Spinoff2009/images/Viterna_4.jpg","story":"\n            Environmental and Agricultural Resources\n                  \n                                  Originating Technology/NASA Contribution \n                  \n                      \n            \n    \n    \n      \n    \n    \n      For over 20 years, NASA’s 4-megawatt WTS-4 wind turbine held the world record for maximum power output.\n    \n  \n            One morning in 1990, a group of Glenn Research Center (then Lewis Research Center) employees arrived to find their workspace upended by an apparent hurricane. Papers were scattered, lights blown out. All eyes turned to \n              the door connecting the office to its neighbor: a 20-foot wind tunnel.\n              \n              The employees did not know it, but they had \n              Dr. Larry Viterna to thank for the state of their workspace. An innovation by the NASA researcher may have led to the accidental trashing of their office, but it would go on to benefit the entire field of wind energy. \n              \n              Viterna joined NASA in 1977, during a time when the country was in an energy crisis. Growing anxiety over fuel costs and environmental impacts led the U.S. Government to explore alternative and renewable energy sources. In a time prior to the formation of the Department of Energy (DOE), the government turned to other agencies like NASA to develop solutions. Glenn had a history of energy research stemming from its work in fuel-efficient aeronautics during World War II and in alternative fuels and related aerospace engines at the start of the Space Age in the 1950s. When Viterna joined the Center, \n              it had already assumed the lead role in the Nation’s \n              wind energy program. NASA’s goal was to develop technology for harnessing the wind’s power and transfer it to private industry.\n              \n              “Our center had an expertise in propellers, propulsion, rotating equipment, and power systems,” making Glenn a natural choice for the job, explains Viterna. The Center’s efforts, he says, ultimately laid the foundations for much of the wind technologies and industry that exist today. \n              \n              Glenn constructed its initial experimental 100-kilowatt (kW) wind turbine at the Center’s Plum Brook Station facility in Sandusky, Ohio in 1975. The Mod­-0 turbine was a two-bladed, horizontal turbine. By 1978, the 2-megawatt (MW) Mod-1, the world’s first multimegawatt wind turbine, was developed—capable of providing electricity to thousands of homes. Successive experimental models (13 in all) were built throughout the country. Viterna notes that these were also record setting in size and output; the 4-MW capability of the WTS-4 turbine, built in 1982 in Medicine Bow, Wyoming, was not surpassed for about 25 years. \n              \n              “That’s how far ahead the program was in terms of developing this technology,” Viterna says.\n              \n                      \n            \n    \n    \n      \n    \n    \n      Glenn Research Center’s Icing Research Tunnel (IRT), built at the end of World War II to study aircraft icing, is one of the world’s largest refrigerated wind tunnels and currently the Center’s busiest facility.\n    \n  \n            NASA’s efforts also led to other industry innovations that are standard today. As Glenn researchers explored ways of reducing the weight and cost of turbine structures, they developed steel tube towers that replaced the rigid truss towers traditionally used. “Today, virtually every large wind turbine uses a steel, tubular tower, which was novel technology at the time,” says Viterna. \n                  \n              Despite the advances made by the NASA-led program, there were still significant challenges. “One of the key things then and now is to accurately predict the forces exerted on a wind turbine,” Viterna says. On a basic level, wind turbines function by the same forces that allow airplanes and helicopters to fly. Wind blowing over the turbine’s blades, or airfoils, creates lift that turns the blades, spinning a shaft that connects to an electricity-producing generator. When engineers first began to model the impact of these forces on wind turbine airfoils in high-wind conditions, they would produce results that were off by at least 50—and sometimes as much as 100—percent. \n              \n                      \n            \n    \n    \n      \n    \n    \n      By shaving the IRT’s wooden fan blades in accordance with the results of Dr. Larry Viterna’s model, Glenn engineers boosted the tunnel’s top wind speed by over 130 miles \n        per hour. \n    \n  \n            The problem was that wind turbines, unlike most other airfoil-based systems, operate at a high angle of attack—the angle formed between the chord of an airfoil and the direction of the airflow. (A chord is an imaginary line through an airfoil’s cross-section, joining the tip of the trailing edge to the center of the leading edge.) In airplanes, when the angle gets too large, the laminar air flow that typically hugs the wing begins to detach and become turbulent, reducing lift and increasing drag; at a certain point, the plane stalls and drops out of the sky. (This could theoretically happen with helicopter blades as well, but these vehicles do not operate near stall conditions.) Wind turbines, especially in high-wind conditions, can routinely stall, limiting the ability of the turbine to produce electricity. The inability to properly predict stall behavior, actual aerodynamic loads, and the relationship between wind speed and power in wind turbines led to inefficient designs and costly turbine failures. At the time, there was a significant lack of research and data in this area, Viterna explains, as well as “three-dimensional effects going on that we had no way of calculating or even measuring.”\n                  \n              In 1981, using data previously collected from an old Danish turbine, coupled with test data gathered by fellow NASA researcher Robert Corrigan from the Plum Brook turbine, Viterna developed a model that took into account three-dimensional effects and predicted stall behavior with far greater accuracy than previous methods.\n              \n              The model was not well accepted by colleagues in the wind energy field, Viterna remembers. “I almost got laughed off the stage when I presented it,” he says, explaining that the model violated existing theories that used two-dimensional airfoil data. Viterna, however, continued to employ the model for NASA’s purposes, even using it in 1991 to improve Glenn’s Icing Research Tunnel, designed to study the effects of ice buildup on aircraft. Based on the model’s results, Viterna suggested that slightly shaving down the wood fan blades could boost the tunnel’s 299-miles-per-hour (mph) capability. During a nighttime test, the wind tunnel’s pressure release door flew open, sending 400-mph winds ripping through the adjoining work area. (The tunnel’s new upper limit after implementing Viterna’s model: 430 mph.) The surprise Viterna’s coworkers encountered the following morning was on par with what Viterna experienced during a random Internet search nearly 25 years after inventing his model. \n              \n              Partnership\n              \n                      \n            \n    \n    \n      \n    \n    \n      Aerostar’s wind turbines are stall regulated, a feature enabled by the Viterna model.\n    \n  \n            In 2005, long after the easing of the energy crisis and shift of the wind energy program to the DOE, Viterna, now in Glenn’s Office of Strategic Management, was searching the Internet when he began to come across multiple references to the “Viterna method” by experts \n              in the wind energy field. He discovered his initially criticized model had, within a decade of its creation, quietly become the established method of modeling \n              the performance of wind turbine airfoils under high angles of attack—stall conditions. \n              \n                      \n            \n    \n      \n    \n  \n            “It had become, and still is, the most widely used stall model in the United States,” says Viterna, who along with Corrigan recently received a “Space Act Award” from NASA’s Inventions and Contributions Board, as well as the Agency’s inaugural “Blue Marble Award” at its Environmental and Energy Conference. \n                  \n              Among the many who use the Viterna method is the DOE’s National Renewable Energy Laboratory’s National Wind Technology Center (NWTC), located in Boulder, Colorado. In 2005, the center added the Viterna model to its design-code software suite for horizontal-axis wind turbines, the most popular variety of turbines in use today. \n              \n              “Viterna’s model does a very effective job of estimating stall behavior on inboard sections of the blade and how it varies along the blade’s span,” says Dr. Sandy Butterfield, wind program chief engineer at the NWTC. “Even though it was invented in the 1980s, it remains a model used by engineers predicting performance and loads for wind turbines.”\n              \n              The NWTC suite—which offers design and analysis software tools for use in achieving worldwide certification of wind turbines—incorporates Viterna’s model in its FoilCheck preprocessor. FoilCheck allows users to generate airfoil tables and compute dynamic stall parameters for use in NWTC’s AeroDyn software library, which enhances the center’s YawDyn, FAST, and ADAMS turbine simulators. The entire suite is available to private industry for free, which has enabled wind turbine manufacturers like Westport, Massachusetts-based Aerostar Inc. to use Viterna’s method to help craft their products. \n              \n              Product Outcome\n              \n              Aerostar produces a 6-meter, 10-kW wind turbine, the design for which was developed in the 1980s by company president Paul Gay, as well as a recently added 11-meter, 30-kW model. Aerostar wind turbines are designed to provide electricity to individual homes, farms, and remote locations with limited or no connection to the power grid. As opposed to a rigidly mounted, three-blade design—the three blades commonly seen on wind turbines today are a feature imported from Denmark and Germany, which became the main technology drivers in wind energy following NASA’s major involvement—Aerostar’s turbines feature teetering, two-bladed rotors like NASA’s early models. This design helps lower the weight and cost of the structure by reducing the large, gyroscopic loads typically inflicted on the turbine and its tower.\n              \n              The company’s turbines belong to a class called fixed pitch turbines. The rotors of fixed pitch turbines turn at a relatively constant speed regardless of the current wind speed. This is in contrast to variable speed turbines (a NASA-developed technology), in which the rotor speed varies with the wind speed. While variable speed turbines have the advantage of producing more power as wind speeds increase, the frequency, voltage, and current of their output also varies, requiring a line commutated inverter to make the output compatible with the power grid. Fixed pitch turbines like Aerostar’s, however, use induction motors to produce electricity. The same kind of motor used in common technologies like water pumps and air conditioners, an induction motor transforms into a generator when its shaft rotates at speeds faster than it turns as a motor. The induction generator is already in phase with the electrical current supplied by the power grid, so the cost and inefficiency of an additional inverter is unnecessary. \n              \n                      \n            \n    \n    \n      \n    \n    \n      The teetering, two-bladed rotor of Aerostar’s wind turbines is similar to that of NASA’s early designs.\n    \n  \n            Because Aerostar’s turbines are of this variety, the Viterna model plays a major role in the manufacture of its products. The company employs the NWTC suite, including FoilCheck, when designing its wind turbines. Utilizing the Viterna method through this software has enabled Aerostar to create efficient, effective turbine designs, says Gay. \n                  \n              “The model makes it possible for manufacturers like us to predict and characterize the performance of airfoils \n              for these turbines,” he says. Viterna’s model is highly important to Aerostar’s turbines because, like many fixed pitch turbines, they are actually regulated by stall, the conditions Viterna’s model was the first to accurately predict for wind turbine airfoils. \n              \n              A constant-speed rotor will only operate effectively in a narrow range of wind speed, Gay explains. Above that range, the airfoils go into stall, and power production tapers off. Aerostar’s turbines and many others utilize stall regulation as an automatic, passive way of managing the turbine at high wind speeds—like a built-in power governor. This eliminates the need for moving parts, which are required for blade pitching, furling, and other active power-limiting devices. \n              \n              “If you can’t calculate how the rotor performs at these higher wind speeds, you might find it producing way too much power, burning out the generator,” Gay says. Being able to accurately predict stall behavior allowed for this kind of control, says Viterna. \n              \n              “We were trying to simplify the design of wind turbines early on to get the market going,” Viterna says. “It was very important to get the entire industry off and running with a design capable of operating reliably in a passive control mode.” (The effort worked: Fixed pitch turbines comprised 60 percent of turbines worldwide \n              by 1991.)\n              \n              The Viterna method is finding applications beyond horizontal wind turbines; Viterna has discovered his once-mocked model is now employed for vertical wind turbines, wind tunnels, and even underwater turbines that make use of tidal energy to produce power. In the meantime, NASA continues to be involved in the advancement of wind energy; Glenn, for example, is supporting the plans of Cuyahoga County, Ohio, to establish on Lake Erie the world’s first freshwater, offshore wind turbine site. \n              \n              The Agency can also expect to see its early work experience a resurgence, predicts Dr. Butterfield of the NWTC. “As the industry moves forward and becomes more competitive and broad, you will see efforts to explore lower cost, more structurally efficient machines, and that’s when people will begin to capitalize again on that good work NASA did in the early 1970s and 1980s,” he says. It seems likely that Viterna’s and NASA’s pioneering work will continue to play a significant role given the Nation’s ambitious energy goals: The DOE has outlined a plan for generating as much as 20 percent of the country’s energy from wind power by 2030.\n              \n              \n              \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/er_4.html","text":"Thermal Insulation Strips Conserve Energy ","image":"http://spinoff.nasa.gov/Spinoff2009/images/R-D_thumb.jpg","story":"\n            \n              Environmental and Agricultural Resources\n              \n                                  Originating Technology/NASA Contribution \n                  \n                    \n            \n      \n      \n        \n      \n      \n        The remarkable insulating properties of aerogels have made them the focus of significant NASA research. \n      \n    \n            Launching the space shuttle involves an interesting paradox: While the temperatures inside the shuttle’s main engines climb higher than 6,000 °F—\n              hot enough to boil iron—for fuel, the engines use liquid hydrogen, the second coldest liquid on Earth after liquid helium. \n              \n              Maintained below 20 K (-423 °F), the liquid hydrogen is contained in the shuttle’s rust-colored external tank. The external tank also contains liquid oxygen (kept \n              below a somewhat less chilly 90 K or -297 °F) that combines with the hydrogen to create an explosive mixture that—along with the shuttle’s two, powdered aluminum-fueled solid rocket boosters—allows the shuttle to escape Earth’s gravity. \n              \n              The cryogenic temperatures of the main engines’ liquid fuel can cause ice, frost, or liquefied air to build up on the external tank and other parts of the numerous launch fueling systems, posing a possible debris risk when the ice breaks off during launch and causing difficulties in the transfer and control of these cryogenic liquid propellants. Keeping the fuel at the necessary ultra-cold temperatures while minimizing ice buildup and other safety hazards, as well as reducing the operational maintenance costs, has required NASA to explore innovative ways for providing superior thermal insulation systems. To address the challenge, the Agency turned to an insulating technology so effective that, even though it is mostly air, a thin sheet can prevent a blowtorch from igniting a match. \n              \n                    \n            \n      \n      \n        \n      \n      \n        Despite a ghostly appearance like a hologram, aerogels feel like Styrofoam. A NASA partnership led to flexible aerogels found in commercial applications today.\n      \n    \n            Aerogels were invented in 1931 and demonstrate properties that make them the most extraordinary insulating materials known; a 1-inch-thick piece of aerogel provides the same insulation as layering 15 panes of glass with air pockets in between. Derived from silica, aluminum oxide, or carbon gels using a supercritical drying process—resulting in a composition of almost 99-percent air—aerogels are the world’s lightest solid (among 15 other titles they hold in the Guinness World Records), can float indefinitely on water if treated to be hydrophobic, and can withstand extremely hot temperatures (from 1,100 °F to 3,000 °F depending on the type of aerogel) down to cryogenic levels, making this “frozen smoke” ideal for use in space. Because of its low weight and ability to withstand temperature extremes, an aerogel was even used as the space-based catcher’s mitt to trap comet particles and space dust for NASA’s Stardust mission, launched in 1999. \n                  \n              All of this remarkable technology’s characteristics were ideal for NASA’s purposes except one: The aerogels were extremely brittle. Through a long-term partnership between Kennedy Space Center and Aspen Aerogels Inc., of Northborough, Massachusetts, researchers developed a flexible, durable form of aerogel that NASA has since used as cryogenic insulation for space shuttle launch systems. Through Aspen Aerogels, the technology has made oil pipeline insulation, extreme weather clothing, and infrared shielding for combat helicopters. \n              \n              Partnership\n              \n              Aspen Aerogels, which developed the \n              “R&D 100” award-winning flexible aerogels under Small Business Innovation Research (SBIR) contracts with Kennedy, approached Acoustiblok Inc., of Tampa, Florida, to perform acoustical testing on its Spaceloft flexible aerogel to explore the potential for enhancing the aerogel’s sound-muffling capabilities. Acoustiblok is an industry leader in acoustical insulation (one-eighth of an inch of Acoustiblok, the company’s proprietary acoustical insulation, reduces more sound than 12 inches of concrete when added to a stud wall) and has previously conducted research with NASA on floor resonance—reducing sound from one floor of a building to the next. Impressed by the aerogel’s qualities, Acoustiblok considered aerogel products for enhancing energy efficiency that could take advantage of the company’s expertise in providing sound insulation for buildings and other applications. \n              \n              While a great deal of energy conservation efforts focus on transportation, “Estimates are that over 50 percent of the energy in the United States is used within buildings,” says Lahnie Johnson, Acoustiblok’s president and founder. He also notes that energy consumption in buildings results in an estimated 46 percent of the Nation’s carbon emissions. Because of this, Acoustiblok saw great potential in engineering a narrow strip of flexible aerogel to be applied to wall studs in buildings to break the thermal transfer (thermal bridging) between the interior and exterior of building walls. The companies arranged for Acoustiblok to take over the production and marketing of this aerogel application. \n              \n              Product Outcome\n              \n              Thermal bridging is an acute problem when it comes to insulating buildings, says Johnson. Over 30 percent of the energy used for temperature control in buildings escapes through walls, more than through the floor, windows, or roof, which is why Johnson foresees a significant impact from his company’s aerogel product: Thermablok.\n              \n              “We see Thermablok as having incredible market potential and providing a benefit to people all over the world,” he says. \n              \n                    \n            \n      \n      \n        \n      \n      \n        Thermablok strips are easily applied to wall studs, providing an affordable and environmentally friendly boost to a wall’s insulation factor.\n      \n    \n            Manufactured by Acoustiblok, Thermablok is a thin, 3/8-inch-thick by 1½-inch-wide strip of flexible aerogel in a plastic casing with a peel-and-stick adhesive backing. The strips are 100-percent recyclable, comprised of more than 30-percent recycled material, and allow low-cost, low-emissions shipping due to their virtually weightless composition. According to tests conducted by the U.S. Department of Energy, a ¼-inch-thick strip of Thermablok applied to wall studs before the installation of drywall increases the wall’s insulation factor by \n              30 percent; a 3/8-inch-thick strip produces an increase of 42 percent. As an example, Acoustiblok notes that a typical 2,400-square-foot Midwest home (16-inch, on-center stud framing; standard insulation; wood siding) outfitted with Thermablok would save over $700 annually in energy costs with an accompanying 3.9-ton reduction in carbon dioxide emissions. The strips can be easily cut to any length and applied using the adhesive backing \n              or staples.\n              \n                    \n            \n      \n        \n      \n    \n            Johnson says Acoustiblok is currently acquiring numerous construction contracts and getting Thermablok, which is also available in sheet form, specified into public and commercial buildings. Thermablok’s hydrophobic qualities (which also render it age-resistant) make it suitable for marine applications as well. Johnson says Thermablok will see use in industrial and commercial boats and in oil rigs and refineries, where piping that is both extremely loud and extremely hot will benefit from Thermablok and Acoustiblok layered together. Lumber yards and commercial chain stores like Home Depot and Lowes are expressing interest in selling the product, as well. \n                  \n              Acoustiblok also plans to take advantage of the popularity of its acoustical insulation in the Middle East, where privacy is highly valued, to meet the need there for superior thermal insulation. Johnson anticipates developers specifying Thermablok into mega building projects in the region.\n              \n              “This is a U.S. product, a U.S. patent,” says Johnson. “It will bring significant cash flow into the U.S. while also benefiting people in other countries.” \n              \n              Johnson traces Thermablok’s potential worldwide impact back to NASA research and development. “NASA is doing things that we just can’t afford to do here in free enterprise,” he says. “It’s important people realize the real benefits of NASA’s work and how it trickles down into many aspects of our world today.”   \n              \n              Guinness World Records™ is a trademark of Guinness World Records Limited.\n              Aspen Aerogels™ is a trademark of Aspen Aerogels Inc.\n              Spaceloft® is a registered trademark of Aspen Aerogels Inc.\n              Thermablok® and Acoustiblok® are registered trademarks of Acoustiblok Inc.\n              \n              \n              \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/er_5.html","text":"Satellite-Respondent Buoys Identify Ocean Debris","image":"http://spinoff.nasa.gov/Spinoff2009/images/Driftingbuoy_1.jpg","story":"\n            Environmental and Agricultural Resources\n                  \n                      Originating Technology/NASA Contribution\n                  \n  NASA operates a series of Earth-observing satellites, which help scientists learn more about our home planet. Through partnerships with universities and other government agencies, like the National Oceanic and Atmospheric Administration (NOAA), the Space Agency helps scientists around the world capture precise movements of the Earth’s crust to learn more about the underground processes related to earthquakes and volcanic eruptions, create accurate assessments of wind resources for future energy use, and preserve endangered species by generating much-needed data about their environments. This work, done primarily from space with satellites using a variety of complex instruments to take readings of the surface below, generates leagues of valuable data that aid scientists on the ground—or in some cases—on the water. \n  \n  As much of the Earth is covered in water—liquid, frozen, saltwater, or fresh—much of NASA’s remote sensing work focuses on the oceans and their health. This valuable, mammoth (yet fragile) resource provides insight into the overall health of our planet, as water, in addition to being abundant, is a key ingredient to all known life on Earth.\n  \n  As part of its ocean-observing work, NASA partnered with NOAA and private industry to develop remote sensing technologies for protecting the seas of the North Pacific from a nefarious and pervasive problem: derelict fishing gear. \n  \n  Partnership\n  \n  Airborne Technologies Inc. (ATI), of Wasilla, Alaska, is a specialist in airborne marine surveying. Having been in business flying the northernmost state for over 25 years, the small company has developed a history of remote sensing from aircraft, aerial mapping, near-shore ocean aerial surveying for fisheries and oceanographic research, and satellite-based asset tracking and monitoring. \n  \n            \n            \n    \n    \n      \n    \n    \n      The satellite-communicating buoys designed by Airborne Technologies Inc. monitor ocean currents to locate areas where floating debris is likely to converge.\n    \n  \n            In 2001, company president Tim Veenstra attended a workshop in Anchorage where he learned of a new research opportunity sponsored by NASA and the State of Alaska. His company had already been conducting remote sensing for a number of years on a variety of projects including locating fish for commercial ventures and tracking sea birds and marine mammals for research, so this new opportunity to develop systems to track high seas debris was well within his range of expertise. ATI’s proposal was to use satellite and airborne remote sensing to locate lost and abandoned commercial fishing gear: errant drift nets known as ghost nets. \n                  \n              Drift netting is a commercial fishing practice using large (between 75 feet to over 30 miles in length) nets weighted at the bottom edge and with buoys floating the top edge. They create a vertical wall of netting in the ocean sometimes several hundred meters deep. Not anchored or attached to a boat, these huge fishing nets are sometimes inadvertently left behind or lost in storms, becoming ghost nets. \n              \n              While these floating ghost nets prove to be navigation hazards for unsuspecting ships whose propellers can get entangled, they have an even more devastating impact on the environment. Unattended nets damage coral reefs; suffocate marine mammals, sea turtles, and birds when they wash ashore; and, if left afloat, bunch up and then begin a perpetual cycle of mass fish kills—dense balls of nets heavy with trapped fish sink, are cleaned by bottom-dwelling scavengers, and float back to the surface \n              to start the cycle over. Modern synthetic netting can sustain this cycle indefinitely while drifting over a vast range: Ghost nets from around the Pacific have washed ashore on beaches as far apart as Alaska and the outer Hawaiian Islands. \n                \n              NASA and NOAA were jointly exploring ways of improving methods of locating and disposing of ghost nets before they could damage vessels and the environment. The effort was also aimed at eliminating labor-intensive manual cleanup of the nets—in the warmer waters of Hawaii usually involving divers with knives cutting the nets free of reefs or propellers and then loading them into inflatable boats—an expense estimated in the millions of dollars per year. In the frigid waters of Alaska, cleanup has been greatly restricted to beach cleanup. Finding the nets in the open ocean before they have the opportunity to cause too much harm was the preferred option, but presented another problem: It was like finding a needle in a haystack.\n              \n              Veenstra and ATI proposed using satellites to monitor the convergence of currents in order to track the paths the nets were likely to take. These spaceborne perspectives would allow researchers to scan thousands of square miles of water at a time, and ATI would provide a series of satellite-communicating buoys that would allow them to narrow the scope and determine current convergence. Knowing how the waters were naturally collecting debris, the researchers could then use sensor-equipped aircraft to find debris fields. Ships could then be deployed \n              to perform cleanup. NASA agreed to the plan, and the work started.\n              \n              After completing the work with NASA, ATI formed a new commercial division, Ocean Trek Research Inc., to expand upon the line of satellite communicating ocean buoys, opening up their use to additional markets. The original work has also led to the development of a prototype unmanned aircraft system and unique complementary software designed to process ocean images to detect debris fields. \n              \n              Product Outcome \n              \n                      \n            \n    \n    \n      \n    \n    \n      Ghost nets, abandoned or lost fishing nets, are nearly invisible yet devastating to marine ecosystems. A NASA, NOAA, and industry collaboration is using satellites and a system of buoys to locate this debris.\n    \n  \n            ATI has already built over 900 buoys, each about the size of a laundry basket. As part of the ghost net remediation project through NOAA, it makes the buoys available to vessels of opportunity, including U.S. Coast Guard and research boats—any craft out on the water in the regions where the nets might be spotted and tagged with a buoy. The tagged nets are then easy to locate and recover for crews who can then collect them. The buoys are also finding additional uses, including as makeshift floating mini-ecosystems. Nearly anything in the water will start to grow algae, which attracts small fish that eat the plants. Larger fish are then attracted to the smaller fish. Commercial fishing vessels are deploying fleets of the buoys to tag floating fish-attracting devices to help attract schools of tuna.\n                  \n              In addition to the buoys, another product that came out of this research is video processing software capable of near-real-time, simultaneous processing of up to three video feeds at a rate of 30 frames per second. It receives data from the downward-facing cameras on aircraft flying over the seas to locate the debris fields. Once set with user-defined parameters, the software is capable of telling an onboard high-resolution camera when to take a picture. It uses an adjustable algorithm and analyzes the video stream, checking for anomalies, then snapping high-resolution pictures and uploading the images to the user’s computer for analysis. \n              \n              The software is designed to complement the small unmanned aircraft system designed and currently being tested by ATI under a Phase I Small Business Innovation Research (SBIR) contract from NOAA. With the ultimate goal of expanding the visual search area of a vessel at sea, it is an all-electric, autonomous, hand-launched “marinized” aircraft capable of carrying a variety of different sensors. Just under 10 pounds with its payload, the aircraft currently has 90 minutes of battery life and a range of approximately 75 miles. It is capable of landing safely both on hard surfaces and in the water, where it can then be retrieved by the operator’s boat. ATI is currently conducting sea trials of the aircraft. \n              \n              \n              \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/er_6.html","text":"Mobile Instruments Measure Atmospheric Pollutants","image":"http://spinoff.nasa.gov/Spinoff2009/images/er_1.jpg","story":"\n      Environmental and Agricultural Resources\n                  \n                            Originating Technology/NASA Contribution\n                  \n          \n      \n    \n    \n      \n    \n    \n      Aerodyne Research Inc. (ARI) uses its Tunable Infrared Laser Differential Absorption Spectrometer (TILDAS) instruments in its mobile laboratory to measure pollutant gasses and submicron particles in a DC-8’s engine exhaust plumes.\n        \n          Image courtesy of Dr. W. B. Knighton of Montana State University\n    \n  \n      As a part of NASA’s active research of the Earth’s atmosphere, which has included missions such as the Atmospheric Laboratory of Applications and Science (ATLAS, launched in 1992) and the Total Ozone Mapping Spectrometer (TOMS, launched on the Earth Probe satellite in 1996), the Agency also performs ground-based air pollution research. The ability to measure trace amounts of airborne pollutants precisely and quickly is important for determining natural patterns and human effects on global warming and air pollution, but until recent advances in field-grade spectroscopic instrumentation, this rapid, accurate data collection was limited and extremely difficult. \n              \n        In order to understand causes of climate change and airborne pollution, NASA has supported the development of compact, low power, rapid response instruments operating in the mid-infrared “molecular fingerprint” portion of the electromagnetic spectrum. These instruments, which measure atmospheric trace gasses and airborne particles, can be deployed in mobile laboratories—customized ground vehicles, typically—to map distributions of pollutants in real time. The instruments must be rugged enough to operate rapidly and accurately, despite frequent jostling that can misalign, damage, or disconnect sensitive components. By measuring quickly while moving through an environment, a mobile laboratory can correlate data and geographic points, revealing patterns in the environment’s pollutants. Rapid pollutant measurements also enable direct determination of pollutant sources and sinks (mechanisms that remove greenhouse gasses and pollutants), providing information critical to understanding and managing atmospheric greenhouse gas and air pollutant concentrations. \n        \n        Partnership\n        \n        With a Small Business Innovation Research (SBIR) contract from Ames Research Center in 1985, Aerodyne Research Inc. (ARI), based in Billerica, Massachusetts, began developing its Tunable Infrared Laser Differential Absorption Spectrometer (TILDAS) instruments for measuring stratospheric ozone depletion and greenhouse gasses. Additional SBIR contracts followed from both Ames and Glenn Research Center to develop TILDAS for measuring ambient pollutant concentrations and pollutant source fluxes.\n        \n        ARI has also collaborated with the Agency’s Office of Earth Sciences, now part of the Science Mission Directorate, to develop innovative mobile laboratory capabilities to characterize and analyze urban air pollution. TILDAS instruments have been used in ARI’s mobile laboratories to map urban greenhouse gas and air pollutant distributions, starting with Agency-sponsored field measurements in Boston and Cambridge, Massachusetts, and in Manchester, New Hampshire in the 1990s. Later, field studies (sponsored in part by Glenn and Langley Research Center) included mobile studies of exhaust emissions from city buses in New York, traffic in Mexico City, and commercial aircraft during taxi, take-off, and landing operations at airports in Oakland, California, and Atlanta. According to ARI’s president, Charles Kolb, these projects enabled ARI to improve the company’s advanced instrumentation for mobile laboratories while providing valuable data for air quality managers working to improve urban air pollution.\n        \n        Product Outcome\n        \n        In 2002, ARI introduced a line of thermoelectrically cooled quantum cascade (QC) TILDAS instruments, which are much smaller, more highly automated, and more robust than earlier lead-salt diode laser systems. ARI developed QC-TILDAS to detect a range of more than 15 of the most important greenhouse gasses and air pollutants—including carbon dioxide, nitrogen dioxide, and methane—at sub-parts-per-billion concentrations. Depending on laser selection and tuning range, each laser can quantify one to three trace gasses. The system consists of the tunable laser, infrared detectors, power electronics, a microcomputer with integrated control and data analysis software, and an astigmatic multiple pass absorption cell. \n        \n          \n      \n    \n    \n      \n    \n    \n      In 2002, ARI introduced a line of thermoelectrically cooled quantum cascade (QC) TILDAS instruments for use in its mobile laboratories. The QC-TILDAS instruments are incorporated into a system that contains the tunable laser, infrared detectors, power electronics, a microcomputer with integrated control and data analysis software, and an astigmatic multiple pass absorption cell. \n    \n  \n      In addition to using QC-TILDAS and TILDAS instruments for mobile measurements from van, aircraft, and ship platforms, ARI and its customers and collaborators use the technology to perform eddy correlation flux measurements, a method of correlating changes in atmospheric composition of trace gasses with wind fluctuations to determine the magnitude of pollutant emission sources and sinks. Kolb explains that with this technique, the ARI team can measure nitrous oxide from fertilizer in nearby fields or can determine which neighborhoods are most affected by emissions from local airports. In the past, meteorologists quantified atmospheric heat fluxes by correlating temperature, water vapor, and wind fluctuations. “Now with rapid response laser sensors available, we can measure trace gas emission or deposition fluxes as well,” Kolb says.\n              \n        A key component to this rapid response is the QC-TILDAS astigmatic mirror absorption cell, which makes the system “tens to hundreds of times more sensitive” than most differential absorption infrared spectrometers, says Kolb. These patented cells pass a laser beam through the sample up to 300 times, producing long absorption paths of 75–300 meters, depending on cell length and mirror configuration. In essence, the longer a path the laser has, the more sensitive the measurement will be, so the long absorption path of the QC-TILDAS, combined with a very small volume sample cell, allows the atmospheric air sample to be changed 20 times per second, providing rapid measurement of changes in pollutant concentration while still providing the measurement sensitivity required. ARI can also adapt QC-TILDAS for open path measurements by replacing the absorption cell with a remote retro-reflecting mirror; the company used this configuration to profile exhaust pollutants from aircraft engines.\n        \n        QC-TILDAS uses a two-step process to detect concentrations of different airborne gasses. A QC laser (or solid-state diode laser, in the earlier system) is emitted in the molecular absorption band of the gas being measured, and then is tuned over the spectral absorption lines of that same gas. The laser’s high-spectral resolution helps isolate spectral lines of the gas with minimal unwanted interference from other molecular absorption lines. The QC-TILDAS analysis software then integrates the measured absorption lines of the sample, and compares them with a theoretical spectral absorption, based on the known spectral line strengths, line broadening coefficients, the ground state energy, and other properties of the absorption lines and the temperature and pressure in the sample cell. This basic measurement and analysis sequence is repeated many thousands of times per second, and the system then averages the results. \n        \n        Because of ARI’s development and commercialization of TILDAS (and QC-TILDAS) and the mobile laboratory, the company’s products are currently in use at numerous academic, government, and industrial air quality and climate change laboratories on five continents. Since the first field deployment of TILDAS in the 1990s, ARI continues to enable NASA and commercial customers to study air pollution in detail, and recent SBIR awards to ARI suggest more systems for monitoring air pollutants are on the way.\n        \n        \n        \n        \n          \n          \n          \n          \n        \n      \n    "},{"href":"http://spinoff.nasa.gov/Spinoff2009/er_7.html","text":"Cloud Imagers Offer New Details on Earth’s Health","image":"http://spinoff.nasa.gov/Spinoff2009/images/TC4_UAV_CPI_MOUNTING_DC-8.jpg","story":"\n            Environmental and Agricultural Resources\n                      \n                      Originating Technology/NASA Contribution\n                  \n  A                \tstunning red sunset or purple sunrise is an aesthetic treat with a scientific explanation: The colors are a direct result of the absorption or reflectance of solar radiation by atmospheric aerosols, minute particles (either solid or liquid) in the Earth’s atmosphere that occur both naturally and because of human activity. At the beginning or end of the day, the Sun’s rays travel farther through the atmosphere to reach an observer’s eyes and more green and yellow light is scattered, making the Sun appear red. Sunset and sunrise are especially colorful when the concentration of atmospheric particles is high. This ability of aerosols to absorb and reflect sunlight is not just pretty; it also determines the amount of radiation and heat that reaches the Earth’s surface, and can profoundly affect climate.\n  \n            \n            \n    \n    \n      \n    \n    \n      Stratton Park Engineering Company Inc. (SPEC) installed its Cloud Particle Imager (CPI) on NASA’s High Altitude Research Program aircraft. Research facilities around the world have since used the commercially available CPI to further atmospheric study.\n    \n  \n            In the atmosphere, aerosols are also important as nuclei for the condensation of water droplets and ice crystals. Clouds with fewer aerosols cannot form as many water droplets (called cloud particles), and consequently, do not scatter light well. In this case, more sunlight reaches the Earth’s surface. When aerosol levels in clouds are high, however, more nucleation points can form small liquid water droplets. These smaller cloud particles can reflect up to 90 percent of visible radiation to space, keeping the heat from ever reaching Earth’s surface.\n                  \n              The tendency for these particles to absorb or reflect the Sun’s energy—called extinction by astronomers—depends on a number of factors, including chemical composition and the humidity and temperature in the surrounding air; because cloud particles are so small, they are affected quickly by minute changes in the atmosphere. Because of this sensitivity, atmospheric scientists study cloud particles to anticipate patterns and shifts in climate.\n              \n              Until recently, NASA’s study of atmospheric aerosols and cloud particles has been focused primarily on satellite images, which, while granting large-scale atmospheric analysis, limited scientists’ ability to acquire detailed information about individual particles. Now, experiments with specialized equipment can be flown on standard jets, making it possible for researchers to monitor and more accurately anticipate changes in Earth’s atmosphere and weather patterns.\n              \n              Partnership\n              \n              Boulder, Colorado-based Stratton Park Engineering Company Inc. (SPEC) has won 16 Phase I Small Business Innovation Research (SBIR) contracts and 11 Phase II contracts with NASA since 1990. These contracts all related to developing atmospheric instrumentation and included: a Phase II Small Business Technology Transfer (STTR) contract in 1996 from Langley Research Center for cloud radiation measurement; a Phase II SBIR in 1999 from Jet Propulsion Laboratory for cloud particle imagers; a Phase I SBIR in 2001 from Goddard Space Flight Center for in situ lidar for cloud and aerosol radiation studies; a Phase II SBIR in 2003 for cloud micro-sensors from Goddard; and a Phase I SBIR in 2008 from Wallops Flight Facility and Goddard for advanced cloud particle probes. \n              \n              Developed with funding from the 1999 SBIR, the SPEC Cloud Particle Imager (CPI) was installed on NASA’s High Altitude Research Program aircraft, the two WB-57s based at Ellington Field near Johnson Space Center. Research facilities around the world have since used the commercially available CPI to further atmospheric study. SPEC has sold its CPIs to the National Center for Atmospheric Research, the University of Washington, the University of North Dakota, and Sandia National Laboratories, in addition to other agencies and institutions in the United States, Australia, and Canada. \n              \n              Product Outcome\n              \n                      \n            \n    \n    \n      \n      As a research aircraft flies through clouds, the externally mounted CPI captures digital images of cloud particles that range in size from 15 to 2,500 micrometers. \n    \n  \n            Recognizing the need to analyze cloud particles from close range, SPEC designed its CPI to be mounted to airplane exteriors; this robust design allows the CPI to operate in most airspeeds, altitudes, and air pressures, and to withstand vibrations and extreme temperatures as low as -70 °C. The system can also be adapted for harsh ground studies, and has been used at locations at the South Pole and New Hampshire’s Mount Washington. \n                  \n              As a research aircraft flies through clouds, the externally mounted CPI captures digital images of cloud particles. As they enter the CPI’s detection subsystem, particles cause light to scatter from two overlapping laser beams. That scattered light hits detectors and triggers the CPI’s imaging system to capture a high-resolution digital photograph of the particles using a 1-megapixel charge coupled device camera, which can image between 75 and 500 frames per second, depending on camera upgrades. The CPI captures images of particles that range in size from 15 to 2,500 micrometers, and the high-resolution images have a nominal resolution of 2.3 micrometers, displaying unprecedented detail for researchers. After capturing a particle’s image, the system transmits the information to a computer and SPEC’s CPI software, which crops and compresses the images. The system then stores the images and information for further analysis.\n              \n              SPEC’s customized post-processing software, CPIView, performs some analysis automatically, calculating perimeters, areas, lengths, and volumes. It also creates graphical displays to show researchers certain distributions, such as patterns over time and in certain locations. \n              \n                      \n            \n    \n    \n      \n    \n    \n      After SPEC’s externally mounted CPI captures a particle’s image, the system transmits the information to a computer and SPEC’s CPI software, which crops and compresses the images. The system then stores the images and information for \n        further analysis.\n    \n  \n            With such long-term studies and histograms of particle sizes, SPEC’s CPI system can help alert scientists to how the Earth’s climate is changing, and how quickly. SPEC president and CEO, Dr. Paul Lawson, explains that clouds and cloud particles have a major impact on global climate change: “If we change the mean size of cloud particles by a micron, a millionth of a meter, then that’s the same as doubling the concentration of carbon dioxide in the atmosphere,” thereby drastically increasing the lower atmosphere’s tendency to trap heat on Earth’s surface.\n                  \n              The company is now developing extremely small instruments that can image cloud particles continuously for up to 24 hours. Under the 2008 Wallops and Goddard SBIR agreement, SPEC has designed a small version of its CPI, the Micro-CPI, for small Uninhabited Aerial Vehicles (UAVs) which span fewer than 6 feet across. NASA and other agencies are using UAVs for atmospheric measurements because, among other reasons, they can fly in extremely cold or oxygen-poor altitudes. Micro-CPI—like the original CPI—measures the properties of ice crystals and water droplets, records the data onboard the UAV, and then sends them back to a computer.\n              \n              SPEC also continues to develop the other particle imaging products funded by SBIR and STTR contracts, including the in situ lidar. This instrument can measure the absorption in liquid clouds with sampling volumes of millions of cubic meters. In this technique, a laser sends out pulses of light horizontally from an aircraft inside an optically thick cloud. Meanwhile, wide field-of-view detectors measure the time series of the number of photons returned. The ultimate use of these instruments is to provide a large volume of high-quality data about clouds for climate prediction models. \n              \n              For its own studies and research using the CPI, the Micro-CPI, and the in situ lidar, SPEC makes the collected data available to the scientific community for analysis and further study, helping promote a better understanding of the Earth’s climate.\n              \n              \n              \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/er_8.html","text":"Antennas Lower Cost of Satellite Access","image":"http://spinoff.nasa.gov/Spinoff2009/images/ResearcherData.jpg","story":"\n    Environmental and Agricultural Resources\n          \n          Originating Technology/NASA Contribution\n        \n      \n    \n      \n      \n        \n      \n      \n        SeaSpace Corporation provides satellite data acquisition for a variety of uses, including weather monitoring and environmental monitoring.\n      \n    \n    Whether for scientific inquiry, weather forecasting, or public safety, the world relies upon the data gathered by satellite remote sensing. Some of NASAâ€™s most valuable work is in its remote sensing capabilitiesâ€”the ability to retrieve data acquired at great distancesâ€”affording a height and scope not available from the ground. NASA satellites in low Earth orbit (LEO) monitor ocean health by taking large-scale pictures of phytoplankton blooms and measuring surface temperatures; snap photographs of full hurricanes from above, teaching researchers about how these giant storms form; and capture images of cloud formation and air pollution, all allowing researchers to further develop understanding of the planetâ€™s health. NASA remote sensing satellites also monitor shifts in the Earthâ€™s crust, analyze wind patterns around the world to develop efficient wind energy, help people around the world recover from natural disasters, and monitor diminishing sea ice levels. \n      \n    \n    Just as researchers are more heavily relying on this data from space to conduct their work, the instruments carried on satellites are getting more sophisticated and capable of capturing increasingly complex and accurate measurements. The satellites are covering larger areas, from farther away, and generating more and more valuable data.\n      \n      The ground-based receivers for this wealth of satellite data have grown increasingly capable of handling greater bandwidth and higher power levels. They have also become less expensive, through a NASA research partnership, with the creation of a high-rate X-band data receiver system that is now in widespread use around the globe. \n      \n      Partnership\n      \n      \n    \n      \n      \n        \n      \n      \n        U.S. Coast Guard cutters use the SeaSpace antennas to determine how thick the Arctic ice is. They are then able to cut channels through the ice.\n      \n    \n    SeaSpace Corporation, of Poway, California, recognized a need for developing economical systems for receiving, processing, analyzing, and archiving incoming data from X-band remote sensing satellites, as they already provided similar systems for L- and S-band satellites. This need was one experienced throughout the world, as people became more reliant upon high-resolution satellite data. This was especially true within NASA, where the Space Agency could save millions of dollars by having available commercial providers of low-cost satellite data receivers accommodate its remote sensing program needs. \n      \n      The company approached NASAâ€™s Jet Propulsion Laboratory with proposals for a two-part research project to create such a system and was granted funding under two Small Business Innovation Research (SBIR) contracts, a Phase I and follow-on Phase II. SeaSpace proposed that its reception and processing systems could reduce the cost of satellite ground tracking by at least a factor of 10, and that the profits from its commercial sales would lead to even more enhancements to the receiver systems, extending applications to land-use management, marine pollution tracking, polar science operations, and ultimately, widespread commercial adoption of \n      its product. \n      \n      Product Outcome\n      \n      SeaSpace engineers were already pioneers in the field of ground-based direct reception stations, and under the NASA SBIR projects, they developed both new hardware and software to help with the acquisition of satellite data. The company was already working with the nearby San Diego-based Scripps Institution of Oceanography, and so applied its radio frequency equipment to an existing Scripps antenna platform to capture high-rate data from EOS-1 (an Earth-observing satellite). SeaSpace also designed and implemented the software necessary to control the antenna frame and process the data, which was later added to their existing TeraScan software product. This proved the viability of the ground-based antenna for receiving X-band. \n      \n      Once the company had demonstrated the usability of this ground station, interested parties took note, and SeaSpace began taking orders. To date, the company has installations in over 35 countries and has sold over 50 X-band systems, adding to an extensive list of customers reaching over 450 TeraScan systems worldwide. Its ground-based receivers are in continuous operation on all seven continents, with customers including aerospace and defense clients, the scientific community, national and local weather services, the research industry, and public safety organizations. \n      \n      Clearly, these customers appreciate the lower price of the units, but in addition to the cost savings (approximately one-tenth the cost of conventional antennas), SeaSpace ground stations, with sizes ranging from 0.6â€“6.1 meters, have additional benefits. Able to receive data from multiple platforms, they are available for a variety of applications: tracking LEO satellites for remote sensing; science; communications; and telemetry, tracking, and command applications, providing true full hemispherical coverage. \n      \n      \n    \n      \n      \n        \n      \n      \n        From weather, oceanography, and environmental studies to disaster management and military operations, SeaSpaceâ€™s ground systems are the complete acquisition and data processing solution for every major polar orbiting X-band satellite.\n      \n    \n    The units require very little maintenance, are reliable with redundancy motors and drives, and have a high level of remote fault detection and fault isolation. A minimal amount of moving parts, extremely low tracking dynamics, and few components all contribute to the ability of this antenna system to run for long periods without downtime. Their ruggedness combined with the ability to run around the clock make these antennas ideal for unattended, remote-controlled use in severe environments. \n      \n      The first X-band system sold by SeaSpace was purchased by the University of Wisconsinâ€™s Space Science and Engineering Center (SSEC), in Madison. The department receives, manages, and distributes large amounts of geophysical data and develops software to visualize and manipulate these data for use by researchers and operational meteorologists all over the world. To aid in this work, the SSEC hosts a 4.5 meter SeaSpace X-band system. \n    \n        The U.S. Navy uses SeaSpace systems for operation flight plans and monitoring dust storms in Iraq and Afghanistan. While this function saves the engines of F-16s by alerting pilots and ground controllers about the threat of the small but invasive airborne debris, it also saves lives. Ground troops can know in advance not to move into an area when they are not going to be able to receive support from the air. Battlefield planners can use the data to make smarter, safer decisions about where to send troops. \n      \n      Another customer, Raytheon Polar Services Company, has two of the systems deployed at literally the far end of the Earth: one at McMurdo Station, a large American research center off of Ross Island in the Antarctic, and the much smaller Palmer Station, located on Anvers Island, just north of the Antarctic Circle. Both of these remote research stations are operated by the National Science Foundation, which has a contract with Raytheon for the company to provide this support. At McMurdo, for example, the outdoor ground-based systems experience an average monthly temperature of -18 Â°C and average wind speeds of 11 miles per hour. With weather like that, it is important that the systems are rugged so they can endure, but also so that researchers do not often have to slough out into the cold to repair or maintain the equipment.\n      \n      In a warmer climate, Mexico, the National Commission for the Knowledge and Use of Biodiversity (CONABIO), a government agency dedicated to coordinating, supporting, and executing activities and projects designed to increase regional understanding of biodiversity, uses a 2.4-meter SeaSpace X-band system. CONABIO produces and collates biodiversity data and assessments across Mexicoâ€™s varied ecosystems. It consolidates this information and guides a range of biological conservation and sustainability projects using the satellite data.\n      TeraScanÂ® is a registered trademark of SeaSpace Corporation.\n      \n      \n      \n                    \n                      \n                      \n                      \n                      \n                    \n                    \n    "},{"href":"http://spinoff.nasa.gov/Spinoff2009/er_9.html","text":"Feature Detection Systems Enhance Satellite Imagery","image":"http://spinoff.nasa.gov/Spinoff2009/images/GDA-2.jpg","story":"\n            Environmental and Agricultural Resources\n                      \n                      Originating Technology/NASA Contribution \n                  \n  In 1963, during the ninth orbit of the Faith 7 capsule, astronaut Gordon Cooper skipped his nap and took some photos of the Earth below using a Hasselblad camera. The sole flier on the Mercury-Atlas 9 mission, Cooper took 24 photos—never-before-seen images including the Tibetan plateau, the crinkled heights of the Himalayas, and the jagged coast of Burma. From his lofty perch over 100 miles above the Earth, Cooper noted villages, roads, rivers, and even, on occasion, individual houses. \n  \n            \n            \n    \n    \n      \n    \n    \n      Launched in 1999, Landsat 7 continues to provide stunning, detailed images of Earth, like this shot of South Florida. Images like these provide unparalleled views of the impact of natural and manmade factors on the health of the planet.\n    \n  \n            In 1965, encouraged by the effectiveness of NASA’s orbital photography experiments during the Mercury and subsequent Gemini manned space flight missions, U.S. Geological Survey (USGS) director William Pecora put forward a plan for a remote sensing satellite program that would collect information about the planet never before attainable. By 1972, NASA had built and launched Landsat 1, the first in a series of Landsat sensors that have combined to provide the longest continuous collection of space-based Earth imagery. The archived Landsat data—37 years worth and counting—has provided a vast library of information allowing not only the extensive mapping of Earth’s surface but also the study of its environmental changes, from receding glaciers and tropical deforestation to urban growth and crop harvests. Developed and launched by NASA with data collection operated at various times by the Agency, the National Oceanic and Atmospheric Administration (NOAA), Earth Observation Satellite Company (EOSAT, a private sector partnership that became Space Imaging Corporation in 1996), and USGS, Landsat sensors have recorded flooding from Hurricane Katrina, the building boom in Dubai, and the extinction of the Aral Sea, offering scientists invaluable insights into the natural and manmade changes that shape the world.\n                  \n              Of the seven Landsat sensors launched since 1972, Landsat 5 and Landsat 7 are still operational. Though both are in use well beyond their intended lifespans, the mid-resolution satellites, which provide the benefit of images detailed enough to reveal large features like highways while still broad enough for global coverage, continue to scan the entirety of the Earth’s surface. In 2012, NASA plans to launch the Landsat Data Continuity Mission (LDCM), or Landsat 8, to extend the Landsat program’s contributions to cartography, water management, natural disaster relief planning, and more. \n              \n              Partnership\n              \n              In 2002, Geospatial Data Analysis Corporation (GDA), of State College, Pennsylvania, received a Phase I Small Business Innovation Research (SBIR) contract with Stennis Space Center. (The company also engaged in a follow-on Phase II SBIR with Stennis.) The NASA center was seeking a new method for detecting clouds for future use with Landsat 8. Cloud contamination is a common problem with satellite imagery. For previous Landsat missions, NASA has used its Automated Cloud Cover Assessment (ACCA) algorithm to estimate cloud contamination in Landsat images. ACCA heavily relies on thermal data from the Landsat satellites—thermal signals being the easiest method for cloud detection. Thermal sensors, however, are expensive additions to satellites, and Landsat 8 will not feature any in its array. GDA took on the challenge of developing a new system that could accurately detect clouds without the benefit of thermal data.\n              \n              “We proposed that, in order to identify clouds automatically and without thermal data, you have to move beyond the spectral signal in the imagery and into spatial feature and pattern recognition,” says Dr. Stephanie Hulina, GDA president and senior scientist. GDA employed its SBIR funding to arrive at the embodiment of this approach: the Cloud and Cloud Shadow Assessment (CASA) software. \n              \n                      \n            \n    \n      \n    \n  \n            CASA is a highly automated feature detection/extraction system. The system contains global libraries of expected spatial, visual, and near-infrared spectral and contextual signatures for the feature of interest (in this case clouds and cloud shadows). For example, depending on the Sun’s angle and viewpoint of the sensor, all of the clouds in any particular image should have shadows in similar locations. CASA uses information like this to confirm or reject elements in a given image as clouds. The system goes through an iterative, hierarchical self-learning process, identifying clouds based on a comparison to the characteristics in its global library. Definitive clouds are logged in a local library for additional comparison, helping CASA learn with increasing accuracy how to identify clouds and cloud shadows. The system produces a raster mask, showing per pixel cloud and cloud shadow contamination of the image. Clouds of different types can be assigned different color shades. \n                  \n              When tested on Landsat 5 and 7 images, CASA comes within 10 percent of the visual cloud estimate for 94 percent of the images tested—comparable to and often exceeding ACCA’s capabilities. \n              \n              “CASA would be the perfect technology for the next-generation Landsat sensor,” says Hulina. \n              \n              Product Outcome\n              \n                      \n            \n    \n    \n      \n    \n    \n      From a satellite image of a South American river valley (left), GDA’s feature detection system produced a detailed map of soybean crop fields (right), revealed in yellow. Capabilities like this can provide useful information on agricultural production. \n    \n  \n            Since establishing CASA’s effectiveness with Landsat imagery, GDA has taken advantage of the system’s versatility and high level of automation to provide cloud detection services for a host of space-based sensors. GDA has proven the CASA software effective for cloud and cloud shadow detection in high-resolution imagery from commercial satellites such as QuickBird (owned and operated by DigitalGlobe), SPOT (Spot Image), IKONOS, and OrbView (both GeoEye). The company also completed a NASA Dual-Use Technology Development contract with Stennis to adapt the CASA algorithms to the Indian Remote Sensing-P6 Advanced Wide Field Sensor, or AWiFS, data. CASA’s automation enables it to process large data sets in short periods of time, allowing GDA to guarantee return of cloud masks within minutes of receiving the raw data on its servers. Using the CASA output, GDA can also remove identified clouds and cloud shadows on a per pixel basis, backfill them, and radiometrically normalize the changes from one image to another—all without the lengthy and expensive process of removing them by hand. The company counts a number of private remote sensing imagery firms among its CASA clients, as well as the U.S. Department of Agriculture (USDA) and the National Geospatial Intelligence Agency.\n                  \n              “The NASA SBIR contracts allowed us to get our start and develop our intellectual property using sound science,” says Hulina. “To have the research and development funding and the backing of NASA to go out into the commercial market has been key for us.” \n              \n              Hulina also notes that GDA has since branched out into other categories of feature detection. Using the same technology it applied for CASA, GDA can provide detection services for virtually any predefined class of features. The company has entered into Phase III SBIRs with the USGS and USDA Forest Service for the development of feature detection systems for stream networks, riparian buffers (vegetated areas along streams or rivers), and certain land covers. The company also has contracts from the USDA Foreign Agricultural Service for detecting crop fields around the globe. GDA provides these clients with outputs like crop acreage maps or flood maps derived from the satellite imagery, allowing them to accurately evaluate key information about everything from agricultural production to the impact of pollution. \n              \n              As concerns about the effects of climate change and population growth lead to a greater need for the valuable data acquired through remote sensing, GDA’s NASA SBIR-developed feature detection capabilities will likely be in high demand.\n              \n              \n              \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/er_10.html","text":"Chlorophyll Meters Aid Plant Nutrient Management","image":"http://spinoff.nasa.gov/Spinoff2009/images/Spectrum-1.jpg","story":"\n            Environmental and Agricultural Resources\n                  \n                      Originating Technology/NASA Contribution \n                  \n    On December 7, 1972, roughly 5 hours and \n    6 minutes after launch, the crew of Apollo 17 took one of history’s most famous photographs. The brilliant image of the fully illuminated Earth, the African and Antarctic continents peering out from behind swirling clouds, came to be known as the “Blue Marble.” Today, Earth still sometimes goes by the Blue Marble nickname, but as the satellites comprising NASA’s Earth Observing System (EOS) scan the planet daily in ever greater resolutions, it is often the amount of green on the planet that is a focus of researchers’ attention. \n    \n            \n            \n      \n      \n        \n      \n      \n        NASA satellites offer insight on topics like climate change and disease outbreaks through data like this Normalized Difference Vegetation Index image showing vegetation in Africa in August 1994. \n      \n    \n            Earth’s over 400,000 known plant species play essential roles in the planet’s health: They absorb carbon dioxide and release the oxygen we breathe, help manage the Earth’s temperature by absorbing and reflecting sunlight, provide food and habitats for animals, and offer building materials, medication, and sustenance for humans. As part of NASA’s efforts to study our own planet along with the universe around it, the Agency’s EOS satellites have been accumulating years of valuable data about Earth’s vegetation (not to mention its land features, oceans, and atmosphere) since the first EOS satellite launched in 1997. Among the powerful sensors used is the Moderate Resolution Imaging Spectroradiometer (MODIS) on board the NASA Terra and Aqua satellites. MODIS sweeps the entire Earth every few days, beaming back information gathered across 36 bands of visible \n              and infrared light, yielding images that let scientists track how much of Earth is green over the course of seasons and years.\n              \n              Monitoring the density and distribution of vegetation on Earth provides a means of determining everything from the impact of natural and human-induced climate change to the potential outbreak of disease. (Goddard Space Flight Center and U.S. Department of Defense researchers have determined, for example, that vegetation density can be used to pinpoint regions of heavy rainfall in Africa—regions ripe for outbreaks of rainfall-correlated diseases like mosquito-borne Rift Valley fever.) \n              \n              While the Space Agency is continually seeking to upgrade the power and scope of its satellite sensors, it is also finding ways to bring that potent information-gathering capacity down to Earth. Scientists at Stennis Space Center developed one such tool that is placing some of those sensor capabilities in the hands of farmers and agricultural researchers on the ground. \n              \n              Partnership\n              \n              In 1998, Mike Thurow, president of Plainfield, Illinois-based Spectrum Technologies Inc., met with Stennis scientists and learned about a new technology the Center had recently patented: a hand-held plant chlorophyll meter developed from Stennis work on satellite sensors. The meter measures two wavelengths of light—700 nanometers (nm) and 840 nm—to determine a plant’s chlorophyll content. Chlorophyll, the pigment found in green plants and algae that allows for the production of energy from light (photosynthesis), comes in two varieties: a and b. Chlorophyll a absorbs 700-nm light, while 840-nm light is unaffected by the chlorophyll but helps indicate the reflectiveness of a leaf’s physical surface. The NASA meter compares the ratio of 700-nm and 840-nm available light to the ratio of the same wavelengths of reflected light, arriving at a chlorophyll index value. Chlorophyll levels are strong indicators of health in green plants; the meter’s Stennis inventors demonstrated that, by detecting chlorophyll amounts, their technology could reveal plant stress caused by factors like heat, insects, disease, and lack of water or nutrients—up to \n              16 days before visible signs emerged. \n              \n              The following year, Spectrum—a leading provider of agricultural measurement instruments in the areas of weather monitoring, nutrient management, integrated pest management, and soil properties—licensed the meter from NASA. Initially marketed as the Observer (featured in Spinoff 2001), Spectrum’s commercial chlorophyll meter featured enhancements to the NASA invention, such as a built-in ambient light sensor, dual high-power targeting lasers, a data logger, and a hardware encasement with a pistol grip for easy use. \n              \n              Product Outcome\n              \n                    \n            \n      \n      \n        \n      \n      \n        The NASA-derived, point-and-shoot FieldScout meter can take chlorophyll measurements from individual leaves or across a canopy, providing valuable information for nutrient management of crops and turf grass. \n      \n    \n            Spectrum now offers its NASA-derived technology as the FieldScout CM 1000 meter, which the company views as a powerful nutrient management tool. \n                  \n              “In the world of nutrient management, nitrogen is one of the key elements for growers to manage,” says Thurow. Nitrogen is a main component of chlorophyll; plants with low chlorophyll levels are thus indicators of poor nitrogen levels in the ground. Growers can respond by providing health-boosting doses of nitrogen fertilizer. \n                  \n              Whereas some chlorophyll meters attach to individual leaves like a clothespin, the FieldScout meter is a point-and-shoot tool that can take measurements from individual leaves or across a plant canopy, making it a fast and accurate way to survey chlorophyll levels not only for crops like cotton or corn, but also for turf (like athletic fields and golf courses) and long grasses like wheat \n              and rice. \n              \n              “With the NASA-developed meter, from 5 to 6 feet away, you can look at a canopy of close to 7 inches in diameter,” says Thurow. “It integrates a larger sample than other meters, making it faster and easier to use.”\n              \n                    \n            \n      \n        \n      \n    \n            The FieldScout meter takes individual readings with the click of the trigger and also supplies a running average. To provide an extra level of value to the meter’s readings, the user can also log the latitude and longitude of each reading with an optional GPS device and upload this information into Spectrum’s SpecMaps Web-based software utility. SpecMaps then produces a map showing the spatial variability of chlorophyll levels based on the meter’s readings. This helps the user more accurately determine the cause of less-than-ideal readings—perhaps poor soil quality in certain areas—and employ a targeted solution, such as providing fertilizer to only those areas low in nitrogen, allowing for maximum economic yield. \n                  \n              Spectrum also now offers a FieldScout CM 1000 NDVI meter, which measures red (660 nm) and near-infrared (840 nm) light reflectance to calculate a Normalized Difference Vegetation Index (NDVI) for an enhanced analysis of the meter’s spectral data. NDVI was originally developed by Goddard for use measuring the health of plant life from space-based sensors. \n              \n              Currently, Thurow says the meters’ main users are researchers working with small grains, turf, and rice, and Spectrum is aiming to grow a larger market base among agricultural consultants and growers. Since the NASA-derived meter was introduced by Spectrum in 2001, the company has sold 350 units, resulting in $700,000 of revenue—good numbers for a specialty product, Thurow says. He credits the product’s success to the benefits of partnership.\n              \n              “I have a strong belief in partnering,” he says. “In our case, NASA had a basic, validated technology that we were able to finish developing. It gave us the opportunity to offer a product that we would never have created on our own. It’s a win-win deal.”\n              \n              FieldScout® is a registered trademark of Spectrum Technologies Inc.\n              SpecMaps™ is a trademark of Spectrum Technologies Inc.\n              \n              \n                \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ct_1.html","text":"Telemetry Boards Interpret Rocket, Airplane Engine Data ","image":"http://spinoff.nasa.gov/Spinoff2009/images/Ulyssix-1.jpg","story":"\n            Computer Technology\n                  \n                      Originating Technology/NASA Contribution \n                  \n  For all the data gathered by the space shuttle while in orbit, NASA engineers are just as concerned about the information it generates on the ground. From the moment the shuttle’s wheels touch the runway to the break of its electrical umbilical cord at 0.4 seconds before its next launch, sensors feed streams of data about the status of the vehicle and its various systems to Kennedy Space Center’s shuttle crews. Even while the shuttle orbiter is refitted in Kennedy’s orbiter processing facility, engineers constantly monitor everything from power levels to the testing of the mechanical arm in the orbiter’s payload bay. On the launch pad and up until liftoff, the Launch Control Center, attached to the large Vehicle Assembly Building, screens all of the shuttle’s vital data. (Once the shuttle clears its launch tower, this responsibility shifts to Mission Control at Johnson Space Center, with Kennedy in a backup role.) \n  \n  Ground systems for satellite launches also generate significant amounts of data. At Cape Canaveral Air Force Station, across the Banana River from Kennedy’s location on Merritt Island, Florida, NASA rockets carrying precious satellite payloads into space flood the Launch Vehicle Data Center with sensor information on temperature, speed, trajectory, and vibration. \n  \n            \n            \n    \n    \n      \n    \n    \n      Ulyssix telemetry products support NASA rocket launches from Wallops Flight Facility and Cape Canaveral Air Force Station—the site of this Atlas IIA rocket launch, carrying a satellite into space.\n    \n  \n            The remote measurement and transmission of systems data—called telemetry—is essential to ensuring the safe and successful launch of the Agency’s space missions. When a launch is unsuccessful, as it was for this year’s Orbiting Carbon Observatory satellite, telemetry data also provides valuable clues as to what went wrong and how to remedy any problems for future attempts. \n                  \n              All of this information is streamed from sensors in the form of binary code: strings of ones and zeros. One small company has partnered with NASA to provide technology that renders raw telemetry data intelligible not only for Agency engineers, but also for those in the private sector. \n              \n              Partnership\n              \n              Ulyssix Technologies Inc., of Frederick, Maryland, has a long-standing and comprehensive relationship with NASA beginning with the company’s founding in 2000. A woman-owned small business focused on supporting the telemetry ground-based market, Ulyssix provides a range of telemetry processing solutions. “Pretty much all of our products are in use at different NASA facilities,” says Glenn Rosenthal, the company’s president and CEO. Beyond shuttle and rocket telemetry at Kennedy and Cape Canaveral, Ulyssix products are used for monitoring sounding rocket launches at NASA’s Wallops Flight Facility and for Glenn Research Center simulations for the Constellation Program. The company is also exploring collaboration with Langley Research Center to provide support for wind tunnel testing of the Orion crew exploration vehicle. \n              \n              In 2007, Ulyssix entered into a Space Act Agreement with Kennedy. The ongoing partnership allows NASA and the company to share resources to further the development of Ulyssix’s pulse code modulation (PCM) processor board—the TarsusPCM, currently in use by the Center for space shuttle and rocket launches—and related software for the benefit of both parties. Ulyssix’s highly versatile TarsusPCM processing board can perform a range of data acquisition and telemetry processing functions, allowing it to bit synchronize (recover the speed of the data transmission), frame synchronize (group the ones and zeros), and decommutate (separate the frame block into individual words that correspond to measurement values) binary code telemetry data. In simple terms, the technology translates the data into understandable measurements to be fed into display systems for engineer analysis. The TarsusPCM is also outfitted with a full PCM simulator that allows engineers to run tests using past data. The device can additionally record live data and then feed that data through the board’s simulator as though it were real-time information. Under the agreement, Ulyssix has also been working with Dryden Flight Research Center, which utilizes these latter capabilities for aeronautical testing involving drone aircraft.\n              \n              Ulyssix has been quick to modify their products to support the needs of the space shuttle program. Many of the suggestions made in conjunction with the shuttle program have been permanently incorporated in the company’s products and made available to other users, governmental and non-governmental alike.\n              \n              Product Outcome\n              \n                      \n            \n    \n    \n      \n    \n    \n      The TarsusPCM board—enhanced through Ulyssix’s partnership with NASA—translates raw telemetry data into understandable measurements for engineer analysis, playing an essential role in satellite launch and ground support, as well as the testing of remote-controlled drones and jet engines.\n    \n  \n            Beyond its extensive role in NASA missions, the company’s Tarsus line provides support to a host of military and aerospace applications. Eglin Air Force Base has employed Linux code created under the NASA Space Act Agreement to use the TarsusPCM card for remote-controlled drone testing. Pratt & Whitney (a division of United Technologies Corporation) and Embraer S.A. are utilizing Ulyssix Tarsus hardware for jet engine and airplane testing and development. ATK Space Systems incorporated the company’s technology into the ground-support equipment for the satellites it built for NASA’s Time History of Events and Macroscale Interactions during Substorms—otherwise known as THEMIS—mission to study the activities of Earth’s magnetosphere that lead to spectacular events like the Northern Lights. Ulyssix is also providing satellite launch support for the United Launch Alliance, a joint venture between Lockheed Martin Corporation and Boeing that offers launch services for the U.S. Government. In addition, Rosenthal notes that Ulyssix products are ideal for the private space industry and is looking forward to expanding the company’s reach into this developing field. “Our products are 100-percent compatible with these efforts,” he says.\n                  \n              The Tarsus line is one of several offered by the company, each named for anatomical parts of the company’s symbol, the bald eagle. (The tarsus is part of the eagle’s leg; the company’s Syrinx line is named for the eagle’s vocal cords, the Hallux line for the eagle’s opposing toe, and the Talon line for the eagle’s claws.) Ulyssix’s products have not only benefitted from NASA’s technical assistance, but from their association with the Agency. \n              \n              “Having the credentials of NASA behind my products has been a great reference,” says Rosenthal. \n              \n              Ulyssix’s partnership with NASA promises to encourage future evolution of its products and capabilities: The company’s processing hardware is supporting special testing of the space shuttles to help with the progress of the Constellation Program. This includes interpreting data from seat sensors to determine the different forces impacting the astronauts during launch—data that will help with the development of the Orion capsule, the space shuttle’s eventual successor. Rosenthal expects Ulyssix will continue to advance its telemetry expertise in support of the Constellation Program.\n              \n              “Rather than just supporting space shuttle launches, our equipment is helping enable this research going forward,” he says. “Our hardware is helping build a bridge between the shuttle and Constellation.” As more aerospace companies incorporate the TarsusPCM into their efforts, it seems likely that Ulyssix’s technology will provide a bridge to future commercial aerospace endeavors, as well.\n              \n              \n              \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ct_2.html","text":"Programs Automate Complex Operations Monitoring","image":"http://spinoff.nasa.gov/Spinoff2009/images/NVA3.jpg","story":"\n            Computer Technology\n              \n              Originating Technology/NASA Contribution\n              \n            \n            \n                  \n                  \n                    \n                  \n                  \n                    Kennedy Space Center’s launch complex—host to the large Vehicle Assembly Building, two launch pads, and myriad support facilities—has grown to accommodate the sophisticated technologies needed to manage today’s space missions. \n                  \n                  \n                      Kennedy Space Center, just off the east coast of Florida on Merritt Island, has been the starting place of every human space flight in NASA’s history. It is where the first Americans left Earth during Project Mercury, the terrestrial departure point of the lunar-bound Apollo astronauts, as well as the last solid ground many astronauts step foot on before beginning their long stays aboard the International Space Station. It will also be the starting point for future NASA missions to the Moon and Mars and temporary host of the new Ares series rockets designed to take us there.\n                        \n                        Since the first days of the early NASA missions, in order to keep up with the demands of the intricate and critical Space Program, the launch complex—host to the large Vehicle Assembly Building, two launch pads, and myriad support facilities—has grown increasingly complex to accommodate the sophisticated technologies needed to manage today’s space missions. To handle the complicated launch coordination safely, NASA found ways to automate mission-critical applications, resulting in streamlined decision-making. One of these methods, management software called the Control Monitor Unit (CMU), created in conjunction with McDonnell Douglas Space & Defense Systems, has since left NASA, and is finding its way into additional applications. \n                        \n                        Partnership\n                        \n                        Command and Control Technologies Corporation (CCT), of Titusville, Florida, was founded in 1997 with the express purpose of commercializing technologies developed by NASA. A team of McDonnell Douglas contractors at Kennedy had helped develop CMU to manage NASA’s complex space station checkout. Realizing that this software had applications outside of the NASA realm, they formed CCT and licensed the software usage rights from NASA (Spinoff 1999). Two years after its founding, CCT was named Kennedy’s “Small Business Contractor of the Year,” and the company has continued supporting the Space Agency with cutting-edge software.\n                        \n                      As CCT’s founders realized, a lot of the same management technologies created for NASA launches apply to other complex yet critical operations. CCT has therefore found applications outside of its NASA work helping the military at weapons test ranges, protecting the borders, and it has the potential to work with large industrial processes, like monitoring and managing power plants. \n                      \n                      Product Outcome\n                      \n                      CCT delivers products, engineering expertise, and support for aerospace, industrial, security, and defense applications. At the core of its capabilities is the software initially developed with NASA and significantly improved over the last 12 years by CCT, marketed commercially as Command and Control Toolkit (CCTK). A turnkey system, the software is customizable to a wide array of intricate situations and capable of handling complex data in real time. \n                      \n                      CCTK is robust and easy to use. It has a graphical interface and is flexible, easily configurable for real-time situational awareness, and capable of handling millions of data, command, event, and message transactions. It runs on any standard personal computer platform and can be customized by the company or directly by each user, depending on need. \n                      \n                      \n                      \n                        \n                        \n                          \n                        \n                        \n                          To handle the complicated launch coordination safely, NASA found ways to automate mission-critical applications, resulting in streamlined decision-making.\n                        \n                      \n                      CCT’s software is capable of simultaneously handling incoming information from varied sources, while still calculating for a variety of additional factors, including safety and engineering aspects. A prime example of this flexibility is the work CCT is conducting at NASA’s Wallops Flight Facility on Virginia’s Eastern Shore. Managed by Goddard Space Flight Center, Wallops is a launch site used by not only NASA, but by the military and the research community. While the launch facility already offers the capacity and expertise needed to enable frequent flight opportunities for a diverse customer base, it expects that in the coming years, it will become increasingly called upon for commercial space launches. \n                        \n                      CCT was contracted by Goddard to provide range safety decision support systems for the test facility at Wallops, as well as process telemetry and radar acquisition data and assist with early analysis for a redesign of the range control center. At Wallops, CCTK also monitors U.S. Navy launches at the site conducted by the nearby Naval Air Systems Command along the Patuxent River in Maryland.\n                      \n                      The Virginia Space Flight Facility, also located at Wallops, has been using CCTK to automate its remote control rocket cryogenic fueling systems. Adding this capability is one of the first steps in gearing the facility for more commercial launches, as it greatly increases the safety of launches by minimizing human exposure to hazardous conditions. CCT was recently contracted by the Virginia Commercial Space Flight Authority to design and develop a new launch vehicle fueling control system that will support the newly designed Orbital Sciences Taurus II launch vehicle, as well as other launch vehicles using the commercial pads at Wallops.\n                      \n                      CCT also received Small Business Innovation Research (SBIR) funding from the Air Force Research Laboratory to create gateways from various weapons systems to surveillance platforms. It collects information, integrates it into a common data format, and then presents the information so that military decision makers have access to all of the critical information. Additional government projects have included designing command and control systems for border protection that integrate radar, seismic, infrared, and proximity sensor data with auto-tracking cameras and automatic dispatch systems. These systems provide the U.S. Department of Homeland Security with accurate, real-time border security information. With an area as large as a border equipped with a wide variety of sensors, collecting and analyzing data to determine threats can be a daunting task. CCTK helps integrate the data and improve the quality of information that border patrol agents use to make interdiction decisions. \n                      \n                      Having demonstrated success with its government clients, CCT has entered the commercial markets. Potential industrial avenues include energy generation, process control, and manufacturing.\n                      \n                      For all of the technical support that NASA has shown CCT, the company has been able to reciprocate in turn by providing the Space Agency with valuable launch services and range safety research and development support.\n                      \n                      CCTK™ is a trademark of Command and Control Technologies Corporation.\n                      \n                      \n                      \n                      \n                        \n                        \n                        \n                        \n                      \n                      \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ct_3.html","text":"Software Tools Streamline Project Management","image":"http://spinoff.nasa.gov/Spinoff2009/images/panoptica.jpg","story":"\n            Computer Technology\n                      \n                      Originating Technology/NASA Contribution\n                  \n    Three innovative software inventions from Ames Research Center (NETMARK, Program Management Tool, and Query-Based Document Management) are finding their way into NASA missions as well as industry applications. \n    \n    The first, NETMARK, is a program that enables integrated searching of data stored in a variety of databases and documents, meaning that users no longer have to look in several places for related information. NETMARK allows users to search and query information across all of these sources in one step. This cross-cutting capability in information analysis has exponentially reduced the amount of time needed to mine data from days or weeks to mere seconds. \n    \n            \n            \n      \n      \n        \n      \n      \n        PanOptica software incorporates three NASA-developed programs.\n      \n    \n            NETMARK has been used widely throughout NASA, enabling this automatic integration of information across many documents and databases. NASA projects that use NETMARK include the internal reporting system and project performance dashboard, Erasmus, NASA’s enterprise management tool, which enhances organizational collaboration and information sharing through document routing and review; the Integrated Financial Management Program; International Space Station Knowledge Management; Mishap and Anomaly Information Reporting System; and management of the Mars Exploration Rovers. \n                  \n              Approximately $1 billion worth of NASA’s projects are currently managed using Program Management Tool (PMT), which is based on NETMARK. PMT is a comprehensive, Web-enabled application tool used to assist program and project managers within NASA enterprises in monitoring, disseminating, and tracking the progress of program and project milestones and other relevant resources. The PMT consists of an integrated knowledge repository built upon advanced enterprise-wide database integration techniques and the latest Web-enabled technologies. The current system is in a pilot operational mode allowing users to automatically manage, track, define, update, and view customizable milestone objectives and goals.\n              \n              The third software invention, Query-Based Document Management (QBDM) is a tool that enables content or context searches, either simple or hierarchical, across a variety of databases. The system enables users to specify notification subscriptions where they associate “contexts of interest” and “events of interest” to one or more documents or collection(s) of documents. Based on these subscriptions, users receive notification when the events of interest occur within the contexts of interest for associated document or collection(s) of documents. Users can also associate at least one notification time as part of the notification subscription, with at least one option for the time period of notifications. \n              \n              Partnership\n              \n              The three software tools have been bundled together for the purpose of executing a nonexclusive patent license, and in June 2006, JumpStart Solutions LLC (JSS), of Cave Creek, Arizona, licensed NETMARK, PMT, and QBDM for use in its PanOptica product suite.\n              \n              This license also allows JSS to re-license the three programs individually to targeted commercial companies, venture capital firms, and other government agencies. \n              \n              Product Outcome\n              \n              In September 2006, JSS announced the availability of PanOptica, its new suite of business intelligence and knowledge management tools. PanOptica was built using NETMARK, PMT, and QBDM and offers customers a cost-effective, scalable, easy-to-use suite of tools to manage projects, portfolios, and knowledge bases and documents.\n              \n              The PanOptica product suite can be understood as a set of collaboration tools, enabling implementers and managers across functionalities, responsibilities, and geographies to communicate with each other, share knowledge, and update their decision-making to evolve action to fit strategic objectives in a changing environment. \n              \n                    \n            \n      \n      \n        \n      \n      \n        PanOptica is a comprehensive, Web-enabled tool set, which provides intuitive and enhanced Web interfaces to automate the tedious process of monitoring, disseminating and tracking the progress of individual projects and project portfolios.\n      \n    \n            PanOptica applies the technologies to enable customer project, portfolio, and program managers to integrate the information from their project plans—work breakdown structures, milestones, budgets—with their financial, operating, and other systems—and to create reports that are useful and intelligible to their varied constituents. In other words, anyone, from principal investigators to senior management, to multiple funding sources and partnering organizations, can know “how are we doing?” on each of the project elements and how they roll up to larger views (portfolios and programs). Earned Value Management tools are applied. PanOptica is particularly useful in complex organizations, where different constituents, such as multiple funding sources for actual work, have their own objectives, and, consequently, have different perspectives on the work being done.\n                  \n              One of the goals of PanOptica is simplicity of use. This starts with assisting the customer to enable data to be entered only once, rather than the multiple iterations often required for different uses. It continues with intuitive Web-based interfaces, using widely understood Microsoft Office applications for reports. It enables straightforward approvals by authorized users of actions, such as releasing funds, to follow and, then, seamlessly, provides information to update the various systems. \n              \n              This product suite provides users a comprehensive set of Web-based tools for project and portfolio management. JSS also plans to integrate other technologies with NETMARK/PMT/QBDM to provide project portfolio \n              management and knowledge document management capabilities for its industry, university, and other customers.\n              \n              Many companies are reluctant to license technology from the U.S. Government. The primary reason is the length of time required to investigate the technologies, determine the technical applications, negotiate the license agreement, and learn the government licensing process. It is JSS’s secondary strategy to shorten the licensing process time and become a clearing house for technologies that it has licensed from Federal agencies and universities that have commercial viability. JSS will prepare the licensed technologies for re-licensing, and re-license them to the private sector or other government entities.\n              \n              PanOptica® is a registered trademark of JumpStart Solutions LLC.\n              \n              \n              \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ct_4.html","text":"Modeling Languages Refine Vehicle Design","image":"http://spinoff.nasa.gov/Spinoff2009/images/NASAContrib-Scramjet.jpg","story":"\n            Computer Technology\n                      \n                      Originating Technology/NASA Contribution\n                  \n    When we watch a space shuttle launch on television, we have only the vaguest sense of the extraordinary amount of work required to make such a complex operation successful. Even with the most highly trained engineers in the world, designing a space vehicle requires many thousands of hours of labor—and that is just in the early concept phases. With new partnerships and developments in software, however, a design task that formerly took 1,000 hours may take fewer than 100 hours.\n    \n    The Vehicle Analysis Branch (VAB) at Langley Research Center is responsible for a variety of important tasks in support of the Agency’s space and planetary exploration missions, including performing preliminary design and analysis of space transportation system concepts. Recent industry collaboration with this advanced analysis branch resulted in a novel software platform that is assisting both NASA’s missions and the aerospace industry in general.\n    \n    Partnership\n    \n    Cincinnati, Ohio’s TechnoSoft Inc. is a leading provider of object-oriented modeling and simulation technology used for commercial and defense applications. The company designed its Adaptive Modeling Language (AML) software for the U.S. Air Force to assist the military with saving time and costs during new vehicle development. This software has since evolved through NASA involvement and is applicable to a wide variety \n    of industries. \n    \n            \n            \n      \n      \n        \n      \n      \n        Artist’s concept of the air-breathing X-43A Hypersonic Experimental Vehicle, or “Hyper-X.” NASA is using software by companies such as TechnoSoft Inc. to design these supersonic combustion ram-air compression jets (scramjets).\n      \n    \n            AML is an object-oriented, knowledge-based engineering modeling framework upon which other applications can be built. It enables multidisciplinary modeling and integration of the entire product and process development cycle. \n                  \n              TechnoSoft’s president, Adel Chemaly, believes the AML product is unique for two reasons: “One aspect is doing modeling—capturing model requirements for \n              different disciplines, like multianalysis design environments. The other aspect is computing—collaboration, distributed computing, object computing, and web-enabled capabilities.”\n              \n              Because the Air Force had such success with the AML framework, TechnoSoft knew that it would also be useful to others who had similar research initiatives, such as NASA. The Air Force helped pave the way for the firm to meet with NASA researchers at Langley: A researcher from the Air Force Research Laboratory was collaborating with Langley engineers on different projects to learn best practices in vehicle design. The researcher recommended using TechnoSoft’s AML program.\n              \n              According to John Martin at Langley’s VAB, the team there had invested “quite a bit of time into developing code for collaborative applications, but it didn’t perform that well.” \n              \n              “The AML software also came with extensive corporate knowledge, and that was a real plus for us,” says Shelly Ferlemann, another VAB researcher. With the vote of confidence from VAB, TechnoSoft eventually received a Small Business Innovation Research (SBIR) contract from Langley to develop the software further.\n              \n              TechnoSoft built the Collaborative Hypersonic Air-breathing Vehicle Design Environment (CoHAVE) on its AML framework. According to Chemaly, the partnership ended up benefiting everyone: TechnoSoft tapped into NASA expertise, and eventually, the company took a leadership role, customizing CoHAVE to help NASA engineers analyze scramjet/ramjet vehicles for two-stage-to-orbit and hypersonic cruise missions.\n              \n              NASA aerospace partners became interested in the capabilities of the enhanced software. Because it provided a mechanism for different disciplines like structural analysis and optimization to work together, CoHAVE improved the product and process design, saving time and money. “If analysis can be performed at an earlier stage,” Chemaly says, “it will help prevent a lot of problems. In the past, you had to choose one or two concepts to pursue and hope the gamble paid off.” Now, designers who utilize TechnoSoft’s AML framework can perform analysis at earlier stages, with higher or lower fidelity as needed. “NASA provided us the methodologies for automation at the various levels, enabling people to introduce higher fidelity earlier in the design process,” says Chemaly. \n              \n              TechnoSoft was ahead of schedule on the software’s development, and by the time they were in an SBIR Phase II contract, the product was already being used in design processes. The success of CoHAVE led to a Phase III contract from Langley. “NASA’s investing in TechnoSoft has helped prove that this technology is valid and that it reduces risk,” Chemaly says. “Once we proved it within certain programs in NASA, we were able to leverage these successes with the Air Force and commercial sectors.”\n              \n              NASA found that CoHAVE is applicable to the Reusable Space Transportation System’s product area for evaluating the architectures of the Space Transportation Architecture Study and second-generation reusable launch vehicle studies. Recently, CoHAVE has been extended to incorporate models for other applications such as reentry vehicles. Since the environment now includes vehicles other than traditional hypersonic air-breathing vehicles, the name has morphed into the Integrated Design and Engineering Analysis Environment, or IDEA.\n              \n              Product Outcome\n              \n              Engineers can use IDEA and the enhanced AML platform early in the design process to analyze a variety of customized models for different designs including fluid dynamics, aerodynamics, structural design, and plenary models. AML offers an advanced modeling paradigm with an open architecture, enabling the automation of an entire product development cycle, integrating product configuration, design, analysis, visualization, production planning, inspection, and cost estimation. \n              \n                    \n            \n      \n      \n        \n      \n      \n        Engineers use the enhanced Adaptive Modeling Language platform to analyze a variety of customized models for different designs, including fluid dynamics, aerodynamics, structural design, \n          and plenary models.\n      \n    \n            AML enables generative modeling, which leaps beyond present approaches to integrated design and analysis processes. In a generative modeling environment, knowledge of the engineer’s tools and the intricacies associated with executing them is captured within a modeling language. This empowers the engineer to search a broader set of product design configurations, rather than being limited to simple parameter changes. “These can be built to switch back and forth and allow a lot of iterations early on, making the process affordable and fast,” Chemaly explains.\n                  \n              The software also greatly improves efficiency, says Chemaly. “We have reduced the design time by at least 50 percent, and some of our customers are quoting \n              90 percent improvement or better.” Since “physics is physics,” he says, the TechnoSoft AML can easily be adapted to different vehicle designs, whether the vehicles are traveling in space, the sea, or on Earth. \n              \n              Current advancements in AML also allow engineers to incorporate changes in cost in a product’s life cycle. This could once again benefit NASA engineers and commercial designers, enabling ongoing cost analysis for everything from surface ships and automobiles to the space shuttles. With AML, Chemaly says, “We can look at the cost of sustaining the design in the long-run,” taking into account such factors as ongoing maintenance and repair costs. “If the technology evolves or if costs change, we need to be able to insert that into a design,” he says.\n              \n                    \n            \n      \n        \n      \n    \n            The program encourages integration with third-party applications through a number of standard methodologies, including shared memory, pipes, TCP/IP sockets, file transfer, and foreign functions. Built-in XML export capability enables a state model of the AML object hierarchy and geometry to be exported automatically to an XML file, which is viewable using TechnoSoft’s AML Viewer. The available “Net Conference” mode enables real-time collaboration among team members across local and global computer networks. A suite of graphical user interface (GUI) classes is provided to allow developers to create customized front-ends to their AML applications. In addition, a visual GUI-builder can be used, making it easier to layout forms and controls, and to assign their associated methods and properties.\n                  \n              TechnoSoft is now customizing AML for clients in green industries, which includes designers for power plant exhaust filtration systems and for wind turbines. TechnoSoft’s focus on making the technology more affordable and deployable by the end of 2009, says Chemaly, has opened the doors to smaller commercial customers. With a platform that can reduce 10,000 work hours to 1,000, it is clear there will be ongoing demand for TechnoSoft’s Adaptive Modeling Language.  \n              \n              Adaptive Modeling Language™ is a trademark of TechnoSoft Inc.\n              \n              \n              \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ct_5.html","text":"Radio Relays Improve Wireless Products","image":"http://spinoff.nasa.gov/Spinoff2009/images/2009-3193.jpg","story":"\n            Computer Technology\n                      \n                      Originating Technology/NASA Contribution \n                      \n                      In order to transmit communications through Earth’s atmosphere, satellites and space vehicles need radio equipment that can operate at higher frequencies than on Earth. These higher frequencies, until recently, have demanded mechanical switches in radio relays. Unfortunately, the mechanical switches had some problems with frequency routing, which inspired NASA to seek more rugged, reliable solutions. \n                      \n                      NASA began to design new, lightweight, microelectromechanical systems, or MEMS. MEMS are extremely small devices (a fraction of a millimeter long) with moving parts, already used in sensors for airbag accelerometers and video game controllers, as well as radio electronics for cell phones, digital mirror displays, and hand-held radios. Switching to MEMS relays for actuators (and not just sensors) from older mechanical switches offered the Agency improved performance in higher frequencies. A California company helped NASA create new MEMS relays that offer some new benefits as well.\n                      \n                      Partnership\n                      \n                \n            \n                  \n                  \n                    \n                  \n                  \n                    \n                  \n                  \n                    NASA’s Lunar Reconnaissance Orbiter, or LRO, and NASA’s Lunar Crater Observation and Sensing Satellite, known as LCROSS, shown at top, launched aboard an Atlas \n                    V/Centaur rocket in 2009. LCROSS will communicate using radio frequency signals, between antennas on the spacecraft and large dish antennas on Earth, such as the one in Canberra, Australia, shown at bottom. This communication depends on distance, spacecraft orientation, and the physical characteristics of the transmitting and receiving antennas and electronics. Companies such as XCOM Wireless Inc. are working with the Agency to improve these electronics.\n                  \n                  \n                      After developing a radio frequency (RF) MEMS relay under U.S. Department of Defense contracts, Signal Hill, California-based XCOM Wireless Inc. continued its research with a Phase II Small Business Innovation Research (SBIR) contract in 2003 through NASA’s Jet Propulsion Laboratory (JPL). In order to improve satellite communication systems, XCOM produced wireless RF MEMS relays and tunable capacitors that use metal-to-metal contact—moving microscopic metal beams into contact with special electrodes—operating much like a light switch small enough to fit on the cross section of a human hair. They have the high speed of solid-state switches, but with mechanical contacts that outperform semiconductor technology. Also, by introducing a MEMS relay with electrostatic—and not electromechanical—actuation, XCOM was able to produce a MEMS relay that consumed less power and was easier to manufacture than earlier relays. \n                        \nThese MEMS relays are used for signal tuning, routing, and phase-shifting circuitry, thus enabling wireless systems to adapt to changing operating conditions, radar or communications waveforms, and other mission needs. For its work with NASA, XCOM Wireless concentrated on frequencies in the range of 70 GHz–100 GHz, while most commercial radio frequencies use the range from 0.1 GHz–6 GHz. Despite the difference in bandwidth, XCOM’s president, Dr. Daniel Hyman, says that the NASA technology is a “fundamental switching device” now incorporated into all of XCOM’s products.\n\nProduct Outcome\n\nAfter designing these improved devices, XCOM entered into a partnership with MEMS manufacturer, Innovative Micro Technology Inc. (IMT), based in Santa Barbara, California. With its NASA-derived design improvements and IMT’s manufacturing abilities, XCOM automated its relay manufacturing and testing, and reduced costs to one-tenth the previous amount. This, Hyman says, gave the new relays potential to be “a mainstream product with thousands of solid industrial customers in a stable and growing market.”\n\nXCOM has two products made possible by the MEMS technology the company developed under the SBIR from JPL. The first is an industrial relay used for high-frequency test equipment and instrumentation, the XW3100 single pole double throw relay. The second, an RF MEMS tuning circuit, is in development for the wireless communications industry.\n\n                      \n                \n  \n  \n  \n    \n  \n  \n    The XCOM Wireless XW3100 microelectromechanical single pole double throw relay, mounted on a radio frequency test coupon. According to the company, the XW3100 relays offer faster performance for automated test equipment, with frequency switching as high as 20 gigahertz.\n      \n        Image courtesy of XCOM Wireless Inc.\n  \n\n                      The XW3100 relays offer faster performance for automated test equipment, with frequency switching as high as 20 GHz—much more efficient than large electromagnetic relays. Typically the size of sugar cubes, electromagnetic relays consume a lot of power, and because of their large size, they are very slow. Conversely, the XW3100s incorporate gold contacts to offer speed in a small footprint. Industrial systems that reconfigure different testing for computer chips or cell phones, for instance, depend on the speed of these relays. Reconfiguration speed can account for half of the total cost of testing final products, so companies are able to cut costs by having faster, smaller relays. “Fifty percent improvement in profits to the chipset makers is our compelling value and why our parts are so desirable,” Hyman says. The XW3100 relays also offer other advantages, such as linearity, lifetime, and bandwidth, but Hyman suggests that the most attractive features are the reduced power consumption and significantly higher switching speed, especially when contrasted with electromagnetic relays. The relays offer a continuous RF current of 400 milliamps.\n                        \nAlthough early interest for the RF MEMS technology was primarily for instrumentation for aerospace and defense industries, the opportunities are now far more varied. Newer applications include fixed and wireless broadband data link equipment, wireless network hardware, cell phones, laptop computers, and personal digital assistants. \n\nThe second product, which will be available in 2010, is an RF MEMS tuning circuit for use in hand-held radios and cell phones. These circuits use the low-loss switch technology developed with the NASA funding, and Hyman expects the technology will greatly improve interoperability and power consumption in tactical radios. Miniaturizing the circuits and integrating them with filter and antenna subsystems allow older and newer radios to communicate seamlessly, making multi-agency operations more efficient. Hyman also expects XCOM’s relays will be incorporated into multiband third generation (3G) cellular systems because they enable cell phones to have better worldwide service, improved simultaneous data and voice use, and better wireless local network service. American cell phones typically do not work in Europe, for example, but the relays can make the numerous waveforms all compatible, thus enabling seamless global coverage. The relays can also switch a phone call from a cellular network to an available broadband wireless network automatically, thereby reducing the use of cell phone minutes and reducing dependence on overloaded cellular infrastructure. Lastly, the technology can also extend battery life and reduce dropped calls. \n\nHyman expects more commercial broadband companies will take advantage of the technology soon. The applications are still growing today as consumer wireless companies continue to reduce cost while increasing functionality in each new model. “These are the technologies and opportunities that will shape the next generation of wireless,” Hyman concludes.\n  \n  \n  \n                      \n                        \n                        \n                        \n                        \n                      \n                      \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ip_1.html","text":"Advanced Sensors Boost Optical Communication, Imaging","image":"http://spinoff.nasa.gov/Spinoff2009/images/ATI-1.jpg","story":"Industrial Productivity\n                  \n                      Originating Technology/NASA Contribution \n                  \n  In 1992, on a gravity assist flyby of Earth that would help propel it along its mission to Jupiter, NASA’s Galileo probe detected a line of light pulses emerging from Earth’s night-darkened hemisphere. Over the next few days, Galileo’s camera imaged similar signals—even though the probe was hurtling through space nearly \n  4 million miles from the planet. \n  \n            \n            \n    \n    \n      \n    \n    \n      Lasers may one day facilitate interplanetary communications networks and high data-rate transmissions from powerful space-based sensors.\n    \n  \n            The pulses Galileo detected were powerful laser bursts from telescopes at NASA’s Table Mountain Observatory in Wrightwood, California, and the U.S. Air Force Phillips Laboratory Starfire Optical Range near Albuquerque. The lasers, firing bursts in the range of tens of megawatts, were part of the Jet Propulsion Laboratory (JPL) Galileo Optical Experiment (GOPEX) that gave a glimpse into the future of communications—and how a Mars colonist might one day phone home. \n                  \n              As the scope of NASA’s missions have expanded in reach, unprecedented levels of data have flooded in from increasingly powerful sensors, and as manned missions and possible colonies on the Moon and Mars have inched closer to becoming viable realities, the Agency has seen the need for more efficient and effective means of communicating across the expanses of space. In addition, the practical demands of space exploration require further reductions in spacecraft size and weight, making smaller, lighter, more energy-efficient communications equipment a priority. GOPEX demonstrated the potential of free space (no physical connection) optical communications. \n              \n              JPL’s Optical Communications Group has been tackling the challenge of enabling space missions to return 10–100 times more data while reducing antenna area to 1 percent of its current size—all while also employing less mass and power. Optical laser communication presents a host of benefits in these regards. It offers high-bandwidth, low mass, and low power consumption, allowing missions to communicate deeper into space. Optical communications are to radio frequency communications as a dart is to a shotgun blast; a radio signal from Mars spreads out to about 100 times Earth’s diameter by the time it reaches the planet, while an optical signal pinpoints a spot about one-tenth of the Earth’s diameter. This kind of precision enhances the security of the communicated data, but there are significant difficulties in acquiring, tracking, and pointing optical signals accurately over such incredible distances. As such, JPL continues to explore increasingly powerful sensor technologies that can help detect even the faintest light signals, helping enable NASA’s effort to establish interplanetary communications networks and a virtual presence throughout the solar system. One company has assisted JPL in this mission by developing a light sensor that has multiple applications on Earth, as well. \n              \n              Partnership\n              \n                      \n            \n    \n    \n      \n    \n    \n      \n    \n    \n      Amplification Technologies’s NIRDAPD photomultiplier can sense infrared light down to individual photons, without the cooling required by other infrared sensors. \n    \n  \n            Brooklyn, New York-based Amplification Technologies Inc. (ATI), a subsidiary of PowerSafe Technology, received Phase I and II Small Business Innovation Research (SBIR) contracts with JPL to pursue the development of a solid-state photomultiplier capable of detecting light down to its most reduced form—particles called photons. Photomultipliers are highly sensitive light sensors that boost the signals of even the faintest light to detectable levels. ATI, an advanced developer of photon detection technology, had already developed its patented Discrete Amplification Photon Detector (DAPD), a solid-state, silicon-based photomultiplier that can detect visible light wavelengths down to a single photon. JPL was looking for photomultipliers that could detect individual photons in the near infrared (NIR) light wavelengths, specifically in the bands of 1060 and 1550 nanometers (nm) that the Center is exploring for use in free space optical communications. ATI employed its SBIR funding to implement a new indium-gallium-arsenide base for its DAPD technology, leading to a photomultiplier that detects single photon levels in the NIR range of 950 nm to 1700 nm. JPL used the device  in its laser communications module, and it is now emerging as a commercial product with a variety of terrestrial uses. \n                  \n              “We looked at the NASA requirements and jumped on the project,” says ATI consultant Dr. Krishna Linga. “We came up with a unique product that no one else has on the market today.”\n              \n              Product Outcome\n              \n              ATI commercialized its SBIR-developed photomultiplier as the company’s NIRDAPD series. The extremely high-gain NIRDAPD sensor takes advantage of ATI’s patented discrete amplification method, which uses \n              multichannel amplification to boost the low-level electrical signal produced when the sensor encounters individual photons.\n              \n              “If you take a simple photodetector, it can only yield one electron from one photon,” says Linga, meaning the sensor will not be very sensitive to the lowest levels of light. “ATI’s detector is able to sense a single photon and yield a million electrons.” Those million electrons, Linga explains, can then be transferred in some form of a current to a resistor, and the significant voltage drop in the resistor can be detected by any general electronic meter. Featuring many tiny cells, each capable of detecting a single photon, the NIRDAPD sensor does not require any additional amplifiers or external circuitry to render the current from the circuit detectable. “You just plug the sensor into any electronic media that can record these signals,” Linga says. The sensor has a fast response time, high voltage and thermal stability, and a low noise factor (intrusion from undesired ambient light has a minimal impact), in addition to being small (less than 5 millimeters), light in weight (less than one-tenth of a pound), and energy efficient. These qualities all amount to a solid-state photomultiplier that ATI says outperforms other solid-state photodetectors in the NIR wavelength range. \n              \n              “This device can be applied for any NIR optical sensing that requires single photon detection,” says Linga, citing communications, the military, and imaging as main markets for the sensor. The NIRDAPD photomultiplier can be used for free space optical communications applications closer to Earth, like satellite communications and data transmission from unmanned aerial vehicles used for military purposes or forest fire detection. Additional military applications include lidar and ladar range-finding used to target munitions with pinpoint accuracy (the sensor detects the faint light from the targeting beam reflected off the target), and night vision goggles, which can take advantage of the sensor’s portability and ability to operate efficiently at room temperature. (Other infrared sensors often require liquid nitrogen cooling to operate effectively.) NIR cameras can also benefit from these qualities. \n              \n              While the company has not yet explored medical applications, says Linga, he notes the sensor can be used as part of a laser-based glucose monitoring system. He also points to quantum cryptography, which employs elements of quantum mechanics—including photons—to secure encrypted information, as a future application for ATI’s NASA SBIR-funded sensor, meaning this technology could one day be used for protecting secrets on Earth and among the stars.\n              \n              \n              \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ip_2.html","text":"Tensile Fabrics Enhance Architecture Around the World","image":"http://spinoff.nasa.gov/Spinoff2009/images/HOF-Medal.jpg","story":"\n            \n                      Industrial Productivity\n                      \n                      Originating Technology/NASA Contribution \n                  \n    On a Friday night in March 2008, fans at a college basketball game at Atlanta’s Georgia Dome noticed the stadium’s scoreboard begin to sway. Outside, winds howled through the city. Unknown to those in the stadium, a tornado was ripping through downtown. The safety of the more than 18,000 people would depend in large part on the integrity of the stadium’s domed roof—built using a material originally developed to protect NASA astronauts. \n    \n            \n            \n      \n      \n        \n      \n      \n        Birdair’s roof structures, using fabric originally developed for the Apollo space suits, now adorn buildings such as (clockwise from top left) the original Birdair “Super Tents” structure at the University of La Verne in La Verne, California; Navy Pier in Chicago, and Palm Springs International Airport in Palm Springs, California.\n      \n    \n            Over 40 years earlier, NASA’s effort to achieve the first manned Moon landing nearly derailed when a fire broke out on the Apollo 1 command module during a test exercise, resulting in the destruction of the module and the deaths of the three astronauts onboard. In the wake of the tragedy, NASA engineers redesigned the Apollo module and searched for ways to enhance the safety performance of the nylon space suits. The suits required an outer layer component that would be durable, strong, lightweight, flexible, and noncombustible. Owens-Corning Fiberglass, of Toledo, Ohio—working with DuPont, of Wilmington, Delaware—proposed a fabric known as “Beta cloth.” The primary component of this fabric was ultrafine glass filaments, which were twisted into yarns and then woven into the fabric. The manufacturers then coated it with polytetrafluoroethylene (PTFE, more commonly known as Teflon), a DuPont invention. The fabric proved noncombustible (with a melting point over 650 °F) and durable enough for NASA’s needs. The Agency incorporated the PTFE fiberglass fabric into the outer protective layers of the Integrated Thermal Micrometeoroid Garment (ITMG) of the A7L space suit worn for the Apollo missions and Skylab program. The PTFE fiberglass fabric layer provided both thermal protection as well as shielding from abrasive lunar dust during Moon landings. \n                  \n              While the current NASA space suit used on the space shuttle and International Space Station employs Ortho-Fabric (a blend of GORE-TEX, Kevlar, and Nomex—all private industry inventions) in its ITMG instead of the PTFE fiberglass fabric, that original innovation has gone on to become a unique component of an unrelated, terrestrial field: architecture. \n              \n              Partnership\n              \n              In 1956, aeronautical engineer Walter Bird founded Birdair Structures Inc. in the kitchen of his home in Buffalo, New York. Birdair initially focused on air-\n              supported, neoprene-coated nylon fabric structures, building upon its founder’s experience crafting such structures for use by the U.S. military.\n              \n              Birdair’s work developing the air-supported, vinyl-coated fiberglass fabric roof (the first of its kind) of the U.S. Pavilion at Expo 1970 in Osaka, Japan, led the company to explore improved fiberglass fabric options for architectural use. The company collaborated with Owens-Corning, DuPont, and Chemical Fabrics Corporation (Chemfab), of Merrimack, New Hampshire on a modified, stronger version of the PTFE glass fiber fabric developed for NASA. The resulting fabric (later called Sheerfill Architectural Membrane, manufactured by Chemfab), expanded the market for Birdair in the field of lightweight, tensile membrane roof structures for roofs, skylights, and canopies.\n              \n              Product Outcome\n              \n              “When there are so many architectural materials out there, fabric is not something architects usually think of offhand,” says William Barden, Birdair’s director of architectural development. “Walter Bird’s pioneering role in the tensile structure industry was to take a technology that was perceived by people as ‘pie in the sky’ and create a market for it.”\n              \n              In 1973, Birdair engineered, fabricated, and installed the world’s first permanent tensile membrane roof system utilizing PTFE fiberglass membrane for the Sports Science and Athletics Pavilion at the University of La Verne in La Verne, California. Thirty-six years later, that original structure remains in excellent condition. Birdair, now a specialty contractor based in Amherst, New York, has grown into a multimillion-dollar company with nearly 900 landmark tensile structures to its name, most of which employ the original PTFE fiberglass fabric developed for NASA. Major transportation hubs, sports facilities, and convention centers are among the buildings around the world that feature Birdair’s signature PTFE fiberglass membrane roofing. These include Denver International Airport’s Jeppesen Terminal; the 105-acre Hajj Terminal in Saudi Arabia; Reliant Stadium in Houston (the first retractable roof in the NFL); the O2/Millennium Dome in London, England (22 acres of fabric roof); the Sony Center in Berlin, Germany; and many others. Barden estimates the company has fabricated and installed over 30 million square feet of the PTFE fiberglass membrane in its various projects. \n              \n                    \n            \n      \n      \n        \n      \n      \n        Houston’s Reliant Stadium features a retractable, PTFE fiberglass fabric roof crafted by Birdair.\n      \n    \n            The same qualities that made the PTFE fiberglass fabric appealing to NASA also make it ideal for large-scale, permanent tensile membrane roofs. The material \n              is pound-for-pound stronger than steel while weighing less than 5 ounces per square foot. It offers up to 24 percent solar translucency while providing as much as 75 percent solar reflectance, meaning the fabric lets in natural light while keeping out heat, making it an energy-efficient roofing alternative. It is also cost-effective due to its durability and low maintenance characteristics. Barden estimates \n              a properly maintained Birdair roof could provide \n              30–35 years or more of useful service life, as opposed to the 20–25 years offered by conventional roofing materials like asphalt shingles or single-ply rubber. As a non-\n              flammable fabric, the PTFE fiberglass material is safer than many roofing options, as well, and allows for the creation of swooping, eye-catching architectural forms. \n              \n              Birdair’s PTFE fiberglass membrane, still manufactured for Birdair by Chemfab (now called Saint-Gobain Performance Plastics), entered the Space Foundation’s Space Technology Hall of Fame in 1989. The material’s capabilities—and possibilities—have yet to be exhausted, however. In 2008, Sheerfill Architectural Membrane was approved by the U.S. Environmental Protection Agency as an ENERGY STAR qualified roof product and recognized by the Cool Roof Rating Council, based on the fabric’s high solar reflectance and thermal emittance. Birdair also introduced its Tensotherm insulated fabric roofing product, which allows natural light to pass through while providing enhanced thermal resistance and acoustical qualities. \n              \n              The company continues to work on new structures—including three out of the four primary stadiums for the 2010 World Cup in South Africa and the new Dallas Cowboys Stadium—while celebrating the enduring quality of its existing creations. Among those is the Georgia Dome, which came out of the March 2008 Atlanta tornado with only slight damage to its roof and not a single injury to its occupants, though winds ranged up to \n              135 miles per hour and caused significant destruction in the city. The stadium roof’s PTFE fiberglass membrane, the same material that once protected astronauts in the harsh environs of the Moon, required only minor repairs.\n              \n              Teflon®, Kevlar®, and Nomex® are registered trademarks of E. I. du Pont de Nemours and Company.\n              GORE-TEX® is a registered trademark of W. L. Gore & Associates.\n              Sheerfill® Architectural Membrane is a registered trademark of Saint-Gobain Performance Plastics Corporation.\n              ENERGY STAR® is a registered mark owned by the U.S. Government.\n              Tensotherm™ is a trademark of Birdair Inc.\n                \n                \n                \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ip_3.html","text":"Robust Light Filters Support Powerful Imaging Devices","image":"http://spinoff.nasa.gov/Spinoff2009/images/Lake-Shore-1.jpg","story":"\n            Industrial Productivity\n                  \n                                  Originating Technology/NASA Contribution \n                  \n                      \n            \n    \n    \n      \n    \n    \n      These Orion nebula images compare an infrared view taken by the Spitzer Space Telescope (left), revealing bright clouds and developing stars, with a darker, dust-obscured, visible light view. \n    \n  \n            Consider the anatomy of a rainbow: From the inner arch, violet shifts to blue, then green, yellow, and red. Contained in the rainbow is the spectrum of light that our eyes take in and translate into images of the world around us. But the human eye only registers a minute percentage of the electromagnetic spectrum, which theoretically stretches into infinity beyond the wavelengths (between 0.38 and 0.76 micrometers) of visible light. Past violet, the wavelengths of ultraviolet, X-rays, and gamma rays cramp closer and closer together. Going in the other direction, past red, stretch the expanding wavelengths of infrared, terahertz, microwaves, and radio waves. It is within these invisible ranges that many of the secrets of our universe remain.\n                  \n              Much of the universe is not observable using visible light. Clouds of cosmic gas and dust obscure the gaze of traditional telescopes, and the ongoing expansion of the universe following the Big Bang further complicates observation of distant galaxies. As the galaxies race away from our position, the visible light they emit is redshifted, or stretched, transforming it into infrared (IR) light—thermal, or heat radiation—which is able to pass unimpeded through cosmic dust clouds. Telescopes that detect IR light are therefore capable of unveiling vastly greater views of our universe and even peering into its very beginnings. \n              \n              NASA has been at the forefront of IR astronomy since 1974, when its Kuiper Airborne Observatory (KAO), an IR telescope mounted on a transport jet, made astonishing observations on a series of flights that lasted until 1995. (The Earth’s atmosphere absorbs much of the IR radiation from space, making high-altitude telescopes far more effective than ground-based versions. Space-based telescopes are more sensitive yet, since they can by cooled to very low temperatures, limiting interference from their own heat radiation.) The Agency has developed many IR observatories, from the 1979 construction of the Infrared Telescope Facility 14,000 feet up the slope of Mauna Kea in Hawaii to the 1983 launch of the Infrared Astronomical Satellite, the first IR satellite telescope, to the Cosmic Background Explorer (COBE), to the near-infrared camera multiobject spectrometer (NICMOS) operating onboard the Hubble Space Telescope since 1997. In 2003, the Spitzer Space Telescope combined sensitive modern infrared detectors with a cooled telescope to produce a remarkably powerful observatory. NASA plans to come full circle in its IR observatory efforts in 2010 with the first operational flight of KAO’s next-generation cousin, the Stratospheric Observatory for Infrared Astronomy (SOFIA), a large, airplane-mounted IR telescope. Four years later, the Agency expects to launch the infrared James Webb Space Telescope, which will allow us to see deeper into the universe than ever before.\n              \n              Partnership\n              \n                      \n            \n    \n    \n      \n    \n    \n      The infrared (IR) telescope of the Stratospheric Observatory for Infrared Astronomy (SOFIA) peers through the opening in the fuselage of its Boeing 747 mothership.\n    \n  \n            Lake Shore Cryotronics Inc., of Westerville, Ohio, entered into 2002 Phase I and Phase II Small Business Innovation Research (SBIR) contracts with NASA’s Jet Propulsion Laboratory (JPL) and similar contracts in 2004 with Langley Research Center. The NASA centers  wanted robust and high performance optical filters for IR astronomy to select the wavelengths of light that reach the detector. Since warm objects emit IR radiation, steps must be taken to reduce the amount of local thermal noise that interferes with the desired signal, typically by cooling the detector and its filters to a near-absolute-zero temperature. Existing IR filters, composed of multiple layers of different materials with different mechanical properties, tend to delaminate (separate from one another) at such extreme temperatures. They are also extremely expensive and often comprised of mechanically and chemically fragile materials. Lake Shore, a leading supplier of cryogenic temperature sensors and instrumentation, magnetic test equipment, metrology systems, and probe stations for the characterization of magnetic and transport properties of material, was intrigued by the problem and used the SBIR funding to investigate porous silicon technology, and subsequently, metal-mesh technology, as possible elements of a new filter technology for the IR. The company invested significant internal funds in the project; Lake Shore prides itself in a research and development budget that is typically double the national average for instrumentation companies. \n                  \n              The effort resulted in a more affordable long wave pass IR filter composed of mesoporous silicon. The filter, composed of a lattice of electrochemically etched, porous layers of monocrystalline silicon, maintains its properties and does not delaminate at extreme temperatures. Its high transparency for the far IR range (most removed from visible light) also makes it more desirable than conventional filter technology, which cannot perform using the long wavelengths employed for deep space imaging.  This research program also resulted in the development of metal-mesh constructed filters (also referred to as frequency selective surfaces) specifically for IR band pass filters. \n              \n              “The SBIR funding jumpstarted this program internally for us,” says David Klein, Lake Shore’s lead on new business development programs. “As we confirmed interest from NASA and other aerospace organizations, it further justified our decision to pursue the technology’s development and push toward commercialization.”\n              \n              Product Outcome\n              \n                      \n            \n    \n    \n      \n    \n    \n      Lake Shore’s SBIR-developed IR filters are ideal for astronomy applications, as well as for technologies like terahertz imaging. \n    \n  \n            Lake Shore now features two standard IR filter pro-ducts: mesoporous silicon long pass filters and a line of metal-mesh band pass and narrow band pass filters. (Long pass filters allow transmission of wavelengths above a certain minimum; a 10 micron long pass filter, for example, allows all wavelengths longer than 10 microns to pass. Band pass filters allow a transmission like a bell curve; a 10 micron band pass filter allows maximum transmission at 10 microns with decreasing transmission at neighboring wavelengths.) During development, Lake Shore determined the mesoporous silicon technology worked well for long pass filters but was not ideal for band pass filters. At the suggestion of Dr. Harvey Moseley, senior astrophysicist at Goddard Space Flight Center, Lake Shore created band pass filters composed of thin metal mesh with varied geometrical openings to allow the transmission of desired wavelengths. The metal-mesh filters—a frequency selective surface (FSS) technology—are also fully functional at ultra-low temperatures, and easily fit into existing filter assemblies. Lake Shore recently delivered a number of the SBIR-developed filters to Cornell University for use with its Faint Object Infrared Camera (FORCAST), designed for NASA’s SOFIA program. \n                  \n              Lake Shore’s main customers for its filter products are within the astronomy community, but there are other promising applications on the horizon. One such opportunity is in the burgeoning field of terahertz imaging. Terahertz radiation—the range of wavelengths between IR and microwaves—is blocked by water or metal but passes through a range of other materials, including wood, cardboard, clothing, ceramics, and plastic. This makes terahertz radiation a highly appealing option for everything from medical imaging to examining artwork. Because certain materials, like plastic explosives, have special spectral signatures when imaged with terahertz radiation, the potential is great for developing highly specific security measures using terahertz. Klein notes that Lake Shore’s filter technology could be useful for this developing field.\n              \n              “Our partnership with NASA has provided us with cross-cutting technology that we can use for other applications in different markets,” says Klein. The company is also investigating ways of using its SBIR-developed macroporous silicon technology in the development of other types of optical and electronic devices. “We wouldn’t have this porous silicon technology if it wasn’t for the NASA SBIR program.” \n              \n              “The relationship between NASA and the private sector results in a cross-pollination of ideas and technologies, some with readymade applications and customers,” says Klein. “The U.S. government’s multi agency SBIR and STTR programs and their focus on supporting the small, technically rich business community provides an incentive for companies like Lake Shore Cryotronics to further invest in these technologies and bring them \n              to market.”\n              \n              \n              \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ip_4.html","text":"Thermoelectric Devices Cool, Power Electronics ","image":"http://spinoff.nasa.gov/Spinoff2009/images/Nextreme-2.jpg","story":"\n            \n                      Industrial Productivity\n                  \n                      Originating Technology/NASA Contribution \n                  \n  More than 10 billion miles away from Earth, a NASA spacecraft continues a journey that began in 1977. Having long since accomplished its original mission to Jupiter and Saturn, Voyager 1 is the farthest human-made object from Earth, hurtling at more than 38,000 miles per hour toward the heliopause—the very edge of the solar system.\n  \n  At these extraordinary distances, the Sun’s light is too faint to power a solar panel-equipped spacecraft. In fact, the Sun does not provide a viable source of power for many NASA missions. To accommodate this need, NASA employs thermoelectric (TE) devices, which can generate electricity from temperature differentials and vice versa. In a power-generating capacity, TE devices work via the Seebeck effect, in which a circuit made from dissimilar metals creates a voltage if a temperature difference exists between its two sides. When a voltage is applied to a TE device and a current flows through it, the reverse action occurs: The electrical input creates a temperature difference, moving heat from one side of the device to the other in what is called the Peltier effect. When functioning this way, TE devices become temperature management tools, cooling or heating a surface depending on the direction of the electrical flow. \n  \n  For 25 missions so far—including Apollo missions to the Moon, the Viking and Pathfinder missions to Mars, and the Voyager, Pioneer, Ulysses, Galileo, and Cassini solar system missions—radioisotope thermoelectric generators (RTGs) have powered NASA spacecraft. A solid-state technology featuring no moving parts and thus significantly reducing the possibility of failure, these TE devices provide steady, reliable supplies of power for as long as their fuel emits enough heat; powered by three RTGs each, both Voyager 1 and its sister Voyager 2 (launched the same year) are expected to continue operation until 2025, a nearly 50-year lifespan. \n  \n  Engineers at NASA’s Jet Propulsion Laboratory (JPL), who built and operate the Voyager spacecraft among other deep-space missions, continue to explore the potential of thermoelectrics for providing energy and thermal management solutions for use in space. Thermoelectrics have a host of applications on Earth as well, among them semiconductor electronics, lasers, infrared sensors, air conditioners, and communication systems. In keeping with the Agency’s mission to facilitate the transfer of space technology for public benefit, JPL has partnered with a North Carolina company to share the fruits of \n  its research.\n  \n  Partnership \n  \n  In 2005, Dr. Jesko von Windheim and his team founded Nextreme Thermal Solutions Inc., based in Research Triangle Park, North Carolina, to commercialize thermoelectric technology acquired from RTI International, also headquartered in Research Triangle Park. Having previously licensed technology from the California Institute of Technology (Caltech) with microelectromechanical systems startup Cronos Integrated Microsystems, von Windheim was aware of JPL’s thermoelectric expertise and its expansive patent portfolio (Caltech manages JPL for NASA). He discovered a broad JPL thermoelectrics patent that complemented Nextreme’s RTI technology. In 2006, the company exclusively licensed the Caltech/JPL patent, which covers thermoelectric devices containing thermoelectric material less than 40 microns thick. The licensed technology enabled Nextreme’s development as a pioneer in solid-state thermal management for electronics and semiconductors. \n  \n  “This license puts us in a strong position competitively in thin film thermoelectrics,” says Dr. Paul Magill, Nextreme’s vice president of marketing and business development.\n  \n  Product Outcome\n  \n            \n            \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      The small size of Nextreme’s thermoelectric coolers (top image and in comparison to a conventional bulk module middle image) is part of what makes them effective solutions for microchip hotspot cooling. The company’s OptoCooler products, including the HV14 module at (bottom), are enabled by thin film thermoelectric technology licensed from NASA.\n    \n  \n            As electronics advance, becoming faster and more powerful while at the same time smaller and more densely built, engineers are running up against a significant challenge: heat. The lack of corresponding advances in cooling techniques has become a barrier to further development in integrated circuit technologies like microprocessors, where heat buildup can affect performance and lead to device failure. The heat generated by microchips is focused in hotspots rather than uniformly distributed, making conventional thermoelectric coolers (TECs)—also referred to as bulk modules and assembled from tiny pillars of thermoelectric material—impractical options due to their relatively large size. According to Nextreme, using system cooling options like fans, heat sinks, and refrigeration to address microchip hotspots is like air conditioning an entire house just to cool an overheated element on a kitchen stove. Nextreme’s licensed NASA technology is enabling the ideal solution for this problem: thin film thermoelectrics. \n                  \n              “We believe that the JPL technology is fundamental to thin film thermoelectric devices,” says von Windheim, Nextreme’s CEO. “We currently implement it in all of our products.”\n              \n              Thin film thermoelectrics is exactly what it sounds like: ultra-thin thermoelectric technology. Using a process called metal-organic chemical vapor deposition, Nextreme engineers grow films of bismuth telluride which are then used to create the company’s breakthrough thermoelectric application: the thermal copper pillar bump. \n              \n              Copper pillar bumps (CPBs) are solder bumps used to create mechanical and electrical connections as part of the flip chip method for joining semiconductor devices like integrated circuits to external circuitry. Nextreme adds thermal management capabilities to these bumps by integrating a thin film layer of thermoelectric material into each bump, converting them into TECs. As electricity is passed through the thermal bump, heat is moved through the Peltier effect from one side of the bump to the other, shifting it out of the chip and resulting in 5–15 °C of spot cooling per bump. \n              \n              Using a modified CPB flip chip manufacturing process employed by major producers like Intel, Amkor, and Casio, designers can either uniformly distribute these thermal bumps (each 238 microns in diameter and 60 microns high) on a chip or locate them at specific hotspots for targeted thermal control. Nextreme notes that this implementation of thin film thermoelectrics is ideal considering that the flip chip market is one of \n              the largest, fastest-growing semiconductor industry segments, and that as much as 40 percent of flip chip devices have significant thermal challenges. By reversing the current flow in a thermal bump, the device can switch between cooling and heating, providing precise, integrated thermal control. \n              \n              “Now you can design new kinds of circuits that cool themselves, temperature stabilize themselves as a function of the circuit, not as an external cooling or refrigeration function,” says von Windheim. In a separate capacity, through the Seebeck effect, heat applied to one side of the thermal bump results in an electrical output—up to \n              10 milliwatts (mW) per bump, transforming the device into an embedded thermoelectric generator (eTEG). \n              \n              \n              The NASA-enabled thermal bump technology also forms the core of its discrete thermoelectric products, each of which is no larger than a piece of confetti. The OptoCooler product line is ideal for applications including photonics, optoelectronics like laser diodes and high-brightness light-emitting diodes (LEDs), and biomedical devices. On the energy generation side, Nextreme’s eTEG can produce up to 260 mW of power, providing a scalable and cost-effective technology for applications like medical implants and wireless sensor networks, the company says. \n              \n              Nextreme continues to develop and improve its thin film thermoelectrics while expanding the technology’s possible uses to applications beyond electronics—such as cooling the human body. “The beauty of these products being so small,” says Magill, “is that they can be easily integrated into clothing and military body armor at places where the blood comes close to the skin” like the wrists or temples. As the body’s entire supply of blood is continuously cycled, the micro-TECs remove small amounts of heat, supplementing the body’s existing thermal management system and helping it cool. \n              \n              The NASA technology developed to help power unprecedented journeys to the stars could also one day help people travel more effectively on Earth. The future could see Nextreme’s thermoelectric devices producing energy by harvesting normally wasted heat from engines, thus improving automobile fuel efficiency.\n              \n              OptoCooler™ and eTEG™ are trademarks of Nextreme Thermal Solutions Inc.\n              \n              \n              \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ip_5.html","text":"Innovative Tools Advance Revolutionary Weld Technique","image":"http://spinoff.nasa.gov/Spinoff2009/images/Nova-Tech_1.jpg","story":"\n            \n                      Industrial Productivity\n                  \n                      Originating Technology/NASA Contribution\n                  \n  The iconic, orange external tank of the space shuttle launch system not only contains the fuel used by the shuttle’s main engines during liftoff but also comprises the shuttle’s “backbone,” supporting the space shuttle orbiter and solid rocket boosters. Given the tank’s structural importance and the extreme forces (7.8 million pounds of thrust load) and temperatures it encounters during launch, the welds used to construct the tank must be highly reliable. \n  \n  Variable polarity plasma arc welding, developed for manufacturing the external tank and later employed for building the International Space Station, was until 1994 the best process for joining the aluminum alloys used during construction. That year, Marshall Space Flight Center engineers began experimenting with a relatively new welding technique called friction stir welding (FSW), developed in 1991 by The Welding Institute, of Cambridge, England. FSW differs from traditional fusion welding in that it is a solid-state welding technique, using frictional heat and motion to join structural components without actually melting any of the material. The weld is created by a shouldered pin tool that is plunged into the seam of the materials to be joined. The tool traverses the line while rotating at high speeds, generating friction that heats and softens—but does not melt—the metal. (The heat produced approaches about 80 percent of the metal’s melting temperature.) The pin tool’s rotation crushes and stirs the “plasticized” metal, extruding it along \n  the seam as the tool moves forward. The material cools and consolidates, resulting in a weld with superior mechanical properties as compared to those weld properties of fusion welds. \n  \n            \n            \n    \n    \n      \n      The retractable pin tool developed at Marshall Space Flight Center fully enables friction stir welding (FSW) for circumferential and tapered thickness welds, like those needed to assemble the space shuttle’s external tank.         \n    \n  \n            The innovative FSW technology promises a number of attractive benefits. Because the welded materials are not melted, many of the undesirables associated with fusion welding—porosity, cracking, shrinkage, and distortion of the weld—are minimized or avoided. The process is more energy efficient, safe (no toxic smoke or shielding gas, liquid metal splatter, arcing, dangerous voltage, or radiation), and environmentally sound (no consumables, fumes, or noise) than fusion welding. Under computer control, an automated FSW machine can create welds with high reproducibility, improving efficiency and overall quality of manufactured materials. The process also allows for welding dissimilar metals as well as those metals considered to be “unweldable” such as the 7xxx series aluminum alloys. Its effectiveness and versatility makes FSW useful for aerospace, rail, automotive, marine, and military applications. \n                  \n              A downside to FSW, however, is the keyhole opening left in the weld when the FSW pin tool exits the weld joint. This is a significant problem when using the FSW process to join circumferential structures such as pipes and storage containers. Furthermore, weld joints that taper in material thickness also present problems when using the conventional FSW pin tool, because the threaded pin rotating within the weld joint material is a fixed length. There must be capability for the rotating pin to both increase and decrease in length in real time while welding the tapered material. (Both circumferential and tapered thickness weldments are found in the space shuttle external tank.) Marshall engineers addressed both the keyhole and tapered material thickness problems by developing the auto-adjustable pin tool. This unique piece of equipment automatically withdraws the pin into the tool’s shoulder for keyhole closeout. In addition, the auto-adjustable pin tool retracts, or shortens, the rotating pin while welding a weld joint that tapers from one thickness to a thinner thickness. This year, the impact of the Marshall innovation was recognized with an “Excellence in Technology Transfer Award” from the Federal Laboratory Consortium.\n              \n              Partnership\n              \n              In the late 1990s, Nova-Tech Engineering LLC, a machine design, aerospace tooling, and manufacturing systems company, based in Lynnwood, Washington, provided Marshall with stir welding machine retrofits that employed the retractable pin tool, for use during the center’s FSW research on longitudinal and circumferential welds for the space shuttle’s external tank. In 2003, Nova-Tech acquired the FSW equipment and process capabilities of Seattle, Washington firm MCE Technologies Inc., which was co-licensee of the 2001 NASA license for the Marshall FSW technology. After acquiring MCE, Nova-Tech applied for and received a co-exclusive license for the auto-adjustable pin tool for friction stir welding.\n              \n                      \n            \n    \n    \n      \n    \n    \n      \n    \n    \n      \n    \n    \n      Nova-Tech’s FSW machines, like this G10K/Large Plate Gantry Friction Stir Welder, achieve increased capabilities with the incorporation of NASA’s auto-adjustable pin tool technology.\n    \n  \n            Product Outcome\n                  \n              The Marshall adjustable pin tool technology is featured on nearly all of Nova-Tech Engineering’s stir welding systems, including the first three FSW weld heads delivered to the Marshall Space Flight Center in the late 1990s. Nova-Tech supplies a wide range of stir welding machine configurations including circumferential and vertical stir welders for rocket tank assembly; large, five-axis horizontal and vertical stir welders for combat vehicle construction; and multiaxis stir welders for research and development use. \n              \n              “There are some distinct advantages to the retractable pin,” says Don Holman, FSW product manager for Nova-Tech. He explains that the pin provides an integrated solution to the keyhole problem on circumferential welds, and though the technology is not necessary for longitudinal welds, it can still be applied to eliminate the keyhole rather than using run-off tabs (additional lengths of metal that can be trimmed off to eliminate keyholes). Holman also notes that the adjustable pin can sustain uninterrupted full penetration welds on plates of varying thicknesses, without requiring multiple pin tools of varying lengths. A computer-controlled servo motor positions the adjustable pin precisely—within 0.001 inch—to ensure the proper pin penetration in the material. “The retractable pin tool increases the capabilities of our machines,” Holman says, making them more efficient at creating more precise, stronger FSW welds.\n              \n              The appeal of Nova-Tech’s adjustable pin-equipped FSW systems has extended across a wide range of industries. Concurrent Technologies Corporation, a nonprofit research and development organization with offices across the country, uses a Nova-Tech five-axis stir welder at its Johnstown, Pennsylvania, location for welding of armor plate for the U.S. Army’s Expeditionary Fighting Vehicle program. Nova-Tech also built a production FSW machine for Noble Drilling Services of Houston, Texas, a leading offshore drilling contractor that uses the machine to weld aluminum riser piping for offshore drilling rigs; the Nova-Tech machine was the first FSW system developed for the oil and gas industry. \n              \n              Nova-Tech FSW systems are also employed by a number of research institutions exploring ways to improve welding processes for manufacturing. These include the Edison Welding Institute in Columbus, Ohio, and the Missouri University of Science and Technology in Rolla, Missouri. Nova-Tech is additionally a partner of an integrated project team that last year developed and delivered a low-cost FSW system prototype to the U.S. Navy Metalworking Center, which plans to use the machine as an efficient, cost-effective production tool for its Littoral Combat Ship (LCS) program. The LCS program is developing next-generation combat ships for use in littoral, or close to shore, zones.\n              \n              Just as the demands of space exploration led to the adjustable pin technology Nova-Tech now incorporates in its FSW machines, the company is also contributing back to the space industry. Space Exploration Technologies Corporation (SpaceX), of Hawthorne, California, performs circumferential welds on its rockets using a Nova-Tech FSW system. A private launch company, SpaceX is working in close cooperation with NASA to develop, among other things, a cargo launch system for transporting supplies to the International Space Station.\n              \n              \n              \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ip_6.html","text":"Methods Reduce Cost, Enhance Quality of Nanotubes","image":"http://spinoff.nasa.gov/Spinoff2009/images/SWeNT-1.jpg","story":"\n            Industrial Productivity\n                  \n                                  Originating Technology/NASA Contribution \n                  \n                    \n            \n      \n      \n        \n      \n      \n        By increasing the size of its fluidized bed reactors, seen here,  SouthWest NanoTechnologies Inc. (SWeNT) increased its carbon nanotube production capacity while at the same time lowering cost. \n      \n    \n            For all the challenges posed by the microgravity conditions of space, weight is actually one of the more significant problems NASA faces in the development of the next generation of U.S. space vehicles. For the Agency’s Constellation Program, engineers at NASA centers are designing and testing new vessels as safe, practical, and cost-effective means of space travel following the eventual retirement of the space shuttle. Program components like the Orion Crew Exploration Vehicle, intended to carry astronauts to the International Space Station and the Moon, must be designed to specific weight requirements to manage fuel consumption and match launch rocket capabilities; Orion’s gross liftoff weight target is about 63,789 pounds. Future space vehicles will require even greater attention to lightweight construction to help conserve fuel for long-range missions to Mars and beyond. \n                  \n              In order to reduce spacecraft weight without sacrificing structural integrity, NASA is pursuing the development of materials that promise to revolutionize not only spacecraft construction, but also a host of potential applications on Earth. Single-walled carbon nanotubes are one material of particular interest. These tubular, single-layer carbon molecules—100,000 of them braided together would be no thicker than a human hair—display a range of remarkable characteristics. Possessing greater tensile strength than steel at a fraction of the weight, the nanotubes are efficient heat conductors with metallic or semiconductor electrical properties depending on their diameter and chirality (the pattern of each nanotube’s hexagonal lattice structure). All of these properties make the nanotubes an appealing material for spacecraft construction, with the potential for nanotube composites to reduce spacecraft weight by 50 percent or more. The nanotubes may also feature in a number of other space exploration applications, including life support, energy storage, and sensor technologies. \n              \n              NASA’s various efforts with carbon nanotubes have made it a global leader in this field. Among the many examples are Johnson Space Center’s Carbon Nanotube Project, which focuses on bulk nanotube production, purification, and application, and Goddard Space Flight Center’s improved arc discharge method of nanotube production, developed under the direction of Jeannette Benavides (featured in Spinoff 2007 and 2008). While the Agency continues its own research, it partners with private companies to advance this unique technology for use on Earth as well as among the stars. \n              \n              Partnership\n              \n              One of the significant challenges involved with taking advantage of single-walled nanotube technology lies in how the nanotubes are made. Typical manufacturing methods are expensive, are not amenable to large scale production, and can be inefficient, resulting in samples containing as low as 10–15 percent nanotubes. Costly and time-consuming separation procedures are needed to sort out nanotubes of the desired diameter, length, \n              and chirality. In addition, nanotube samples can be tainted with residual catalyst impurities and common byproducts like amorphous carbon and graphite nanofibers. Thus, affordable, largely pure nanotube supplies with tailored properties for research and commercial efforts have been lacking. \n              \n              To address these issues, Johnson awarded Phase I and II Small Business Innovation Research (SBIR) contracts to SouthWest NanoTechnologies Inc. (SWeNT), of Norman, Oklahoma, to pursue the development of a new nanotube production method. Founded in 2001, SWeNT is the offshoot of landmark research conducted by Daniel Resasco at the University of Oklahoma. Resasco pioneered a controlled catalytic method for creating nanotubes that is inherently scalable for mass production. During Resasco’s cobalt-molybdenum catalytic procedure—known as the CoMoCAT process—pure carbon monoxide (CO) flows through suspended cobalt and molybdenum catalyst particles in a device called a tubular fluidized bed reactor. At certain temperatures and pressure, the nanotubes are grown as the CO decomposes into carbon and carbon dioxide. By controlling the conditions and catalyst within the reactor, Resasco was able to grow significant, highly selective amounts of high-quality nanotubes within a couple of hours. \n              \n              Using the NASA SBIR funding, SWeNT demonstrated that increasing the size of the fluidized bed reactor platform increased production capacity while decreasing cost. The SBIR support also provided another welcome outcome: higher quality nanotubes. \n              \n              “When we invested in larger scale equipment, we also invested in more automation, instrumentation, and process controls,” says SWeNT CEO David Arthur. “That resulted in significant improvement in quality at the same time that we were expanding capacity and reducing cost.”\n              \n              Product Outcome\n              \n              In 2008, SWeNT opened a commercial-scale nanotube manufacturing plant. Since beginning operations at the 18,000-square-foot facility, Arthur says, the company has experienced a hundredfold increase in production coupled with a tenfold reduction in cost. SWeNT now offers two single-walled carbon nanotube product lines, as well as customized orders for the company’s hundreds of customers. \n              \n                    \n            \n      \n      \n        \n      \n      \n        This image of SWeNT’s single-walled carbon nanotubes reveals the hexagonal lattice sidewall structure of the nanotubes. The pattern of this structure plays a role in determining the nanotubes’ properties.\n      \n    \n            “We are one of the only companies that is able to supply these materials in commercial quantities in North America,” says Arthur. “None of this would have happened without the original NASA SBIR funds to prove our production methods.”\n                  \n              Those production methods are the key to increasing output while lowering cost, Arthur notes. By controlling nanotube synthesis, SWeNT can selectively grow the nanotubes its clients want while avoiding an expensive, wasteful, time-consuming, and non-scalable sorting process. Using the CoMoCAT process, the company delivers nanotube orders that are routinely 95 percent carbon in composition, with more than 90 percent of that carbon in the form of nanotubes—all above typical industry outcomes. \n              \n              SWeNT’s controlled synthesis capabilities have allowed it to provide customers with customized nanotubes for a wide range of new and developing technologies. The company has supplied diameter-specific nanotubes for use in reinforcing carbon fibers, with the potential to yield a material 17 times stronger than Kevlar for use in bulletproof body and vehicle armor. It is working with aerospace and nanomaterials clients to produce chirality-specific nanotubes—the goal, Arthur says, is to create the most electrically conductive carbon nanotubes in the world—for nanocomposite cable wiring to replace standard metal wiring in commercial aircraft. The company is exploring the use of its semiconducting nanotubes in the form of an ink, enabling the production of low-cost, printable electronics; applications include radio frequency identification, biological and chemical sensors, and electronic displays. Arthur foresees SWeNT nanotubes also enabling more affordable solar photovoltaic panels and solid-state lighting products that could have a dramatic impact on energy consumption.\n              \n                    \n            \n      \n        \n      \n    \n            SWeNT has set its sights on expanding its capabilities to also produce small-diameter, multiwalled carbon nanotubes for niche electrical applications, as well as building on its current single-walled nanotube success. \n                  \n              “Our vision is to once again increase our production scale a hundredfold and enjoy another tenfold reduction in cost,” says Arthur. At that point, he says, the company can even further reduce costs by recycling the CO feed gas used in the synthesis process—its most expensive production material. \n              \n              SWeNT’s NASA SBIR-enabled CoMoCAT process is receiving notice from beyond its customer base. The company received a 2007 “Tibbets Award” for excellence in SBIR achievement, and last year the National Institute of Standards and Technology designated SWeNT’s SG65 single-walled carbon nanotubes as a starting material for developing a carbon nanotube Standard Reference Material. These reference materials are employed by industry, academia, and government as standards for commerce, trade, and research and development.\n              \n              SWeNT® and CoMoCAT® are registered trademarks of SouthWest NanoTechnologies Inc.\n              Kevlar® is a registered trademark of E. I. du Pont de Nemours and Company.\n                \n                \n                \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ip_7.html","text":"Gauging Systems Monitor Cryogenic Liquids","image":"http://spinoff.nasa.gov/Spinoff2009/images/R-D_thumb.jpg","story":"\n            \n              Industrial Productivity\n                  \n                                  Originating Technology/NASA Contribution\n                  \n                    \n            \n      \n      \n        \n      \n      \n        The Saturn V was a liquid-fueled expendable rocket used for Apollo and Skylab missions. Apollo 15, shown here, used \n          over three-quarters of a million gallons of liquid oxygen and liquid hydrogen.\n      \n    \n            Rocket fuel needs to stay cool—super cool, in fact. The ability to store gas propellants like liquid hydrogen and oxygen at cryogenic temperatures (below -243 °F) is crucial for space missions in order to reduce their volumes and allow their storage in smaller (and therefore, less costly) tanks. The Agency has used these cryogenic fluids for vehicle propellants, reactants, and life support systems since 1962 with the Centaur upper stage rocket, which was powered with liquid oxygen and liquid hydrogen.\n                  \n              During proposed long-duration missions, super-cooled fluids will also be used in space power systems, spaceports, and lunar habitation systems. In the next generation of launch vehicles, gaseous propellants will be cooled to and stored for extended periods at even colder temperatures than currently employed via a process called densification. Densification sub-cools liquids to temperatures even closer to absolute zero (-459 °F), increasing the fluid’s density and shrinking its volume beyond common cryogenics. Sub-cooling cryogenic liquid hydrogen, for instance, from 20 K (-423 °F) to 15 K (-432.4 °F) \n              reduces its mass by 10 percent. These densified liquid gasses can provide more cost savings from reduced payload volume.\n              \n              In order to benefit from this cost savings, the Agency is working with private industry to prevent evaporation, leakage, and other inadvertent loss of liquids and gasses in payloads—requiring new cryogenic systems to prevent 98 percent (or more) of boil-off loss. Boil-off occurs \n              when cryogenic or densified liquids evaporate, and is a concern during launch pad holds. Accurate sensing of propellants aboard space vehicles is also critical for proper engine shutdown and re-ignition after launch, and zero boil-off fuel systems are also in development for the Altair lunar lander.\n              \n              Partnership\n              \n              One company, in partnership with NASA, has developed a liquid-sensing system that monitors cryogens and densified propellants. Fremont, Ohio’s Sierra Lobo Inc. (SLI) specializes in cryogenics and propulsion, and, in particular, produces propellant storage systems. The Hispanic-American-owned company that began with only 9 employees in 1993 now has an ISO 9001:2008 registration and currently employs over 370 people in its Ohio, Florida, Texas, Alabama, Virginia, and California facilities. \n              \n              In 2006, SLI developed the Cryo-Tracker Mass Gauging System (Cryo-Tracker MGS) with funding from a Phase III Small Business Innovation Research (SBIR) contract from Kennedy Space Center, after receiving Phase I and Phase II funding from the U.S. Department of Defense. The Cryo-Tracker (CT) probe—the key component of the Cryo-Tracker MGS—works in conjunction with the system’s other two components: electronics that provide power and signal management for each sensing element, and software that displays data received from the probe. Since winning the initial SBIR contract, SLI has successfully tested Cryo-Tracker MGS on parabolic flights, which simulate the reduced gravity of space flight without the high costs. On these flights, SLI researchers validated wicking technology used in the system’s sensors by capturing numerous images of the system’s CT probe operating in water during 90 reduced-gravity parabolas lasting 25 seconds each. Sierra Lobo also successfully tested a 33-foot CT probe and the Cryo-Tracker MGS in a simulation of typical pre-launch and flight operations in a large-scale expendable launch vehicle liquid oxygen tank. \n              \n              SLI has also received funding from NASA’s Innovative Partnerships Program Seed Fund in order to advance its system’s flight readiness for use on NASA and commercial launch vehicles. The NASA Launch Services Program, which certifies launch vehicles and manages payloads for the Agency, rated the Cryo-Tracker MGS at technology readiness level (TRL) 6, which indicates successful testing of a prototype in a relevant environment. The next level, TRL 7, requires successful operation in space. Cryo-Tracker MGS has been successfully tested with the liquid forms of nitrogen, oxygen, methane, and hydrogen, and the system proved robust in extensive vibration testing. \n              \n              Product Outcome\n              \n                    \n            \n      \n      \n        \n      \n      \n        \n      \n      \n        The Cryo-Tracker probe (at top) can monitor mass, levels, temperature, and pressure of stored cryogenic liquids. bottom, the Cryo-Tracker probe descends into a large tank where a worker checks conditions.\n      \n    \n            SLI is marketing the Cryo-Tracker MGS as a commercial product to testing facilities that use and store cryogens. Various industries routinely use cryogenic Dewar flasks (vacuum flasks) to store or transport super-cooled liquids, including the medical industry, metals processing, and semiconductor manufacturing. The Cryo-Tracker MGS is used in these industries to monitor mass, liquid levels, temperature, and pressure for stored liquid helium, hydrogen, nitrogen, or oxygen. \n                  \n              The Cryo-Tracker MGS is a three-part system that integrates the use of software, electronics, and the “R&D 100” award-winning CT probe. The probe offers increased reliability and adaptability over other cryogenic probes, according to Mark Haberbusch, director of research and technology at SLI. The patented probe has low mass for quick thermal response and flexible, one-piece construction, which reduces potential problems from vibration or breakage. It can also be adapted to different applications that may have size restrictions; Haberbusch explains that the CT probe can be manufactured to virtually any length and width, and has a nominal thickness of 0.030 inches (0.76 millimeters). Flexible material allows the CT probe to be installed along non-uniform tank walls, allowing it to gauge mass, tank pressure, liquid temperature profiles, and liquid levels in tight spaces. \n                  \n              In addition, the probe offers a flexible design configuration; each of the probe’s silicon diode sensors can be independently operated to detect liquid level or sense temperatures ranging from 1.4 K (-457 °F) to 325 K \n              (125 °F) in the liquid as well as the unfilled container space (called ullage). Each diode’s sensing mode can then be toggled on the fly or by a preprogrammed logic of operations. A 1-millimeter-thick layer of polyimide insulates the diodes inside the probe from the fluids, enabling the probe to respond accurately to temperature and liquid-level changes in less than 1 second. The sensing elements can detect the difference between liquid and vapor (even when they are at the same temperature) through the difference in voltage output. This quick response adds a level of safety to cryogenic operations and storage by providing the ability to detect dangerous heat levels inside a tank that could lead to rapid over-pressurization. \n              \n              An electrical enclosure houses the Cryo-Tracker MGS electronics, which include a circuit board and electrical connections. These electronics power the CT probe’s \n              sensors and relay data from the sensors to the Cryo-Tracker MGS software. A microcontroller in the electronics regulates the diode currents, which convey data from the sensors. \n              \n                    \n            \n      \n        \n      \n    \n            The third component in the system, the Cryo-Tracker MGS software, determines the mass of fluid in a tank by monitoring liquid temperature, level, and ullage pressure. The software calculates mass and mass uncertainty, identifying the components needing the most monitoring. The software can monitor liquid mass for a variety of fluids in different types of Dewar flasks or tanks. In addition, the software uses computational fluid dynamics to determine the optimum number of sensors and their ideal locations for mass measurements. \n                  \n              Although SLI is currently marketing the Cryo-Tracker MGS primarily to customers interested in medical or industrial storage, it may only be a few years before this “super cool” gauging system appears in consumer products. SLI soon expects that manufacturers will begin using SLI’s Cryo-Tracker MGS to monitor tanks for \n              gas grills and no-vent fuel tanks in liquid hydrogen-powered automobiles.\n              \n              Cryo-Tracker® is a registered trademark of Sierra Lobo Inc.\n                \n                \n                \n              \n                \n                \n                \n                \n              \n            \n          "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ip_8.html","text":"Voltage Sensors Monitor Harmful Static","image":"http://spinoff.nasa.gov/Spinoff2009/images/Sojourner_on_Mars.jpg","story":"\n                            Industrial Productivity\n        \n        Originating Technology/NASA Contribution\n        \n      \n      \n                  \n                  \n                    \n                  \n                  \n                    Concern over static electricity damaging components on Mars rovers Spirit and Opportunity led scientists to add grounding wires to the base of the rovers’ antennas. \n                  \n                  \n                      Anyone who has ever experienced an unpleasant jolt from a doorknob after shuffling across the carpet on a dry morning knows that static electricity—also known as triboelectric charging—can be a nuisance. However, many computer enthusiasts are too familiar with how built-up triboelectricity can actually cause major problems when building a home computer; a simple spark from a finger can damage sensitive components and render them unusable. Under certain conditions, built-up triboelectricity discharges in these seemingly minor jolts, called electrostatic discharge (ESD), which can also cause major problems for NASA, as well as the computer industry. ESD can create sparks that ignite fuel in launch operations, and ESD can also damage delicate electronics and avionics, for operations on Earth as well as on space missions. \n                        \n    This concern over static electricity damaging mission-critical components led scientists to add grounding wires to the base of antennas for Spirit and Opportunity, which continuously discharge up to a few hundred volts, accumulated as they make their way across the dry surface of Mars. Without some sort of grounding or protection, the Mars rovers might have been incapacitated by a single electric shock. \n    \n    Kennedy Space Center’s Electrostatics and Surface Physics Labo­ratory scientist, Dr. Carlos Calle, proposed developing static sensors for future missions, in which larger vehicles would be at greater risk from accumulating more dangerous levels of triboelectricity. These static sensors would not just be useful on other planets for roving robots, however; they could also help protect sensitive components here on Earth.\n    \n    In addition to causing problems for personal computers, ESD can also cause problems in the manufacture of hard disk drives, semiconductors, flat panel displays, and avionics. These problems include electrostatic attraction drawing contaminants onto the product, the ESD itself causing defects, and electromagnetic interference causing consequent malfunction in the products and production equipment.\n    \n    Partnership\n    \n    In 2004, San Diego’s QUASAR Federal Systems Inc.(QFS) completed Phase I of a Small Business Inno­vation Research (SBIR) contract for Kennedy’s Electrostatics and Surface Physics Labo­ratory, after Calle provided NASA’s requirements for a wearable electrostatic sensor. QFS focuses on electromagnetic sensor products for relatively low frequencies, from near-DC through the megahertz range. Led by the company’s vice-president of research and development, Dr. Yongming Zhang, QFS completed a prototype of an electrostatic hazard detection sensor in Phase II of the contract in 2006. The company now calls the product its Remote Voltage Sensor (RVS).\n    \n    QFS formed a partnership with Novx Corporation, which was then acquired by MKS Instruments Inc. (MKS). A creator of ionization and monitoring products for \n    many electronics and industrial markets, MKS now distributes the QFS RVS sensor as part of its ION Systems product line.\n    \n    Product Outcome\n    \n    The RVS is a dime-sized electrometer designed to measure triboelectric changes in the environment. Eric Duff, vice president of business development at QFS, explains how the sensor works: “The RVS is an extremely sensitive measure of the electric potential in free space,” he says. “Any voltage on anything in front of the sensor will shift that potential. It’s essentially a sensor that is sensitive to any voltage changes in the environment.” The sensor only responds to stationary objects acquiring a charge from various sources, or to time-varying fields, which are caused by charged objects moving into the sensor’s range. The sensor does not respond to static DC fields, but will sense potential changes down to 0.2 Hz, so equipment that is operating normally near the RVS will not trigger it.\n    \n                      \n                \n      \n      \n        \n      \n      \n        MKS Instruments markets the RVS as part of its Novx Series 7000 and Novx Series 3370 monitoring systems. These systems allow the customer to set the instrument sensitivity, thus tailoring the instrument’s output to a specific need.\n          \n          Image courtesy of MKS Ion Systems\n      \n    \n                      One of the unique qualities of the RVS is that, because of its sensitivity, it can detect static at greater distances than previous devices. According to Zhang, earlier sensors had to be within 2.5 centimeters of the subject in order to detect potential ESD, but the RVS can now measure voltage changes from a few centimeters to a few meters away, due to its much-improved sensitivity.\n                        \n    This “work station protection,” as Duff calls it, monitors electrostatic fields in real time, and is rugged, low power, and low cost. Because the RVS does not have moving parts, it cannot be a source of ESD itself, which was a major problem with prior devices. Additional features include fast response time, reduction of DC drift issues, variable voltage range settings, and ultra-low circuit noise, which makes the sensor up to 1,000 times more sensitive than traditional electric field mills (devices which measure the strength of electric fields).\n    \n    Because of its small size, this sensor can be worn on clothing to monitor the triboelectric energy a worker accumulates, or can be affixed to laboratory entrances or specific equipment to monitor voltage changes near sensitive instruments. The sensor’s very small footprint also allows it to be easily integrated into existing equipment and applications. \n    \n    MKS Instruments markets the RVS as part of its Novx Series 7000 Monitoring System for single-sensor uses, and offers the Novx Series 3370 for applications requiring multiple sensors. These systems take data transmitted by the sensor and allow the customer to set the instrument sensitivity “filtering,” thus tailoring the instrument’s output to specific need.\n    \n    QFS, which has a patent pending for the sensor, is finding success in sensitive-manufacturing facilities, including those that produce semiconductor wafers and flat-panel displays. For semiconductor applications, the RVS offers 300-millimeter wafer diagnostics, continuous wafer charge monitoring, pre-cursor identification for electrostatic chuck failures, and external monitoring of vacuum chamber wafer charges. By allowing manufacturers to avoid static-related product defects, the RVS contributes to the overall productivity of the electronics industry, which also includes medical device manufacturing and aerospace electronics manufacturing. \n    \n    Duff says the company looks forward to infusing its commercialized technology back into NASA, but in the meantime, the company is selling the RVS and developing related sensors for a variety of customers. Although sales of the RVS have been limited in 2009, the company believes there will be more demand as the market recovers from the economic slowdown and market production increases, particularly in the semiconductor industry. Meanwhile, the company continues to pursue SBIRs with several government agencies, and found working with NASA, according to Duff, a productive collaboration QFS would like to re-experience.\n    \n    ION Systems® is a registered trademark of MKS Instruments Inc. \n    \n    \n    \n                      \n                        \n                        \n                        \n                        \n                      \n                      \n    "},{"href":"http://spinoff.nasa.gov/Spinoff2009/ip_9.html","text":"Compact Instruments Measure Heat Potential","image":"http://spinoff.nasa.gov/Spinoff2009/images/Partnership-SPSR.jpg","story":"\n                          Industrial Productivity\n                  \n                                  Originating Technology/NASA Contribution\n                  \n                    \n            \n      \n      \n        \n      \n      \n        During training exercies, an astronaut uses a mockup of a space-portable spectral reflectometer, an instrument for measuring the thermal properties of surfaces in space. \n      \n    \n            Without the insulating protection of Earth’s atmosphere, orbiting space shuttles, space stations, and satellites are subject to thermal damage from radiation. This damage varies with different orbital parameters, solar activity, and the vehicle’s angle to the Sun, so these external surfaces must be designed to resist degradation and protect payloads (and crew) in these varying conditions. \n                  \n              When designing space vehicles and structures, it is important to know how effectively materials will heat or cool a system, and how much they change while in use. Spectral reflectometers, which measure these thermal properties, determine how well a surface absorbs, reflects, emits, or radiates heat. When measuring the surface properties of a material that will be used in space, scientists have traditionally used reflectometers with integrating spheres (also called Ulbricht spheres), which are best suited for the solar spectrum where radiation is hemispherical and the heat sink is all-encompassing, as is the case in space. \n              \n              In the 1980s, NASA sought an instrument that astronauts could carry on extravehicular activities (EVAs) to assess conditions of external surfaces on space shuttles and space stations. NASA has also used these devices to assess spacecraft instruments and coatings prior to launch to ensure proper thermal properties. \n              \n              Partnership\n              \n              A woman- and veteran-owned small business with 35 employees, AZ Technology Inc. offers expertise in electromechanical-optical design and advanced coatings. It sells several portable instruments for measuring different optical properties, including solar absorptance, reflectance, transmittance, and emittance. Based in Huntsville, Alabama, AZ Technology has received eight Small Business Innovation Research (SBIR) contracts with Marshall Space Flight Center for the development of spectral reflectometers and the measurement of surface thermal properties. \n              \n              Marshall awarded AZ Technology its first NASA contract in 1989 to develop a space-portable spectral reflectometer (SPSR), a hand-held instrument for measuring the thermal properties of surfaces in space. The SPSR was transported to the Mir space station on STS-86, and then used in EVAs to assess the optical performance of external spacecraft radiation tiles. Based on its experience with the SPSR, AZ Technology then entered into a dual-use agreement with Kennedy Space Center for the development of another portable reflectometer, the Total Emittance and Solar Absorption (TESA) instrument, featured in Spinoff 1999. \n              \n              AZ Technology has also received funding from a Phase III SBIR to develop its Spectrafire laboratory-based spectral emissometer. Recently, the company adapted the Spectrafire into a high-temperature spectral emissometer for Marshall, where it is being used to evaluate ablative materials and emittance characterizations of rocket nozzle designs. The company has also been awarded several SBIRs relating to thermal coatings, which continue to develop concurrently with the company’s expertise in thermal design and instrumentation.\n              \n              Product Outcome\n              \n              At ambient conditions, typically near room temperature, most energy transfer is in the infrared spectrum. The materials used to make good integrating spheres—useful for the solar spectrum—do not work well for the infrared spectrum on Earth. To work around bandpass limitations and the need for special calibrations, among other issues, AZ Technology engineers created the Spectrafire with an ellipsoidal collector. This type of collector allows several advantages over an integrating sphere.\n              \n                    \n            \n      \n      \n        \n      \n      \n        Shown attached to a personal computer for processing, the Spectrafire is an emissometer that uses an ellipsoidal collector, which allows this bench unit to be smaller than its predecessors. \n      \n    \n            David Crandall, AZ Technology’s executive vice president in instruments and engineering services, explains that the ellipsoidal collector allows the Spectrafire to take full advantage of extended spectral ranges. When the Spectrafire is used with a Fourier transform interferometer, spectral total hemispherical reflectance can be measured and, from that, optical properties from the ultraviolet range through far infrared can be calculated. \n              In this configuration, the Spectrafire can predict emittance at temperatures outside of ambient range: “On a regular basis, we see good projections up to 600 °C,” Crandall says.\n              \n              Another advantage, Crandall explains, is that the measurement is absolute, and not relative, so there is no operator calibration required for normal emittance. Traditional emittance measurement systems required calibration, often multiple times a day.\n              \n              In the infrared region there is a loss of energy, which presents a limitation for integrating sphere-based systems. By design, energy that is collected in an integrating sphere is reflected many times before it reaches the detector, causing loss. If a sphere liner is 95-percent reflective, after two reflections, only 90 percent of the energy would remain, and after 14 reflections, more than half of the energy would be absorbed. With an ellipsoidal collector, as is used in the Spectrafire, this is not a problem. There is only one reflection off the collector wall, so the energy throughput is far better. Also, the collector is considerably smaller than an equivalent integrating sphere, which enables the Spectrafire to be even smaller than its predecessors.\n              \n              Using the Spectrafire, AZ Technology is also able to determine the transmittance of thin materials, such as frosted glass and translucent polymer films. Typically, conventional instruments measure specular transmissions and can measure the transmittance of clear glass, but translucent materials are problematic because they scatter energy; this results in erroneous measurements. The Spectrafire is able to account for that scattering and provide accurate information about the optical properties of translucent materials.\n              \n              The development of Spectrafire and AZ Technology’s ability to generate spectral reflectance and emittance measurements, Crandall says, enabled the company to begin offering unique services to industry. In 2007, the company used Spectrafire when providing measurement services to General Electric Company (GE) for the design of its Giraffe Warmer for newborns in neonatal intensive care units. “We made suggestions on how they could tailor the emittance with changes in materials and surface finishes,” Crandall says. The device incorporates a heat source that shines onto a reflector. “And that reflector has to emit properly to maintain that baby’s temperature,” explains Crandall. “They had a thermal designer, but he had to know the emittance, and we were able to provide that.” The Giraffe Warmer won the 2008 “Medical Design Excellence Award.”\n              \n              Thanks to the core competencies developed through its long line of contracts with NASA, AZ Technology sells several other optical measurement tools for field and laboratory use. The TEMP 2000A, for which the company also received NASA funding, has been used to qualify heat exchanger pipe coatings in solar collectors and roofing materials for ENERGY STAR designation. Additionally, the company also qualifies reflectors for infrared camera systems and black baffle coatings for infrared optical systems. Lastly, because of its unique expertise, AZ Technology develops calibration standards for instrumentation, including emissometers and scatterometers. In addition to its optical measurement tools and services, AZ Technology sells thermal control coatings, which have also been developed with NASA funding.\n              \n              Giraffe™ is a trademark of Datex-Ohmeda Inc.\n              ENERGY STAR® is a registered mark owned by the U.S. Government.\n              \n              \n              \n              \n                \n                \n                \n                \n              \n            \n          "}]