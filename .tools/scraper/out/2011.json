[{"href":"http://spinoff.nasa.gov/Spinoff2011/hm_1.html","text":"Bioreactors Drive Advances in Tissue Engineering","image":"http://spinoff.nasa.gov/Spinoff2011/Images/hm-1_fmt1.jpg","story":"\n    NASA Technology\n    It was an unlikely moment for inspiration. Engineers David Wolf and Ray Schwarz stopped by their lab around midday. Wolf, of Johnson Space Center, and Schwarz, with NASA contractor Krug Life Sciences (now Wyle Laboratories Inc.), were part of a team tasked with developing a unique technology with the potential to enhance medical research. But that wasn’t the focus at the moment: The pair was rounding up colleagues interested in grabbing some lunch. \n    \n      \n      \n        \n      \n      \n        Because of gravity, cells grown in Petri dishes settle in flat layers rather than assemble into 3D tissues like in the human body. By mimicking microgravity, the NASA bioreactor yields healthier, more realistic cell cultures.\n      \n    \n    One of the lab’s other Krug engineers, Tinh Trinh, was doing something that made Wolf forget about food. Trinh was toying with an electric drill. He had stuck the barrel of a syringe on the bit; it spun with a high-pitched whirr when he squeezed the drill’s trigger. \n    At the time, a multidisciplinary team of engineers and biologists—including Wolf, Schwarz, Trinh, and project manager Charles D. Anderson, who formerly led the recovery of the Apollo capsules after splashdown and now worked for Krug—was pursuing the development of a technology called a bioreactor, a cylindrical device used to culture human cells. The team’s immediate goal was to grow human kidney cells to produce erythropoietin, a hormone that regulates red blood cell production and can be used to treat anemia. But there was a major barrier to the technology’s success: Moving the liquid growth media to keep it from stagnating resulted in turbulent conditions that damaged the delicate cells, causing them to quickly die. \n    The team was looking forward to testing the bioreactor in space, hoping the device would perform more effectively in microgravity. But on January 28, 1986, the Space Shuttle Challenger broke apart shortly after launch, killing its seven crew members. The subsequent grounding of the shuttle fleet had left researchers with no access to space, and thus no way to study the effects of microgravity on human cells. \n    As Wolf looked from Trinh’s syringe-capped drill to where the bioreactor sat on a workbench, he suddenly saw a possible solution to both problems.\n    “It dawned on me that rotating the wall of the reactor would solve one of our fundamental fluid mechanical problems, specifically by removing the velocity gradient of the tissue culture fluid media near the reactor’s walls,” says Wolf. “It looked as though it would allow us to suspend the growing cells within the reactor without introducing turbulent fluid mechanical conditions.” \n    \n      \n      \n        \n      \n      \n        Astronaut David Wolf performs maintenance on a NASA bioreactor unit onboard the Mir space station. Experiments conducted by Wolf demonstrated that the bioreactor produces even more effective cell growth results in space.\n      \n    \n    The three engineers skipped lunch. They quickly built a prototype from components lying around the lab and tested the bioreactor that night using hamster kidney cells (cheaper than their human counterparts). When the team returned in the morning, not much had changed; the cells were all dead. But after running chemical analyses, Wolf and his colleagues realized the cells had died from an altogether different reason than before: They had run out of nutrients because they grew too fast. The new bioreactor was, in a sense, too effective. \n    The bioreactor’s rotating wall eliminated the problematic mechanical forces that had damaged previous cell cultures, creating a constant free fall effect within the media and suspending the cells in a way very similar to microgravity. As the team discovered means of supplying nutrients and oxygen and removing waste at high enough rates to support the cell cultures, they noticed new structures forming within the bioreactor. While standard human cell cultures grown in Petri dishes settle into flat layers thanks to gravity, the NASA bioreactor’s microgravity mimicry produced very different results. \n    “These were three-dimensional structures that very accurately represented the way human tissue is structured in the body,” says Wolf. The bioreactor performed even better in space, as was later demonstrated by Wolf himself as an astronaut onboard the STS-86 mission to the Mir Space Station. \n    “When I first put the space-grown tissue samples under the microscope, I was astounded. With many years of experience culturing tissues, I had never seen any so well organized and with such fine structure,” Wolf says. It was another breakthrough moment, he says, similar to when the team first discovered the ability to assemble 3D tissue on Earth using the simulated microgravity of the NASA bioreactor. Wolf, Schwarz, and Trinh won NASA “Inventor of the Year” honors for their innovation.\n    Partnership \n    In 1990, Anderson and Schwarz licensed patents for the rotating wall bioreactor technology and founded Synthecon Inc. in Houston, Texas, to commercialize the device. \n    “When they saw what the technology could do, they thought, ‘Wow, we really have a better mousetrap,’” says Bill Anderson, Charles Anderson’s son and current president of the company. Synthecon’s founders saw great potential in the bioreactor not only as a powerful tool for growing healthy cell cultures, but also as an enabler for more effective drug development and production techniques and even entirely new fields of medicine. \n    The problem was waiting for the rest of the medical industry to catch up, explains Anderson. Scientists were satisfied using flasks to culture cells, and drug companies were relying on the resulting two-dimensional cells, unlike any in the human body, to provide them with data for their pharmaceutical compounds.\n    “The technology was 7 to 8 years ahead of its time,” Anderson says. \n    While Synthecon worked to demonstrate the potential of the rotating wall bioreactor, it received significant support from NASA.\n    “We were fortunate in the early days that NASA saw the importance of the technology and formed a grant program around it,” Anderson says. The Agency funded researchers from schools like Harvard University and the Massachusetts Institute of Technology to test the device’s value for what was then a burgeoning medical field—tissue engineering, seeding an artificial matrix with cells that grow into implantable human tissues. Synthecon provided the bioreactors for these studies, and the results—success growing different tissue types, as well as tumor models for testing cancer treatments outside of the body—led to numerous published findings that added relevance to the technology. \n    “It really helped us stay alive when most small businesses don’t get that benefit,” says Anderson. \n    Benefits\n    Synthecon has since built a portfolio of patents based on the original NASA bioreactor and improved upon the original technology in a number of ways, creating models inexpensive enough to be disposable, as well as automated versions that can change the growth media without stopping the reactor’s rotation. Now the company’s NASA-developed Rotary Cell Culture Systems (RCCS)—an “R&D 100” award-winning technology—are key tools for medical research being conducted around the globe, and the company, bioreactor technology, and original NASA innovators were all inducted into the Space Technology Hall of Fame in 2011.\n    “It might have been ahead of its time, but our technology is really filling its shoes quickly,” Anderson says. \n    \n      \n      \n        \n      \n      \n        Synthecon Inc. has further advanced the bioreactor technology, creating platforms like this perfused culture system that allows the cell growth medium to be exchanged, sampled, or modified without stopping the bioreactor’s rotation and potentially damaging the cells.\n      \n    \n    Major pharmaceutical companies, Anderson explains, spend significant amounts of money on drug discovery and now want to test candidate compounds on RCCS-grown, 3D cells to get a more accurate sense of a potential drug’s effects. Synthecon is also scaling up the bioreactor technology for the production of recombinant proteins and antibodies. (Recombinant proteins are expressed from cells containing genetically modified DNA; this is the method used to create human insulin and the hepatitis B vaccine among other vaccinations and disease treatments. Synthecon is working with researchers on recombinant protein studies that may yield drugs for diseases like rheumatoid arthritis and lupus.) The company has found that an RCCS can churn out multifold more product than standard systems because it treats cells so gently, meaning the cells expressing the proteins do not spend energy on repair, a major drain on their productivity. A 100-liter RCCS can thus generate the same output as a 1,000-liter standard system. \n    Another developing area of medical research in which Synthecon’s NASA technology promises to be a major contributor is regenerative medicine. Much has been made in recent years about the prospects of stem cells to treat conditions as varied as cancer, diabetes, and sickle cell anemia. (In simple terms, stem cells are special cells that can transform into other cell types, offering the potential to replace damaged or malfunctioning cells with healthy ones.) A major obstacle, however, is supply. Synthecon is currently engaged in studies using its RCCS devices to multiply stem cells from umbilical cord blood—a plentiful source without the ethical concerns raised by embryonic stem cells. Cord blood transplants have already been demonstrated to treat leukemia and other cancers, Anderson says, and the RCCS offers the means to efficiently generate the amounts of healthy stem cells necessary for medical use. \n    Synthecon is also helping improve a therapy technique for Type 1 diabetes. In the pancreas, tiny clusters called islets of Langerhans—each about the size of a period—contain certain cells that generate insulin. Previous methods of transplanting healthy donor islets into a diabetic’s pancreas involved placing the islets into a flask before transplantation, resulting in a roughly 50 percent or worse survival rate for the donor cells, Anderson explains. Researchers working with Synthecon’s technology found that placing the cells in the bioreactor prior to transplantation significantly improved the health of the donor islets, to the point where only one-third as many were needed to produce a secure therapeutic dose. Synthecon is collaborating with the University of Illinois at Chicago Transplant Center to conduct a human clinical trial in 2011.\n    “We think the bioreactor is going to provide a lot of benefit to a lot of patients moving forward,” says Anderson. “The applications seem to grow every year.” \n    “I think it is reasonable to say that the fields of regenerative medicine and molecular biology have evolved in the interim years to complement this technology,” says Wolf, who says he is proud to see a technology conceived within the government make a successful transfer to the private sector. “We have a very powerful set of tools to make the next set of innovations and contributions to future medical science.”\n    Wolf believes that the lunchtime epiphany that led to the development of the NASA bioreactor is indicative of how true innovation works. \n    “Innovation is an inherently messy process,” he says. “It’s based on the correct balance of sticking to the original plan but also being able to appropriately deviate and adapt to new information and discoveries. The future of NASA, our country, and world is depending on this process for ever more innovations for deep space exploration and for improving life on Earth.”\n    Rotary Cell Culture System™ and RCCS™ are trademarks of Synthecon Inc.\n  "},{"href":"http://spinoff.nasa.gov/Spinoff2011/hm_2.html","text":"Tooling Techniques Enhance Medical Imaging","image":"http://spinoff.nasa.gov/Spinoff2011/Images/hm-6_fmt.jpg","story":"\n    \n      NASA Technology\n      They can release as much energy as tens of billions of hydrogen bombs exploding at the same time. They send protons and electrons rocketing at near the speed of light. They heat gas in the Sun’s atmosphere to tens of millions of degrees Celsius. They send a blast of gas and particles toward Earth, posing a danger to spacecraft and astronauts outside the planet’s magnetosphere, in rare cases even knocking out radio communications and power grids on the ground. \n      \n        \n        \n          \n        \n        \n          A solar flare is imaged by RHESSI in conjunction with two other NASA spacecraft, SOHO and TRACE.\n        \n      \n      They are so-called solar eruptive events, made up of solar flares and the often associated coronal mass ejections.\n      Because of the scientific mystery of how these solar eruptions are produced on the Sun with such scale and force, and also the major role they play in space weather that can impact life on Earth, NASA researchers have innovated new methods of gathering information about these violent events. \n      One NASA mission, the Reuven Ramaty High Energy Solar Spectroscopic Imager (RHESSI) has significantly advanced understanding of solar flares since its launch in 2002. RHESSI scientists use the spacecraft’s imaging spectrometer to piece together pictures of solar flares from the high-energy X-ray and gamma-ray radiation they emit. While there is still much to be learned, data gathered by RHESSI has revealed how magnetic fields in the vast expanse of the solar atmosphere may be the force that drives the immense explosions. The instrument has imaged around 50,000 flares to date, providing information that may explain not only the workings of solar flares but also of much more massive energy releases from distant objects like black holes and quasars. \n      “We have been able to make images from X-rays with much finer resolution and greater sensitivity than have ever been made before,” says Brian Dennis, RHESSI Mission Scientist and astrophysicist in the Solar Physics Laboratory at Goddard Space Flight Center. \n      The key to RHESSI’s unprecedented capabilities lie in a set of essential components a NASA partner created for the mission. The manufacturing techniques developed to create the components have yielded innovations advancing medical imaging, transportation security, and even energy efficiency. \n      Partnership\n      To gather its groundbreaking imagery, RHESSI’s spectrometer was outfitted with metal grids incorporated in devices called rotation modulation collimators (RMCs). As the spacecraft rotates, the grids block and unblock X-rays emanating from the Sun. The instrument’s detectors record the modulated radiation passing through the grids and transmit the information to the ground, where scientists generate images using computers. For this setup to function effectively, NASA needed the most finely crafted grids yet created. A number of attempts to create the technology failed until engineer Mike Appleby, working at a company called Thermo Electron Tecomet, was able to meet NASA’s requirement, producing grids using photoetched tungsten foils built up into precise stack laminations. \n      “Finding Mike Appleby was the real secret,” says Dennis. “Collaborating with him allowed us to do this mission.” \n      Appleby founded Mikro Systems Inc., based in Charlottesville, Virginia, in 2000 to build upon the unique lithography-based manufacturing platform he used to craft the RHESSI grids. Mikro partnered with NASA through the Small Business Innovation Research (SBIR) program to improve the company’s platform for producing even finer, more complex grids for future space imaging missions. \n      Benefits\n      Now in its 11th year of operation, Mikro Systems has fully developed its patented TOMO lithographic molding technology and, according to Appleby, Mikro’s president and CEO, is applying the lessons and techniques the company derived from its NASA work to manufacturing advanced products for multiple markets. \n      The TOMO process starts with a 3D computer model of the part to be created. The model is sliced into thin layers ranging from 25–200 microns in thickness. Using photomasks created from the layers, a chemical machining process is applied to etch each layer in thin metal foils. The layers are then bound together using stack lamination and epoxy to create a master pattern. The pattern serves as the basis for a mold then used to cast the products. With this process, says Appleby, Mikro can cast ceramics, powdered metals, polymers, and composites with high precision and at low cost. \n      \n        \n        \n          \n        \n        \n          A Mikro Systems Inc. employee holds a layer of a TOMO tool. Mikro’s NASA-derived TOMO process allows for the manufacturing of new medical imaging components, like the 2D antiscatter grid shown on the right.\n        \n      \n      One of the company’s main markets developed from its NASA collimator work. Just like the RHESSI instrument, X-ray-based medical imaging machines require collimators, also known as antiscatter grids. These grids, typically made of tungsten or molybdenum, sit between the X-ray source and the detector. As the X-rays pass through the body, some are scattered; the grid absorbs the scattered radiation while allowing the unscattered X-rays to pass through, ensuring a clean image for doctors to study. \n      Using the TOMO process, Mikro now creates unique collimators for computed tomography (CT) machines used to image injuries and other conditions in regions like the brain, heart, and lungs. These collimators are two-dimensional grids—as opposed to the standard one-dimensional collimator—a device that was not possible to create prior to the innovation of the TOMO process, Appleby says. The 2D grid provides significant benefits including improved scatter rejection (and thus better imaging) and enhanced strength. These features are key to newer CT machines that move the detector-carrying gantry around patients at higher speeds and produce more comprehensive imagery. The advanced qualities all come at a reduced cost; the TOMO process uses powdered tungsten instead of tungsten foil to create the grids, lowering material expenses from between $300–$500 a pound to around $20 a pound. \n      In addition to the medical imaging applications, Mikro’s collimators are currently used in a high-resolution scanner for airport security screening, and Mikro is also applying the TOMO process to the production of blades for gas turbine engines used for aircraft propulsion and energy generation. The hotter a turbine engine runs, the more efficiently it operates, so effective methods for managing the engine’s heat are essential to boosting efficiency. The TOMO process allows Mikro to cast blades containing finer and more complex cooling passages than previously achievable. At the same time, TOMO reduces the cost of the tooling process by one third and shortens the time involved from between 30–40 weeks down to 4–6 weeks. Mikro is currently working with major firms like Siemens Energy to advance the technology for energy-generating industrial gas turbines.\n      Launched with three employees, Mikro now has 40, including 15 recent hires to support the company’s medical imaging efforts. The company’s turbine work is growing even faster, and all of this success can be traced back to Mikro’s NASA collaboration, says Appleby.\n      “We are always proud to accomplish something on the cutting edge,” he says. “This is the privilege we have in working with NASA and other Government agencies.”\n      Dennis says that Mikro’s new etched grids, smaller but more complex than those used for RHESSI, are essential for enabling the Solar Telescope for Imaging X-rays (STIX) to be flown on the Solar Orbiter, a joint NASA/European Space Agency mission that will venture within the orbit of the planet Mercury to obtain a close-up look at the Sun. It seems a NASA partnership will once again play a role in drawing back the veil on the Sun’s mysteries. \n    \n     \n    \n      NASA Technology\n      They can release as much energy as tens of billions of hydrogen bombs exploding at the same time. They send protons and electrons rocketing at near the speed of light. They heat gas in the Sun’s atmosphere to tens of millions of degrees Celsius. They send a blast of gas and particles toward Earth, posing a danger to spacecraft and astronauts outside the planet’s magnetosphere, in rare cases even knocking out radio communications and power grids on the ground. \n      \n        \n        \n          \n        \n        \n          A solar flare is imaged by RHESSI in conjunction with two other NASA spacecraft, SOHO and TRACE.\n        \n      \n      They are so-called solar eruptive events, made up of solar flares and the often associated coronal mass ejections.\n      Because of the scientific mystery of how these solar eruptions are produced on the Sun with such scale and force, and also the major role they play in space weather that can impact life on Earth, NASA researchers have innovated new methods of gathering information about these violent events. \n      One NASA mission, the Reuven Ramaty High Energy Solar Spectroscopic Imager (RHESSI) has significantly advanced understanding of solar flares since its launch in 2002. RHESSI scientists use the spacecraft’s imaging spectrometer to piece together pictures of solar flares from the high-energy X-ray and gamma-ray radiation they emit. While there is still much to be learned, data gathered by RHESSI has revealed how magnetic fields in the vast expanse of the solar atmosphere may be the force that drives the immense explosions. The instrument has imaged around 50,000 flares to date, providing information that may explain not only the workings of solar flares but also of much more massive energy releases from distant objects like black holes and quasars. \n      “We have been able to make images from X-rays with much finer resolution and greater sensitivity than have ever been made before,” says Brian Dennis, RHESSI Mission Scientist and astrophysicist in the Solar Physics Laboratory at Goddard Space Flight Center. \n      The key to RHESSI’s unprecedented capabilities lie in a set of essential components a NASA partner created for the mission. The manufacturing techniques developed to create the components have yielded innovations advancing medical imaging, transportation security, and even energy efficiency. \n      Partnership\n      To gather its groundbreaking imagery, RHESSI’s spectrometer was outfitted with metal grids incorporated in devices called rotation modulation collimators (RMCs). As the spacecraft rotates, the grids block and unblock X-rays emanating from the Sun. The instrument’s detectors record the modulated radiation passing through the grids and transmit the information to the ground, where scientists generate images using computers. For this setup to function effectively, NASA needed the most finely crafted grids yet created. A number of attempts to create the technology failed until engineer Mike Appleby, working at a company called Thermo Electron Tecomet, was able to meet NASA’s requirement, producing grids using photoetched tungsten foils built up into precise stack laminations. \n      “Finding Mike Appleby was the real secret,” says Dennis. “Collaborating with him allowed us to do this mission.” \n      Appleby founded Mikro Systems Inc., based in Charlottesville, Virginia, in 2000 to build upon the unique lithography-based manufacturing platform he used to craft the RHESSI grids. Mikro partnered with NASA through the Small Business Innovation Research (SBIR) program to improve the company’s platform for producing even finer, more complex grids for future space imaging missions. \n      Benefits\n      Now in its 11th year of operation, Mikro Systems has fully developed its patented TOMO lithographic molding technology and, according to Appleby, Mikro’s president and CEO, is applying the lessons and techniques the company derived from its NASA work to manufacturing advanced products for multiple markets. \n      The TOMO process starts with a 3D computer model of the part to be created. The model is sliced into thin layers ranging from 25–200 microns in thickness. Using photomasks created from the layers, a chemical machining process is applied to etch each layer in thin metal foils. The layers are then bound together using stack lamination and epoxy to create a master pattern. The pattern serves as the basis for a mold then used to cast the products. With this process, says Appleby, Mikro can cast ceramics, powdered metals, polymers, and composites with high precision and at low cost. \n      \n        \n        \n          \n        \n        \n          A Mikro Systems Inc. employee holds a layer of a TOMO tool. Mikro’s NASA-derived TOMO process allows for the manufacturing of new medical imaging components, like the 2D antiscatter grid shown on the right.\n        \n      \n      One of the company’s main markets developed from its NASA collimator work. Just like the RHESSI instrument, X-ray-based medical imaging machines require collimators, also known as antiscatter grids. These grids, typically made of tungsten or molybdenum, sit between the X-ray source and the detector. As the X-rays pass through the body, some are scattered; the grid absorbs the scattered radiation while allowing the unscattered X-rays to pass through, ensuring a clean image for doctors to study. \n      Using the TOMO process, Mikro now creates unique collimators for computed tomography (CT) machines used to image injuries and other conditions in regions like the brain, heart, and lungs. These collimators are two-dimensional grids—as opposed to the standard one-dimensional collimator—a device that was not possible to create prior to the innovation of the TOMO process, Appleby says. The 2D grid provides significant benefits including improved scatter rejection (and thus better imaging) and enhanced strength. These features are key to newer CT machines that move the detector-carrying gantry around patients at higher speeds and produce more comprehensive imagery. The advanced qualities all come at a reduced cost; the TOMO process uses powdered tungsten instead of tungsten foil to create the grids, lowering material expenses from between $300–$500 a pound to around $20 a pound. \n      In addition to the medical imaging applications, Mikro’s collimators are currently used in a high-resolution scanner for airport security screening, and Mikro is also applying the TOMO process to the production of blades for gas turbine engines used for aircraft propulsion and energy generation. The hotter a turbine engine runs, the more efficiently it operates, so effective methods for managing the engine’s heat are essential to boosting efficiency. The TOMO process allows Mikro to cast blades containing finer and more complex cooling passages than previously achievable. At the same time, TOMO reduces the cost of the tooling process by one third and shortens the time involved from between 30–40 weeks down to 4–6 weeks. Mikro is currently working with major firms like Siemens Energy to advance the technology for energy-generating industrial gas turbines.\n      Launched with three employees, Mikro now has 40, including 15 recent hires to support the company’s medical imaging efforts. The company’s turbine work is growing even faster, and all of this success can be traced back to Mikro’s NASA collaboration, says Appleby.\n      “We are always proud to accomplish something on the cutting edge,” he says. “This is the privilege we have in working with NASA and other Government agencies.”\n      Dennis says that Mikro’s new etched grids, smaller but more complex than those used for RHESSI, are essential for enabling the Solar Telescope for Imaging X-rays (STIX) to be flown on the Solar Orbiter, a joint NASA/European Space Agency mission that will venture within the orbit of the planet Mercury to obtain a close-up look at the Sun. It seems a NASA partnership will once again play a role in drawing back the veil on the Sun’s mysteries. \n    "},{"href":"http://spinoff.nasa.gov/Spinoff2011/hm_3.html","text":"Ventilator Technologies Sustain Critically Injured Patients ","image":"http://spinoff.nasa.gov/Spinoff2011/Images/hm-10_fmt1.jpg","story":"\n    \n      NASA Technology\n      Consider this scenario: A soldier has been critically wounded in a sudden firefight in a remote region of Afghanistan. The soldier’s comrades attend to him and radio for help, but the soldier needs immediate medical expertise and treatment that is currently miles away. \n      The connection between medical support for soldiers on the battlefield and astronauts in space may not be immediately obvious. But when it comes to providing adequate critical care, “NASA and the military have very similar operational challenges,” says Shannon Melton of NASA contractor Wyle Integrated Science and Engineering. Melton works within Johnson Space Center’s Space Medicine Division, which supports astronaut crew health before, during, and after flight.\n       “In space, we have a limited number of care providers, and those providers are not always clinicians with extensive medical training. We have limited room to provide care, limited consumables, and our environment is not like that of a hospital,” she says.\n      \n        \n        \n          \n        \n        \n          Impact Instrumentation Inc.’s 754-AP medical ventilator, on the cart and next to the laptop in the right side of the image, is tested in a clinical trial. The technology was developed through a NASA partnership.\n        \n      \n      The Space Medicine Division’s Advanced Projects Group works on combining the expertise of both clinicians and engineers to develop new capabilities that address the challenges of medical support in space, including providing care to distant patients. This field, called telemedicine, blends advanced communications practices and technologies with innovative medical devices and techniques to allow caregivers with limited or no medical experience to support a patient’s needs. \n      “NASA, just by its nature, has been doing remote medicine since the beginning of the Space Program,” says Melton, an engineer in the Advanced Projects Group. \n      Since part of NASA’s mandate is to transfer the results of its technological innovation for the benefit of the public, the Agency has worked with doctors and private industry to find ways to apply the benefits of space medicine on Earth. In one such case, a NASA partnership has resulted in new technologies that may improve the quality of emergency medicine for wounded soldiers on the battlefield and regular civilians. \n      Partnership\n      Impact Instrumentation Inc. of West Caldwell, New Jersey, is an innovator and manufacturer of respiratory care products and instrumentation for military and civil emergency medicine. Recognizing a common interest in advancing critical care capabilities and the potential for mutual benefit from a sharing of resources, NASA and Impact entered into a Space Act Agreement (SAA). \n      “There was a common vision of what would be needed for an advanced healthcare system for the military as well as for a space station or deep space mission,” says George Beck, an engineer and former head of critical care development at Johnson who is now vice president of engineering and research for Impact. One project under the SAA focused on adapting Impact’s Model 754 medical ventilator for use in space by making it a remotely controlled device. (A medical ventilator mechanically moves air and oxygen in and out of the lungs of patients who are unable to breathe effectively on their own.) Impact used the resulting Model 754-AP ventilator to develop closed-loop capabilities for the device, leading to clinical trials of a ventilator that could operate itself. \n      “The way forward with space medicine is not just smaller devices but also smarter devices that run themselves in the absence of a skilled care provider,” says Beck. \n      Benefits\n      Fully automated ventilators are still a technology for the future, but Impact’s work developing the Model 754-AP led to the company’s next generation ventilator technology: the Uni-Vent 731 Series of ventilators (which includes the EMV+ and Eagle II ventilators) for prehospital treatment and transport and in the hospital: intensive care units, emergency rooms and intrahospital transport. The 731 Series ventilators combine small size and energy efficiency with ease-of-use features designed for operators with minimal mechanical ventilation experience in any environment. The ventilators’ Smart Help display provides prompts to guide the caregiver in managing the patient and stabilizing a patient’s blood oxygen saturation and heart rate. A comprehensive alarm system and altitude compensation capabilities are among the other features that make Impact’s ventilators suitable for use just about anywhere, according to Beck.\n      “Our equipment is used on both polar icecaps and \n        by militaries around the world in unique environments,” he says. \n      \n        \n        \n          \n        \n        \n          Impact’s NASA work led to the company’s next generation medical ventilators, including the EMV+ (left). Impact is now working with NASA to advance emergency medicine even further with the development of the Lightweight Trauma Module (right). \n        \n      \n      Also under the SAA and in conjunction with military funding, Impact, with support from NASA, is developing a system that could provide comprehensive medical care to patients far-removed from the benefits of a hospital—whether in space, on the battlefield, onboard a rescue helicopter, or in a mass casualty event field hospital. The Lightweight Trauma Module (LTM) combines an array of medical technology into a single device about the size of a briefcase.\n      “To date, most critical care transport systems use an aggregation of individual devices,” Beck says. These devices include ventilators, heart monitors, and IV pumps that have their own screens, power supplies, and operating systems. “These levels of redundancy lead to higher mass, higher volume, and higher power consumption. What the LTM does is take all of those components and put them into a highly portable 30-pound box,” says Beck.\n      The Advanced Project Group at NASA worked with Impact to design and produce multiple prototype iterations of the LTM. The result is a state-of-the-art device suitable for use in all environments and operated with minimal training. Impact recently delivered two LTMs to the U.S. military for initial testing, and through a grant from the NASA-funded National Space Biomedical Research Institute, Impact and 10Blade Inc. of Acton, Massachusetts, are integrating the LTM with 10Blade’s iRevive medical software. \n      The iRevive technology uses the information gathered by the LTM and organizes it into a patient care plan. It also compiles the data and provides it in an efficient, medically relevant format to remote doctors, who can use the information to help guide the caregiver. The result, Beck says, is a common platform to monitor both the patient and the therapeutic intervention. Documentation of the data produced by the LTM, whether it is the patient’s condition during transport and at arrival or trending vital signs and administered treatments, provides caregivers a unique opportunity to assess patient status and treatment options on an easy-to-use interface. And since the patient data is efficiently organized and formatted, patient data can be sent ahead to allow receiving caregivers time to review critical care information and continue the patient treatment plan upon arrival.\n      “For prehospital care and critical care transport inside and outside the hospital, the LTM is going to be the way forward,” Beck states.\n      Impact®, Uni-Vent®, EMV+®, and LTM® are registered trademarks of Impact Instrumentation Inc.\n        Eagle II™ and Smart Help™ are trademarks of Impact Instrumentation Inc.\n        iRevive® is a registered trademark of 10Blade Inc\n      \n    \n      NASA Technology\n      Consider this scenario: A soldier has been critically wounded in a sudden firefight in a remote region of Afghanistan. The soldier’s comrades attend to him and radio for help, but the soldier needs immediate medical expertise and treatment that is currently miles away. \n      The connection between medical support for soldiers on the battlefield and astronauts in space may not be immediately obvious. But when it comes to providing adequate critical care, “NASA and the military have very similar operational challenges,” says Shannon Melton of NASA contractor Wyle Integrated Science and Engineering. Melton works within Johnson Space Center’s Space Medicine Division, which supports astronaut crew health before, during, and after flight.\n       “In space, we have a limited number of care providers, and those providers are not always clinicians with extensive medical training. We have limited room to provide care, limited consumables, and our environment is not like that of a hospital,” she says.\n      \n        \n        \n          \n        \n        \n          Impact Instrumentation Inc.’s 754-AP medical ventilator, on the cart and next to the laptop in the right side of the image, is tested in a clinical trial. The technology was developed through a NASA partnership.\n        \n      \n      The Space Medicine Division’s Advanced Projects Group works on combining the expertise of both clinicians and engineers to develop new capabilities that address the challenges of medical support in space, including providing care to distant patients. This field, called telemedicine, blends advanced communications practices and technologies with innovative medical devices and techniques to allow caregivers with limited or no medical experience to support a patient’s needs. \n      “NASA, just by its nature, has been doing remote medicine since the beginning of the Space Program,” says Melton, an engineer in the Advanced Projects Group. \n      Since part of NASA’s mandate is to transfer the results of its technological innovation for the benefit of the public, the Agency has worked with doctors and private industry to find ways to apply the benefits of space medicine on Earth. In one such case, a NASA partnership has resulted in new technologies that may improve the quality of emergency medicine for wounded soldiers on the battlefield and regular civilians. \n      Partnership\n      Impact Instrumentation Inc. of West Caldwell, New Jersey, is an innovator and manufacturer of respiratory care products and instrumentation for military and civil emergency medicine. Recognizing a common interest in advancing critical care capabilities and the potential for mutual benefit from a sharing of resources, NASA and Impact entered into a Space Act Agreement (SAA). \n      “There was a common vision of what would be needed for an advanced healthcare system for the military as well as for a space station or deep space mission,” says George Beck, an engineer and former head of critical care development at Johnson who is now vice president of engineering and research for Impact. One project under the SAA focused on adapting Impact’s Model 754 medical ventilator for use in space by making it a remotely controlled device. (A medical ventilator mechanically moves air and oxygen in and out of the lungs of patients who are unable to breathe effectively on their own.) Impact used the resulting Model 754-AP ventilator to develop closed-loop capabilities for the device, leading to clinical trials of a ventilator that could operate itself. \n      “The way forward with space medicine is not just smaller devices but also smarter devices that run themselves in the absence of a skilled care provider,” says Beck. \n      Benefits\n      Fully automated ventilators are still a technology for the future, but Impact’s work developing the Model 754-AP led to the company’s next generation ventilator technology: the Uni-Vent 731 Series of ventilators (which includes the EMV+ and Eagle II ventilators) for prehospital treatment and transport and in the hospital: intensive care units, emergency rooms and intrahospital transport. The 731 Series ventilators combine small size and energy efficiency with ease-of-use features designed for operators with minimal mechanical ventilation experience in any environment. The ventilators’ Smart Help display provides prompts to guide the caregiver in managing the patient and stabilizing a patient’s blood oxygen saturation and heart rate. A comprehensive alarm system and altitude compensation capabilities are among the other features that make Impact’s ventilators suitable for use just about anywhere, according to Beck.\n      “Our equipment is used on both polar icecaps and \n        by militaries around the world in unique environments,” he says. \n      \n        \n        \n          \n        \n        \n          Impact’s NASA work led to the company’s next generation medical ventilators, including the EMV+ (left). Impact is now working with NASA to advance emergency medicine even further with the development of the Lightweight Trauma Module (right). \n        \n      \n      Also under the SAA and in conjunction with military funding, Impact, with support from NASA, is developing a system that could provide comprehensive medical care to patients far-removed from the benefits of a hospital—whether in space, on the battlefield, onboard a rescue helicopter, or in a mass casualty event field hospital. The Lightweight Trauma Module (LTM) combines an array of medical technology into a single device about the size of a briefcase.\n      “To date, most critical care transport systems use an aggregation of individual devices,” Beck says. These devices include ventilators, heart monitors, and IV pumps that have their own screens, power supplies, and operating systems. “These levels of redundancy lead to higher mass, higher volume, and higher power consumption. What the LTM does is take all of those components and put them into a highly portable 30-pound box,” says Beck.\n      The Advanced Project Group at NASA worked with Impact to design and produce multiple prototype iterations of the LTM. The result is a state-of-the-art device suitable for use in all environments and operated with minimal training. Impact recently delivered two LTMs to the U.S. military for initial testing, and through a grant from the NASA-funded National Space Biomedical Research Institute, Impact and 10Blade Inc. of Acton, Massachusetts, are integrating the LTM with 10Blade’s iRevive medical software. \n      The iRevive technology uses the information gathered by the LTM and organizes it into a patient care plan. It also compiles the data and provides it in an efficient, medically relevant format to remote doctors, who can use the information to help guide the caregiver. The result, Beck says, is a common platform to monitor both the patient and the therapeutic intervention. Documentation of the data produced by the LTM, whether it is the patient’s condition during transport and at arrival or trending vital signs and administered treatments, provides caregivers a unique opportunity to assess patient status and treatment options on an easy-to-use interface. And since the patient data is efficiently organized and formatted, patient data can be sent ahead to allow receiving caregivers time to review critical care information and continue the patient treatment plan upon arrival.\n      “For prehospital care and critical care transport inside and outside the hospital, the LTM is going to be the way forward,” Beck states.\n      Impact®, Uni-Vent®, EMV+®, and LTM® are registered trademarks of Impact Instrumentation Inc.\n        Eagle II™ and Smart Help™ are trademarks of Impact Instrumentation Inc.\n        iRevive® is a registered trademark of 10Blade Inc\n      "},{"href":"http://spinoff.nasa.gov/Spinoff2011/hm_4.html","text":"Protein Innovations Advance Drug Treatments, Skin Care","image":"http://spinoff.nasa.gov/Spinoff2011/Images/hm-12_fmt.png","story":"\n    \n      \n        Protein Innovations Advance Drug Treatments, Skin Care\n      \n      \n        NASA Technology\n        Dan Carter carefully layered the sheets of tracing paper on the light box. On each sheet were renderings of the atomic components of an essential human protein, one whose structure had long been a mystery. With each layer Carter laid down, a never-before-seen image became clearer. \n        \n          \n          \n            \n          \n          \n            A surface rendering of the atomic structure of human serum albumin, illustrating charge distribution. NASA researchers at Marshall Space Flight Center were the first to map the atomic structure of albumin, an important blood protein.\n          \n        \n        Carter joined NASA’s Marshall Space Flight Center in 1985 and began exploring processes of protein crystal growth in space. By bouncing intense X-rays off the crystals, researchers can determine the electron densities around the thousands of atoms forming the protein molecules, unveiling their atomic structures. Cultivating crystals of sufficient quality on Earth was problematic; the microgravity conditions of space were far more accommodating. At the time, only a few hundred protein structures had been mapped, and the methods were time consuming and tedious. Carter hoped his work would help reveal the structure of human serum albumin, a major protein in the human circulatory system responsible for ferrying numerous small molecules in the blood.\n        More was at stake than scientific curiosity.\n        “Albumin has a high affinity for most of the world’s pharmaceuticals,” Carter explains, “and its interaction with drugs can change their safety and efficacy.” When a medication enters the bloodstream—a cancer chemotherapy drug, for example—a majority of it can bind with albumin, leaving only a small percentage active for treatment. How a drug interacts with albumin can influence considerations like the necessary effective dosage, playing a significant role in the design and application of therapeutic measures. \n        In spite of numerous difficulties, including having no access to microgravity following the 1986 Space Shuttle Challenger disaster, the image Carter had hoped to see was finally clarifying. In 1988, his lab had acquired specialized X-ray and detection equipment—a tipping point. Carter and his colleagues began to piece together albumin’s portrait, the formation of its electron densities coalescing on the sheets of tracing paper he arranged on the light box. While space-grown crystals were ultimately not involved in the achievement, a year later, Carter says, “we were on the cover of Science magazine, having determined the atomic structure of albumin.” \n        Partnership\n        The albumin mapping project began to reveal important aspects of how the protein bound with and transported drugs. After a number of years studying the formerly inscrutable molecule, it became apparent to Carter and a number of his colleagues that the potential of this knowledge to impact drug design and development was too great to ignore. In 1997, they founded New Century Pharmaceuticals Inc., based in Huntsville, Alabama, to launch a large-scale structural biology program to map at an atomic resolution the structures of drugs bound to albumin, with the intent to improve drug performance. \n        Over the following years, New Century continued to work with NASA through a series of grants and contracts in support of the Agency’s protein crystal growth in microgravity program. Several inventions discovered at NASA were also licensed to New Century so Carter and his team could continue to test and develop its albumin-based innovations. The company also developed a unique set of technologies based on the original albumin breakthrough. \n        Benefits\n        \n          \n          \n            \n          \n          \n            New Century Pharmaceuticals Inc. has built upon the original NASA work on albumin to develop a new cancer drug combination approach that promises to improve anticancer drug performance and diminish the toxic side effects of chemotherapy.\n          \n        \n        Today, New Century’s Crystallography and Albumin-based Drug Design and Evaluation platform, or CADEX, is the world’s most extensive library of atomic structures demonstrating the binding characteristics of drugs and albumin. Covering over 25 therapeutic categories from antidepressants to anti-cancer agents to antihistamines, CADEX provides a comprehensive knowledge base for the development of drugs tailored to interact effectively with albumin. \n        As an outcome of compiling CADEX, New Century was able to create a number of other innovations with potential for medical benefit, including its first commercial product, Albagen recombinant human serum albumin (rHSA). Produced synthetically in yeast rather than derived from animal sources, the Albagen rHSA is hypoallergenic and poses no risk of dangerous contaminants like viruses or prions. New Century licensed the Albagen technology to Albumin Bioscience in 2009, which is expanding the application of Albagen into potential research and therapeutic markets including drug delivery and in vitro fertilization. Albumin Bioscience has also incorporated Albagen into a line of unique skin care products designed to improve skin health by replenishing albumin levels in the skin. \n        Meanwhile, New Century continues to build upon the foundation of its CADEX repository. \n        “Our goal is that this will be used to \n          improve the clinical outcome of cancer \n          patients everywhere.”\n          —Dan Carter, New Century Pharmaceuticals \n        “We learned that the bulk of large complex anticancer drugs bind to the same location in albumin,” says Carter, who served as chief of Marshall’s Biophysics \n          and Advanced Materials Branch and won multiple NASA honors before founding New Century. “We also learned of molecules that have no anticancer activity and which are very powerful in blocking that particular binding site.” \n        The outcome is a new cancer drug combination approach called Salus, which in effect “tunes” the patient’s blood chemistry so that less of the anticancer drugs bind with albumin. This results in lower dose requirements—good news for patients who suffer from the toxic side effects of chemotherapy. The company plans to start clinical trials this year. \n                  “When we look at the activity against cancer cell lines, there is dramatic improvement in performance,” says Carter. “Our goal is that this will be used to improve the clinical outcome of cancer patients everywhere.” \n        New Century has cultivated a number of successes outside of its albumin research. At Marshall in 1991, Carter, NASA colleague Joseph X. Ho and Florian Rüker, then with the Institute of Applied Microbiology in Vienna, helped determine the atomic structure of an antibody that recognized HIV—another scientific first. This collaboration culminated in a modular antibody technology that the company licensed and later sold to Austrian biotechnology company f-star, which is using the innovation to develop novel antibody-based treatments for conditions ranging from cancer to autoimmune diseases. New Century also invented a family of nanoparticle protein technologies, Ferrigen, with potential applications ranging from vaccines to drug delivery; developed a candidate HIV vaccine platform utilizing the Ferrigen technology; and crafted hardware currently under testing at Marshall for growing large crystals in space—ideal for neutron imaging applications that can reveal atomic structures more clearly than ever before. \n        With its origins at NASA, New Century’s CADEX platform is still the world’s largest repository of albumin structures, Carter says, and the potential clinical benefit of that data has yet to be fully realized.\n        “The challenge ahead of us is how that information \n          is translated into helping people,” he says. “That’s an ongoing process.”\n        CADEX™, Albagen™, Salus™, and Ferrigen™ are trademarks of New Century Pharmaceuticals Inc\n      \n      \n    \n      \n        Protein Innovations Advance Drug Treatments, Skin Care\n      \n      \n        NASA Technology\n        Dan Carter carefully layered the sheets of tracing paper on the light box. On each sheet were renderings of the atomic components of an essential human protein, one whose structure had long been a mystery. With each layer Carter laid down, a never-before-seen image became clearer. \n        \n          \n          \n            \n          \n          \n            A surface rendering of the atomic structure of human serum albumin, illustrating charge distribution. NASA researchers at Marshall Space Flight Center were the first to map the atomic structure of albumin, an important blood protein.\n          \n        \n        Carter joined NASA’s Marshall Space Flight Center in 1985 and began exploring processes of protein crystal growth in space. By bouncing intense X-rays off the crystals, researchers can determine the electron densities around the thousands of atoms forming the protein molecules, unveiling their atomic structures. Cultivating crystals of sufficient quality on Earth was problematic; the microgravity conditions of space were far more accommodating. At the time, only a few hundred protein structures had been mapped, and the methods were time consuming and tedious. Carter hoped his work would help reveal the structure of human serum albumin, a major protein in the human circulatory system responsible for ferrying numerous small molecules in the blood.\n        More was at stake than scientific curiosity.\n        “Albumin has a high affinity for most of the world’s pharmaceuticals,” Carter explains, “and its interaction with drugs can change their safety and efficacy.” When a medication enters the bloodstream—a cancer chemotherapy drug, for example—a majority of it can bind with albumin, leaving only a small percentage active for treatment. How a drug interacts with albumin can influence considerations like the necessary effective dosage, playing a significant role in the design and application of therapeutic measures. \n        In spite of numerous difficulties, including having no access to microgravity following the 1986 Space Shuttle Challenger disaster, the image Carter had hoped to see was finally clarifying. In 1988, his lab had acquired specialized X-ray and detection equipment—a tipping point. Carter and his colleagues began to piece together albumin’s portrait, the formation of its electron densities coalescing on the sheets of tracing paper he arranged on the light box. While space-grown crystals were ultimately not involved in the achievement, a year later, Carter says, “we were on the cover of Science magazine, having determined the atomic structure of albumin.” \n        Partnership\n        The albumin mapping project began to reveal important aspects of how the protein bound with and transported drugs. After a number of years studying the formerly inscrutable molecule, it became apparent to Carter and a number of his colleagues that the potential of this knowledge to impact drug design and development was too great to ignore. In 1997, they founded New Century Pharmaceuticals Inc., based in Huntsville, Alabama, to launch a large-scale structural biology program to map at an atomic resolution the structures of drugs bound to albumin, with the intent to improve drug performance. \n        Over the following years, New Century continued to work with NASA through a series of grants and contracts in support of the Agency’s protein crystal growth in microgravity program. Several inventions discovered at NASA were also licensed to New Century so Carter and his team could continue to test and develop its albumin-based innovations. The company also developed a unique set of technologies based on the original albumin breakthrough. \n        Benefits\n        \n          \n          \n            \n          \n          \n            New Century Pharmaceuticals Inc. has built upon the original NASA work on albumin to develop a new cancer drug combination approach that promises to improve anticancer drug performance and diminish the toxic side effects of chemotherapy.\n          \n        \n        Today, New Century’s Crystallography and Albumin-based Drug Design and Evaluation platform, or CADEX, is the world’s most extensive library of atomic structures demonstrating the binding characteristics of drugs and albumin. Covering over 25 therapeutic categories from antidepressants to anti-cancer agents to antihistamines, CADEX provides a comprehensive knowledge base for the development of drugs tailored to interact effectively with albumin. \n        As an outcome of compiling CADEX, New Century was able to create a number of other innovations with potential for medical benefit, including its first commercial product, Albagen recombinant human serum albumin (rHSA). Produced synthetically in yeast rather than derived from animal sources, the Albagen rHSA is hypoallergenic and poses no risk of dangerous contaminants like viruses or prions. New Century licensed the Albagen technology to Albumin Bioscience in 2009, which is expanding the application of Albagen into potential research and therapeutic markets including drug delivery and in vitro fertilization. Albumin Bioscience has also incorporated Albagen into a line of unique skin care products designed to improve skin health by replenishing albumin levels in the skin. \n        Meanwhile, New Century continues to build upon the foundation of its CADEX repository. \n        “Our goal is that this will be used to \n          improve the clinical outcome of cancer \n          patients everywhere.”\n          —Dan Carter, New Century Pharmaceuticals \n        “We learned that the bulk of large complex anticancer drugs bind to the same location in albumin,” says Carter, who served as chief of Marshall’s Biophysics \n          and Advanced Materials Branch and won multiple NASA honors before founding New Century. “We also learned of molecules that have no anticancer activity and which are very powerful in blocking that particular binding site.” \n        The outcome is a new cancer drug combination approach called Salus, which in effect “tunes” the patient’s blood chemistry so that less of the anticancer drugs bind with albumin. This results in lower dose requirements—good news for patients who suffer from the toxic side effects of chemotherapy. The company plans to start clinical trials this year. \n                  “When we look at the activity against cancer cell lines, there is dramatic improvement in performance,” says Carter. “Our goal is that this will be used to improve the clinical outcome of cancer patients everywhere.” \n        New Century has cultivated a number of successes outside of its albumin research. At Marshall in 1991, Carter, NASA colleague Joseph X. Ho and Florian Rüker, then with the Institute of Applied Microbiology in Vienna, helped determine the atomic structure of an antibody that recognized HIV—another scientific first. This collaboration culminated in a modular antibody technology that the company licensed and later sold to Austrian biotechnology company f-star, which is using the innovation to develop novel antibody-based treatments for conditions ranging from cancer to autoimmune diseases. New Century also invented a family of nanoparticle protein technologies, Ferrigen, with potential applications ranging from vaccines to drug delivery; developed a candidate HIV vaccine platform utilizing the Ferrigen technology; and crafted hardware currently under testing at Marshall for growing large crystals in space—ideal for neutron imaging applications that can reveal atomic structures more clearly than ever before. \n        With its origins at NASA, New Century’s CADEX platform is still the world’s largest repository of albumin structures, Carter says, and the potential clinical benefit of that data has yet to be fully realized.\n        “The challenge ahead of us is how that information \n          is translated into helping people,” he says. “That’s an ongoing process.”\n        CADEX™, Albagen™, Salus™, and Ferrigen™ are trademarks of New Century Pharmaceuticals Inc\n      \n      \n        Protein Innovations Advance Drug Treatments, Skin Care\n      \n        NASA Technology\n        Dan Carter carefully layered the sheets of tracing paper on the light box. On each sheet were renderings of the atomic components of an essential human protein, one whose structure had long been a mystery. With each layer Carter laid down, a never-before-seen image became clearer. \n        \n          \n          \n            \n          \n          \n            A surface rendering of the atomic structure of human serum albumin, illustrating charge distribution. NASA researchers at Marshall Space Flight Center were the first to map the atomic structure of albumin, an important blood protein.\n          \n        \n        Carter joined NASA’s Marshall Space Flight Center in 1985 and began exploring processes of protein crystal growth in space. By bouncing intense X-rays off the crystals, researchers can determine the electron densities around the thousands of atoms forming the protein molecules, unveiling their atomic structures. Cultivating crystals of sufficient quality on Earth was problematic; the microgravity conditions of space were far more accommodating. At the time, only a few hundred protein structures had been mapped, and the methods were time consuming and tedious. Carter hoped his work would help reveal the structure of human serum albumin, a major protein in the human circulatory system responsible for ferrying numerous small molecules in the blood.\n        More was at stake than scientific curiosity.\n        “Albumin has a high affinity for most of the world’s pharmaceuticals,” Carter explains, “and its interaction with drugs can change their safety and efficacy.” When a medication enters the bloodstream—a cancer chemotherapy drug, for example—a majority of it can bind with albumin, leaving only a small percentage active for treatment. How a drug interacts with albumin can influence considerations like the necessary effective dosage, playing a significant role in the design and application of therapeutic measures. \n        In spite of numerous difficulties, including having no access to microgravity following the 1986 Space Shuttle Challenger disaster, the image Carter had hoped to see was finally clarifying. In 1988, his lab had acquired specialized X-ray and detection equipment—a tipping point. Carter and his colleagues began to piece together albumin’s portrait, the formation of its electron densities coalescing on the sheets of tracing paper he arranged on the light box. While space-grown crystals were ultimately not involved in the achievement, a year later, Carter says, “we were on the cover of Science magazine, having determined the atomic structure of albumin.” \n        Partnership\n        The albumin mapping project began to reveal important aspects of how the protein bound with and transported drugs. After a number of years studying the formerly inscrutable molecule, it became apparent to Carter and a number of his colleagues that the potential of this knowledge to impact drug design and development was too great to ignore. In 1997, they founded New Century Pharmaceuticals Inc., based in Huntsville, Alabama, to launch a large-scale structural biology program to map at an atomic resolution the structures of drugs bound to albumin, with the intent to improve drug performance. \n        Over the following years, New Century continued to work with NASA through a series of grants and contracts in support of the Agency’s protein crystal growth in microgravity program. Several inventions discovered at NASA were also licensed to New Century so Carter and his team could continue to test and develop its albumin-based innovations. The company also developed a unique set of technologies based on the original albumin breakthrough. \n        Benefits\n        \n          \n          \n            \n          \n          \n            New Century Pharmaceuticals Inc. has built upon the original NASA work on albumin to develop a new cancer drug combination approach that promises to improve anticancer drug performance and diminish the toxic side effects of chemotherapy.\n          \n        \n        Today, New Century’s Crystallography and Albumin-based Drug Design and Evaluation platform, or CADEX, is the world’s most extensive library of atomic structures demonstrating the binding characteristics of drugs and albumin. Covering over 25 therapeutic categories from antidepressants to anti-cancer agents to antihistamines, CADEX provides a comprehensive knowledge base for the development of drugs tailored to interact effectively with albumin. \n        As an outcome of compiling CADEX, New Century was able to create a number of other innovations with potential for medical benefit, including its first commercial product, Albagen recombinant human serum albumin (rHSA). Produced synthetically in yeast rather than derived from animal sources, the Albagen rHSA is hypoallergenic and poses no risk of dangerous contaminants like viruses or prions. New Century licensed the Albagen technology to Albumin Bioscience in 2009, which is expanding the application of Albagen into potential research and therapeutic markets including drug delivery and in vitro fertilization. Albumin Bioscience has also incorporated Albagen into a line of unique skin care products designed to improve skin health by replenishing albumin levels in the skin. \n        Meanwhile, New Century continues to build upon the foundation of its CADEX repository. \n        “Our goal is that this will be used to \n          improve the clinical outcome of cancer \n          patients everywhere.”\n          —Dan Carter, New Century Pharmaceuticals \n        “We learned that the bulk of large complex anticancer drugs bind to the same location in albumin,” says Carter, who served as chief of Marshall’s Biophysics \n          and Advanced Materials Branch and won multiple NASA honors before founding New Century. “We also learned of molecules that have no anticancer activity and which are very powerful in blocking that particular binding site.” \n        The outcome is a new cancer drug combination approach called Salus, which in effect “tunes” the patient’s blood chemistry so that less of the anticancer drugs bind with albumin. This results in lower dose requirements—good news for patients who suffer from the toxic side effects of chemotherapy. The company plans to start clinical trials this year. \n                  “When we look at the activity against cancer cell lines, there is dramatic improvement in performance,” says Carter. “Our goal is that this will be used to improve the clinical outcome of cancer patients everywhere.” \n        New Century has cultivated a number of successes outside of its albumin research. At Marshall in 1991, Carter, NASA colleague Joseph X. Ho and Florian Rüker, then with the Institute of Applied Microbiology in Vienna, helped determine the atomic structure of an antibody that recognized HIV—another scientific first. This collaboration culminated in a modular antibody technology that the company licensed and later sold to Austrian biotechnology company f-star, which is using the innovation to develop novel antibody-based treatments for conditions ranging from cancer to autoimmune diseases. New Century also invented a family of nanoparticle protein technologies, Ferrigen, with potential applications ranging from vaccines to drug delivery; developed a candidate HIV vaccine platform utilizing the Ferrigen technology; and crafted hardware currently under testing at Marshall for growing large crystals in space—ideal for neutron imaging applications that can reveal atomic structures more clearly than ever before. \n        With its origins at NASA, New Century’s CADEX platform is still the world’s largest repository of albumin structures, Carter says, and the potential clinical benefit of that data has yet to be fully realized.\n        “The challenge ahead of us is how that information \n          is translated into helping people,” he says. “That’s an ongoing process.”\n        CADEX™, Albagen™, Salus™, and Ferrigen™ are trademarks of New Century Pharmaceuticals Inc\n      "},{"href":"http://spinoff.nasa.gov/Spinoff2011/hm_5.html","text":"Mass Analyzers Facilitate Research \n                on Addiction","image":"http://spinoff.nasa.gov/Spinoff2011/Images/hm-17_fmt.jpg","story":"\n    \n      \n        \n          NASA Technology\n          The famous “go/no go” command for space shuttle launches comes from a place called the Firing Room. Located at Kennedy Space Center in the Launch Control Center (LCC), there are actually four Firing Rooms that take up most of the third floor of the LCC. These rooms comprise the nerve center for space shuttle launch and processing. \n          Test engineers in the Firing Rooms operate the Launch Processing System (LPS), which is a highly automated, computer-controlled system for assembly, checkout, and launch of the space shuttle. LPS monitors thousands of measurements on the space shuttle and its ground support equipment, compares them to predefined tolerance levels, and then displays values that are out of tolerance. Firing Room operators view the data and send commands about everything from propellant levels inside the external tank to temperatures inside the crew compartment. In many cases, LPS will automatically react to abnormal conditions and perform related functions without test engineer intervention; however, firing room engineers continue to look at each and every happening to ensure a safe launch.\n          Some of the systems monitored during launch operations include electrical, cooling, communications, and computers. One of the thousands of measurements derived from these systems is the amount of hydrogen and oxygen inside the shuttle during launch. \n          Partnership\n          \n            \n            \n              \n            \n            \n              Inside the firing room at Kennedy Space Center, members of the NASA management team watch the final launch of Space Shuttle Discovery on February 24, 2011.\n            \n          \n          In 1999, to enhance the technology that continuously monitored these gas levels inside the orbiter while on the launch pad, Kennedy awarded a Small Business Innovation Research (SBIR) contract to Houston-based Ionwerks Inc. to fabricate a small, fast, time-of-flight mass spectrometer (TOFMS). \n          A TOFMS is one of many different types of mass spectrometers for measuring the exact weight of molecular ions (created by electron impact ionization of molecules). These molecular ions can be present in parts per million (ppm) levels in solids, liquids, gasses, and plasma. For leak detection of hydrogen and oxygen within the orbiter at Kennedy, ions were created from atmospheric gas samples. The TOF analytical technique separated the different ionized molecules according to their weight by measuring the time it takes for them to travel across a fixed distance.\n          Ionwerks’ previous collaborations with organizations such as Argonne National Laboratory, the National Institutes of Health (NIH), Texas A&M University, Rice University, and several companies helped Ionwerks evolve dual-use electronics in TOF mass spectrometry, based on timing chips originally developed for high energy physics. Since Ionwerks had already commercialized the crucial components, an advanced compact TOF instrument was rapidly prototyped through the SBIR partnership to provide a rugged, low-power option for quick remote monitoring of the gas composition inside the space shuttle. \n          According to Al Schultz, the founder of Ionwerks, “The application at Kennedy was unique, and we demonstrated that the instrument could be fast and accurate for determining parts-per-million changes in hydrogen and oxygen on top of large signals already present in the orbiter atmosphere. After the SBIR, we used the experience and the electronics as a springboard to do other work, especially in the area of detecting large molecules on surfaces—especially bio-surfaces.” \n          Benefits\n          Over the last decade, as a result of its SBIR work with NASA and NIH, Ionwerks’ technology has taken two commercial paths: one in Europe and one in \n            the United States. \n          Two researchers who were employed at Ionwerks during the NASA SBIR, Katrin Fuhrer and Marc Gonin, adapted the approach to improve a commercial gas analyzer for environmental monitoring of airborne contaminants. “By replacing a quadrupole mass spectrometer with the TOF, all masses are measured at once,” says Schultz. “More sensitivity is achieved, even at a specific mass, than with the quadrupole.” The technique quickly and precisely determines the composition of a sample. To provide the NASA-inspired technology for industrial, government, and academic research labs, Fuhrer and Gonin founded a company in Thun, Switzerland, called Tofwerk. \n          Back in the United States, Ionwerks incorporated many of the innovations developed during the SBIR with Kennedy into its commercial laser imaging spectrometer for surface analysis. Today, Ionwerks sells the complete spectrometer to industrial, government, and academic laboratories for biological mass spectrometry and basic biological research. One of the instrument’s unique features is its precision, which allows users to see subtle differences in the masses and shapes of compounds desorbed (released) from a surface. \n          \n            \n            \n              \n            \n            \n              After working with NASA, Ionwerks Inc. used its experience and electronics to develop this system for imaging biological tissues at the National Institutes of Health’s National Institute on Drug Abuse. \n            \n          \n          For one application, Ionwerks’ spectrometer has been incorporated into ongoing contractual and SBIR work with the NIH’s National Institute on Drug Abuse (NIDA). “Most of the hardware and electronics we developed for NASA found dual use in work with NIDA,” says Schultz. “After engineering the technology with NASA, it was easier to evolve a unique instrument for the NIDA applications.”\n          Research led by Amina Woods at NIDA’s Intramural Research program is aimed at imaging biological tissues to search for biomarker molecules as indicators of addiction or brain injury. Ionwerks’ molecular imager combines mass spectrometry with an ionization method called matrix assisted laser desorption ionization (MALDI) and a gas phase separations technique called ion mobility spectrometry to locate and identify large biomolecules on the surface of biological samples. \n          “If you move the laser focus from one spot to the next spot and measure the number and type of ions originating from each spot, you can create an image—a molecular map—of what molecules are where on the surface of the tissue. If researchers can find biomarkers that are collocated with diseased areas, then perhaps it will be possible to chemically mitigate neurological disease or injuries,” says Schultz. Ultimately, NIDA is attempting to correlate the presence of certain molecules with cases of addiction. Schultz notes, “If the tool can be used for one set of neurological problems, it can be used for others.” \n          In 2006, the company was recognized for its work with NIDA with the prestigious “Tibbetts Award” for small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program.\n          Without the SBIRs and use of retained earnings from Ionwerks’ commercial sales, Schultz says the work to create the product would not have been possible. But aside from the success of the instrument, Schultz hopes for the success of something even bigger. “Our company hopes to help the research community, all the people doing molecular imaging, to develop technologies that will use ever-improving instrumentation to achieve more specific molecular information, even within single cells,” he says. “Everyone in this field shares the dream that molecular imaging technology will ultimately be used clinically for early onset detection of diseases in time to do something about them.\n        \n        \n      \n    \n      \n        \n          NASA Technology\n          The famous “go/no go” command for space shuttle launches comes from a place called the Firing Room. Located at Kennedy Space Center in the Launch Control Center (LCC), there are actually four Firing Rooms that take up most of the third floor of the LCC. These rooms comprise the nerve center for space shuttle launch and processing. \n          Test engineers in the Firing Rooms operate the Launch Processing System (LPS), which is a highly automated, computer-controlled system for assembly, checkout, and launch of the space shuttle. LPS monitors thousands of measurements on the space shuttle and its ground support equipment, compares them to predefined tolerance levels, and then displays values that are out of tolerance. Firing Room operators view the data and send commands about everything from propellant levels inside the external tank to temperatures inside the crew compartment. In many cases, LPS will automatically react to abnormal conditions and perform related functions without test engineer intervention; however, firing room engineers continue to look at each and every happening to ensure a safe launch.\n          Some of the systems monitored during launch operations include electrical, cooling, communications, and computers. One of the thousands of measurements derived from these systems is the amount of hydrogen and oxygen inside the shuttle during launch. \n          Partnership\n          \n            \n            \n              \n            \n            \n              Inside the firing room at Kennedy Space Center, members of the NASA management team watch the final launch of Space Shuttle Discovery on February 24, 2011.\n            \n          \n          In 1999, to enhance the technology that continuously monitored these gas levels inside the orbiter while on the launch pad, Kennedy awarded a Small Business Innovation Research (SBIR) contract to Houston-based Ionwerks Inc. to fabricate a small, fast, time-of-flight mass spectrometer (TOFMS). \n          A TOFMS is one of many different types of mass spectrometers for measuring the exact weight of molecular ions (created by electron impact ionization of molecules). These molecular ions can be present in parts per million (ppm) levels in solids, liquids, gasses, and plasma. For leak detection of hydrogen and oxygen within the orbiter at Kennedy, ions were created from atmospheric gas samples. The TOF analytical technique separated the different ionized molecules according to their weight by measuring the time it takes for them to travel across a fixed distance.\n          Ionwerks’ previous collaborations with organizations such as Argonne National Laboratory, the National Institutes of Health (NIH), Texas A&M University, Rice University, and several companies helped Ionwerks evolve dual-use electronics in TOF mass spectrometry, based on timing chips originally developed for high energy physics. Since Ionwerks had already commercialized the crucial components, an advanced compact TOF instrument was rapidly prototyped through the SBIR partnership to provide a rugged, low-power option for quick remote monitoring of the gas composition inside the space shuttle. \n          According to Al Schultz, the founder of Ionwerks, “The application at Kennedy was unique, and we demonstrated that the instrument could be fast and accurate for determining parts-per-million changes in hydrogen and oxygen on top of large signals already present in the orbiter atmosphere. After the SBIR, we used the experience and the electronics as a springboard to do other work, especially in the area of detecting large molecules on surfaces—especially bio-surfaces.” \n          Benefits\n          Over the last decade, as a result of its SBIR work with NASA and NIH, Ionwerks’ technology has taken two commercial paths: one in Europe and one in \n            the United States. \n          Two researchers who were employed at Ionwerks during the NASA SBIR, Katrin Fuhrer and Marc Gonin, adapted the approach to improve a commercial gas analyzer for environmental monitoring of airborne contaminants. “By replacing a quadrupole mass spectrometer with the TOF, all masses are measured at once,” says Schultz. “More sensitivity is achieved, even at a specific mass, than with the quadrupole.” The technique quickly and precisely determines the composition of a sample. To provide the NASA-inspired technology for industrial, government, and academic research labs, Fuhrer and Gonin founded a company in Thun, Switzerland, called Tofwerk. \n          Back in the United States, Ionwerks incorporated many of the innovations developed during the SBIR with Kennedy into its commercial laser imaging spectrometer for surface analysis. Today, Ionwerks sells the complete spectrometer to industrial, government, and academic laboratories for biological mass spectrometry and basic biological research. One of the instrument’s unique features is its precision, which allows users to see subtle differences in the masses and shapes of compounds desorbed (released) from a surface. \n          \n            \n            \n              \n            \n            \n              After working with NASA, Ionwerks Inc. used its experience and electronics to develop this system for imaging biological tissues at the National Institutes of Health’s National Institute on Drug Abuse. \n            \n          \n          For one application, Ionwerks’ spectrometer has been incorporated into ongoing contractual and SBIR work with the NIH’s National Institute on Drug Abuse (NIDA). “Most of the hardware and electronics we developed for NASA found dual use in work with NIDA,” says Schultz. “After engineering the technology with NASA, it was easier to evolve a unique instrument for the NIDA applications.”\n          Research led by Amina Woods at NIDA’s Intramural Research program is aimed at imaging biological tissues to search for biomarker molecules as indicators of addiction or brain injury. Ionwerks’ molecular imager combines mass spectrometry with an ionization method called matrix assisted laser desorption ionization (MALDI) and a gas phase separations technique called ion mobility spectrometry to locate and identify large biomolecules on the surface of biological samples. \n          “If you move the laser focus from one spot to the next spot and measure the number and type of ions originating from each spot, you can create an image—a molecular map—of what molecules are where on the surface of the tissue. If researchers can find biomarkers that are collocated with diseased areas, then perhaps it will be possible to chemically mitigate neurological disease or injuries,” says Schultz. Ultimately, NIDA is attempting to correlate the presence of certain molecules with cases of addiction. Schultz notes, “If the tool can be used for one set of neurological problems, it can be used for others.” \n          In 2006, the company was recognized for its work with NIDA with the prestigious “Tibbetts Award” for small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program.\n          Without the SBIRs and use of retained earnings from Ionwerks’ commercial sales, Schultz says the work to create the product would not have been possible. But aside from the success of the instrument, Schultz hopes for the success of something even bigger. “Our company hopes to help the research community, all the people doing molecular imaging, to develop technologies that will use ever-improving instrumentation to achieve more specific molecular information, even within single cells,” he says. “Everyone in this field shares the dream that molecular imaging technology will ultimately be used clinically for early onset detection of diseases in time to do something about them.\n        \n        \n      \n        \n          NASA Technology\n          The famous “go/no go” command for space shuttle launches comes from a place called the Firing Room. Located at Kennedy Space Center in the Launch Control Center (LCC), there are actually four Firing Rooms that take up most of the third floor of the LCC. These rooms comprise the nerve center for space shuttle launch and processing. \n          Test engineers in the Firing Rooms operate the Launch Processing System (LPS), which is a highly automated, computer-controlled system for assembly, checkout, and launch of the space shuttle. LPS monitors thousands of measurements on the space shuttle and its ground support equipment, compares them to predefined tolerance levels, and then displays values that are out of tolerance. Firing Room operators view the data and send commands about everything from propellant levels inside the external tank to temperatures inside the crew compartment. In many cases, LPS will automatically react to abnormal conditions and perform related functions without test engineer intervention; however, firing room engineers continue to look at each and every happening to ensure a safe launch.\n          Some of the systems monitored during launch operations include electrical, cooling, communications, and computers. One of the thousands of measurements derived from these systems is the amount of hydrogen and oxygen inside the shuttle during launch. \n          Partnership\n          \n            \n            \n              \n            \n            \n              Inside the firing room at Kennedy Space Center, members of the NASA management team watch the final launch of Space Shuttle Discovery on February 24, 2011.\n            \n          \n          In 1999, to enhance the technology that continuously monitored these gas levels inside the orbiter while on the launch pad, Kennedy awarded a Small Business Innovation Research (SBIR) contract to Houston-based Ionwerks Inc. to fabricate a small, fast, time-of-flight mass spectrometer (TOFMS). \n          A TOFMS is one of many different types of mass spectrometers for measuring the exact weight of molecular ions (created by electron impact ionization of molecules). These molecular ions can be present in parts per million (ppm) levels in solids, liquids, gasses, and plasma. For leak detection of hydrogen and oxygen within the orbiter at Kennedy, ions were created from atmospheric gas samples. The TOF analytical technique separated the different ionized molecules according to their weight by measuring the time it takes for them to travel across a fixed distance.\n          Ionwerks’ previous collaborations with organizations such as Argonne National Laboratory, the National Institutes of Health (NIH), Texas A&M University, Rice University, and several companies helped Ionwerks evolve dual-use electronics in TOF mass spectrometry, based on timing chips originally developed for high energy physics. Since Ionwerks had already commercialized the crucial components, an advanced compact TOF instrument was rapidly prototyped through the SBIR partnership to provide a rugged, low-power option for quick remote monitoring of the gas composition inside the space shuttle. \n          According to Al Schultz, the founder of Ionwerks, “The application at Kennedy was unique, and we demonstrated that the instrument could be fast and accurate for determining parts-per-million changes in hydrogen and oxygen on top of large signals already present in the orbiter atmosphere. After the SBIR, we used the experience and the electronics as a springboard to do other work, especially in the area of detecting large molecules on surfaces—especially bio-surfaces.” \n          Benefits\n          Over the last decade, as a result of its SBIR work with NASA and NIH, Ionwerks’ technology has taken two commercial paths: one in Europe and one in \n            the United States. \n          Two researchers who were employed at Ionwerks during the NASA SBIR, Katrin Fuhrer and Marc Gonin, adapted the approach to improve a commercial gas analyzer for environmental monitoring of airborne contaminants. “By replacing a quadrupole mass spectrometer with the TOF, all masses are measured at once,” says Schultz. “More sensitivity is achieved, even at a specific mass, than with the quadrupole.” The technique quickly and precisely determines the composition of a sample. To provide the NASA-inspired technology for industrial, government, and academic research labs, Fuhrer and Gonin founded a company in Thun, Switzerland, called Tofwerk. \n          Back in the United States, Ionwerks incorporated many of the innovations developed during the SBIR with Kennedy into its commercial laser imaging spectrometer for surface analysis. Today, Ionwerks sells the complete spectrometer to industrial, government, and academic laboratories for biological mass spectrometry and basic biological research. One of the instrument’s unique features is its precision, which allows users to see subtle differences in the masses and shapes of compounds desorbed (released) from a surface. \n          \n            \n            \n              \n            \n            \n              After working with NASA, Ionwerks Inc. used its experience and electronics to develop this system for imaging biological tissues at the National Institutes of Health’s National Institute on Drug Abuse. \n            \n          \n          For one application, Ionwerks’ spectrometer has been incorporated into ongoing contractual and SBIR work with the NIH’s National Institute on Drug Abuse (NIDA). “Most of the hardware and electronics we developed for NASA found dual use in work with NIDA,” says Schultz. “After engineering the technology with NASA, it was easier to evolve a unique instrument for the NIDA applications.”\n          Research led by Amina Woods at NIDA’s Intramural Research program is aimed at imaging biological tissues to search for biomarker molecules as indicators of addiction or brain injury. Ionwerks’ molecular imager combines mass spectrometry with an ionization method called matrix assisted laser desorption ionization (MALDI) and a gas phase separations technique called ion mobility spectrometry to locate and identify large biomolecules on the surface of biological samples. \n          “If you move the laser focus from one spot to the next spot and measure the number and type of ions originating from each spot, you can create an image—a molecular map—of what molecules are where on the surface of the tissue. If researchers can find biomarkers that are collocated with diseased areas, then perhaps it will be possible to chemically mitigate neurological disease or injuries,” says Schultz. Ultimately, NIDA is attempting to correlate the presence of certain molecules with cases of addiction. Schultz notes, “If the tool can be used for one set of neurological problems, it can be used for others.” \n          In 2006, the company was recognized for its work with NIDA with the prestigious “Tibbetts Award” for small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program.\n          Without the SBIRs and use of retained earnings from Ionwerks’ commercial sales, Schultz says the work to create the product would not have been possible. But aside from the success of the instrument, Schultz hopes for the success of something even bigger. “Our company hopes to help the research community, all the people doing molecular imaging, to develop technologies that will use ever-improving instrumentation to achieve more specific molecular information, even within single cells,” he says. “Everyone in this field shares the dream that molecular imaging technology will ultimately be used clinically for early onset detection of diseases in time to do something about them.\n        \n        \n          NASA Technology\n          The famous “go/no go” command for space shuttle launches comes from a place called the Firing Room. Located at Kennedy Space Center in the Launch Control Center (LCC), there are actually four Firing Rooms that take up most of the third floor of the LCC. These rooms comprise the nerve center for space shuttle launch and processing. \n          Test engineers in the Firing Rooms operate the Launch Processing System (LPS), which is a highly automated, computer-controlled system for assembly, checkout, and launch of the space shuttle. LPS monitors thousands of measurements on the space shuttle and its ground support equipment, compares them to predefined tolerance levels, and then displays values that are out of tolerance. Firing Room operators view the data and send commands about everything from propellant levels inside the external tank to temperatures inside the crew compartment. In many cases, LPS will automatically react to abnormal conditions and perform related functions without test engineer intervention; however, firing room engineers continue to look at each and every happening to ensure a safe launch.\n          Some of the systems monitored during launch operations include electrical, cooling, communications, and computers. One of the thousands of measurements derived from these systems is the amount of hydrogen and oxygen inside the shuttle during launch. \n          Partnership\n          \n            \n            \n              \n            \n            \n              Inside the firing room at Kennedy Space Center, members of the NASA management team watch the final launch of Space Shuttle Discovery on February 24, 2011.\n            \n          \n          In 1999, to enhance the technology that continuously monitored these gas levels inside the orbiter while on the launch pad, Kennedy awarded a Small Business Innovation Research (SBIR) contract to Houston-based Ionwerks Inc. to fabricate a small, fast, time-of-flight mass spectrometer (TOFMS). \n          A TOFMS is one of many different types of mass spectrometers for measuring the exact weight of molecular ions (created by electron impact ionization of molecules). These molecular ions can be present in parts per million (ppm) levels in solids, liquids, gasses, and plasma. For leak detection of hydrogen and oxygen within the orbiter at Kennedy, ions were created from atmospheric gas samples. The TOF analytical technique separated the different ionized molecules according to their weight by measuring the time it takes for them to travel across a fixed distance.\n          Ionwerks’ previous collaborations with organizations such as Argonne National Laboratory, the National Institutes of Health (NIH), Texas A&M University, Rice University, and several companies helped Ionwerks evolve dual-use electronics in TOF mass spectrometry, based on timing chips originally developed for high energy physics. Since Ionwerks had already commercialized the crucial components, an advanced compact TOF instrument was rapidly prototyped through the SBIR partnership to provide a rugged, low-power option for quick remote monitoring of the gas composition inside the space shuttle. \n          According to Al Schultz, the founder of Ionwerks, “The application at Kennedy was unique, and we demonstrated that the instrument could be fast and accurate for determining parts-per-million changes in hydrogen and oxygen on top of large signals already present in the orbiter atmosphere. After the SBIR, we used the experience and the electronics as a springboard to do other work, especially in the area of detecting large molecules on surfaces—especially bio-surfaces.” \n          Benefits\n          Over the last decade, as a result of its SBIR work with NASA and NIH, Ionwerks’ technology has taken two commercial paths: one in Europe and one in \n            the United States. \n          Two researchers who were employed at Ionwerks during the NASA SBIR, Katrin Fuhrer and Marc Gonin, adapted the approach to improve a commercial gas analyzer for environmental monitoring of airborne contaminants. “By replacing a quadrupole mass spectrometer with the TOF, all masses are measured at once,” says Schultz. “More sensitivity is achieved, even at a specific mass, than with the quadrupole.” The technique quickly and precisely determines the composition of a sample. To provide the NASA-inspired technology for industrial, government, and academic research labs, Fuhrer and Gonin founded a company in Thun, Switzerland, called Tofwerk. \n          Back in the United States, Ionwerks incorporated many of the innovations developed during the SBIR with Kennedy into its commercial laser imaging spectrometer for surface analysis. Today, Ionwerks sells the complete spectrometer to industrial, government, and academic laboratories for biological mass spectrometry and basic biological research. One of the instrument’s unique features is its precision, which allows users to see subtle differences in the masses and shapes of compounds desorbed (released) from a surface. \n          \n            \n            \n              \n            \n            \n              After working with NASA, Ionwerks Inc. used its experience and electronics to develop this system for imaging biological tissues at the National Institutes of Health’s National Institute on Drug Abuse. \n            \n          \n          For one application, Ionwerks’ spectrometer has been incorporated into ongoing contractual and SBIR work with the NIH’s National Institute on Drug Abuse (NIDA). “Most of the hardware and electronics we developed for NASA found dual use in work with NIDA,” says Schultz. “After engineering the technology with NASA, it was easier to evolve a unique instrument for the NIDA applications.”\n          Research led by Amina Woods at NIDA’s Intramural Research program is aimed at imaging biological tissues to search for biomarker molecules as indicators of addiction or brain injury. Ionwerks’ molecular imager combines mass spectrometry with an ionization method called matrix assisted laser desorption ionization (MALDI) and a gas phase separations technique called ion mobility spectrometry to locate and identify large biomolecules on the surface of biological samples. \n          “If you move the laser focus from one spot to the next spot and measure the number and type of ions originating from each spot, you can create an image—a molecular map—of what molecules are where on the surface of the tissue. If researchers can find biomarkers that are collocated with diseased areas, then perhaps it will be possible to chemically mitigate neurological disease or injuries,” says Schultz. Ultimately, NIDA is attempting to correlate the presence of certain molecules with cases of addiction. Schultz notes, “If the tool can be used for one set of neurological problems, it can be used for others.” \n          In 2006, the company was recognized for its work with NIDA with the prestigious “Tibbetts Award” for small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program.\n          Without the SBIRs and use of retained earnings from Ionwerks’ commercial sales, Schultz says the work to create the product would not have been possible. But aside from the success of the instrument, Schultz hopes for the success of something even bigger. “Our company hopes to help the research community, all the people doing molecular imaging, to develop technologies that will use ever-improving instrumentation to achieve more specific molecular information, even within single cells,” he says. “Everyone in this field shares the dream that molecular imaging technology will ultimately be used clinically for early onset detection of diseases in time to do something about them.\n        "},{"href":"http://spinoff.nasa.gov/Spinoff2011/hm_6.html","text":"Frameworks Coordinate Scientific Data Management","image":"http://spinoff.nasa.gov/Spinoff2011/Images/hm-19_fmt.jpg","story":"\n    \n      \n        \n          \n            NASA Technology\n            Voyager 2 sailing beyond the far boundary of the solar system. The rover Opportunity churning across the red soil of Mars. Cassini-Huygens imaging the moons of Saturn.\n            \n              \n              \n                \n              \n              \n                Data from NASA’s many spacefaring missions, like this image of Saturn from the Cassini-Huygens spacecraft, is stored in the Planetary Data System, a massive archive of scientific information distributed across the Nation.\n              \n            \n            Capable of journeying well beyond the reach of human explorers, NASA’s robotic missions have probed the distant reaches of space, sending back to Earth streams of unique data and images essential to developing an understanding of our universe. These returns are ultimately housed in NASA’s Planetary Data System (PDS), an archive of data products derived from NASA’s robotic missions, from Galileo to Pioneer to Stardust and more. Appropriately massive for the information it contains, the PDS is distributed across the Nation and organized in eight nodes in conjunction with a host of NASA partner institutions.\n            To help researchers draw the information they need from the ever-growing repositories of the PDS, in 1998 Daniel Crichton, program manager and principal computer scientist at NASA’s Jet Propulsion Laboratory, designed a unique software framework called the Object Oriented Data Technology (OODT) that transformed the PDS into an accessible virtual knowledge system. “The idea of OODT was to be able to capture all the data, the history of the data, and be able to tie and link all that together into an integrated but distributed system,” says Crichton.\n            OODT primarily functions as a set of building blocks for constructing systems that capture and manage complex parcels of scientific data, Crichton explains. Its cumulative power allows users to connect multiple, distributed databases and other data sources and then to search for and pull together information in varied data formats, building and populating databases with the aggregated results. During the software’s development, Crichton was careful to separate software architecture from data architecture, meaning OODT functions as a general-use tool that can plug into existing systems and be tailored and extended for their data. In addition to the PDS, NASA also uses OODT for multiple Earth science missions.\n            Partnership\n            While developing OODT, Crichton was already thinking about applications for the software beyond NASA’s missions.\n            “We saw the unification and integration of science data as a real national need,” he says. Crichton and his colleagues looked into ways of better engaging the open-source software community to transfer the benefits of NASA software innovations to the public. With this in mind, Chris Mattmann, a senior computer scientist at JPL who worked with Crichton on OODT, cultivated connections at the Apache Software Foundation (ASF), based in Forest Hill, Maryland. An all-volunteer, nonprofit organization supported by major information technology companies like Google, Microsoft, and Yahoo!, the ASF manages almost 150 open-source software projects, including the Apache HTTP Server—a key technology in the development of the World Wide Web and the world’s most widely used Web server—and other popular developer software. Mattmann believed Apache was the ideal partner for transferring OODT for public use.\n             “The more we can share software, the more \n              benefit we’re going to see in our scientific \n              community.”\n              —Daniel Crichton, \n  Jet Propulsion Laboratory \n            “Apache is different from other open-source communities,” he says. The organization follows a unique vetting process, he explains, that includes an incubation period to ensure that the candidate software is not only sound, but is also supported by a diverse community that will grow the software. It also provides infrastructure and leadership for housing, distributing, and managing the continued development of the technology.\n            “The ASF has been well known as having the ‘secret sauce’ for how to create successful, long-term, healthy open-source projects,” says ASF president Jim Jagielski. “We worry about the mailing lists, infrastructure, resources, and fundraising, and the projects can focus on what they do best, which is building great code and great communities.”\n            The ASF placed OODT in the Apache incubator program, a 1-year process during which Mattmann, Apache mentors, and committed collaborators from institutions as diverse as AOL, the University of Southern California, and Children’s Hospital Los Angeles thoroughly reviewed the software for open-source use and expanded OODT’s community. In November 2010, OODT graduated as an Apache Top-Level Project—the first NASA-developed software to gain the distinction—and now benefits from the full resources of the ASF, including an Apache Project Management Committee that guides day-to-day operations, product releases, and community development for the technology. \n            Benefits\n            \n              \n              \n                \n              \n              \n                NASA’s robotic missions, such as the Mars Reconnaissance Orbiter pictured here in an artist’s rendering, beam massive amounts of data back to Earth for scientific review. The challenge of accessing that data effectively led to the development of the Object Oriented Data Technology software now in use by hospitals and medical researchers through the Apache Software Foundation. \n              \n            \n            Apache OODT version 0.1 is currently available for public use under the Apache Software License. The software is generating significant worldwide interest and contributions while supporting a number of research networks outside of NASA. “If you look at planetary science, Earth science, even cancer research, there’s actually a lot of consistency or similarity in the kinds of software capabilities needed,” Crichton says. \n            Even before the release of version 0.1, OODT had found users who have employed the NASA-developed software to forward medical research. The National Cancer Institute uses OODT as the foundation of its Early Detection Research Network, unifying multiple laboratories to capture and share research into the early detection of cancer biomarkers. Children’s Hospital Los Angeles is establishing a virtual infrastructure for joining pediatric intensive care units across the country, allowing doctors to examine the outcomes of various interventions and make better informed treatment decisions. \n            These organizations and others will benefit as OODT improves as a result of open-source community contributions, says Mattmann, who is also vice president of Apache OODT. “The dissemination of information happens out in the clear, where others can contribute and weigh in. We get lots of feedback,” he says. \n            Sharing innovative technology with the public is an impulse that is common to both NASA and the ASF, according to Jagielski, a former Goddard Space Flight Center engineer of 19 years. “It’s all about developing technology that you can then distribute to whoever needs it for the public good,” he says. “It’s a win-win for everyone, because from the taxpayer money that was invested, we now have many groups that are able to use this technology,” says Crichton. He says Apache OODT is already benefitting from the Apache partnership and the contributions of open-source developers. These contributions, he notes, will pay dividends for scientific research in the future.\n            “The more we can share software, the more benefit we’re going to see in our scientific community.”\n            Apache™, Apache HTTP Server™, and Apache OODT™ are trademarks of the Apache Software Foundation\n          \n          \n        \n      \n    \n      \n        \n          \n            NASA Technology\n            Voyager 2 sailing beyond the far boundary of the solar system. The rover Opportunity churning across the red soil of Mars. Cassini-Huygens imaging the moons of Saturn.\n            \n              \n              \n                \n              \n              \n                Data from NASA’s many spacefaring missions, like this image of Saturn from the Cassini-Huygens spacecraft, is stored in the Planetary Data System, a massive archive of scientific information distributed across the Nation.\n              \n            \n            Capable of journeying well beyond the reach of human explorers, NASA’s robotic missions have probed the distant reaches of space, sending back to Earth streams of unique data and images essential to developing an understanding of our universe. These returns are ultimately housed in NASA’s Planetary Data System (PDS), an archive of data products derived from NASA’s robotic missions, from Galileo to Pioneer to Stardust and more. Appropriately massive for the information it contains, the PDS is distributed across the Nation and organized in eight nodes in conjunction with a host of NASA partner institutions.\n            To help researchers draw the information they need from the ever-growing repositories of the PDS, in 1998 Daniel Crichton, program manager and principal computer scientist at NASA’s Jet Propulsion Laboratory, designed a unique software framework called the Object Oriented Data Technology (OODT) that transformed the PDS into an accessible virtual knowledge system. “The idea of OODT was to be able to capture all the data, the history of the data, and be able to tie and link all that together into an integrated but distributed system,” says Crichton.\n            OODT primarily functions as a set of building blocks for constructing systems that capture and manage complex parcels of scientific data, Crichton explains. Its cumulative power allows users to connect multiple, distributed databases and other data sources and then to search for and pull together information in varied data formats, building and populating databases with the aggregated results. During the software’s development, Crichton was careful to separate software architecture from data architecture, meaning OODT functions as a general-use tool that can plug into existing systems and be tailored and extended for their data. In addition to the PDS, NASA also uses OODT for multiple Earth science missions.\n            Partnership\n            While developing OODT, Crichton was already thinking about applications for the software beyond NASA’s missions.\n            “We saw the unification and integration of science data as a real national need,” he says. Crichton and his colleagues looked into ways of better engaging the open-source software community to transfer the benefits of NASA software innovations to the public. With this in mind, Chris Mattmann, a senior computer scientist at JPL who worked with Crichton on OODT, cultivated connections at the Apache Software Foundation (ASF), based in Forest Hill, Maryland. An all-volunteer, nonprofit organization supported by major information technology companies like Google, Microsoft, and Yahoo!, the ASF manages almost 150 open-source software projects, including the Apache HTTP Server—a key technology in the development of the World Wide Web and the world’s most widely used Web server—and other popular developer software. Mattmann believed Apache was the ideal partner for transferring OODT for public use.\n             “The more we can share software, the more \n              benefit we’re going to see in our scientific \n              community.”\n              —Daniel Crichton, \n  Jet Propulsion Laboratory \n            “Apache is different from other open-source communities,” he says. The organization follows a unique vetting process, he explains, that includes an incubation period to ensure that the candidate software is not only sound, but is also supported by a diverse community that will grow the software. It also provides infrastructure and leadership for housing, distributing, and managing the continued development of the technology.\n            “The ASF has been well known as having the ‘secret sauce’ for how to create successful, long-term, healthy open-source projects,” says ASF president Jim Jagielski. “We worry about the mailing lists, infrastructure, resources, and fundraising, and the projects can focus on what they do best, which is building great code and great communities.”\n            The ASF placed OODT in the Apache incubator program, a 1-year process during which Mattmann, Apache mentors, and committed collaborators from institutions as diverse as AOL, the University of Southern California, and Children’s Hospital Los Angeles thoroughly reviewed the software for open-source use and expanded OODT’s community. In November 2010, OODT graduated as an Apache Top-Level Project—the first NASA-developed software to gain the distinction—and now benefits from the full resources of the ASF, including an Apache Project Management Committee that guides day-to-day operations, product releases, and community development for the technology. \n            Benefits\n            \n              \n              \n                \n              \n              \n                NASA’s robotic missions, such as the Mars Reconnaissance Orbiter pictured here in an artist’s rendering, beam massive amounts of data back to Earth for scientific review. The challenge of accessing that data effectively led to the development of the Object Oriented Data Technology software now in use by hospitals and medical researchers through the Apache Software Foundation. \n              \n            \n            Apache OODT version 0.1 is currently available for public use under the Apache Software License. The software is generating significant worldwide interest and contributions while supporting a number of research networks outside of NASA. “If you look at planetary science, Earth science, even cancer research, there’s actually a lot of consistency or similarity in the kinds of software capabilities needed,” Crichton says. \n            Even before the release of version 0.1, OODT had found users who have employed the NASA-developed software to forward medical research. The National Cancer Institute uses OODT as the foundation of its Early Detection Research Network, unifying multiple laboratories to capture and share research into the early detection of cancer biomarkers. Children’s Hospital Los Angeles is establishing a virtual infrastructure for joining pediatric intensive care units across the country, allowing doctors to examine the outcomes of various interventions and make better informed treatment decisions. \n            These organizations and others will benefit as OODT improves as a result of open-source community contributions, says Mattmann, who is also vice president of Apache OODT. “The dissemination of information happens out in the clear, where others can contribute and weigh in. We get lots of feedback,” he says. \n            Sharing innovative technology with the public is an impulse that is common to both NASA and the ASF, according to Jagielski, a former Goddard Space Flight Center engineer of 19 years. “It’s all about developing technology that you can then distribute to whoever needs it for the public good,” he says. “It’s a win-win for everyone, because from the taxpayer money that was invested, we now have many groups that are able to use this technology,” says Crichton. He says Apache OODT is already benefitting from the Apache partnership and the contributions of open-source developers. These contributions, he notes, will pay dividends for scientific research in the future.\n            “The more we can share software, the more benefit we’re going to see in our scientific community.”\n            Apache™, Apache HTTP Server™, and Apache OODT™ are trademarks of the Apache Software Foundation\n          \n          \n        \n      \n        \n          \n            NASA Technology\n            Voyager 2 sailing beyond the far boundary of the solar system. The rover Opportunity churning across the red soil of Mars. Cassini-Huygens imaging the moons of Saturn.\n            \n              \n              \n                \n              \n              \n                Data from NASA’s many spacefaring missions, like this image of Saturn from the Cassini-Huygens spacecraft, is stored in the Planetary Data System, a massive archive of scientific information distributed across the Nation.\n              \n            \n            Capable of journeying well beyond the reach of human explorers, NASA’s robotic missions have probed the distant reaches of space, sending back to Earth streams of unique data and images essential to developing an understanding of our universe. These returns are ultimately housed in NASA’s Planetary Data System (PDS), an archive of data products derived from NASA’s robotic missions, from Galileo to Pioneer to Stardust and more. Appropriately massive for the information it contains, the PDS is distributed across the Nation and organized in eight nodes in conjunction with a host of NASA partner institutions.\n            To help researchers draw the information they need from the ever-growing repositories of the PDS, in 1998 Daniel Crichton, program manager and principal computer scientist at NASA’s Jet Propulsion Laboratory, designed a unique software framework called the Object Oriented Data Technology (OODT) that transformed the PDS into an accessible virtual knowledge system. “The idea of OODT was to be able to capture all the data, the history of the data, and be able to tie and link all that together into an integrated but distributed system,” says Crichton.\n            OODT primarily functions as a set of building blocks for constructing systems that capture and manage complex parcels of scientific data, Crichton explains. Its cumulative power allows users to connect multiple, distributed databases and other data sources and then to search for and pull together information in varied data formats, building and populating databases with the aggregated results. During the software’s development, Crichton was careful to separate software architecture from data architecture, meaning OODT functions as a general-use tool that can plug into existing systems and be tailored and extended for their data. In addition to the PDS, NASA also uses OODT for multiple Earth science missions.\n            Partnership\n            While developing OODT, Crichton was already thinking about applications for the software beyond NASA’s missions.\n            “We saw the unification and integration of science data as a real national need,” he says. Crichton and his colleagues looked into ways of better engaging the open-source software community to transfer the benefits of NASA software innovations to the public. With this in mind, Chris Mattmann, a senior computer scientist at JPL who worked with Crichton on OODT, cultivated connections at the Apache Software Foundation (ASF), based in Forest Hill, Maryland. An all-volunteer, nonprofit organization supported by major information technology companies like Google, Microsoft, and Yahoo!, the ASF manages almost 150 open-source software projects, including the Apache HTTP Server—a key technology in the development of the World Wide Web and the world’s most widely used Web server—and other popular developer software. Mattmann believed Apache was the ideal partner for transferring OODT for public use.\n             “The more we can share software, the more \n              benefit we’re going to see in our scientific \n              community.”\n              —Daniel Crichton, \n  Jet Propulsion Laboratory \n            “Apache is different from other open-source communities,” he says. The organization follows a unique vetting process, he explains, that includes an incubation period to ensure that the candidate software is not only sound, but is also supported by a diverse community that will grow the software. It also provides infrastructure and leadership for housing, distributing, and managing the continued development of the technology.\n            “The ASF has been well known as having the ‘secret sauce’ for how to create successful, long-term, healthy open-source projects,” says ASF president Jim Jagielski. “We worry about the mailing lists, infrastructure, resources, and fundraising, and the projects can focus on what they do best, which is building great code and great communities.”\n            The ASF placed OODT in the Apache incubator program, a 1-year process during which Mattmann, Apache mentors, and committed collaborators from institutions as diverse as AOL, the University of Southern California, and Children’s Hospital Los Angeles thoroughly reviewed the software for open-source use and expanded OODT’s community. In November 2010, OODT graduated as an Apache Top-Level Project—the first NASA-developed software to gain the distinction—and now benefits from the full resources of the ASF, including an Apache Project Management Committee that guides day-to-day operations, product releases, and community development for the technology. \n            Benefits\n            \n              \n              \n                \n              \n              \n                NASA’s robotic missions, such as the Mars Reconnaissance Orbiter pictured here in an artist’s rendering, beam massive amounts of data back to Earth for scientific review. The challenge of accessing that data effectively led to the development of the Object Oriented Data Technology software now in use by hospitals and medical researchers through the Apache Software Foundation. \n              \n            \n            Apache OODT version 0.1 is currently available for public use under the Apache Software License. The software is generating significant worldwide interest and contributions while supporting a number of research networks outside of NASA. “If you look at planetary science, Earth science, even cancer research, there’s actually a lot of consistency or similarity in the kinds of software capabilities needed,” Crichton says. \n            Even before the release of version 0.1, OODT had found users who have employed the NASA-developed software to forward medical research. The National Cancer Institute uses OODT as the foundation of its Early Detection Research Network, unifying multiple laboratories to capture and share research into the early detection of cancer biomarkers. Children’s Hospital Los Angeles is establishing a virtual infrastructure for joining pediatric intensive care units across the country, allowing doctors to examine the outcomes of various interventions and make better informed treatment decisions. \n            These organizations and others will benefit as OODT improves as a result of open-source community contributions, says Mattmann, who is also vice president of Apache OODT. “The dissemination of information happens out in the clear, where others can contribute and weigh in. We get lots of feedback,” he says. \n            Sharing innovative technology with the public is an impulse that is common to both NASA and the ASF, according to Jagielski, a former Goddard Space Flight Center engineer of 19 years. “It’s all about developing technology that you can then distribute to whoever needs it for the public good,” he says. “It’s a win-win for everyone, because from the taxpayer money that was invested, we now have many groups that are able to use this technology,” says Crichton. He says Apache OODT is already benefitting from the Apache partnership and the contributions of open-source developers. These contributions, he notes, will pay dividends for scientific research in the future.\n            “The more we can share software, the more benefit we’re going to see in our scientific community.”\n            Apache™, Apache HTTP Server™, and Apache OODT™ are trademarks of the Apache Software Foundation\n          \n          \n        \n          \n            NASA Technology\n            Voyager 2 sailing beyond the far boundary of the solar system. The rover Opportunity churning across the red soil of Mars. Cassini-Huygens imaging the moons of Saturn.\n            \n              \n              \n                \n              \n              \n                Data from NASA’s many spacefaring missions, like this image of Saturn from the Cassini-Huygens spacecraft, is stored in the Planetary Data System, a massive archive of scientific information distributed across the Nation.\n              \n            \n            Capable of journeying well beyond the reach of human explorers, NASA’s robotic missions have probed the distant reaches of space, sending back to Earth streams of unique data and images essential to developing an understanding of our universe. These returns are ultimately housed in NASA’s Planetary Data System (PDS), an archive of data products derived from NASA’s robotic missions, from Galileo to Pioneer to Stardust and more. Appropriately massive for the information it contains, the PDS is distributed across the Nation and organized in eight nodes in conjunction with a host of NASA partner institutions.\n            To help researchers draw the information they need from the ever-growing repositories of the PDS, in 1998 Daniel Crichton, program manager and principal computer scientist at NASA’s Jet Propulsion Laboratory, designed a unique software framework called the Object Oriented Data Technology (OODT) that transformed the PDS into an accessible virtual knowledge system. “The idea of OODT was to be able to capture all the data, the history of the data, and be able to tie and link all that together into an integrated but distributed system,” says Crichton.\n            OODT primarily functions as a set of building blocks for constructing systems that capture and manage complex parcels of scientific data, Crichton explains. Its cumulative power allows users to connect multiple, distributed databases and other data sources and then to search for and pull together information in varied data formats, building and populating databases with the aggregated results. During the software’s development, Crichton was careful to separate software architecture from data architecture, meaning OODT functions as a general-use tool that can plug into existing systems and be tailored and extended for their data. In addition to the PDS, NASA also uses OODT for multiple Earth science missions.\n            Partnership\n            While developing OODT, Crichton was already thinking about applications for the software beyond NASA’s missions.\n            “We saw the unification and integration of science data as a real national need,” he says. Crichton and his colleagues looked into ways of better engaging the open-source software community to transfer the benefits of NASA software innovations to the public. With this in mind, Chris Mattmann, a senior computer scientist at JPL who worked with Crichton on OODT, cultivated connections at the Apache Software Foundation (ASF), based in Forest Hill, Maryland. An all-volunteer, nonprofit organization supported by major information technology companies like Google, Microsoft, and Yahoo!, the ASF manages almost 150 open-source software projects, including the Apache HTTP Server—a key technology in the development of the World Wide Web and the world’s most widely used Web server—and other popular developer software. Mattmann believed Apache was the ideal partner for transferring OODT for public use.\n             “The more we can share software, the more \n              benefit we’re going to see in our scientific \n              community.”\n              —Daniel Crichton, \n  Jet Propulsion Laboratory \n            “Apache is different from other open-source communities,” he says. The organization follows a unique vetting process, he explains, that includes an incubation period to ensure that the candidate software is not only sound, but is also supported by a diverse community that will grow the software. It also provides infrastructure and leadership for housing, distributing, and managing the continued development of the technology.\n            “The ASF has been well known as having the ‘secret sauce’ for how to create successful, long-term, healthy open-source projects,” says ASF president Jim Jagielski. “We worry about the mailing lists, infrastructure, resources, and fundraising, and the projects can focus on what they do best, which is building great code and great communities.”\n            The ASF placed OODT in the Apache incubator program, a 1-year process during which Mattmann, Apache mentors, and committed collaborators from institutions as diverse as AOL, the University of Southern California, and Children’s Hospital Los Angeles thoroughly reviewed the software for open-source use and expanded OODT’s community. In November 2010, OODT graduated as an Apache Top-Level Project—the first NASA-developed software to gain the distinction—and now benefits from the full resources of the ASF, including an Apache Project Management Committee that guides day-to-day operations, product releases, and community development for the technology. \n            Benefits\n            \n              \n              \n                \n              \n              \n                NASA’s robotic missions, such as the Mars Reconnaissance Orbiter pictured here in an artist’s rendering, beam massive amounts of data back to Earth for scientific review. The challenge of accessing that data effectively led to the development of the Object Oriented Data Technology software now in use by hospitals and medical researchers through the Apache Software Foundation. \n              \n            \n            Apache OODT version 0.1 is currently available for public use under the Apache Software License. The software is generating significant worldwide interest and contributions while supporting a number of research networks outside of NASA. “If you look at planetary science, Earth science, even cancer research, there’s actually a lot of consistency or similarity in the kinds of software capabilities needed,” Crichton says. \n            Even before the release of version 0.1, OODT had found users who have employed the NASA-developed software to forward medical research. The National Cancer Institute uses OODT as the foundation of its Early Detection Research Network, unifying multiple laboratories to capture and share research into the early detection of cancer biomarkers. Children’s Hospital Los Angeles is establishing a virtual infrastructure for joining pediatric intensive care units across the country, allowing doctors to examine the outcomes of various interventions and make better informed treatment decisions. \n            These organizations and others will benefit as OODT improves as a result of open-source community contributions, says Mattmann, who is also vice president of Apache OODT. “The dissemination of information happens out in the clear, where others can contribute and weigh in. We get lots of feedback,” he says. \n            Sharing innovative technology with the public is an impulse that is common to both NASA and the ASF, according to Jagielski, a former Goddard Space Flight Center engineer of 19 years. “It’s all about developing technology that you can then distribute to whoever needs it for the public good,” he says. “It’s a win-win for everyone, because from the taxpayer money that was invested, we now have many groups that are able to use this technology,” says Crichton. He says Apache OODT is already benefitting from the Apache partnership and the contributions of open-source developers. These contributions, he notes, will pay dividends for scientific research in the future.\n            “The more we can share software, the more benefit we’re going to see in our scientific community.”\n            Apache™, Apache HTTP Server™, and Apache OODT™ are trademarks of the Apache Software Foundation\n          \n          \n            NASA Technology\n            Voyager 2 sailing beyond the far boundary of the solar system. The rover Opportunity churning across the red soil of Mars. Cassini-Huygens imaging the moons of Saturn.\n            \n              \n              \n                \n              \n              \n                Data from NASA’s many spacefaring missions, like this image of Saturn from the Cassini-Huygens spacecraft, is stored in the Planetary Data System, a massive archive of scientific information distributed across the Nation.\n              \n            \n            Capable of journeying well beyond the reach of human explorers, NASA’s robotic missions have probed the distant reaches of space, sending back to Earth streams of unique data and images essential to developing an understanding of our universe. These returns are ultimately housed in NASA’s Planetary Data System (PDS), an archive of data products derived from NASA’s robotic missions, from Galileo to Pioneer to Stardust and more. Appropriately massive for the information it contains, the PDS is distributed across the Nation and organized in eight nodes in conjunction with a host of NASA partner institutions.\n            To help researchers draw the information they need from the ever-growing repositories of the PDS, in 1998 Daniel Crichton, program manager and principal computer scientist at NASA’s Jet Propulsion Laboratory, designed a unique software framework called the Object Oriented Data Technology (OODT) that transformed the PDS into an accessible virtual knowledge system. “The idea of OODT was to be able to capture all the data, the history of the data, and be able to tie and link all that together into an integrated but distributed system,” says Crichton.\n            OODT primarily functions as a set of building blocks for constructing systems that capture and manage complex parcels of scientific data, Crichton explains. Its cumulative power allows users to connect multiple, distributed databases and other data sources and then to search for and pull together information in varied data formats, building and populating databases with the aggregated results. During the software’s development, Crichton was careful to separate software architecture from data architecture, meaning OODT functions as a general-use tool that can plug into existing systems and be tailored and extended for their data. In addition to the PDS, NASA also uses OODT for multiple Earth science missions.\n            Partnership\n            While developing OODT, Crichton was already thinking about applications for the software beyond NASA’s missions.\n            “We saw the unification and integration of science data as a real national need,” he says. Crichton and his colleagues looked into ways of better engaging the open-source software community to transfer the benefits of NASA software innovations to the public. With this in mind, Chris Mattmann, a senior computer scientist at JPL who worked with Crichton on OODT, cultivated connections at the Apache Software Foundation (ASF), based in Forest Hill, Maryland. An all-volunteer, nonprofit organization supported by major information technology companies like Google, Microsoft, and Yahoo!, the ASF manages almost 150 open-source software projects, including the Apache HTTP Server—a key technology in the development of the World Wide Web and the world’s most widely used Web server—and other popular developer software. Mattmann believed Apache was the ideal partner for transferring OODT for public use.\n             “The more we can share software, the more \n              benefit we’re going to see in our scientific \n              community.”\n              —Daniel Crichton, \n  Jet Propulsion Laboratory \n            “Apache is different from other open-source communities,” he says. The organization follows a unique vetting process, he explains, that includes an incubation period to ensure that the candidate software is not only sound, but is also supported by a diverse community that will grow the software. It also provides infrastructure and leadership for housing, distributing, and managing the continued development of the technology.\n            “The ASF has been well known as having the ‘secret sauce’ for how to create successful, long-term, healthy open-source projects,” says ASF president Jim Jagielski. “We worry about the mailing lists, infrastructure, resources, and fundraising, and the projects can focus on what they do best, which is building great code and great communities.”\n            The ASF placed OODT in the Apache incubator program, a 1-year process during which Mattmann, Apache mentors, and committed collaborators from institutions as diverse as AOL, the University of Southern California, and Children’s Hospital Los Angeles thoroughly reviewed the software for open-source use and expanded OODT’s community. In November 2010, OODT graduated as an Apache Top-Level Project—the first NASA-developed software to gain the distinction—and now benefits from the full resources of the ASF, including an Apache Project Management Committee that guides day-to-day operations, product releases, and community development for the technology. \n            Benefits\n            \n              \n              \n                \n              \n              \n                NASA’s robotic missions, such as the Mars Reconnaissance Orbiter pictured here in an artist’s rendering, beam massive amounts of data back to Earth for scientific review. The challenge of accessing that data effectively led to the development of the Object Oriented Data Technology software now in use by hospitals and medical researchers through the Apache Software Foundation. \n              \n            \n            Apache OODT version 0.1 is currently available for public use under the Apache Software License. The software is generating significant worldwide interest and contributions while supporting a number of research networks outside of NASA. “If you look at planetary science, Earth science, even cancer research, there’s actually a lot of consistency or similarity in the kinds of software capabilities needed,” Crichton says. \n            Even before the release of version 0.1, OODT had found users who have employed the NASA-developed software to forward medical research. The National Cancer Institute uses OODT as the foundation of its Early Detection Research Network, unifying multiple laboratories to capture and share research into the early detection of cancer biomarkers. Children’s Hospital Los Angeles is establishing a virtual infrastructure for joining pediatric intensive care units across the country, allowing doctors to examine the outcomes of various interventions and make better informed treatment decisions. \n            These organizations and others will benefit as OODT improves as a result of open-source community contributions, says Mattmann, who is also vice president of Apache OODT. “The dissemination of information happens out in the clear, where others can contribute and weigh in. We get lots of feedback,” he says. \n            Sharing innovative technology with the public is an impulse that is common to both NASA and the ASF, according to Jagielski, a former Goddard Space Flight Center engineer of 19 years. “It’s all about developing technology that you can then distribute to whoever needs it for the public good,” he says. “It’s a win-win for everyone, because from the taxpayer money that was invested, we now have many groups that are able to use this technology,” says Crichton. He says Apache OODT is already benefitting from the Apache partnership and the contributions of open-source developers. These contributions, he notes, will pay dividends for scientific research in the future.\n            “The more we can share software, the more benefit we’re going to see in our scientific community.”\n            Apache™, Apache HTTP Server™, and Apache OODT™ are trademarks of the Apache Software Foundation\n          "},{"href":"http://spinoff.nasa.gov/Spinoff2011/t_1.html","text":"Cameras Improve Navigation for Pilots, Drivers","image":"http://spinoff.nasa.gov/Spinoff2011/Images/t_1_opt.jpg","story":"\n    \n      NASA Technology\n      \n        \n        \n          \n        \n        \n          An artist’s concept depicts NASA’s Phoenix Mars Lander just moments before landing on Mars. NASA is investigating camera technologies to produce 3D images of planetary terrain in real time to reveal landing hazards and to enable accurate navigation for spacecraft like Phoenix.\n        \n      \n      After 10 months of traveling through deep space to Mars, the Phoenix Lander finally approached its destination. The last 7 minutes of the spacecraft’s 423 million-mile-journey—the entry, descent, and landing (EDL) phase—were the most critical and also the most difficult. In the history of Mars landing missions, only 5 of 13 attempts have succeeded. It would have been tragic for Phoenix to go so far yet fail to arrive safely. \n      Landing on the Red Planet is extremely challenging. Tucked inside its aeroshell, Phoenix entered the atmosphere of Mars at a speed of 12,750 miles per hour. After decelerating using atmospheric drag and a parachute, Phoenix discarded its aeroshell in preparation for touchdown in a region characterized only by orbital reconnaissance data. Lacking real-time terrain mapping and hazard-avoidance capabilities, Phoenix faced the potential for serious damage or tip over from landing on a rock or other surface hazard during the final seconds of the mission.\n      To ensure the future success and reliability of such crucial landing missions, NASA is investigating a variety of terrain-sensing technologies, including cameras capable of producing real-time, 3D images of planetary terrain under any lighting conditions to reveal hazards and to enable accurate navigation to a safe landing location. \n      Partnership\n      Advanced Scientific Concepts Inc. (ASC), of Santa Barbara, California, received a Small Business Innovation Research (SBIR) award from the Jet Propulsion Laboratory (JPL) in 2006 to assess the suitability of ASC’s 3D flash light detection and ranging (LIDAR) video camera for EDL applications. With the SBIR funding, ASC tested the technology on simulated Martian landscape at the JPL Mars Yard.\n      “We want the ability to be able to make a real-time map of the hazards as we are landing so we can avoid them. That is what LIDAR is ideally suited for,” says Gary Spiers, supervisor of the Active Optical Sensing Group at JPL.\n      To develop an integrated landing system capable of detecting and avoiding surface hazards and guiding a crewed or robotic lander to a safe and accurate touchdown, NASA chartered the Automated Landing Hazard Avoidance Technology (ALHAT) Project in 2006. The ALHAT team, combining technical expertise from the Johnson Space Center, Langley Research Center, Draper Laboratory, and JPL, identified flash LIDAR technology as a highly promising approach for real-time terrain mapping and hazard detection. ASC subsequently received several SBIR awards and a NASA Research Announcement contract to continue the development and refinement of 3D flash LIDAR technologies. Over the past few years, several combinations of ASC flash LIDAR sensors and related lasers and optical components have been evaluated by NASA personnel in the lab, in the field, and in airborne tests.\n      “The primary reason NASA was interested in the technology was for safe landings. The second priority was for rendezvous and docking at the International Space Station,” says Farzin Amzajerdian, a senior scientist at Langley leading the LIDAR sensor development effort for ALHAT.\n      At Johnson, the Commercial Crew and Cargo Program Office (C3PO) invests resources to stimulate the private sector to develop and demonstrate space transportation capabilities. Under the Commercial Orbital Transportation Services project of this office, Hawthorne, California-based SpaceX is developing its Dragon spacecraft to deliver cargo and supplies to the International Space Station (ISS). Because SpaceX intends to use ASC’s technology to assist with docking at the ISS, the flash LIDAR device flew on both STS-127 and STS-133 for demonstration and evaluation.\n      “The technology is used to determine how you are posed in relation to a target, how far away you are, and how fast you are moving in relation to it,” says Warren P. Ruemmele, assistant project executive for C3PO. “If earlier investments hadn’t been made and successful, it wouldn’t be a candidate for what we are trying to do.”\n      Benefits\n      \n        \n        \n          \n        \n        \n          Advanced Scientific Concepts Inc. refined this 3D flash light detection and ranging video camera through SBIR work with NASA. The space version of the camera can assist vehicles docking at the International Space Station, and the terrestrial version can assist with navigation and collision avoidance here on Earth.\n        \n      \n      ASC’s flash LIDAR sensors use a short pulse of radiation from a near-infrared laser to illuminate a scene in front of the camera lens. Each pixel in the camera detector array measures the round trip time for the photons, which is then converted into an accurate range measurement. Each pulse of the flash LIDAR produces a 3D image consisting of thousands or tens of thousands of points acquired essentially simultaneously, which effectively eliminates motion-induced distortions. \n      A graphical user interface on a computer displays the data in the form of a color-coded range (distance) map. Current ASC flash LIDAR cameras are capable of acquiring 3D images at rates of up to 30 frames per second, which can be viewed as a video and processed for identifying various scene features. In practice, a data processor could autonomously analyze the surrounding environment and execute vehicle maneuvers.\n      Two versions of ASC’s 3D flash LIDAR camera are currently available: the DragonEye Space Camera (named after the Dragon spacecraft), and a terrestrial version called TigerEye. Both products incorporate improvements that resulted from working with NASA to make the camera ready for space—including its compact size, low power, light weight, and enhanced performance and sensitivity.\n      “After we brought the technology to NASA, they helped us develop it for space applications. That refined it for other applications,” says Dr. Roger Stettner, founder and president of ASC.\n      A number of large-and medium-sized aerospace organizations, including SpaceX, Ball Aerospace, and Northrop Grumman, have purchased flash LIDAR cameras from ASC. By 2010, ASC had sold about 100 cameras—not only for potential space use, but for use on Earth as well. 3D flash LIDAR cameras can assist almost any manned or unmanned vehicle with collision avoidance, navigation, or object tracking—through brownout (helicopter-landing-generated dust clouds) conditions, tree leaves, smoke, fog, darkness, or under water. It could also be used for surveillance around the perimeter of a facility or at a border. \n      “The cameras can be the basis for a solution that would give pilots situational awareness, visibility, and the ability to map the terrain while coming in for a landing—in much the same way you would expect of a spacecraft landing on the Moon or Mars,” says Dr. Stettner.\n      One particularly useful application is in cars and trucks. When mounted on an automobile, the technology can show a driver how close or far away things are to assist in avoiding collisions. A monitor on the car would distinguish how far away others cars, bicyclists, or pedestrians are, as well as how fast they are moving. Objects that are closer might appear red in the image while objects that are far away might appear green. According to ASC, the cameras could come standard on high-end automobiles in just 6 to 8 years.\n      In the meantime, NASA continues to fund flash LIDAR technology development efforts through SBIRs and projects such as ALHAT to progress toward a more robust and flight-like sensor configuration with a larger detector array, greater sensitivity, finer range resolution, lower range measurement noise, and flight-qualified electronics and detectors. The objective is an optimal combination of laser power, operational range, and sensor mass and performance for NASA missions.\n      The way Thomas Laux, vice president of business development at ASC, sees it, “There is a future within NASA—and certainly outside of NASA—for this technology.”\n      The DragonEye Space Camera™ and TigerEye 3D Flash LIDAR Camera Kit™ are trademarks of Advanced Scientific Concepts Inc.\n    \n    \n      NASA Technology\n      \n        \n        \n          \n        \n        \n          An artist’s concept depicts NASA’s Phoenix Mars Lander just moments before landing on Mars. NASA is investigating camera technologies to produce 3D images of planetary terrain in real time to reveal landing hazards and to enable accurate navigation for spacecraft like Phoenix.\n        \n      \n      After 10 months of traveling through deep space to Mars, the Phoenix Lander finally approached its destination. The last 7 minutes of the spacecraft’s 423 million-mile-journey—the entry, descent, and landing (EDL) phase—were the most critical and also the most difficult. In the history of Mars landing missions, only 5 of 13 attempts have succeeded. It would have been tragic for Phoenix to go so far yet fail to arrive safely. \n      Landing on the Red Planet is extremely challenging. Tucked inside its aeroshell, Phoenix entered the atmosphere of Mars at a speed of 12,750 miles per hour. After decelerating using atmospheric drag and a parachute, Phoenix discarded its aeroshell in preparation for touchdown in a region characterized only by orbital reconnaissance data. Lacking real-time terrain mapping and hazard-avoidance capabilities, Phoenix faced the potential for serious damage or tip over from landing on a rock or other surface hazard during the final seconds of the mission.\n      To ensure the future success and reliability of such crucial landing missions, NASA is investigating a variety of terrain-sensing technologies, including cameras capable of producing real-time, 3D images of planetary terrain under any lighting conditions to reveal hazards and to enable accurate navigation to a safe landing location. \n      Partnership\n      Advanced Scientific Concepts Inc. (ASC), of Santa Barbara, California, received a Small Business Innovation Research (SBIR) award from the Jet Propulsion Laboratory (JPL) in 2006 to assess the suitability of ASC’s 3D flash light detection and ranging (LIDAR) video camera for EDL applications. With the SBIR funding, ASC tested the technology on simulated Martian landscape at the JPL Mars Yard.\n      “We want the ability to be able to make a real-time map of the hazards as we are landing so we can avoid them. That is what LIDAR is ideally suited for,” says Gary Spiers, supervisor of the Active Optical Sensing Group at JPL.\n      To develop an integrated landing system capable of detecting and avoiding surface hazards and guiding a crewed or robotic lander to a safe and accurate touchdown, NASA chartered the Automated Landing Hazard Avoidance Technology (ALHAT) Project in 2006. The ALHAT team, combining technical expertise from the Johnson Space Center, Langley Research Center, Draper Laboratory, and JPL, identified flash LIDAR technology as a highly promising approach for real-time terrain mapping and hazard detection. ASC subsequently received several SBIR awards and a NASA Research Announcement contract to continue the development and refinement of 3D flash LIDAR technologies. Over the past few years, several combinations of ASC flash LIDAR sensors and related lasers and optical components have been evaluated by NASA personnel in the lab, in the field, and in airborne tests.\n      “The primary reason NASA was interested in the technology was for safe landings. The second priority was for rendezvous and docking at the International Space Station,” says Farzin Amzajerdian, a senior scientist at Langley leading the LIDAR sensor development effort for ALHAT.\n      At Johnson, the Commercial Crew and Cargo Program Office (C3PO) invests resources to stimulate the private sector to develop and demonstrate space transportation capabilities. Under the Commercial Orbital Transportation Services project of this office, Hawthorne, California-based SpaceX is developing its Dragon spacecraft to deliver cargo and supplies to the International Space Station (ISS). Because SpaceX intends to use ASC’s technology to assist with docking at the ISS, the flash LIDAR device flew on both STS-127 and STS-133 for demonstration and evaluation.\n      “The technology is used to determine how you are posed in relation to a target, how far away you are, and how fast you are moving in relation to it,” says Warren P. Ruemmele, assistant project executive for C3PO. “If earlier investments hadn’t been made and successful, it wouldn’t be a candidate for what we are trying to do.”\n      Benefits\n      \n        \n        \n          \n        \n        \n          Advanced Scientific Concepts Inc. refined this 3D flash light detection and ranging video camera through SBIR work with NASA. The space version of the camera can assist vehicles docking at the International Space Station, and the terrestrial version can assist with navigation and collision avoidance here on Earth.\n        \n      \n      ASC’s flash LIDAR sensors use a short pulse of radiation from a near-infrared laser to illuminate a scene in front of the camera lens. Each pixel in the camera detector array measures the round trip time for the photons, which is then converted into an accurate range measurement. Each pulse of the flash LIDAR produces a 3D image consisting of thousands or tens of thousands of points acquired essentially simultaneously, which effectively eliminates motion-induced distortions. \n      A graphical user interface on a computer displays the data in the form of a color-coded range (distance) map. Current ASC flash LIDAR cameras are capable of acquiring 3D images at rates of up to 30 frames per second, which can be viewed as a video and processed for identifying various scene features. In practice, a data processor could autonomously analyze the surrounding environment and execute vehicle maneuvers.\n      Two versions of ASC’s 3D flash LIDAR camera are currently available: the DragonEye Space Camera (named after the Dragon spacecraft), and a terrestrial version called TigerEye. Both products incorporate improvements that resulted from working with NASA to make the camera ready for space—including its compact size, low power, light weight, and enhanced performance and sensitivity.\n      “After we brought the technology to NASA, they helped us develop it for space applications. That refined it for other applications,” says Dr. Roger Stettner, founder and president of ASC.\n      A number of large-and medium-sized aerospace organizations, including SpaceX, Ball Aerospace, and Northrop Grumman, have purchased flash LIDAR cameras from ASC. By 2010, ASC had sold about 100 cameras—not only for potential space use, but for use on Earth as well. 3D flash LIDAR cameras can assist almost any manned or unmanned vehicle with collision avoidance, navigation, or object tracking—through brownout (helicopter-landing-generated dust clouds) conditions, tree leaves, smoke, fog, darkness, or under water. It could also be used for surveillance around the perimeter of a facility or at a border. \n      “The cameras can be the basis for a solution that would give pilots situational awareness, visibility, and the ability to map the terrain while coming in for a landing—in much the same way you would expect of a spacecraft landing on the Moon or Mars,” says Dr. Stettner.\n      One particularly useful application is in cars and trucks. When mounted on an automobile, the technology can show a driver how close or far away things are to assist in avoiding collisions. A monitor on the car would distinguish how far away others cars, bicyclists, or pedestrians are, as well as how fast they are moving. Objects that are closer might appear red in the image while objects that are far away might appear green. According to ASC, the cameras could come standard on high-end automobiles in just 6 to 8 years.\n      In the meantime, NASA continues to fund flash LIDAR technology development efforts through SBIRs and projects such as ALHAT to progress toward a more robust and flight-like sensor configuration with a larger detector array, greater sensitivity, finer range resolution, lower range measurement noise, and flight-qualified electronics and detectors. The objective is an optimal combination of laser power, operational range, and sensor mass and performance for NASA missions.\n      The way Thomas Laux, vice president of business development at ASC, sees it, “There is a future within NASA—and certainly outside of NASA—for this technology.”\n      The DragonEye Space Camera™ and TigerEye 3D Flash LIDAR Camera Kit™ are trademarks of Advanced Scientific Concepts Inc.\n    "},{"href":"http://spinoff.nasa.gov/Spinoff2011/t_2.html","text":"Integrated Design Tools Reduce Risk, Cost","image":"http://spinoff.nasa.gov/Spinoff2011/Images/t_3_opt.jpg","story":"\n    \n      \n        NASA Technology\n        \n          \n          \n            \n          \n          \n            NASA’s Fundamental Aeronautics Program (FAP) assesses concepts and technologies for a range of air vehicles, including the subsonic fixed wing aircraft in this artist’s rendering.\n                              \n              Image courtesy of Massachusetts Institute of Technology\n          \n        \n        As NASA designs new spacecraft for its science missions and begins designs for the next generation of human spaceflight vehicles, it also works to revolutionize Earth’s airspace with safer, more efficient air vehicles. Throughout its research and development activities, NASA employs the best design tools available. \n        Some of the tools focus on analyzing the strength of composite structures and new materials; while some experiment with size and shape configurations and their effect on performance; still others analyze propulsion systems, airflow, noise signatures, or fuel consumption. Many of the tools are commercial products, and others were developed by NASA. Each provides high-level analysis of complex systems to provide designers with key information for decision making. \n        A dilemma, however, is that the programs are not designed to communicate with each other. NASA, therefore, entered into multiple research partnerships with an industry leader to develop a program that could serve as a framework for various design inputs, allowing designers to save time while optimizing designs. The resulting toolset met both NASA and industry needs by enabling greater use of physics-based simulation models earlier in the design process. It ties together existing tools and simulates one complex system. \n        Partnership\n        Phoenix Integration Inc., based in Wayne, Pennsylvania, is a leader in the design process optimization software market. Even though it is a small business, the company has had a big impact on the aerospace engineering community. Client users include nearly all of the top aerospace companies such as Boeing, ATK, Airbus, Northrop Grumman, Pratt & Whitney, Lockheed Martin, and Raytheon, as well as nonaerospace clients such as Kawasaki, Samsung, General Electric, and Ford. The company’s software is also being used at NASA and other government agencies. \n        Despite its many industry and government partnerships, the company is quick to note that one of the most important has been with the Federal Small Business Innovation Research (SBIR) program. Through SBIRs, Phoenix Integration modified and advanced its PHX ModelCenter software, a graphical environment for process integration and design automation. ModelCenter provides a framework for integrating multiple design elements into one useable platform, speeding design time and increasing the number of design options. As a robust design and analysis framework, PHX ModelCenter can be used in the early stages of next-generation vehicle design. \n        The original NASA SBIR contract work involved development of a Multi-Disciplinary Multi-Fidelity Design Environment. Conducted through NASA’s Langley Research Center, the project built upon SBIR work that Phoenix Integration had completed with the U.S. Navy in 1997. The results were enhancements to PHX ModelCenter that, in combination with existing tools such as PHX CAD-Fusion, resulted in a robust design and analysis framework. \n        The technologies created were incorporated into the company’s commercial software, increasing the capabilities of its PHX ModelCenter program. In January 2009, a new geometry rendering capability was incorporated into ModelCenter 8.0. A year later, additional technology was added to ModelCenter 9.0 to allow engineers to more easily integrate high-fidelity simulation tools into the ModelCenter environment and to create a multi-disciplinary, multi-fidelity system model. \n        Benefits \n        \n          \n          \n            \n          \n          \n            Software from Phoenix Integration Inc. was advanced through an SBIR with Langley Research Center. By enabling process integration, the tool allows engineers to spend more time on engineering design and less time on software programming.\n          \n        \n        For NASA, the tool has resulted in lower project costs and reductions in design time; clients of Phoenix Integration are experiencing the same rewards. Because of the existing customer base for previous versions, the new product was rapidly commercialized when it was included in Phoenix Integration’s core software.\n        PHX ModelCenter allows engineers to spend more time on engineering design and less time on software programming. It does this by enabling process integration for conceptual modeling in engineering design.\n        According to Scott Ragon, director of research at Phoenix Integration, “Given a fixed amount of time, designers can consider a greater number of alternatives.” With ModelCenter automating the execution of a variety of systems, designers can more efficiently meet design requirements, which translate into a time savings, or they can review more design options in the same amount of time, which allows designers to experiment with a greater number of possibilities, perhaps finding a better solution to a problem. As Ragon explains, the program will either provide “better design results in the same time, or the same results in less time.” \n        Ragon notes, however, that ModelCenter does not automate the design process. Qualified engineers still make the final design decision; the framework simply makes them more efficient at the process. \n        The Jet Propulsion Laboratory will be employing ModelCenter to design new space architecture concepts, and engineers at Ames Research Center’s Systems Analysis Branch have taken advantage of the design tool in their quest to improve aircraft safety and efficiency, minimize the environmental impact of aviation, and increase the competitiveness of the U.S. aviation industry. \n        Primarily, teams at Langley are using the software as part of the NASA Fundamental Aeronautics Program (FAP), which is assessing concepts and technologies for a wide range of air vehicles. One focus of FAP is design and testing of new subsonic fixed wing aircraft that would lower noise and emissions while increasing performance. Langley engineers will realize reduced risks and cost by using ModelCenter’s physics-based models early in the design process. \n        Langley’s Mark Guynn, who worked on this project, says, “The workflow process capability developed under this SBIR and commercialized in ModelCenter 9.0 was instrumental in the Subsonic Fixed Wing Project, meeting a major project milestone this year.”\n        Today, over 1,000 engineers in over 100 different locations can use the SBIR-funded technology, which will allow NASA and industry to design innovations from next-generation air vehicles to consumer electronics.\n        ModelCenter® is a registered trademark of Phoenix Integration Inc.\n      \n      \n    \n      \n        NASA Technology\n        \n          \n          \n            \n          \n          \n            NASA’s Fundamental Aeronautics Program (FAP) assesses concepts and technologies for a range of air vehicles, including the subsonic fixed wing aircraft in this artist’s rendering.\n                              \n              Image courtesy of Massachusetts Institute of Technology\n          \n        \n        As NASA designs new spacecraft for its science missions and begins designs for the next generation of human spaceflight vehicles, it also works to revolutionize Earth’s airspace with safer, more efficient air vehicles. Throughout its research and development activities, NASA employs the best design tools available. \n        Some of the tools focus on analyzing the strength of composite structures and new materials; while some experiment with size and shape configurations and their effect on performance; still others analyze propulsion systems, airflow, noise signatures, or fuel consumption. Many of the tools are commercial products, and others were developed by NASA. Each provides high-level analysis of complex systems to provide designers with key information for decision making. \n        A dilemma, however, is that the programs are not designed to communicate with each other. NASA, therefore, entered into multiple research partnerships with an industry leader to develop a program that could serve as a framework for various design inputs, allowing designers to save time while optimizing designs. The resulting toolset met both NASA and industry needs by enabling greater use of physics-based simulation models earlier in the design process. It ties together existing tools and simulates one complex system. \n        Partnership\n        Phoenix Integration Inc., based in Wayne, Pennsylvania, is a leader in the design process optimization software market. Even though it is a small business, the company has had a big impact on the aerospace engineering community. Client users include nearly all of the top aerospace companies such as Boeing, ATK, Airbus, Northrop Grumman, Pratt & Whitney, Lockheed Martin, and Raytheon, as well as nonaerospace clients such as Kawasaki, Samsung, General Electric, and Ford. The company’s software is also being used at NASA and other government agencies. \n        Despite its many industry and government partnerships, the company is quick to note that one of the most important has been with the Federal Small Business Innovation Research (SBIR) program. Through SBIRs, Phoenix Integration modified and advanced its PHX ModelCenter software, a graphical environment for process integration and design automation. ModelCenter provides a framework for integrating multiple design elements into one useable platform, speeding design time and increasing the number of design options. As a robust design and analysis framework, PHX ModelCenter can be used in the early stages of next-generation vehicle design. \n        The original NASA SBIR contract work involved development of a Multi-Disciplinary Multi-Fidelity Design Environment. Conducted through NASA’s Langley Research Center, the project built upon SBIR work that Phoenix Integration had completed with the U.S. Navy in 1997. The results were enhancements to PHX ModelCenter that, in combination with existing tools such as PHX CAD-Fusion, resulted in a robust design and analysis framework. \n        The technologies created were incorporated into the company’s commercial software, increasing the capabilities of its PHX ModelCenter program. In January 2009, a new geometry rendering capability was incorporated into ModelCenter 8.0. A year later, additional technology was added to ModelCenter 9.0 to allow engineers to more easily integrate high-fidelity simulation tools into the ModelCenter environment and to create a multi-disciplinary, multi-fidelity system model. \n        Benefits \n        \n          \n          \n            \n          \n          \n            Software from Phoenix Integration Inc. was advanced through an SBIR with Langley Research Center. By enabling process integration, the tool allows engineers to spend more time on engineering design and less time on software programming.\n          \n        \n        For NASA, the tool has resulted in lower project costs and reductions in design time; clients of Phoenix Integration are experiencing the same rewards. Because of the existing customer base for previous versions, the new product was rapidly commercialized when it was included in Phoenix Integration’s core software.\n        PHX ModelCenter allows engineers to spend more time on engineering design and less time on software programming. It does this by enabling process integration for conceptual modeling in engineering design.\n        According to Scott Ragon, director of research at Phoenix Integration, “Given a fixed amount of time, designers can consider a greater number of alternatives.” With ModelCenter automating the execution of a variety of systems, designers can more efficiently meet design requirements, which translate into a time savings, or they can review more design options in the same amount of time, which allows designers to experiment with a greater number of possibilities, perhaps finding a better solution to a problem. As Ragon explains, the program will either provide “better design results in the same time, or the same results in less time.” \n        Ragon notes, however, that ModelCenter does not automate the design process. Qualified engineers still make the final design decision; the framework simply makes them more efficient at the process. \n        The Jet Propulsion Laboratory will be employing ModelCenter to design new space architecture concepts, and engineers at Ames Research Center’s Systems Analysis Branch have taken advantage of the design tool in their quest to improve aircraft safety and efficiency, minimize the environmental impact of aviation, and increase the competitiveness of the U.S. aviation industry. \n        Primarily, teams at Langley are using the software as part of the NASA Fundamental Aeronautics Program (FAP), which is assessing concepts and technologies for a wide range of air vehicles. One focus of FAP is design and testing of new subsonic fixed wing aircraft that would lower noise and emissions while increasing performance. Langley engineers will realize reduced risks and cost by using ModelCenter’s physics-based models early in the design process. \n        Langley’s Mark Guynn, who worked on this project, says, “The workflow process capability developed under this SBIR and commercialized in ModelCenter 9.0 was instrumental in the Subsonic Fixed Wing Project, meeting a major project milestone this year.”\n        Today, over 1,000 engineers in over 100 different locations can use the SBIR-funded technology, which will allow NASA and industry to design innovations from next-generation air vehicles to consumer electronics.\n        ModelCenter® is a registered trademark of Phoenix Integration Inc.\n      \n      \n        NASA Technology\n        \n          \n          \n            \n          \n          \n            NASA’s Fundamental Aeronautics Program (FAP) assesses concepts and technologies for a range of air vehicles, including the subsonic fixed wing aircraft in this artist’s rendering.\n                              \n              Image courtesy of Massachusetts Institute of Technology\n          \n        \n        As NASA designs new spacecraft for its science missions and begins designs for the next generation of human spaceflight vehicles, it also works to revolutionize Earth’s airspace with safer, more efficient air vehicles. Throughout its research and development activities, NASA employs the best design tools available. \n        Some of the tools focus on analyzing the strength of composite structures and new materials; while some experiment with size and shape configurations and their effect on performance; still others analyze propulsion systems, airflow, noise signatures, or fuel consumption. Many of the tools are commercial products, and others were developed by NASA. Each provides high-level analysis of complex systems to provide designers with key information for decision making. \n        A dilemma, however, is that the programs are not designed to communicate with each other. NASA, therefore, entered into multiple research partnerships with an industry leader to develop a program that could serve as a framework for various design inputs, allowing designers to save time while optimizing designs. The resulting toolset met both NASA and industry needs by enabling greater use of physics-based simulation models earlier in the design process. It ties together existing tools and simulates one complex system. \n        Partnership\n        Phoenix Integration Inc., based in Wayne, Pennsylvania, is a leader in the design process optimization software market. Even though it is a small business, the company has had a big impact on the aerospace engineering community. Client users include nearly all of the top aerospace companies such as Boeing, ATK, Airbus, Northrop Grumman, Pratt & Whitney, Lockheed Martin, and Raytheon, as well as nonaerospace clients such as Kawasaki, Samsung, General Electric, and Ford. The company’s software is also being used at NASA and other government agencies. \n        Despite its many industry and government partnerships, the company is quick to note that one of the most important has been with the Federal Small Business Innovation Research (SBIR) program. Through SBIRs, Phoenix Integration modified and advanced its PHX ModelCenter software, a graphical environment for process integration and design automation. ModelCenter provides a framework for integrating multiple design elements into one useable platform, speeding design time and increasing the number of design options. As a robust design and analysis framework, PHX ModelCenter can be used in the early stages of next-generation vehicle design. \n        The original NASA SBIR contract work involved development of a Multi-Disciplinary Multi-Fidelity Design Environment. Conducted through NASA’s Langley Research Center, the project built upon SBIR work that Phoenix Integration had completed with the U.S. Navy in 1997. The results were enhancements to PHX ModelCenter that, in combination with existing tools such as PHX CAD-Fusion, resulted in a robust design and analysis framework. \n        The technologies created were incorporated into the company’s commercial software, increasing the capabilities of its PHX ModelCenter program. In January 2009, a new geometry rendering capability was incorporated into ModelCenter 8.0. A year later, additional technology was added to ModelCenter 9.0 to allow engineers to more easily integrate high-fidelity simulation tools into the ModelCenter environment and to create a multi-disciplinary, multi-fidelity system model. \n        Benefits \n        \n          \n          \n            \n          \n          \n            Software from Phoenix Integration Inc. was advanced through an SBIR with Langley Research Center. By enabling process integration, the tool allows engineers to spend more time on engineering design and less time on software programming.\n          \n        \n        For NASA, the tool has resulted in lower project costs and reductions in design time; clients of Phoenix Integration are experiencing the same rewards. Because of the existing customer base for previous versions, the new product was rapidly commercialized when it was included in Phoenix Integration’s core software.\n        PHX ModelCenter allows engineers to spend more time on engineering design and less time on software programming. It does this by enabling process integration for conceptual modeling in engineering design.\n        According to Scott Ragon, director of research at Phoenix Integration, “Given a fixed amount of time, designers can consider a greater number of alternatives.” With ModelCenter automating the execution of a variety of systems, designers can more efficiently meet design requirements, which translate into a time savings, or they can review more design options in the same amount of time, which allows designers to experiment with a greater number of possibilities, perhaps finding a better solution to a problem. As Ragon explains, the program will either provide “better design results in the same time, or the same results in less time.” \n        Ragon notes, however, that ModelCenter does not automate the design process. Qualified engineers still make the final design decision; the framework simply makes them more efficient at the process. \n        The Jet Propulsion Laboratory will be employing ModelCenter to design new space architecture concepts, and engineers at Ames Research Center’s Systems Analysis Branch have taken advantage of the design tool in their quest to improve aircraft safety and efficiency, minimize the environmental impact of aviation, and increase the competitiveness of the U.S. aviation industry. \n        Primarily, teams at Langley are using the software as part of the NASA Fundamental Aeronautics Program (FAP), which is assessing concepts and technologies for a wide range of air vehicles. One focus of FAP is design and testing of new subsonic fixed wing aircraft that would lower noise and emissions while increasing performance. Langley engineers will realize reduced risks and cost by using ModelCenter’s physics-based models early in the design process. \n        Langley’s Mark Guynn, who worked on this project, says, “The workflow process capability developed under this SBIR and commercialized in ModelCenter 9.0 was instrumental in the Subsonic Fixed Wing Project, meeting a major project milestone this year.”\n        Today, over 1,000 engineers in over 100 different locations can use the SBIR-funded technology, which will allow NASA and industry to design innovations from next-generation air vehicles to consumer electronics.\n        ModelCenter® is a registered trademark of Phoenix Integration Inc.\n      "},{"href":"http://spinoff.nasa.gov/Spinoff2011/t_3.html","text":"Advisory Systems Save Time, Fuel for Airlines ","image":"http://spinoff.nasa.gov/Spinoff2011/Images/t_6a_opt.jpg","story":"\n    \n      \n        \n          NASA Technology\n          \n            \n            \n              \n            \n            \n              In the 1990s, scientists at Ames Research Center devised a software algorithm to shorten the routes airlines fly between take-off and landing. That technology is now commercially available from Boeing.\n            \n          \n          Heinz Erzberger never thought the sky was falling, but he knew it could benefit from enhanced traffic control. Throughout the 1990s, Erzberger led a team at Ames Research Center to develop a suite of automated tools to reduce restrictions and improve the efficiency of air traffic control operations. Called CTAS, or Center-TRACON (Terminal Radar Approach Control) Automation System, the software won NASA’s Software of the Year award in 1998, and one of the tools in the suite—the traffic management advisor—was adopted by the Federal Aviation Administration and implemented at traffic control centers across the United States. Another one of the tools, Direct-To, has followed a different path. \n          The idea behind Direct-To, explains Erzberger, a senior scientist at Ames, was that airlines could save fuel and money by shortening the routes they flew between take-off and landing. Aircraft are often limited to following established airways comprised of inefficient route segments. The routes are not easily adjusted because neither the pilot nor the aircraft controller can anticipate the constantly changing air traffic situation. To make the routes more direct while in flight, Erzberger came up with an idea for a software algorithm that could automatically examine air traffic in real-time, check to see if a shortcut was available, and then check for conflicts. If there were no conflicts and the shortcut saved more than 1 minute of flight time, the controller could be notified.\n           “I was trying to figure out what goes on in the pilot and controller’s minds when they decide to guide the aircraft in a certain way. That resulted in a different kind analysis,” Erzberger says. \n          As the engineer’s idea went from theory to practice, in 2001, NASA demonstrated Direct-To in the airspace of Dallas-Ft. Worth. Estimations based on the demonstration found the technology was capable of saving 900 flying minutes per day for the aircraft in the test area.\n          “Direct Routes is an ideal application \n            of government investment plus some industry innovation. \n            The result is real savings \n            to airlines, passengers, and \n            \n            the environment.”\n            —Michael Lewis, Boeing          \n          Partnership\n          Interested in building upon Erzberger’s work, Michael Lewis, director of Boeing Commercial Airplanes’ Airline Efficiency Services based in Seattle, met with Erzberger and others at Ames Research Center to discuss Direct-To. Boeing was optimistic about transitioning Direct-To into a product that was practical for airlines to use.\n          “With the right set of data input, we thought it should be possible to deliver fuel and flight time savings advisories to airplanes while they were in flight,” says Lewis. “We thought the NASA software would be a great jumpstart.” \n          After the groups shared information, Boeing and NASA signed a Space Act Agreement. Soon after, Boeing licensed the technology and developed new software code on top of the core algorithms in the NASA tool. To test and confirm that the technology was practical for airlines to use, Boeing conducted trials with Southwest Airlines and Continental Airlines in 2008 and 2009.\n          “The trials confirmed our ability to run a significant amount of Boeing software, and ensured the advisories that we were sending worked properly,” says Lewis. “The main result was that the operational concept really worked.”\n          By 2010, Boeing had incorporated the technology into a subscription-based product called Direct Routes. Commercially available from 2011 as part of \n            the company’s InFlight Optimization Services, Direct Routes provides real-time advisories to aircraft for suggested shortcuts that are prechecked for traffic conflicts, wind conditions, established airspace constraints, and other factors. \n          Benefits\n          According to Boeing, Direct Routes can save tens of thousands of flight minutes per year for a medium-sized U.S. operator. In total, Lewis estimates the technology could save 20 million gallons of fuel per year for commercial airlines—the equivalent of approximately 50 million dollars per year. These fuel savings also translate into a direct reduction of thousands of tons of carbon emissions each year. \n          \n            \n            \n              \n            \n            \n              Boeing Commercial Airplanes incorporated Benefits into its Direct Routes service to monitor flights in real time and check for time savings. In this example, a flight saved 1.3 minutes by diverting from its original route to fly a more direct route.\n            \n          \n          Direct Routes continuously monitors flights in real time to check for traffic control system variables, the aircraft’s current flight trajectory, air traffic control acceptability, weather conditions, and other factors. When there are small course adjustments along an airplane’s intended route that can reduce at least 1 minute of flight time, the pilot is notified with a message much like a text message on a cell phone. The pilot can then make a verbal request to the controller who can approve the new route.\n          “There are thousands of opportunities every day in the system that are currently left unrealized because neither the pilot nor controller is actively looking for them,” says Lewis. \n            “Neither pilot nor controller has the full set of information. Direct Routes can automatically look at it all and insert the advisory within the normal operating procedure.”\n          The advisories made by Direct Routes are transmitted using existing communication channels and are designed to comply with current operating procedures. There are also no regulatory changes and minimal new equipment required. “There’s a small amount of start-up and readiness preparation, but no capital investment on the part of the airlines. In general, if an airline starts the service, it starts seeing fuel savings immediately,” says Lewis.\n          Direct Routes is currently available as a subscription service. Potential customers including aircraft flying in U.S. airspace such as commercial airlines, business aviation, military, general aviation, and international flights—many of which are already in discussion with Boeing about Direct Routes. “They all have opportunities to take shorter routes,” says Lewis. “Direct Routes is an ideal application of government investment plus some industry innovation. The result is real savings to airlines, passengers, and the environment.”\n        \n        \n      \n    \n      \n        \n          NASA Technology\n          \n            \n            \n              \n            \n            \n              In the 1990s, scientists at Ames Research Center devised a software algorithm to shorten the routes airlines fly between take-off and landing. That technology is now commercially available from Boeing.\n            \n          \n          Heinz Erzberger never thought the sky was falling, but he knew it could benefit from enhanced traffic control. Throughout the 1990s, Erzberger led a team at Ames Research Center to develop a suite of automated tools to reduce restrictions and improve the efficiency of air traffic control operations. Called CTAS, or Center-TRACON (Terminal Radar Approach Control) Automation System, the software won NASA’s Software of the Year award in 1998, and one of the tools in the suite—the traffic management advisor—was adopted by the Federal Aviation Administration and implemented at traffic control centers across the United States. Another one of the tools, Direct-To, has followed a different path. \n          The idea behind Direct-To, explains Erzberger, a senior scientist at Ames, was that airlines could save fuel and money by shortening the routes they flew between take-off and landing. Aircraft are often limited to following established airways comprised of inefficient route segments. The routes are not easily adjusted because neither the pilot nor the aircraft controller can anticipate the constantly changing air traffic situation. To make the routes more direct while in flight, Erzberger came up with an idea for a software algorithm that could automatically examine air traffic in real-time, check to see if a shortcut was available, and then check for conflicts. If there were no conflicts and the shortcut saved more than 1 minute of flight time, the controller could be notified.\n           “I was trying to figure out what goes on in the pilot and controller’s minds when they decide to guide the aircraft in a certain way. That resulted in a different kind analysis,” Erzberger says. \n          As the engineer’s idea went from theory to practice, in 2001, NASA demonstrated Direct-To in the airspace of Dallas-Ft. Worth. Estimations based on the demonstration found the technology was capable of saving 900 flying minutes per day for the aircraft in the test area.\n          “Direct Routes is an ideal application \n            of government investment plus some industry innovation. \n            The result is real savings \n            to airlines, passengers, and \n            \n            the environment.”\n            —Michael Lewis, Boeing          \n          Partnership\n          Interested in building upon Erzberger’s work, Michael Lewis, director of Boeing Commercial Airplanes’ Airline Efficiency Services based in Seattle, met with Erzberger and others at Ames Research Center to discuss Direct-To. Boeing was optimistic about transitioning Direct-To into a product that was practical for airlines to use.\n          “With the right set of data input, we thought it should be possible to deliver fuel and flight time savings advisories to airplanes while they were in flight,” says Lewis. “We thought the NASA software would be a great jumpstart.” \n          After the groups shared information, Boeing and NASA signed a Space Act Agreement. Soon after, Boeing licensed the technology and developed new software code on top of the core algorithms in the NASA tool. To test and confirm that the technology was practical for airlines to use, Boeing conducted trials with Southwest Airlines and Continental Airlines in 2008 and 2009.\n          “The trials confirmed our ability to run a significant amount of Boeing software, and ensured the advisories that we were sending worked properly,” says Lewis. “The main result was that the operational concept really worked.”\n          By 2010, Boeing had incorporated the technology into a subscription-based product called Direct Routes. Commercially available from 2011 as part of \n            the company’s InFlight Optimization Services, Direct Routes provides real-time advisories to aircraft for suggested shortcuts that are prechecked for traffic conflicts, wind conditions, established airspace constraints, and other factors. \n          Benefits\n          According to Boeing, Direct Routes can save tens of thousands of flight minutes per year for a medium-sized U.S. operator. In total, Lewis estimates the technology could save 20 million gallons of fuel per year for commercial airlines—the equivalent of approximately 50 million dollars per year. These fuel savings also translate into a direct reduction of thousands of tons of carbon emissions each year. \n          \n            \n            \n              \n            \n            \n              Boeing Commercial Airplanes incorporated Benefits into its Direct Routes service to monitor flights in real time and check for time savings. In this example, a flight saved 1.3 minutes by diverting from its original route to fly a more direct route.\n            \n          \n          Direct Routes continuously monitors flights in real time to check for traffic control system variables, the aircraft’s current flight trajectory, air traffic control acceptability, weather conditions, and other factors. When there are small course adjustments along an airplane’s intended route that can reduce at least 1 minute of flight time, the pilot is notified with a message much like a text message on a cell phone. The pilot can then make a verbal request to the controller who can approve the new route.\n          “There are thousands of opportunities every day in the system that are currently left unrealized because neither the pilot nor controller is actively looking for them,” says Lewis. \n            “Neither pilot nor controller has the full set of information. Direct Routes can automatically look at it all and insert the advisory within the normal operating procedure.”\n          The advisories made by Direct Routes are transmitted using existing communication channels and are designed to comply with current operating procedures. There are also no regulatory changes and minimal new equipment required. “There’s a small amount of start-up and readiness preparation, but no capital investment on the part of the airlines. In general, if an airline starts the service, it starts seeing fuel savings immediately,” says Lewis.\n          Direct Routes is currently available as a subscription service. Potential customers including aircraft flying in U.S. airspace such as commercial airlines, business aviation, military, general aviation, and international flights—many of which are already in discussion with Boeing about Direct Routes. “They all have opportunities to take shorter routes,” says Lewis. “Direct Routes is an ideal application of government investment plus some industry innovation. The result is real savings to airlines, passengers, and the environment.”\n        \n        \n      \n        \n          NASA Technology\n          \n            \n            \n              \n            \n            \n              In the 1990s, scientists at Ames Research Center devised a software algorithm to shorten the routes airlines fly between take-off and landing. That technology is now commercially available from Boeing.\n            \n          \n          Heinz Erzberger never thought the sky was falling, but he knew it could benefit from enhanced traffic control. Throughout the 1990s, Erzberger led a team at Ames Research Center to develop a suite of automated tools to reduce restrictions and improve the efficiency of air traffic control operations. Called CTAS, or Center-TRACON (Terminal Radar Approach Control) Automation System, the software won NASA’s Software of the Year award in 1998, and one of the tools in the suite—the traffic management advisor—was adopted by the Federal Aviation Administration and implemented at traffic control centers across the United States. Another one of the tools, Direct-To, has followed a different path. \n          The idea behind Direct-To, explains Erzberger, a senior scientist at Ames, was that airlines could save fuel and money by shortening the routes they flew between take-off and landing. Aircraft are often limited to following established airways comprised of inefficient route segments. The routes are not easily adjusted because neither the pilot nor the aircraft controller can anticipate the constantly changing air traffic situation. To make the routes more direct while in flight, Erzberger came up with an idea for a software algorithm that could automatically examine air traffic in real-time, check to see if a shortcut was available, and then check for conflicts. If there were no conflicts and the shortcut saved more than 1 minute of flight time, the controller could be notified.\n           “I was trying to figure out what goes on in the pilot and controller’s minds when they decide to guide the aircraft in a certain way. That resulted in a different kind analysis,” Erzberger says. \n          As the engineer’s idea went from theory to practice, in 2001, NASA demonstrated Direct-To in the airspace of Dallas-Ft. Worth. Estimations based on the demonstration found the technology was capable of saving 900 flying minutes per day for the aircraft in the test area.\n          “Direct Routes is an ideal application \n            of government investment plus some industry innovation. \n            The result is real savings \n            to airlines, passengers, and \n            \n            the environment.”\n            —Michael Lewis, Boeing          \n          Partnership\n          Interested in building upon Erzberger’s work, Michael Lewis, director of Boeing Commercial Airplanes’ Airline Efficiency Services based in Seattle, met with Erzberger and others at Ames Research Center to discuss Direct-To. Boeing was optimistic about transitioning Direct-To into a product that was practical for airlines to use.\n          “With the right set of data input, we thought it should be possible to deliver fuel and flight time savings advisories to airplanes while they were in flight,” says Lewis. “We thought the NASA software would be a great jumpstart.” \n          After the groups shared information, Boeing and NASA signed a Space Act Agreement. Soon after, Boeing licensed the technology and developed new software code on top of the core algorithms in the NASA tool. To test and confirm that the technology was practical for airlines to use, Boeing conducted trials with Southwest Airlines and Continental Airlines in 2008 and 2009.\n          “The trials confirmed our ability to run a significant amount of Boeing software, and ensured the advisories that we were sending worked properly,” says Lewis. “The main result was that the operational concept really worked.”\n          By 2010, Boeing had incorporated the technology into a subscription-based product called Direct Routes. Commercially available from 2011 as part of \n            the company’s InFlight Optimization Services, Direct Routes provides real-time advisories to aircraft for suggested shortcuts that are prechecked for traffic conflicts, wind conditions, established airspace constraints, and other factors. \n          Benefits\n          According to Boeing, Direct Routes can save tens of thousands of flight minutes per year for a medium-sized U.S. operator. In total, Lewis estimates the technology could save 20 million gallons of fuel per year for commercial airlines—the equivalent of approximately 50 million dollars per year. These fuel savings also translate into a direct reduction of thousands of tons of carbon emissions each year. \n          \n            \n            \n              \n            \n            \n              Boeing Commercial Airplanes incorporated Benefits into its Direct Routes service to monitor flights in real time and check for time savings. In this example, a flight saved 1.3 minutes by diverting from its original route to fly a more direct route.\n            \n          \n          Direct Routes continuously monitors flights in real time to check for traffic control system variables, the aircraft’s current flight trajectory, air traffic control acceptability, weather conditions, and other factors. When there are small course adjustments along an airplane’s intended route that can reduce at least 1 minute of flight time, the pilot is notified with a message much like a text message on a cell phone. The pilot can then make a verbal request to the controller who can approve the new route.\n          “There are thousands of opportunities every day in the system that are currently left unrealized because neither the pilot nor controller is actively looking for them,” says Lewis. \n            “Neither pilot nor controller has the full set of information. Direct Routes can automatically look at it all and insert the advisory within the normal operating procedure.”\n          The advisories made by Direct Routes are transmitted using existing communication channels and are designed to comply with current operating procedures. There are also no regulatory changes and minimal new equipment required. “There’s a small amount of start-up and readiness preparation, but no capital investment on the part of the airlines. In general, if an airline starts the service, it starts seeing fuel savings immediately,” says Lewis.\n          Direct Routes is currently available as a subscription service. Potential customers including aircraft flying in U.S. airspace such as commercial airlines, business aviation, military, general aviation, and international flights—many of which are already in discussion with Boeing about Direct Routes. “They all have opportunities to take shorter routes,” says Lewis. “Direct Routes is an ideal application of government investment plus some industry innovation. The result is real savings to airlines, passengers, and the environment.”\n        \n        \n          NASA Technology\n          \n            \n            \n              \n            \n            \n              In the 1990s, scientists at Ames Research Center devised a software algorithm to shorten the routes airlines fly between take-off and landing. That technology is now commercially available from Boeing.\n            \n          \n          Heinz Erzberger never thought the sky was falling, but he knew it could benefit from enhanced traffic control. Throughout the 1990s, Erzberger led a team at Ames Research Center to develop a suite of automated tools to reduce restrictions and improve the efficiency of air traffic control operations. Called CTAS, or Center-TRACON (Terminal Radar Approach Control) Automation System, the software won NASA’s Software of the Year award in 1998, and one of the tools in the suite—the traffic management advisor—was adopted by the Federal Aviation Administration and implemented at traffic control centers across the United States. Another one of the tools, Direct-To, has followed a different path. \n          The idea behind Direct-To, explains Erzberger, a senior scientist at Ames, was that airlines could save fuel and money by shortening the routes they flew between take-off and landing. Aircraft are often limited to following established airways comprised of inefficient route segments. The routes are not easily adjusted because neither the pilot nor the aircraft controller can anticipate the constantly changing air traffic situation. To make the routes more direct while in flight, Erzberger came up with an idea for a software algorithm that could automatically examine air traffic in real-time, check to see if a shortcut was available, and then check for conflicts. If there were no conflicts and the shortcut saved more than 1 minute of flight time, the controller could be notified.\n           “I was trying to figure out what goes on in the pilot and controller’s minds when they decide to guide the aircraft in a certain way. That resulted in a different kind analysis,” Erzberger says. \n          As the engineer’s idea went from theory to practice, in 2001, NASA demonstrated Direct-To in the airspace of Dallas-Ft. Worth. Estimations based on the demonstration found the technology was capable of saving 900 flying minutes per day for the aircraft in the test area.\n          “Direct Routes is an ideal application \n            of government investment plus some industry innovation. \n            The result is real savings \n            to airlines, passengers, and \n            \n            the environment.”\n            —Michael Lewis, Boeing          \n          Partnership\n          Interested in building upon Erzberger’s work, Michael Lewis, director of Boeing Commercial Airplanes’ Airline Efficiency Services based in Seattle, met with Erzberger and others at Ames Research Center to discuss Direct-To. Boeing was optimistic about transitioning Direct-To into a product that was practical for airlines to use.\n          “With the right set of data input, we thought it should be possible to deliver fuel and flight time savings advisories to airplanes while they were in flight,” says Lewis. “We thought the NASA software would be a great jumpstart.” \n          After the groups shared information, Boeing and NASA signed a Space Act Agreement. Soon after, Boeing licensed the technology and developed new software code on top of the core algorithms in the NASA tool. To test and confirm that the technology was practical for airlines to use, Boeing conducted trials with Southwest Airlines and Continental Airlines in 2008 and 2009.\n          “The trials confirmed our ability to run a significant amount of Boeing software, and ensured the advisories that we were sending worked properly,” says Lewis. “The main result was that the operational concept really worked.”\n          By 2010, Boeing had incorporated the technology into a subscription-based product called Direct Routes. Commercially available from 2011 as part of \n            the company’s InFlight Optimization Services, Direct Routes provides real-time advisories to aircraft for suggested shortcuts that are prechecked for traffic conflicts, wind conditions, established airspace constraints, and other factors. \n          Benefits\n          According to Boeing, Direct Routes can save tens of thousands of flight minutes per year for a medium-sized U.S. operator. In total, Lewis estimates the technology could save 20 million gallons of fuel per year for commercial airlines—the equivalent of approximately 50 million dollars per year. These fuel savings also translate into a direct reduction of thousands of tons of carbon emissions each year. \n          \n            \n            \n              \n            \n            \n              Boeing Commercial Airplanes incorporated Benefits into its Direct Routes service to monitor flights in real time and check for time savings. In this example, a flight saved 1.3 minutes by diverting from its original route to fly a more direct route.\n            \n          \n          Direct Routes continuously monitors flights in real time to check for traffic control system variables, the aircraft’s current flight trajectory, air traffic control acceptability, weather conditions, and other factors. When there are small course adjustments along an airplane’s intended route that can reduce at least 1 minute of flight time, the pilot is notified with a message much like a text message on a cell phone. The pilot can then make a verbal request to the controller who can approve the new route.\n          “There are thousands of opportunities every day in the system that are currently left unrealized because neither the pilot nor controller is actively looking for them,” says Lewis. \n            “Neither pilot nor controller has the full set of information. Direct Routes can automatically look at it all and insert the advisory within the normal operating procedure.”\n          The advisories made by Direct Routes are transmitted using existing communication channels and are designed to comply with current operating procedures. There are also no regulatory changes and minimal new equipment required. “There’s a small amount of start-up and readiness preparation, but no capital investment on the part of the airlines. In general, if an airline starts the service, it starts seeing fuel savings immediately,” says Lewis.\n          Direct Routes is currently available as a subscription service. Potential customers including aircraft flying in U.S. airspace such as commercial airlines, business aviation, military, general aviation, and international flights—many of which are already in discussion with Boeing about Direct Routes. “They all have opportunities to take shorter routes,” says Lewis. “Direct Routes is an ideal application of government investment plus some industry innovation. The result is real savings to airlines, passengers, and the environment.”\n        "},{"href":"http://spinoff.nasa.gov/Spinoff2011/t_4.html","text":"Modeling Programs Increase Aircraft \n                Design Safety","image":"http://spinoff.nasa.gov/Spinoff2011/Images/t_12_opt.jpg","story":"\n    \n      \n        \n          \n            NASA Technology\n            “Flutter” may sound like a benign word when associated with a flag in a breeze, a butterfly, or seaweed in an ocean current. When used in the context of aerodynamics, however, it describes a highly dangerous, potentially deadly condition. \n            \n              \n              \n                \n              \n              \n                An F/A-18 E/F model undergoes flutter clearance testing in the Langley Research Center Transonic Dynamics Tunnel. \n              \n            \n            Consider the case of the Lockheed L-188 Electra Turboprop, an airliner that first took to the skies in 1957. Two years later, an Electra plummeted to the ground en route from Houston to Dallas. Within another year, a second Electra crashed. In both cases, all crew and passengers died. \n            Lockheed engineers were at a loss as to why the planes’ wings were tearing off in midair. For an answer, the company turned to NASA’s Transonic Dynamics Tunnel (TDT) at Langley Research Center. At the time, the newly renovated wind tunnel offered engineers the capability of testing aeroelastic qualities in aircraft flying at transonic speeds—near or just below the speed of sound. (Aeroelasticity is the interaction between aerodynamic forces and the structural dynamics of an aircraft or other structure.) Through round-the-clock testing in the TDT, NASA and industry researchers discovered the cause: flutter. \n            Flutter occurs when aerodynamic forces acting on a wing cause it to vibrate. As the aircraft moves faster, certain conditions can cause that vibration to multiply and feed off itself, building to greater amplitudes until the flutter causes severe damage or even the destruction of the aircraft. Flutter can impact other structures as well. Famous film footage of the Tacoma Narrows Bridge in Washington in 1940 shows the main span of the bridge collapsing after strong winds generated powerful flutter forces. In the Electra’s case, faulty engine mounts allowed a type of flutter known as whirl flutter, generated by the spinning propellers, to transfer to the wings, causing them to vibrate violently enough to tear off. \n            Thanks to the NASA testing, Lockheed was able to correct the Electra’s design flaws that led to the flutter conditions and return the aircraft to safe flight. Today, all aircraft must have a flutter boundary 15 percent beyond the aircraft’s expected maximum speed to ensure that flutter conditions are not encountered in flight. NASA continues to support research in new aircraft designs to improve knowledge of aeroelasticity and flutter. Through platforms such as Dryden Flight Research Center’s Active Aeroelastic Wing (AAW) research aircraft, the Agency researches methods for in-flight validation of predictions and for controlling and taking advantage of aeroelastic conditions to enhance aircraft performance. \n            Partnership\n            “Flutter clearance is a big part of the cost to approve a new aircraft for flight,” says Marty Brenner, aerospace engineer at Dryden. “What we’ve been supporting is how to estimate what this boundary is based on flight test data.” To do this, Dryden partnered with ZONA Technology of Scottsdale, Arizona, through the Small Business Innovation Research (SBIR) program. \n            An industry leader in aeroelastic modeling software, ZONA engaged in multiple SBIR projects with Dryden for predicting flutter boundaries, developing adaptive controls to help suppress impending flutter, and innovating new ways of conducting flutter testing without wind tunnels. Through these partnerships, ZONA has developed unique technology that help aircraft designers ensure the performance and safety of their vehicles in efficient, cost-effective ways.\n            Benefits\n            \n              \n              \n                \n              \n              \n                Dryden Flight Research Center’s Active Aeroelastic Wing aircraft shows off its form during a research flight. \n              \n            \n            The ZONA Online Flutter Estimator (ZOFE), one of the outcomes of the company’s collaboration with Dryden, is a software tool that not only helps manufacturers design safe, flutter-free aircraft, but also helps maintain the safety of the flight tests of these designs.\n            “During the flight test, you don’t want the aircraft running into flutter,” says PC Chen, ZONA’s president. “At the same time, you do want to know where the flutter boundary is. This software allows you to fly the aircraft in preflutter conditions, then calculate or predict the flutter boundary at the higher speed.” \n            ZOFE takes the real-time measurements acquired during the flight test and applies a technique to extrapolate the aircraft’s flutter boundary, Chen explains, allowing designers to obtain essential information without potentially endangering the test aircraft or pilot.\n            ZOFE is in use by the U.S. Air Force for special projects for testing flutter suppression and innovating new kinds of air vehicles. Major aircraft manufacturers are also testing the product.\n            \n              \n              \n                \n              \n              \n                A model created by ZONA Technology shows aircraft deformations due to flutter. \n              \n            \n            In the meantime, ZONA is developing an additional innovation in partnership with Dryden that promises potentially significant changes to flutter testing. Through SBIR contracts, ZONA created its Dry Wind Tunnel (DWT) technology for conducting ground flutter testing without a wind tunnel. \n            “A lot of wind tunnel data is suspect because of tunnel effects,” explains Brenner. Wind tunnels are not big enough to accommodate full-scale test aircraft, so smaller models of the aircraft have to be used instead. While these models still provide valuable aerodynamic information, Brenner says, “some parameters don’t scale up properly to a full-scale aircraft.” \n            ZONA’s DWT uses shaker devices to mimic the effects of aerodynamic forces on a full-scale wing or aircraft. The system’s software can calculate the aerodynamic forces and give that command to the shaker, which then applies that force to the true structure so engineers can record and observe the effects. The company claims that DWT can thus eliminate the uncertainties inherent in wind tunnel testing \n            “DWT is more accurate,” says ZONA project manager Jennifer Scherr, “because you have all of the control surfaces included, you are not making a scaled-down version of the aircraft, and you don’t have the wind tunnel walls adding other variables to the mix.” The technology also helps eliminate significant costs. Chen notes that the wind tunnel flutter test for a recent new aircraft design cost about \n              $3 million to fabricate the scaled-down model and around $50,000 a day for the wind tunnel testing.\n            “Flight flutter testing of a new or modified vehicle is very expensive and time consuming,” says Starr Ginn, Dryden’s aerostructures deputy branch chief and contract monitor for the \n              Phase II Small Business Technology Transfer (STTR) project to develop the DWT. “It takes roughly 25 people to prepare the aircraft, a large staff in the control room, fuel costs for each flight, and time in-between flights to review the data. Using the DWT will help identify where the flutter sensitivity is on the ground, allowing for a reduced number of flutter test points.” \n            ZONA continues to work with Dryden to advance the DWT technology, and is planning testing on the AAW aircraft in 2011. The company’s NASA partnerships have been essential for its ability to innovate new technologies, says ZONA engineer and director of operations Darius Sarhaddi. \n            “Aeroelasticity is not something that everyone needs,” he explains. “This type of technology is very narrow. For our business, government partnership is very important.” \n            It may be a specialized field, but the benefits of ZONA’s NASA partnerships—helping keep flutter confined to flags and seaweed—are very real.\n          \n          \n        \n      \n    \n      \n        \n          \n            NASA Technology\n            “Flutter” may sound like a benign word when associated with a flag in a breeze, a butterfly, or seaweed in an ocean current. When used in the context of aerodynamics, however, it describes a highly dangerous, potentially deadly condition. \n            \n              \n              \n                \n              \n              \n                An F/A-18 E/F model undergoes flutter clearance testing in the Langley Research Center Transonic Dynamics Tunnel. \n              \n            \n            Consider the case of the Lockheed L-188 Electra Turboprop, an airliner that first took to the skies in 1957. Two years later, an Electra plummeted to the ground en route from Houston to Dallas. Within another year, a second Electra crashed. In both cases, all crew and passengers died. \n            Lockheed engineers were at a loss as to why the planes’ wings were tearing off in midair. For an answer, the company turned to NASA’s Transonic Dynamics Tunnel (TDT) at Langley Research Center. At the time, the newly renovated wind tunnel offered engineers the capability of testing aeroelastic qualities in aircraft flying at transonic speeds—near or just below the speed of sound. (Aeroelasticity is the interaction between aerodynamic forces and the structural dynamics of an aircraft or other structure.) Through round-the-clock testing in the TDT, NASA and industry researchers discovered the cause: flutter. \n            Flutter occurs when aerodynamic forces acting on a wing cause it to vibrate. As the aircraft moves faster, certain conditions can cause that vibration to multiply and feed off itself, building to greater amplitudes until the flutter causes severe damage or even the destruction of the aircraft. Flutter can impact other structures as well. Famous film footage of the Tacoma Narrows Bridge in Washington in 1940 shows the main span of the bridge collapsing after strong winds generated powerful flutter forces. In the Electra’s case, faulty engine mounts allowed a type of flutter known as whirl flutter, generated by the spinning propellers, to transfer to the wings, causing them to vibrate violently enough to tear off. \n            Thanks to the NASA testing, Lockheed was able to correct the Electra’s design flaws that led to the flutter conditions and return the aircraft to safe flight. Today, all aircraft must have a flutter boundary 15 percent beyond the aircraft’s expected maximum speed to ensure that flutter conditions are not encountered in flight. NASA continues to support research in new aircraft designs to improve knowledge of aeroelasticity and flutter. Through platforms such as Dryden Flight Research Center’s Active Aeroelastic Wing (AAW) research aircraft, the Agency researches methods for in-flight validation of predictions and for controlling and taking advantage of aeroelastic conditions to enhance aircraft performance. \n            Partnership\n            “Flutter clearance is a big part of the cost to approve a new aircraft for flight,” says Marty Brenner, aerospace engineer at Dryden. “What we’ve been supporting is how to estimate what this boundary is based on flight test data.” To do this, Dryden partnered with ZONA Technology of Scottsdale, Arizona, through the Small Business Innovation Research (SBIR) program. \n            An industry leader in aeroelastic modeling software, ZONA engaged in multiple SBIR projects with Dryden for predicting flutter boundaries, developing adaptive controls to help suppress impending flutter, and innovating new ways of conducting flutter testing without wind tunnels. Through these partnerships, ZONA has developed unique technology that help aircraft designers ensure the performance and safety of their vehicles in efficient, cost-effective ways.\n            Benefits\n            \n              \n              \n                \n              \n              \n                Dryden Flight Research Center’s Active Aeroelastic Wing aircraft shows off its form during a research flight. \n              \n            \n            The ZONA Online Flutter Estimator (ZOFE), one of the outcomes of the company’s collaboration with Dryden, is a software tool that not only helps manufacturers design safe, flutter-free aircraft, but also helps maintain the safety of the flight tests of these designs.\n            “During the flight test, you don’t want the aircraft running into flutter,” says PC Chen, ZONA’s president. “At the same time, you do want to know where the flutter boundary is. This software allows you to fly the aircraft in preflutter conditions, then calculate or predict the flutter boundary at the higher speed.” \n            ZOFE takes the real-time measurements acquired during the flight test and applies a technique to extrapolate the aircraft’s flutter boundary, Chen explains, allowing designers to obtain essential information without potentially endangering the test aircraft or pilot.\n            ZOFE is in use by the U.S. Air Force for special projects for testing flutter suppression and innovating new kinds of air vehicles. Major aircraft manufacturers are also testing the product.\n            \n              \n              \n                \n              \n              \n                A model created by ZONA Technology shows aircraft deformations due to flutter. \n              \n            \n            In the meantime, ZONA is developing an additional innovation in partnership with Dryden that promises potentially significant changes to flutter testing. Through SBIR contracts, ZONA created its Dry Wind Tunnel (DWT) technology for conducting ground flutter testing without a wind tunnel. \n            “A lot of wind tunnel data is suspect because of tunnel effects,” explains Brenner. Wind tunnels are not big enough to accommodate full-scale test aircraft, so smaller models of the aircraft have to be used instead. While these models still provide valuable aerodynamic information, Brenner says, “some parameters don’t scale up properly to a full-scale aircraft.” \n            ZONA’s DWT uses shaker devices to mimic the effects of aerodynamic forces on a full-scale wing or aircraft. The system’s software can calculate the aerodynamic forces and give that command to the shaker, which then applies that force to the true structure so engineers can record and observe the effects. The company claims that DWT can thus eliminate the uncertainties inherent in wind tunnel testing \n            “DWT is more accurate,” says ZONA project manager Jennifer Scherr, “because you have all of the control surfaces included, you are not making a scaled-down version of the aircraft, and you don’t have the wind tunnel walls adding other variables to the mix.” The technology also helps eliminate significant costs. Chen notes that the wind tunnel flutter test for a recent new aircraft design cost about \n              $3 million to fabricate the scaled-down model and around $50,000 a day for the wind tunnel testing.\n            “Flight flutter testing of a new or modified vehicle is very expensive and time consuming,” says Starr Ginn, Dryden’s aerostructures deputy branch chief and contract monitor for the \n              Phase II Small Business Technology Transfer (STTR) project to develop the DWT. “It takes roughly 25 people to prepare the aircraft, a large staff in the control room, fuel costs for each flight, and time in-between flights to review the data. Using the DWT will help identify where the flutter sensitivity is on the ground, allowing for a reduced number of flutter test points.” \n            ZONA continues to work with Dryden to advance the DWT technology, and is planning testing on the AAW aircraft in 2011. The company’s NASA partnerships have been essential for its ability to innovate new technologies, says ZONA engineer and director of operations Darius Sarhaddi. \n            “Aeroelasticity is not something that everyone needs,” he explains. “This type of technology is very narrow. For our business, government partnership is very important.” \n            It may be a specialized field, but the benefits of ZONA’s NASA partnerships—helping keep flutter confined to flags and seaweed—are very real.\n          \n          \n        \n      \n        \n          \n            NASA Technology\n            “Flutter” may sound like a benign word when associated with a flag in a breeze, a butterfly, or seaweed in an ocean current. When used in the context of aerodynamics, however, it describes a highly dangerous, potentially deadly condition. \n            \n              \n              \n                \n              \n              \n                An F/A-18 E/F model undergoes flutter clearance testing in the Langley Research Center Transonic Dynamics Tunnel. \n              \n            \n            Consider the case of the Lockheed L-188 Electra Turboprop, an airliner that first took to the skies in 1957. Two years later, an Electra plummeted to the ground en route from Houston to Dallas. Within another year, a second Electra crashed. In both cases, all crew and passengers died. \n            Lockheed engineers were at a loss as to why the planes’ wings were tearing off in midair. For an answer, the company turned to NASA’s Transonic Dynamics Tunnel (TDT) at Langley Research Center. At the time, the newly renovated wind tunnel offered engineers the capability of testing aeroelastic qualities in aircraft flying at transonic speeds—near or just below the speed of sound. (Aeroelasticity is the interaction between aerodynamic forces and the structural dynamics of an aircraft or other structure.) Through round-the-clock testing in the TDT, NASA and industry researchers discovered the cause: flutter. \n            Flutter occurs when aerodynamic forces acting on a wing cause it to vibrate. As the aircraft moves faster, certain conditions can cause that vibration to multiply and feed off itself, building to greater amplitudes until the flutter causes severe damage or even the destruction of the aircraft. Flutter can impact other structures as well. Famous film footage of the Tacoma Narrows Bridge in Washington in 1940 shows the main span of the bridge collapsing after strong winds generated powerful flutter forces. In the Electra’s case, faulty engine mounts allowed a type of flutter known as whirl flutter, generated by the spinning propellers, to transfer to the wings, causing them to vibrate violently enough to tear off. \n            Thanks to the NASA testing, Lockheed was able to correct the Electra’s design flaws that led to the flutter conditions and return the aircraft to safe flight. Today, all aircraft must have a flutter boundary 15 percent beyond the aircraft’s expected maximum speed to ensure that flutter conditions are not encountered in flight. NASA continues to support research in new aircraft designs to improve knowledge of aeroelasticity and flutter. Through platforms such as Dryden Flight Research Center’s Active Aeroelastic Wing (AAW) research aircraft, the Agency researches methods for in-flight validation of predictions and for controlling and taking advantage of aeroelastic conditions to enhance aircraft performance. \n            Partnership\n            “Flutter clearance is a big part of the cost to approve a new aircraft for flight,” says Marty Brenner, aerospace engineer at Dryden. “What we’ve been supporting is how to estimate what this boundary is based on flight test data.” To do this, Dryden partnered with ZONA Technology of Scottsdale, Arizona, through the Small Business Innovation Research (SBIR) program. \n            An industry leader in aeroelastic modeling software, ZONA engaged in multiple SBIR projects with Dryden for predicting flutter boundaries, developing adaptive controls to help suppress impending flutter, and innovating new ways of conducting flutter testing without wind tunnels. Through these partnerships, ZONA has developed unique technology that help aircraft designers ensure the performance and safety of their vehicles in efficient, cost-effective ways.\n            Benefits\n            \n              \n              \n                \n              \n              \n                Dryden Flight Research Center’s Active Aeroelastic Wing aircraft shows off its form during a research flight. \n              \n            \n            The ZONA Online Flutter Estimator (ZOFE), one of the outcomes of the company’s collaboration with Dryden, is a software tool that not only helps manufacturers design safe, flutter-free aircraft, but also helps maintain the safety of the flight tests of these designs.\n            “During the flight test, you don’t want the aircraft running into flutter,” says PC Chen, ZONA’s president. “At the same time, you do want to know where the flutter boundary is. This software allows you to fly the aircraft in preflutter conditions, then calculate or predict the flutter boundary at the higher speed.” \n            ZOFE takes the real-time measurements acquired during the flight test and applies a technique to extrapolate the aircraft’s flutter boundary, Chen explains, allowing designers to obtain essential information without potentially endangering the test aircraft or pilot.\n            ZOFE is in use by the U.S. Air Force for special projects for testing flutter suppression and innovating new kinds of air vehicles. Major aircraft manufacturers are also testing the product.\n            \n              \n              \n                \n              \n              \n                A model created by ZONA Technology shows aircraft deformations due to flutter. \n              \n            \n            In the meantime, ZONA is developing an additional innovation in partnership with Dryden that promises potentially significant changes to flutter testing. Through SBIR contracts, ZONA created its Dry Wind Tunnel (DWT) technology for conducting ground flutter testing without a wind tunnel. \n            “A lot of wind tunnel data is suspect because of tunnel effects,” explains Brenner. Wind tunnels are not big enough to accommodate full-scale test aircraft, so smaller models of the aircraft have to be used instead. While these models still provide valuable aerodynamic information, Brenner says, “some parameters don’t scale up properly to a full-scale aircraft.” \n            ZONA’s DWT uses shaker devices to mimic the effects of aerodynamic forces on a full-scale wing or aircraft. The system’s software can calculate the aerodynamic forces and give that command to the shaker, which then applies that force to the true structure so engineers can record and observe the effects. The company claims that DWT can thus eliminate the uncertainties inherent in wind tunnel testing \n            “DWT is more accurate,” says ZONA project manager Jennifer Scherr, “because you have all of the control surfaces included, you are not making a scaled-down version of the aircraft, and you don’t have the wind tunnel walls adding other variables to the mix.” The technology also helps eliminate significant costs. Chen notes that the wind tunnel flutter test for a recent new aircraft design cost about \n              $3 million to fabricate the scaled-down model and around $50,000 a day for the wind tunnel testing.\n            “Flight flutter testing of a new or modified vehicle is very expensive and time consuming,” says Starr Ginn, Dryden’s aerostructures deputy branch chief and contract monitor for the \n              Phase II Small Business Technology Transfer (STTR) project to develop the DWT. “It takes roughly 25 people to prepare the aircraft, a large staff in the control room, fuel costs for each flight, and time in-between flights to review the data. Using the DWT will help identify where the flutter sensitivity is on the ground, allowing for a reduced number of flutter test points.” \n            ZONA continues to work with Dryden to advance the DWT technology, and is planning testing on the AAW aircraft in 2011. The company’s NASA partnerships have been essential for its ability to innovate new technologies, says ZONA engineer and director of operations Darius Sarhaddi. \n            “Aeroelasticity is not something that everyone needs,” he explains. “This type of technology is very narrow. For our business, government partnership is very important.” \n            It may be a specialized field, but the benefits of ZONA’s NASA partnerships—helping keep flutter confined to flags and seaweed—are very real.\n          \n          \n        \n          \n            NASA Technology\n            “Flutter” may sound like a benign word when associated with a flag in a breeze, a butterfly, or seaweed in an ocean current. When used in the context of aerodynamics, however, it describes a highly dangerous, potentially deadly condition. \n            \n              \n              \n                \n              \n              \n                An F/A-18 E/F model undergoes flutter clearance testing in the Langley Research Center Transonic Dynamics Tunnel. \n              \n            \n            Consider the case of the Lockheed L-188 Electra Turboprop, an airliner that first took to the skies in 1957. Two years later, an Electra plummeted to the ground en route from Houston to Dallas. Within another year, a second Electra crashed. In both cases, all crew and passengers died. \n            Lockheed engineers were at a loss as to why the planes’ wings were tearing off in midair. For an answer, the company turned to NASA’s Transonic Dynamics Tunnel (TDT) at Langley Research Center. At the time, the newly renovated wind tunnel offered engineers the capability of testing aeroelastic qualities in aircraft flying at transonic speeds—near or just below the speed of sound. (Aeroelasticity is the interaction between aerodynamic forces and the structural dynamics of an aircraft or other structure.) Through round-the-clock testing in the TDT, NASA and industry researchers discovered the cause: flutter. \n            Flutter occurs when aerodynamic forces acting on a wing cause it to vibrate. As the aircraft moves faster, certain conditions can cause that vibration to multiply and feed off itself, building to greater amplitudes until the flutter causes severe damage or even the destruction of the aircraft. Flutter can impact other structures as well. Famous film footage of the Tacoma Narrows Bridge in Washington in 1940 shows the main span of the bridge collapsing after strong winds generated powerful flutter forces. In the Electra’s case, faulty engine mounts allowed a type of flutter known as whirl flutter, generated by the spinning propellers, to transfer to the wings, causing them to vibrate violently enough to tear off. \n            Thanks to the NASA testing, Lockheed was able to correct the Electra’s design flaws that led to the flutter conditions and return the aircraft to safe flight. Today, all aircraft must have a flutter boundary 15 percent beyond the aircraft’s expected maximum speed to ensure that flutter conditions are not encountered in flight. NASA continues to support research in new aircraft designs to improve knowledge of aeroelasticity and flutter. Through platforms such as Dryden Flight Research Center’s Active Aeroelastic Wing (AAW) research aircraft, the Agency researches methods for in-flight validation of predictions and for controlling and taking advantage of aeroelastic conditions to enhance aircraft performance. \n            Partnership\n            “Flutter clearance is a big part of the cost to approve a new aircraft for flight,” says Marty Brenner, aerospace engineer at Dryden. “What we’ve been supporting is how to estimate what this boundary is based on flight test data.” To do this, Dryden partnered with ZONA Technology of Scottsdale, Arizona, through the Small Business Innovation Research (SBIR) program. \n            An industry leader in aeroelastic modeling software, ZONA engaged in multiple SBIR projects with Dryden for predicting flutter boundaries, developing adaptive controls to help suppress impending flutter, and innovating new ways of conducting flutter testing without wind tunnels. Through these partnerships, ZONA has developed unique technology that help aircraft designers ensure the performance and safety of their vehicles in efficient, cost-effective ways.\n            Benefits\n            \n              \n              \n                \n              \n              \n                Dryden Flight Research Center’s Active Aeroelastic Wing aircraft shows off its form during a research flight. \n              \n            \n            The ZONA Online Flutter Estimator (ZOFE), one of the outcomes of the company’s collaboration with Dryden, is a software tool that not only helps manufacturers design safe, flutter-free aircraft, but also helps maintain the safety of the flight tests of these designs.\n            “During the flight test, you don’t want the aircraft running into flutter,” says PC Chen, ZONA’s president. “At the same time, you do want to know where the flutter boundary is. This software allows you to fly the aircraft in preflutter conditions, then calculate or predict the flutter boundary at the higher speed.” \n            ZOFE takes the real-time measurements acquired during the flight test and applies a technique to extrapolate the aircraft’s flutter boundary, Chen explains, allowing designers to obtain essential information without potentially endangering the test aircraft or pilot.\n            ZOFE is in use by the U.S. Air Force for special projects for testing flutter suppression and innovating new kinds of air vehicles. Major aircraft manufacturers are also testing the product.\n            \n              \n              \n                \n              \n              \n                A model created by ZONA Technology shows aircraft deformations due to flutter. \n              \n            \n            In the meantime, ZONA is developing an additional innovation in partnership with Dryden that promises potentially significant changes to flutter testing. Through SBIR contracts, ZONA created its Dry Wind Tunnel (DWT) technology for conducting ground flutter testing without a wind tunnel. \n            “A lot of wind tunnel data is suspect because of tunnel effects,” explains Brenner. Wind tunnels are not big enough to accommodate full-scale test aircraft, so smaller models of the aircraft have to be used instead. While these models still provide valuable aerodynamic information, Brenner says, “some parameters don’t scale up properly to a full-scale aircraft.” \n            ZONA’s DWT uses shaker devices to mimic the effects of aerodynamic forces on a full-scale wing or aircraft. The system’s software can calculate the aerodynamic forces and give that command to the shaker, which then applies that force to the true structure so engineers can record and observe the effects. The company claims that DWT can thus eliminate the uncertainties inherent in wind tunnel testing \n            “DWT is more accurate,” says ZONA project manager Jennifer Scherr, “because you have all of the control surfaces included, you are not making a scaled-down version of the aircraft, and you don’t have the wind tunnel walls adding other variables to the mix.” The technology also helps eliminate significant costs. Chen notes that the wind tunnel flutter test for a recent new aircraft design cost about \n              $3 million to fabricate the scaled-down model and around $50,000 a day for the wind tunnel testing.\n            “Flight flutter testing of a new or modified vehicle is very expensive and time consuming,” says Starr Ginn, Dryden’s aerostructures deputy branch chief and contract monitor for the \n              Phase II Small Business Technology Transfer (STTR) project to develop the DWT. “It takes roughly 25 people to prepare the aircraft, a large staff in the control room, fuel costs for each flight, and time in-between flights to review the data. Using the DWT will help identify where the flutter sensitivity is on the ground, allowing for a reduced number of flutter test points.” \n            ZONA continues to work with Dryden to advance the DWT technology, and is planning testing on the AAW aircraft in 2011. The company’s NASA partnerships have been essential for its ability to innovate new technologies, says ZONA engineer and director of operations Darius Sarhaddi. \n            “Aeroelasticity is not something that everyone needs,” he explains. “This type of technology is very narrow. For our business, government partnership is very important.” \n            It may be a specialized field, but the benefits of ZONA’s NASA partnerships—helping keep flutter confined to flags and seaweed—are very real.\n          \n          \n            NASA Technology\n            “Flutter” may sound like a benign word when associated with a flag in a breeze, a butterfly, or seaweed in an ocean current. When used in the context of aerodynamics, however, it describes a highly dangerous, potentially deadly condition. \n            \n              \n              \n                \n              \n              \n                An F/A-18 E/F model undergoes flutter clearance testing in the Langley Research Center Transonic Dynamics Tunnel. \n              \n            \n            Consider the case of the Lockheed L-188 Electra Turboprop, an airliner that first took to the skies in 1957. Two years later, an Electra plummeted to the ground en route from Houston to Dallas. Within another year, a second Electra crashed. In both cases, all crew and passengers died. \n            Lockheed engineers were at a loss as to why the planes’ wings were tearing off in midair. For an answer, the company turned to NASA’s Transonic Dynamics Tunnel (TDT) at Langley Research Center. At the time, the newly renovated wind tunnel offered engineers the capability of testing aeroelastic qualities in aircraft flying at transonic speeds—near or just below the speed of sound. (Aeroelasticity is the interaction between aerodynamic forces and the structural dynamics of an aircraft or other structure.) Through round-the-clock testing in the TDT, NASA and industry researchers discovered the cause: flutter. \n            Flutter occurs when aerodynamic forces acting on a wing cause it to vibrate. As the aircraft moves faster, certain conditions can cause that vibration to multiply and feed off itself, building to greater amplitudes until the flutter causes severe damage or even the destruction of the aircraft. Flutter can impact other structures as well. Famous film footage of the Tacoma Narrows Bridge in Washington in 1940 shows the main span of the bridge collapsing after strong winds generated powerful flutter forces. In the Electra’s case, faulty engine mounts allowed a type of flutter known as whirl flutter, generated by the spinning propellers, to transfer to the wings, causing them to vibrate violently enough to tear off. \n            Thanks to the NASA testing, Lockheed was able to correct the Electra’s design flaws that led to the flutter conditions and return the aircraft to safe flight. Today, all aircraft must have a flutter boundary 15 percent beyond the aircraft’s expected maximum speed to ensure that flutter conditions are not encountered in flight. NASA continues to support research in new aircraft designs to improve knowledge of aeroelasticity and flutter. Through platforms such as Dryden Flight Research Center’s Active Aeroelastic Wing (AAW) research aircraft, the Agency researches methods for in-flight validation of predictions and for controlling and taking advantage of aeroelastic conditions to enhance aircraft performance. \n            Partnership\n            “Flutter clearance is a big part of the cost to approve a new aircraft for flight,” says Marty Brenner, aerospace engineer at Dryden. “What we’ve been supporting is how to estimate what this boundary is based on flight test data.” To do this, Dryden partnered with ZONA Technology of Scottsdale, Arizona, through the Small Business Innovation Research (SBIR) program. \n            An industry leader in aeroelastic modeling software, ZONA engaged in multiple SBIR projects with Dryden for predicting flutter boundaries, developing adaptive controls to help suppress impending flutter, and innovating new ways of conducting flutter testing without wind tunnels. Through these partnerships, ZONA has developed unique technology that help aircraft designers ensure the performance and safety of their vehicles in efficient, cost-effective ways.\n            Benefits\n            \n              \n              \n                \n              \n              \n                Dryden Flight Research Center’s Active Aeroelastic Wing aircraft shows off its form during a research flight. \n              \n            \n            The ZONA Online Flutter Estimator (ZOFE), one of the outcomes of the company’s collaboration with Dryden, is a software tool that not only helps manufacturers design safe, flutter-free aircraft, but also helps maintain the safety of the flight tests of these designs.\n            “During the flight test, you don’t want the aircraft running into flutter,” says PC Chen, ZONA’s president. “At the same time, you do want to know where the flutter boundary is. This software allows you to fly the aircraft in preflutter conditions, then calculate or predict the flutter boundary at the higher speed.” \n            ZOFE takes the real-time measurements acquired during the flight test and applies a technique to extrapolate the aircraft’s flutter boundary, Chen explains, allowing designers to obtain essential information without potentially endangering the test aircraft or pilot.\n            ZOFE is in use by the U.S. Air Force for special projects for testing flutter suppression and innovating new kinds of air vehicles. Major aircraft manufacturers are also testing the product.\n            \n              \n              \n                \n              \n              \n                A model created by ZONA Technology shows aircraft deformations due to flutter. \n              \n            \n            In the meantime, ZONA is developing an additional innovation in partnership with Dryden that promises potentially significant changes to flutter testing. Through SBIR contracts, ZONA created its Dry Wind Tunnel (DWT) technology for conducting ground flutter testing without a wind tunnel. \n            “A lot of wind tunnel data is suspect because of tunnel effects,” explains Brenner. Wind tunnels are not big enough to accommodate full-scale test aircraft, so smaller models of the aircraft have to be used instead. While these models still provide valuable aerodynamic information, Brenner says, “some parameters don’t scale up properly to a full-scale aircraft.” \n            ZONA’s DWT uses shaker devices to mimic the effects of aerodynamic forces on a full-scale wing or aircraft. The system’s software can calculate the aerodynamic forces and give that command to the shaker, which then applies that force to the true structure so engineers can record and observe the effects. The company claims that DWT can thus eliminate the uncertainties inherent in wind tunnel testing \n            “DWT is more accurate,” says ZONA project manager Jennifer Scherr, “because you have all of the control surfaces included, you are not making a scaled-down version of the aircraft, and you don’t have the wind tunnel walls adding other variables to the mix.” The technology also helps eliminate significant costs. Chen notes that the wind tunnel flutter test for a recent new aircraft design cost about \n              $3 million to fabricate the scaled-down model and around $50,000 a day for the wind tunnel testing.\n            “Flight flutter testing of a new or modified vehicle is very expensive and time consuming,” says Starr Ginn, Dryden’s aerostructures deputy branch chief and contract monitor for the \n              Phase II Small Business Technology Transfer (STTR) project to develop the DWT. “It takes roughly 25 people to prepare the aircraft, a large staff in the control room, fuel costs for each flight, and time in-between flights to review the data. Using the DWT will help identify where the flutter sensitivity is on the ground, allowing for a reduced number of flutter test points.” \n            ZONA continues to work with Dryden to advance the DWT technology, and is planning testing on the AAW aircraft in 2011. The company’s NASA partnerships have been essential for its ability to innovate new technologies, says ZONA engineer and director of operations Darius Sarhaddi. \n            “Aeroelasticity is not something that everyone needs,” he explains. “This type of technology is very narrow. For our business, government partnership is very important.” \n            It may be a specialized field, but the benefits of ZONA’s NASA partnerships—helping keep flutter confined to flags and seaweed—are very real.\n          "},{"href":"http://spinoff.nasa.gov/Spinoff2011/t_5.html","text":"Fly-by-Wire Systems Enable Safer,  \n                More Efficient Flight","image":"http://spinoff.nasa.gov/Spinoff2011/Images/t_9_opt.jpg","story":"\n    \n      \n        \n          \n            \n              Fly-by-Wire Systems Enable Safer, More Efficient Flight\n            \n            \n              NASA Technology\n              In 1961, not long after NASA received the imperative from President John F. Kennedy to land a man on the Moon within the decade, then-NASA administrator James Webb posed a question to Charles Stark “Doc” Draper, head of the Massachusetts Institute of Technology (MIT) Instrumentation Lab. Webb wanted to know if it was possible to create a guidance system that could lead a man to the Moon and return him safely to Earth.\n                \n              \n              Doc Draper had pioneered the field of inertial navigation—the use of instruments such as gyroscopes and accelerometers to provide guidance for a vehicle—and the Lab had developed the guidance systems for the Nation’s first ballistic missiles and even conducted work in the 1950s on an autonomous probe that could find its way to Mars and back.\n              Doc Draper’s answer was a definitive “Yes.” \n              Known today as Draper Laboratory, an independent, nonprofit institution based in Cambridge, Massachusetts, the MIT Instrumentation Laboratory became the first major contractor for the Apollo program. Working with other contractors, the lab developed the Apollo Primary Guidance, Navigation, and Control System (PGNCS, pronounced “pings”). Consisting of an inertial measurement unit, optical and other components, the system had at its heart the Apollo Guidance Computer. Designed and programmed by the Lab and largely built by Raytheon, the computer would be the brain for both the Apollo Command Module and the Lunar Module that would deliver the first astronauts to the Moon’s surface. To do this, it had to be faultless.\n              “It had to work and it had to work flawlessly. There was no possibility for repair,” says Darryl Sargent, vice president of programs for Draper. \n              And it did. Throughout the course of the Apollo program, the computer never experienced a failure. In addition to enabling the PGNCS system that in turn enabled the Moon landings, the computer also contributed to the rescue of Apollo 13 through the use of a program that helped push the damaged Command Module into a safe course back to Earth. \n              Meanwhile, at NASA’s Flight Research Center in California (now known as Dryden Flight Research Center), aeronautics engineers were asking questions about how computers could contribute to flight on Earth—questions that the Apollo Guidance Computer would help answer. \n              Partnership\n              \n                \n                \n                  \n                \n                \n                  The Primary Guidance, Navigation, and Control System of the Apollo Lunar Module. The display and keyboard (DSKY, pronounced “diskey”) interface used by the astronauts to input commands can be seen in the bottom center of the image. \n                \n              \n              At that point, mechanically controlled aircraft—in which the vehicle’s control surfaces are operated through cables and pushrods connecting the aerodynamic surfaces to the pilot’s control sticks and rudder pedals—were the norm in aviation. In 1970, a Dryden team visited NASA Headquarters proposing an advanced aircraft controlled by an analog fly-by-wire system with no mechanical backup. \n              The idea of flying an aircraft electronically was not a new one. In a fly-by-wire system, a computer collects sensor data from the pilot’s controls and sends those signals via wires to actuators that decode the signals and move the aircraft’s control surfaces accordingly. Dryden researchers had developed significant experience in electronic flight controls through the development of experimental aircraft; in fact, the Lunar Landing Training Vehicle NASA used to train the Apollo spacecraft commanders employed an analog fly-by-wire system with no mechanical backup—making it the first genuine fly-by-wire vehicle. But these systems all used analog computers, as opposed to digital ones. Electronic analog computers use variations in the physical properties of electricity to represent numbers; digital computers use binary code. Though slower for certain functions than their analog counterparts, digital computers can store large quantities of data and can be programmed with complex software. \n              While the actual aircraft the Dryden team proposed proved too futuristic to pursue, the question was raised, “What about a digital fly-by-wire system?” \n              \n                \n                \n                  \n                \n                \n                  In 1994, the Boeing 777 became the second commercial airliner to fly using DFBW. For commercial aircraft, the replacement of heavy mechanical systems with DFBW controls provides greater fuel efficiency or the ability to carry more passengers or cargo.\n                    \n                  Image courtesy of Kevin Koske\n                \n              \n              “The answer was that there were no flight qualified digital computers for airplanes,” says Ken Szalai, then a young engineer at Dryden. An objection was raised by a well-known figure (and former Dryden test pilot) in what was then NASA’s Office of Advanced Research and Technology: Neil Armstrong. He had recently flown to the Moon and back with his life entrusted to the guidance of a digital computer. Szalai approached Draper Laboratory, the architect of the Apollo PGNCS, to see whether it could be adapted to test the feasibility of digital fly-by-wire for aircraft. The answer, again, was “Yes.”\n              Through Armstrong’s support, and that of U.S. Navy Vice Admiral Donald Engen, Dryden acquired a trio of F-8C Crusaders from the Navy and, working with Draper, the Center installed an adapted extra Apollo PGNCS on one of the planes, which became the Digital Fly-by-Wire (DFBW) research aircraft. Another of the F-8s was converted into an “Iron Bird” ground-based simulator for testing the flight software and training pilots, and the third F-8 was used to familiarize test pilots with the aircraft. \n              “The Apollo system wasn’t an ideal configuration for airplane control,” says Philip Felleman, who was the DFBW program manager for Draper. “But it did have one big thing going for it: It was highly reliable.” \n              The DFBW program (also commonly known as the F-8 program) was divided into two phases. In Phase I, the objective was to demonstrate the viability of flying an aircraft by digital computer alone. The first use of an analog fly-by-wire system in an aircraft was in early May of 1972 by the U.S. Air Force YF-4E Control Configured Vehicle. About three weeks later, on May 25, 1972, Gary Krier piloted the DFBW research aircraft on the first flight of an aircraft controlled by digital computer. The plane had no mechanical backup, only a three-computer analog emergency system. The backup system was not needed for that flight, nor any other for the length of the program. \n              \n                More than 30 successful flights later, Phase I finished having proven a digital computer could be used to fly an aircraft. The next question was how to make it practical. Commercial digital computers did not have the reliability of the Apollo Guidance Computer. A DFBW system would require more than just one or even two computers to operate with any acceptable assurance of safety. In Phase II of the DFBW program, Dryden collaborated with Draper, Langley Research Center, and others to create the hardware and software necessary for a highly reliable, fault-tolerant, three-computer DFBW system.\n              \n              \n                \n                \n                  \n                \n                \n                  The Northrop Grumman B-2 Spirit is one of the aircraft designs enabled by DFBW technology.\n                \n              \n              “The big job was to be able to manage the redundancy, to be able to tolerate a failure and still be able to fly,” says Felleman. To do that, Szalai says, “We worked untold hours to develop the logic schemes, and then we had to test it and verify that it worked in all the various combinations.” \n              Draper, meanwhile, was also working with NASA on the guidance, navigation, and control system for an entirely new kind of aircraft: the Space Shuttle. Employing a quad-redundant digital fly-by-wire system, the shuttle benefited from the work done during the DFBW program, which in one case identified a hardware issue with the flight computers (both programs used IBM AP-101s), and in another helped solve a potentially hazardous problem with pilot-induced oscillation that occurred during the final test flight of the Space Shuttle Enterprise. \n              “There was feedback between the programs, mostly from us to the shuttle program because we were doing everything first,” says Felleman. \n              The DFBW program’s final flight occurred on \n                April 2, 1985—the last of more than 200 successful flights that collectively provided the impetus for changing the way aircraft are designed and flown around the world. \n              Benefits\n              “Some of the techniques we developed at that time are still being used, and that spawned the digital fly-by-wire revolution,” says Szalai, who went on to become Dryden’s center director before retiring in 1998. “We communicated with all of the major airframe manufacturers and were able to transfer a lot of the technology.” \n              \n                \n                \n                  \n                \n                \n                  The U.S. Navy’s Seawolf class submarines feature a “swim-by-wire” system adapted by NASA partner Draper Laboratory from the Lab’s work during the DFBW program.\n                \n              \n              The first commercial airliner to fly with DFBW was the Airbus 320 in 1987, followed by Boeing’s 777 in 1994. Today, the technology features in a number of aircraft from both manufacturers. For commercial aircraft, the technology replaces heavy mechanical systems, allowing airlines to benefit from greater fuel efficiency or carry more passengers and cargo. The heightened responsiveness of DFBW-enabled aircraft allows pilots to provide a smoother flight, and the system’s redundancies help ensure safe operation of the vehicle. Mechanical maintenance needs are also reduced, saving costs and time spent on upkeep and repairs of the mechanical systems and reducing the chance of failures. \n              “Now, when you fly any major, large airplane, you’re flying a digital fly-by-wire system based on the technology from the F-8 program,” says Sargent. Even smaller aircraft are now incorporating the technology; in 2005, the Dassault Falcon 7X became the first business jet with a DFBW system.\n              One of the biggest contributions to aviation to emerge from the DFBW program is the ability to support entirely new forms of aircraft, says Szalai. The enhanced control capabilities of a DFBW system allow pilots to fly aerodynamically unstable aircraft that could not be controlled otherwise. While current aircraft are still designed as aerodynamically stable to at least some degree, unstable aircraft promise higher performance—such as increased maneuverability in fighter jets and minimized drag and increased range in civil transport—and future aircraft may capitalize on this benefit.\n              “Digital fly-by-wire has unshackled designers from the rules of the 1950s and 1960s, so you end up with vehicles like the Space Shuttle, the B-2 bomber, and the F-117. You couldn’t have these kinds of aircraft without a fly-by-wire system,” says Szalai. In addition to those, Szalai notes, many other military aircraft benefit from DFBW systems, including the F/A-18 and F-22. The F-16 began with an analog fly-by-wire system—the first production aircraft with fly-by-wire—and later switched to DFBW controls. \n              The benefits of digital computer vehicle control systems as demonstrated by the DFBW program are not limited to the skies, however. The electronic cruise control features found in many automobiles are enabled by drive-by-wire technology, as are antilock braking and electronic stability control systems, both of which significantly enhance safety. Auto and motorcycle manufacturers have also incorporated electronic throttles into their vehicles—the first being the BMW 7 series in 1988—eliminating moving mechanical systems between the accelerator and the engine. \n              For Draper, the outcomes of the DFBW program have served to enhance the Lab’s expertise and reputation in the field of guidance, navigation, and control systems. \n              “What NASA has meant to us is a steady stream of hard problems to work on. The skills we learned and technologies we developed from our work with NASA we then turn around and apply as broadly as possible,” says Sargent. Beyond aircraft, Draper has applied the DFBW technology to a range of unmanned underwater vehicles and the U.S. Navy’s Seawolf class submarines. “A redundant, fault tolerant, ‘swim-by-wire’ system,” Sargent says. And Draper recently delivered a DFBW system to Orbital Sciences for the company’s launch vehicle and Cygnus capsule, being developed in support of NASA’s Commercial Orbital Transportation Services (COTS) program.\n               “You can draw direct heritage from the F-8 system to the systems that fly the Space Shuttle and the International Space Station, and now we’ve taken that technology into the COTS program. That says a lot for the power of what was done back then,” Sargent says.\n              Szalai recalls countless hours in the desert where Dryden is located, standing up in a lean-to hangar with the F-8 Iron Bird simulator and a computer test set, working out software anomalies, trudging up and down the steps to the cockpit to work with the pilots in training. The hangar was drafty, dusty. Sand slid in under the roll-down door. \n              “One of the values of flight research is that reality meets with dreams and visions,” Szalai says. “They meet and they clash. You have to solve the real world issues. You can’t always take a picture of the spinoff. Sometimes it’s showing that you can do something.”\n            \n             \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              Fly-by-Wire Systems Enable Safer, More Efficient Flight\n            \n            \n              NASA Technology\n              In 1961, not long after NASA received the imperative from President John F. Kennedy to land a man on the Moon within the decade, then-NASA administrator James Webb posed a question to Charles Stark “Doc” Draper, head of the Massachusetts Institute of Technology (MIT) Instrumentation Lab. Webb wanted to know if it was possible to create a guidance system that could lead a man to the Moon and return him safely to Earth.\n                \n              \n              Doc Draper had pioneered the field of inertial navigation—the use of instruments such as gyroscopes and accelerometers to provide guidance for a vehicle—and the Lab had developed the guidance systems for the Nation’s first ballistic missiles and even conducted work in the 1950s on an autonomous probe that could find its way to Mars and back.\n              Doc Draper’s answer was a definitive “Yes.” \n              Known today as Draper Laboratory, an independent, nonprofit institution based in Cambridge, Massachusetts, the MIT Instrumentation Laboratory became the first major contractor for the Apollo program. Working with other contractors, the lab developed the Apollo Primary Guidance, Navigation, and Control System (PGNCS, pronounced “pings”). Consisting of an inertial measurement unit, optical and other components, the system had at its heart the Apollo Guidance Computer. Designed and programmed by the Lab and largely built by Raytheon, the computer would be the brain for both the Apollo Command Module and the Lunar Module that would deliver the first astronauts to the Moon’s surface. To do this, it had to be faultless.\n              “It had to work and it had to work flawlessly. There was no possibility for repair,” says Darryl Sargent, vice president of programs for Draper. \n              And it did. Throughout the course of the Apollo program, the computer never experienced a failure. In addition to enabling the PGNCS system that in turn enabled the Moon landings, the computer also contributed to the rescue of Apollo 13 through the use of a program that helped push the damaged Command Module into a safe course back to Earth. \n              Meanwhile, at NASA’s Flight Research Center in California (now known as Dryden Flight Research Center), aeronautics engineers were asking questions about how computers could contribute to flight on Earth—questions that the Apollo Guidance Computer would help answer. \n              Partnership\n              \n                \n                \n                  \n                \n                \n                  The Primary Guidance, Navigation, and Control System of the Apollo Lunar Module. The display and keyboard (DSKY, pronounced “diskey”) interface used by the astronauts to input commands can be seen in the bottom center of the image. \n                \n              \n              At that point, mechanically controlled aircraft—in which the vehicle’s control surfaces are operated through cables and pushrods connecting the aerodynamic surfaces to the pilot’s control sticks and rudder pedals—were the norm in aviation. In 1970, a Dryden team visited NASA Headquarters proposing an advanced aircraft controlled by an analog fly-by-wire system with no mechanical backup. \n              The idea of flying an aircraft electronically was not a new one. In a fly-by-wire system, a computer collects sensor data from the pilot’s controls and sends those signals via wires to actuators that decode the signals and move the aircraft’s control surfaces accordingly. Dryden researchers had developed significant experience in electronic flight controls through the development of experimental aircraft; in fact, the Lunar Landing Training Vehicle NASA used to train the Apollo spacecraft commanders employed an analog fly-by-wire system with no mechanical backup—making it the first genuine fly-by-wire vehicle. But these systems all used analog computers, as opposed to digital ones. Electronic analog computers use variations in the physical properties of electricity to represent numbers; digital computers use binary code. Though slower for certain functions than their analog counterparts, digital computers can store large quantities of data and can be programmed with complex software. \n              While the actual aircraft the Dryden team proposed proved too futuristic to pursue, the question was raised, “What about a digital fly-by-wire system?” \n              \n                \n                \n                  \n                \n                \n                  In 1994, the Boeing 777 became the second commercial airliner to fly using DFBW. For commercial aircraft, the replacement of heavy mechanical systems with DFBW controls provides greater fuel efficiency or the ability to carry more passengers or cargo.\n                    \n                  Image courtesy of Kevin Koske\n                \n              \n              “The answer was that there were no flight qualified digital computers for airplanes,” says Ken Szalai, then a young engineer at Dryden. An objection was raised by a well-known figure (and former Dryden test pilot) in what was then NASA’s Office of Advanced Research and Technology: Neil Armstrong. He had recently flown to the Moon and back with his life entrusted to the guidance of a digital computer. Szalai approached Draper Laboratory, the architect of the Apollo PGNCS, to see whether it could be adapted to test the feasibility of digital fly-by-wire for aircraft. The answer, again, was “Yes.”\n              Through Armstrong’s support, and that of U.S. Navy Vice Admiral Donald Engen, Dryden acquired a trio of F-8C Crusaders from the Navy and, working with Draper, the Center installed an adapted extra Apollo PGNCS on one of the planes, which became the Digital Fly-by-Wire (DFBW) research aircraft. Another of the F-8s was converted into an “Iron Bird” ground-based simulator for testing the flight software and training pilots, and the third F-8 was used to familiarize test pilots with the aircraft. \n              “The Apollo system wasn’t an ideal configuration for airplane control,” says Philip Felleman, who was the DFBW program manager for Draper. “But it did have one big thing going for it: It was highly reliable.” \n              The DFBW program (also commonly known as the F-8 program) was divided into two phases. In Phase I, the objective was to demonstrate the viability of flying an aircraft by digital computer alone. The first use of an analog fly-by-wire system in an aircraft was in early May of 1972 by the U.S. Air Force YF-4E Control Configured Vehicle. About three weeks later, on May 25, 1972, Gary Krier piloted the DFBW research aircraft on the first flight of an aircraft controlled by digital computer. The plane had no mechanical backup, only a three-computer analog emergency system. The backup system was not needed for that flight, nor any other for the length of the program. \n              \n                More than 30 successful flights later, Phase I finished having proven a digital computer could be used to fly an aircraft. The next question was how to make it practical. Commercial digital computers did not have the reliability of the Apollo Guidance Computer. A DFBW system would require more than just one or even two computers to operate with any acceptable assurance of safety. In Phase II of the DFBW program, Dryden collaborated with Draper, Langley Research Center, and others to create the hardware and software necessary for a highly reliable, fault-tolerant, three-computer DFBW system.\n              \n              \n                \n                \n                  \n                \n                \n                  The Northrop Grumman B-2 Spirit is one of the aircraft designs enabled by DFBW technology.\n                \n              \n              “The big job was to be able to manage the redundancy, to be able to tolerate a failure and still be able to fly,” says Felleman. To do that, Szalai says, “We worked untold hours to develop the logic schemes, and then we had to test it and verify that it worked in all the various combinations.” \n              Draper, meanwhile, was also working with NASA on the guidance, navigation, and control system for an entirely new kind of aircraft: the Space Shuttle. Employing a quad-redundant digital fly-by-wire system, the shuttle benefited from the work done during the DFBW program, which in one case identified a hardware issue with the flight computers (both programs used IBM AP-101s), and in another helped solve a potentially hazardous problem with pilot-induced oscillation that occurred during the final test flight of the Space Shuttle Enterprise. \n              “There was feedback between the programs, mostly from us to the shuttle program because we were doing everything first,” says Felleman. \n              The DFBW program’s final flight occurred on \n                April 2, 1985—the last of more than 200 successful flights that collectively provided the impetus for changing the way aircraft are designed and flown around the world. \n              Benefits\n              “Some of the techniques we developed at that time are still being used, and that spawned the digital fly-by-wire revolution,” says Szalai, who went on to become Dryden’s center director before retiring in 1998. “We communicated with all of the major airframe manufacturers and were able to transfer a lot of the technology.” \n              \n                \n                \n                  \n                \n                \n                  The U.S. Navy’s Seawolf class submarines feature a “swim-by-wire” system adapted by NASA partner Draper Laboratory from the Lab’s work during the DFBW program.\n                \n              \n              The first commercial airliner to fly with DFBW was the Airbus 320 in 1987, followed by Boeing’s 777 in 1994. Today, the technology features in a number of aircraft from both manufacturers. For commercial aircraft, the technology replaces heavy mechanical systems, allowing airlines to benefit from greater fuel efficiency or carry more passengers and cargo. The heightened responsiveness of DFBW-enabled aircraft allows pilots to provide a smoother flight, and the system’s redundancies help ensure safe operation of the vehicle. Mechanical maintenance needs are also reduced, saving costs and time spent on upkeep and repairs of the mechanical systems and reducing the chance of failures. \n              “Now, when you fly any major, large airplane, you’re flying a digital fly-by-wire system based on the technology from the F-8 program,” says Sargent. Even smaller aircraft are now incorporating the technology; in 2005, the Dassault Falcon 7X became the first business jet with a DFBW system.\n              One of the biggest contributions to aviation to emerge from the DFBW program is the ability to support entirely new forms of aircraft, says Szalai. The enhanced control capabilities of a DFBW system allow pilots to fly aerodynamically unstable aircraft that could not be controlled otherwise. While current aircraft are still designed as aerodynamically stable to at least some degree, unstable aircraft promise higher performance—such as increased maneuverability in fighter jets and minimized drag and increased range in civil transport—and future aircraft may capitalize on this benefit.\n              “Digital fly-by-wire has unshackled designers from the rules of the 1950s and 1960s, so you end up with vehicles like the Space Shuttle, the B-2 bomber, and the F-117. You couldn’t have these kinds of aircraft without a fly-by-wire system,” says Szalai. In addition to those, Szalai notes, many other military aircraft benefit from DFBW systems, including the F/A-18 and F-22. The F-16 began with an analog fly-by-wire system—the first production aircraft with fly-by-wire—and later switched to DFBW controls. \n              The benefits of digital computer vehicle control systems as demonstrated by the DFBW program are not limited to the skies, however. The electronic cruise control features found in many automobiles are enabled by drive-by-wire technology, as are antilock braking and electronic stability control systems, both of which significantly enhance safety. Auto and motorcycle manufacturers have also incorporated electronic throttles into their vehicles—the first being the BMW 7 series in 1988—eliminating moving mechanical systems between the accelerator and the engine. \n              For Draper, the outcomes of the DFBW program have served to enhance the Lab’s expertise and reputation in the field of guidance, navigation, and control systems. \n              “What NASA has meant to us is a steady stream of hard problems to work on. The skills we learned and technologies we developed from our work with NASA we then turn around and apply as broadly as possible,” says Sargent. Beyond aircraft, Draper has applied the DFBW technology to a range of unmanned underwater vehicles and the U.S. Navy’s Seawolf class submarines. “A redundant, fault tolerant, ‘swim-by-wire’ system,” Sargent says. And Draper recently delivered a DFBW system to Orbital Sciences for the company’s launch vehicle and Cygnus capsule, being developed in support of NASA’s Commercial Orbital Transportation Services (COTS) program.\n               “You can draw direct heritage from the F-8 system to the systems that fly the Space Shuttle and the International Space Station, and now we’ve taken that technology into the COTS program. That says a lot for the power of what was done back then,” Sargent says.\n              Szalai recalls countless hours in the desert where Dryden is located, standing up in a lean-to hangar with the F-8 Iron Bird simulator and a computer test set, working out software anomalies, trudging up and down the steps to the cockpit to work with the pilots in training. The hangar was drafty, dusty. Sand slid in under the roll-down door. \n              “One of the values of flight research is that reality meets with dreams and visions,” Szalai says. “They meet and they clash. You have to solve the real world issues. You can’t always take a picture of the spinoff. Sometimes it’s showing that you can do something.”\n            \n             \n            \n          \n        \n      \n        \n          \n            \n              Fly-by-Wire Systems Enable Safer, More Efficient Flight\n            \n            \n              NASA Technology\n              In 1961, not long after NASA received the imperative from President John F. Kennedy to land a man on the Moon within the decade, then-NASA administrator James Webb posed a question to Charles Stark “Doc” Draper, head of the Massachusetts Institute of Technology (MIT) Instrumentation Lab. Webb wanted to know if it was possible to create a guidance system that could lead a man to the Moon and return him safely to Earth.\n                \n              \n              Doc Draper had pioneered the field of inertial navigation—the use of instruments such as gyroscopes and accelerometers to provide guidance for a vehicle—and the Lab had developed the guidance systems for the Nation’s first ballistic missiles and even conducted work in the 1950s on an autonomous probe that could find its way to Mars and back.\n              Doc Draper’s answer was a definitive “Yes.” \n              Known today as Draper Laboratory, an independent, nonprofit institution based in Cambridge, Massachusetts, the MIT Instrumentation Laboratory became the first major contractor for the Apollo program. Working with other contractors, the lab developed the Apollo Primary Guidance, Navigation, and Control System (PGNCS, pronounced “pings”). Consisting of an inertial measurement unit, optical and other components, the system had at its heart the Apollo Guidance Computer. Designed and programmed by the Lab and largely built by Raytheon, the computer would be the brain for both the Apollo Command Module and the Lunar Module that would deliver the first astronauts to the Moon’s surface. To do this, it had to be faultless.\n              “It had to work and it had to work flawlessly. There was no possibility for repair,” says Darryl Sargent, vice president of programs for Draper. \n              And it did. Throughout the course of the Apollo program, the computer never experienced a failure. In addition to enabling the PGNCS system that in turn enabled the Moon landings, the computer also contributed to the rescue of Apollo 13 through the use of a program that helped push the damaged Command Module into a safe course back to Earth. \n              Meanwhile, at NASA’s Flight Research Center in California (now known as Dryden Flight Research Center), aeronautics engineers were asking questions about how computers could contribute to flight on Earth—questions that the Apollo Guidance Computer would help answer. \n              Partnership\n              \n                \n                \n                  \n                \n                \n                  The Primary Guidance, Navigation, and Control System of the Apollo Lunar Module. The display and keyboard (DSKY, pronounced “diskey”) interface used by the astronauts to input commands can be seen in the bottom center of the image. \n                \n              \n              At that point, mechanically controlled aircraft—in which the vehicle’s control surfaces are operated through cables and pushrods connecting the aerodynamic surfaces to the pilot’s control sticks and rudder pedals—were the norm in aviation. In 1970, a Dryden team visited NASA Headquarters proposing an advanced aircraft controlled by an analog fly-by-wire system with no mechanical backup. \n              The idea of flying an aircraft electronically was not a new one. In a fly-by-wire system, a computer collects sensor data from the pilot’s controls and sends those signals via wires to actuators that decode the signals and move the aircraft’s control surfaces accordingly. Dryden researchers had developed significant experience in electronic flight controls through the development of experimental aircraft; in fact, the Lunar Landing Training Vehicle NASA used to train the Apollo spacecraft commanders employed an analog fly-by-wire system with no mechanical backup—making it the first genuine fly-by-wire vehicle. But these systems all used analog computers, as opposed to digital ones. Electronic analog computers use variations in the physical properties of electricity to represent numbers; digital computers use binary code. Though slower for certain functions than their analog counterparts, digital computers can store large quantities of data and can be programmed with complex software. \n              While the actual aircraft the Dryden team proposed proved too futuristic to pursue, the question was raised, “What about a digital fly-by-wire system?” \n              \n                \n                \n                  \n                \n                \n                  In 1994, the Boeing 777 became the second commercial airliner to fly using DFBW. For commercial aircraft, the replacement of heavy mechanical systems with DFBW controls provides greater fuel efficiency or the ability to carry more passengers or cargo.\n                    \n                  Image courtesy of Kevin Koske\n                \n              \n              “The answer was that there were no flight qualified digital computers for airplanes,” says Ken Szalai, then a young engineer at Dryden. An objection was raised by a well-known figure (and former Dryden test pilot) in what was then NASA’s Office of Advanced Research and Technology: Neil Armstrong. He had recently flown to the Moon and back with his life entrusted to the guidance of a digital computer. Szalai approached Draper Laboratory, the architect of the Apollo PGNCS, to see whether it could be adapted to test the feasibility of digital fly-by-wire for aircraft. The answer, again, was “Yes.”\n              Through Armstrong’s support, and that of U.S. Navy Vice Admiral Donald Engen, Dryden acquired a trio of F-8C Crusaders from the Navy and, working with Draper, the Center installed an adapted extra Apollo PGNCS on one of the planes, which became the Digital Fly-by-Wire (DFBW) research aircraft. Another of the F-8s was converted into an “Iron Bird” ground-based simulator for testing the flight software and training pilots, and the third F-8 was used to familiarize test pilots with the aircraft. \n              “The Apollo system wasn’t an ideal configuration for airplane control,” says Philip Felleman, who was the DFBW program manager for Draper. “But it did have one big thing going for it: It was highly reliable.” \n              The DFBW program (also commonly known as the F-8 program) was divided into two phases. In Phase I, the objective was to demonstrate the viability of flying an aircraft by digital computer alone. The first use of an analog fly-by-wire system in an aircraft was in early May of 1972 by the U.S. Air Force YF-4E Control Configured Vehicle. About three weeks later, on May 25, 1972, Gary Krier piloted the DFBW research aircraft on the first flight of an aircraft controlled by digital computer. The plane had no mechanical backup, only a three-computer analog emergency system. The backup system was not needed for that flight, nor any other for the length of the program. \n              \n                More than 30 successful flights later, Phase I finished having proven a digital computer could be used to fly an aircraft. The next question was how to make it practical. Commercial digital computers did not have the reliability of the Apollo Guidance Computer. A DFBW system would require more than just one or even two computers to operate with any acceptable assurance of safety. In Phase II of the DFBW program, Dryden collaborated with Draper, Langley Research Center, and others to create the hardware and software necessary for a highly reliable, fault-tolerant, three-computer DFBW system.\n              \n              \n                \n                \n                  \n                \n                \n                  The Northrop Grumman B-2 Spirit is one of the aircraft designs enabled by DFBW technology.\n                \n              \n              “The big job was to be able to manage the redundancy, to be able to tolerate a failure and still be able to fly,” says Felleman. To do that, Szalai says, “We worked untold hours to develop the logic schemes, and then we had to test it and verify that it worked in all the various combinations.” \n              Draper, meanwhile, was also working with NASA on the guidance, navigation, and control system for an entirely new kind of aircraft: the Space Shuttle. Employing a quad-redundant digital fly-by-wire system, the shuttle benefited from the work done during the DFBW program, which in one case identified a hardware issue with the flight computers (both programs used IBM AP-101s), and in another helped solve a potentially hazardous problem with pilot-induced oscillation that occurred during the final test flight of the Space Shuttle Enterprise. \n              “There was feedback between the programs, mostly from us to the shuttle program because we were doing everything first,” says Felleman. \n              The DFBW program’s final flight occurred on \n                April 2, 1985—the last of more than 200 successful flights that collectively provided the impetus for changing the way aircraft are designed and flown around the world. \n              Benefits\n              “Some of the techniques we developed at that time are still being used, and that spawned the digital fly-by-wire revolution,” says Szalai, who went on to become Dryden’s center director before retiring in 1998. “We communicated with all of the major airframe manufacturers and were able to transfer a lot of the technology.” \n              \n                \n                \n                  \n                \n                \n                  The U.S. Navy’s Seawolf class submarines feature a “swim-by-wire” system adapted by NASA partner Draper Laboratory from the Lab’s work during the DFBW program.\n                \n              \n              The first commercial airliner to fly with DFBW was the Airbus 320 in 1987, followed by Boeing’s 777 in 1994. Today, the technology features in a number of aircraft from both manufacturers. For commercial aircraft, the technology replaces heavy mechanical systems, allowing airlines to benefit from greater fuel efficiency or carry more passengers and cargo. The heightened responsiveness of DFBW-enabled aircraft allows pilots to provide a smoother flight, and the system’s redundancies help ensure safe operation of the vehicle. Mechanical maintenance needs are also reduced, saving costs and time spent on upkeep and repairs of the mechanical systems and reducing the chance of failures. \n              “Now, when you fly any major, large airplane, you’re flying a digital fly-by-wire system based on the technology from the F-8 program,” says Sargent. Even smaller aircraft are now incorporating the technology; in 2005, the Dassault Falcon 7X became the first business jet with a DFBW system.\n              One of the biggest contributions to aviation to emerge from the DFBW program is the ability to support entirely new forms of aircraft, says Szalai. The enhanced control capabilities of a DFBW system allow pilots to fly aerodynamically unstable aircraft that could not be controlled otherwise. While current aircraft are still designed as aerodynamically stable to at least some degree, unstable aircraft promise higher performance—such as increased maneuverability in fighter jets and minimized drag and increased range in civil transport—and future aircraft may capitalize on this benefit.\n              “Digital fly-by-wire has unshackled designers from the rules of the 1950s and 1960s, so you end up with vehicles like the Space Shuttle, the B-2 bomber, and the F-117. You couldn’t have these kinds of aircraft without a fly-by-wire system,” says Szalai. In addition to those, Szalai notes, many other military aircraft benefit from DFBW systems, including the F/A-18 and F-22. The F-16 began with an analog fly-by-wire system—the first production aircraft with fly-by-wire—and later switched to DFBW controls. \n              The benefits of digital computer vehicle control systems as demonstrated by the DFBW program are not limited to the skies, however. The electronic cruise control features found in many automobiles are enabled by drive-by-wire technology, as are antilock braking and electronic stability control systems, both of which significantly enhance safety. Auto and motorcycle manufacturers have also incorporated electronic throttles into their vehicles—the first being the BMW 7 series in 1988—eliminating moving mechanical systems between the accelerator and the engine. \n              For Draper, the outcomes of the DFBW program have served to enhance the Lab’s expertise and reputation in the field of guidance, navigation, and control systems. \n              “What NASA has meant to us is a steady stream of hard problems to work on. The skills we learned and technologies we developed from our work with NASA we then turn around and apply as broadly as possible,” says Sargent. Beyond aircraft, Draper has applied the DFBW technology to a range of unmanned underwater vehicles and the U.S. Navy’s Seawolf class submarines. “A redundant, fault tolerant, ‘swim-by-wire’ system,” Sargent says. And Draper recently delivered a DFBW system to Orbital Sciences for the company’s launch vehicle and Cygnus capsule, being developed in support of NASA’s Commercial Orbital Transportation Services (COTS) program.\n               “You can draw direct heritage from the F-8 system to the systems that fly the Space Shuttle and the International Space Station, and now we’ve taken that technology into the COTS program. That says a lot for the power of what was done back then,” Sargent says.\n              Szalai recalls countless hours in the desert where Dryden is located, standing up in a lean-to hangar with the F-8 Iron Bird simulator and a computer test set, working out software anomalies, trudging up and down the steps to the cockpit to work with the pilots in training. The hangar was drafty, dusty. Sand slid in under the roll-down door. \n              “One of the values of flight research is that reality meets with dreams and visions,” Szalai says. “They meet and they clash. You have to solve the real world issues. You can’t always take a picture of the spinoff. Sometimes it’s showing that you can do something.”\n            \n             \n            \n          \n        \n          \n            \n              Fly-by-Wire Systems Enable Safer, More Efficient Flight\n            \n            \n              NASA Technology\n              In 1961, not long after NASA received the imperative from President John F. Kennedy to land a man on the Moon within the decade, then-NASA administrator James Webb posed a question to Charles Stark “Doc” Draper, head of the Massachusetts Institute of Technology (MIT) Instrumentation Lab. Webb wanted to know if it was possible to create a guidance system that could lead a man to the Moon and return him safely to Earth.\n                \n              \n              Doc Draper had pioneered the field of inertial navigation—the use of instruments such as gyroscopes and accelerometers to provide guidance for a vehicle—and the Lab had developed the guidance systems for the Nation’s first ballistic missiles and even conducted work in the 1950s on an autonomous probe that could find its way to Mars and back.\n              Doc Draper’s answer was a definitive “Yes.” \n              Known today as Draper Laboratory, an independent, nonprofit institution based in Cambridge, Massachusetts, the MIT Instrumentation Laboratory became the first major contractor for the Apollo program. Working with other contractors, the lab developed the Apollo Primary Guidance, Navigation, and Control System (PGNCS, pronounced “pings”). Consisting of an inertial measurement unit, optical and other components, the system had at its heart the Apollo Guidance Computer. Designed and programmed by the Lab and largely built by Raytheon, the computer would be the brain for both the Apollo Command Module and the Lunar Module that would deliver the first astronauts to the Moon’s surface. To do this, it had to be faultless.\n              “It had to work and it had to work flawlessly. There was no possibility for repair,” says Darryl Sargent, vice president of programs for Draper. \n              And it did. Throughout the course of the Apollo program, the computer never experienced a failure. In addition to enabling the PGNCS system that in turn enabled the Moon landings, the computer also contributed to the rescue of Apollo 13 through the use of a program that helped push the damaged Command Module into a safe course back to Earth. \n              Meanwhile, at NASA’s Flight Research Center in California (now known as Dryden Flight Research Center), aeronautics engineers were asking questions about how computers could contribute to flight on Earth—questions that the Apollo Guidance Computer would help answer. \n              Partnership\n              \n                \n                \n                  \n                \n                \n                  The Primary Guidance, Navigation, and Control System of the Apollo Lunar Module. The display and keyboard (DSKY, pronounced “diskey”) interface used by the astronauts to input commands can be seen in the bottom center of the image. \n                \n              \n              At that point, mechanically controlled aircraft—in which the vehicle’s control surfaces are operated through cables and pushrods connecting the aerodynamic surfaces to the pilot’s control sticks and rudder pedals—were the norm in aviation. In 1970, a Dryden team visited NASA Headquarters proposing an advanced aircraft controlled by an analog fly-by-wire system with no mechanical backup. \n              The idea of flying an aircraft electronically was not a new one. In a fly-by-wire system, a computer collects sensor data from the pilot’s controls and sends those signals via wires to actuators that decode the signals and move the aircraft’s control surfaces accordingly. Dryden researchers had developed significant experience in electronic flight controls through the development of experimental aircraft; in fact, the Lunar Landing Training Vehicle NASA used to train the Apollo spacecraft commanders employed an analog fly-by-wire system with no mechanical backup—making it the first genuine fly-by-wire vehicle. But these systems all used analog computers, as opposed to digital ones. Electronic analog computers use variations in the physical properties of electricity to represent numbers; digital computers use binary code. Though slower for certain functions than their analog counterparts, digital computers can store large quantities of data and can be programmed with complex software. \n              While the actual aircraft the Dryden team proposed proved too futuristic to pursue, the question was raised, “What about a digital fly-by-wire system?” \n              \n                \n                \n                  \n                \n                \n                  In 1994, the Boeing 777 became the second commercial airliner to fly using DFBW. For commercial aircraft, the replacement of heavy mechanical systems with DFBW controls provides greater fuel efficiency or the ability to carry more passengers or cargo.\n                    \n                  Image courtesy of Kevin Koske\n                \n              \n              “The answer was that there were no flight qualified digital computers for airplanes,” says Ken Szalai, then a young engineer at Dryden. An objection was raised by a well-known figure (and former Dryden test pilot) in what was then NASA’s Office of Advanced Research and Technology: Neil Armstrong. He had recently flown to the Moon and back with his life entrusted to the guidance of a digital computer. Szalai approached Draper Laboratory, the architect of the Apollo PGNCS, to see whether it could be adapted to test the feasibility of digital fly-by-wire for aircraft. The answer, again, was “Yes.”\n              Through Armstrong’s support, and that of U.S. Navy Vice Admiral Donald Engen, Dryden acquired a trio of F-8C Crusaders from the Navy and, working with Draper, the Center installed an adapted extra Apollo PGNCS on one of the planes, which became the Digital Fly-by-Wire (DFBW) research aircraft. Another of the F-8s was converted into an “Iron Bird” ground-based simulator for testing the flight software and training pilots, and the third F-8 was used to familiarize test pilots with the aircraft. \n              “The Apollo system wasn’t an ideal configuration for airplane control,” says Philip Felleman, who was the DFBW program manager for Draper. “But it did have one big thing going for it: It was highly reliable.” \n              The DFBW program (also commonly known as the F-8 program) was divided into two phases. In Phase I, the objective was to demonstrate the viability of flying an aircraft by digital computer alone. The first use of an analog fly-by-wire system in an aircraft was in early May of 1972 by the U.S. Air Force YF-4E Control Configured Vehicle. About three weeks later, on May 25, 1972, Gary Krier piloted the DFBW research aircraft on the first flight of an aircraft controlled by digital computer. The plane had no mechanical backup, only a three-computer analog emergency system. The backup system was not needed for that flight, nor any other for the length of the program. \n              \n                More than 30 successful flights later, Phase I finished having proven a digital computer could be used to fly an aircraft. The next question was how to make it practical. Commercial digital computers did not have the reliability of the Apollo Guidance Computer. A DFBW system would require more than just one or even two computers to operate with any acceptable assurance of safety. In Phase II of the DFBW program, Dryden collaborated with Draper, Langley Research Center, and others to create the hardware and software necessary for a highly reliable, fault-tolerant, three-computer DFBW system.\n              \n              \n                \n                \n                  \n                \n                \n                  The Northrop Grumman B-2 Spirit is one of the aircraft designs enabled by DFBW technology.\n                \n              \n              “The big job was to be able to manage the redundancy, to be able to tolerate a failure and still be able to fly,” says Felleman. To do that, Szalai says, “We worked untold hours to develop the logic schemes, and then we had to test it and verify that it worked in all the various combinations.” \n              Draper, meanwhile, was also working with NASA on the guidance, navigation, and control system for an entirely new kind of aircraft: the Space Shuttle. Employing a quad-redundant digital fly-by-wire system, the shuttle benefited from the work done during the DFBW program, which in one case identified a hardware issue with the flight computers (both programs used IBM AP-101s), and in another helped solve a potentially hazardous problem with pilot-induced oscillation that occurred during the final test flight of the Space Shuttle Enterprise. \n              “There was feedback between the programs, mostly from us to the shuttle program because we were doing everything first,” says Felleman. \n              The DFBW program’s final flight occurred on \n                April 2, 1985—the last of more than 200 successful flights that collectively provided the impetus for changing the way aircraft are designed and flown around the world. \n              Benefits\n              “Some of the techniques we developed at that time are still being used, and that spawned the digital fly-by-wire revolution,” says Szalai, who went on to become Dryden’s center director before retiring in 1998. “We communicated with all of the major airframe manufacturers and were able to transfer a lot of the technology.” \n              \n                \n                \n                  \n                \n                \n                  The U.S. Navy’s Seawolf class submarines feature a “swim-by-wire” system adapted by NASA partner Draper Laboratory from the Lab’s work during the DFBW program.\n                \n              \n              The first commercial airliner to fly with DFBW was the Airbus 320 in 1987, followed by Boeing’s 777 in 1994. Today, the technology features in a number of aircraft from both manufacturers. For commercial aircraft, the technology replaces heavy mechanical systems, allowing airlines to benefit from greater fuel efficiency or carry more passengers and cargo. The heightened responsiveness of DFBW-enabled aircraft allows pilots to provide a smoother flight, and the system’s redundancies help ensure safe operation of the vehicle. Mechanical maintenance needs are also reduced, saving costs and time spent on upkeep and repairs of the mechanical systems and reducing the chance of failures. \n              “Now, when you fly any major, large airplane, you’re flying a digital fly-by-wire system based on the technology from the F-8 program,” says Sargent. Even smaller aircraft are now incorporating the technology; in 2005, the Dassault Falcon 7X became the first business jet with a DFBW system.\n              One of the biggest contributions to aviation to emerge from the DFBW program is the ability to support entirely new forms of aircraft, says Szalai. The enhanced control capabilities of a DFBW system allow pilots to fly aerodynamically unstable aircraft that could not be controlled otherwise. While current aircraft are still designed as aerodynamically stable to at least some degree, unstable aircraft promise higher performance—such as increased maneuverability in fighter jets and minimized drag and increased range in civil transport—and future aircraft may capitalize on this benefit.\n              “Digital fly-by-wire has unshackled designers from the rules of the 1950s and 1960s, so you end up with vehicles like the Space Shuttle, the B-2 bomber, and the F-117. You couldn’t have these kinds of aircraft without a fly-by-wire system,” says Szalai. In addition to those, Szalai notes, many other military aircraft benefit from DFBW systems, including the F/A-18 and F-22. The F-16 began with an analog fly-by-wire system—the first production aircraft with fly-by-wire—and later switched to DFBW controls. \n              The benefits of digital computer vehicle control systems as demonstrated by the DFBW program are not limited to the skies, however. The electronic cruise control features found in many automobiles are enabled by drive-by-wire technology, as are antilock braking and electronic stability control systems, both of which significantly enhance safety. Auto and motorcycle manufacturers have also incorporated electronic throttles into their vehicles—the first being the BMW 7 series in 1988—eliminating moving mechanical systems between the accelerator and the engine. \n              For Draper, the outcomes of the DFBW program have served to enhance the Lab’s expertise and reputation in the field of guidance, navigation, and control systems. \n              “What NASA has meant to us is a steady stream of hard problems to work on. The skills we learned and technologies we developed from our work with NASA we then turn around and apply as broadly as possible,” says Sargent. Beyond aircraft, Draper has applied the DFBW technology to a range of unmanned underwater vehicles and the U.S. Navy’s Seawolf class submarines. “A redundant, fault tolerant, ‘swim-by-wire’ system,” Sargent says. And Draper recently delivered a DFBW system to Orbital Sciences for the company’s launch vehicle and Cygnus capsule, being developed in support of NASA’s Commercial Orbital Transportation Services (COTS) program.\n               “You can draw direct heritage from the F-8 system to the systems that fly the Space Shuttle and the International Space Station, and now we’ve taken that technology into the COTS program. That says a lot for the power of what was done back then,” Sargent says.\n              Szalai recalls countless hours in the desert where Dryden is located, standing up in a lean-to hangar with the F-8 Iron Bird simulator and a computer test set, working out software anomalies, trudging up and down the steps to the cockpit to work with the pilots in training. The hangar was drafty, dusty. Sand slid in under the roll-down door. \n              “One of the values of flight research is that reality meets with dreams and visions,” Szalai says. “They meet and they clash. You have to solve the real world issues. You can’t always take a picture of the spinoff. Sometimes it’s showing that you can do something.”\n            \n             \n            \n          \n            \n              Fly-by-Wire Systems Enable Safer, More Efficient Flight\n            \n            \n              NASA Technology\n              In 1961, not long after NASA received the imperative from President John F. Kennedy to land a man on the Moon within the decade, then-NASA administrator James Webb posed a question to Charles Stark “Doc” Draper, head of the Massachusetts Institute of Technology (MIT) Instrumentation Lab. Webb wanted to know if it was possible to create a guidance system that could lead a man to the Moon and return him safely to Earth.\n                \n              \n              Doc Draper had pioneered the field of inertial navigation—the use of instruments such as gyroscopes and accelerometers to provide guidance for a vehicle—and the Lab had developed the guidance systems for the Nation’s first ballistic missiles and even conducted work in the 1950s on an autonomous probe that could find its way to Mars and back.\n              Doc Draper’s answer was a definitive “Yes.” \n              Known today as Draper Laboratory, an independent, nonprofit institution based in Cambridge, Massachusetts, the MIT Instrumentation Laboratory became the first major contractor for the Apollo program. Working with other contractors, the lab developed the Apollo Primary Guidance, Navigation, and Control System (PGNCS, pronounced “pings”). Consisting of an inertial measurement unit, optical and other components, the system had at its heart the Apollo Guidance Computer. Designed and programmed by the Lab and largely built by Raytheon, the computer would be the brain for both the Apollo Command Module and the Lunar Module that would deliver the first astronauts to the Moon’s surface. To do this, it had to be faultless.\n              “It had to work and it had to work flawlessly. There was no possibility for repair,” says Darryl Sargent, vice president of programs for Draper. \n              And it did. Throughout the course of the Apollo program, the computer never experienced a failure. In addition to enabling the PGNCS system that in turn enabled the Moon landings, the computer also contributed to the rescue of Apollo 13 through the use of a program that helped push the damaged Command Module into a safe course back to Earth. \n              Meanwhile, at NASA’s Flight Research Center in California (now known as Dryden Flight Research Center), aeronautics engineers were asking questions about how computers could contribute to flight on Earth—questions that the Apollo Guidance Computer would help answer. \n              Partnership\n              \n                \n                \n                  \n                \n                \n                  The Primary Guidance, Navigation, and Control System of the Apollo Lunar Module. The display and keyboard (DSKY, pronounced “diskey”) interface used by the astronauts to input commands can be seen in the bottom center of the image. \n                \n              \n              At that point, mechanically controlled aircraft—in which the vehicle’s control surfaces are operated through cables and pushrods connecting the aerodynamic surfaces to the pilot’s control sticks and rudder pedals—were the norm in aviation. In 1970, a Dryden team visited NASA Headquarters proposing an advanced aircraft controlled by an analog fly-by-wire system with no mechanical backup. \n              The idea of flying an aircraft electronically was not a new one. In a fly-by-wire system, a computer collects sensor data from the pilot’s controls and sends those signals via wires to actuators that decode the signals and move the aircraft’s control surfaces accordingly. Dryden researchers had developed significant experience in electronic flight controls through the development of experimental aircraft; in fact, the Lunar Landing Training Vehicle NASA used to train the Apollo spacecraft commanders employed an analog fly-by-wire system with no mechanical backup—making it the first genuine fly-by-wire vehicle. But these systems all used analog computers, as opposed to digital ones. Electronic analog computers use variations in the physical properties of electricity to represent numbers; digital computers use binary code. Though slower for certain functions than their analog counterparts, digital computers can store large quantities of data and can be programmed with complex software. \n              While the actual aircraft the Dryden team proposed proved too futuristic to pursue, the question was raised, “What about a digital fly-by-wire system?” \n              \n                \n                \n                  \n                \n                \n                  In 1994, the Boeing 777 became the second commercial airliner to fly using DFBW. For commercial aircraft, the replacement of heavy mechanical systems with DFBW controls provides greater fuel efficiency or the ability to carry more passengers or cargo.\n                    \n                  Image courtesy of Kevin Koske\n                \n              \n              “The answer was that there were no flight qualified digital computers for airplanes,” says Ken Szalai, then a young engineer at Dryden. An objection was raised by a well-known figure (and former Dryden test pilot) in what was then NASA’s Office of Advanced Research and Technology: Neil Armstrong. He had recently flown to the Moon and back with his life entrusted to the guidance of a digital computer. Szalai approached Draper Laboratory, the architect of the Apollo PGNCS, to see whether it could be adapted to test the feasibility of digital fly-by-wire for aircraft. The answer, again, was “Yes.”\n              Through Armstrong’s support, and that of U.S. Navy Vice Admiral Donald Engen, Dryden acquired a trio of F-8C Crusaders from the Navy and, working with Draper, the Center installed an adapted extra Apollo PGNCS on one of the planes, which became the Digital Fly-by-Wire (DFBW) research aircraft. Another of the F-8s was converted into an “Iron Bird” ground-based simulator for testing the flight software and training pilots, and the third F-8 was used to familiarize test pilots with the aircraft. \n              “The Apollo system wasn’t an ideal configuration for airplane control,” says Philip Felleman, who was the DFBW program manager for Draper. “But it did have one big thing going for it: It was highly reliable.” \n              The DFBW program (also commonly known as the F-8 program) was divided into two phases. In Phase I, the objective was to demonstrate the viability of flying an aircraft by digital computer alone. The first use of an analog fly-by-wire system in an aircraft was in early May of 1972 by the U.S. Air Force YF-4E Control Configured Vehicle. About three weeks later, on May 25, 1972, Gary Krier piloted the DFBW research aircraft on the first flight of an aircraft controlled by digital computer. The plane had no mechanical backup, only a three-computer analog emergency system. The backup system was not needed for that flight, nor any other for the length of the program. \n              \n                More than 30 successful flights later, Phase I finished having proven a digital computer could be used to fly an aircraft. The next question was how to make it practical. Commercial digital computers did not have the reliability of the Apollo Guidance Computer. A DFBW system would require more than just one or even two computers to operate with any acceptable assurance of safety. In Phase II of the DFBW program, Dryden collaborated with Draper, Langley Research Center, and others to create the hardware and software necessary for a highly reliable, fault-tolerant, three-computer DFBW system.\n              \n              \n                \n                \n                  \n                \n                \n                  The Northrop Grumman B-2 Spirit is one of the aircraft designs enabled by DFBW technology.\n                \n              \n              “The big job was to be able to manage the redundancy, to be able to tolerate a failure and still be able to fly,” says Felleman. To do that, Szalai says, “We worked untold hours to develop the logic schemes, and then we had to test it and verify that it worked in all the various combinations.” \n              Draper, meanwhile, was also working with NASA on the guidance, navigation, and control system for an entirely new kind of aircraft: the Space Shuttle. Employing a quad-redundant digital fly-by-wire system, the shuttle benefited from the work done during the DFBW program, which in one case identified a hardware issue with the flight computers (both programs used IBM AP-101s), and in another helped solve a potentially hazardous problem with pilot-induced oscillation that occurred during the final test flight of the Space Shuttle Enterprise. \n              “There was feedback between the programs, mostly from us to the shuttle program because we were doing everything first,” says Felleman. \n              The DFBW program’s final flight occurred on \n                April 2, 1985—the last of more than 200 successful flights that collectively provided the impetus for changing the way aircraft are designed and flown around the world. \n              Benefits\n              “Some of the techniques we developed at that time are still being used, and that spawned the digital fly-by-wire revolution,” says Szalai, who went on to become Dryden’s center director before retiring in 1998. “We communicated with all of the major airframe manufacturers and were able to transfer a lot of the technology.” \n              \n                \n                \n                  \n                \n                \n                  The U.S. Navy’s Seawolf class submarines feature a “swim-by-wire” system adapted by NASA partner Draper Laboratory from the Lab’s work during the DFBW program.\n                \n              \n              The first commercial airliner to fly with DFBW was the Airbus 320 in 1987, followed by Boeing’s 777 in 1994. Today, the technology features in a number of aircraft from both manufacturers. For commercial aircraft, the technology replaces heavy mechanical systems, allowing airlines to benefit from greater fuel efficiency or carry more passengers and cargo. The heightened responsiveness of DFBW-enabled aircraft allows pilots to provide a smoother flight, and the system’s redundancies help ensure safe operation of the vehicle. Mechanical maintenance needs are also reduced, saving costs and time spent on upkeep and repairs of the mechanical systems and reducing the chance of failures. \n              “Now, when you fly any major, large airplane, you’re flying a digital fly-by-wire system based on the technology from the F-8 program,” says Sargent. Even smaller aircraft are now incorporating the technology; in 2005, the Dassault Falcon 7X became the first business jet with a DFBW system.\n              One of the biggest contributions to aviation to emerge from the DFBW program is the ability to support entirely new forms of aircraft, says Szalai. The enhanced control capabilities of a DFBW system allow pilots to fly aerodynamically unstable aircraft that could not be controlled otherwise. While current aircraft are still designed as aerodynamically stable to at least some degree, unstable aircraft promise higher performance—such as increased maneuverability in fighter jets and minimized drag and increased range in civil transport—and future aircraft may capitalize on this benefit.\n              “Digital fly-by-wire has unshackled designers from the rules of the 1950s and 1960s, so you end up with vehicles like the Space Shuttle, the B-2 bomber, and the F-117. You couldn’t have these kinds of aircraft without a fly-by-wire system,” says Szalai. In addition to those, Szalai notes, many other military aircraft benefit from DFBW systems, including the F/A-18 and F-22. The F-16 began with an analog fly-by-wire system—the first production aircraft with fly-by-wire—and later switched to DFBW controls. \n              The benefits of digital computer vehicle control systems as demonstrated by the DFBW program are not limited to the skies, however. The electronic cruise control features found in many automobiles are enabled by drive-by-wire technology, as are antilock braking and electronic stability control systems, both of which significantly enhance safety. Auto and motorcycle manufacturers have also incorporated electronic throttles into their vehicles—the first being the BMW 7 series in 1988—eliminating moving mechanical systems between the accelerator and the engine. \n              For Draper, the outcomes of the DFBW program have served to enhance the Lab’s expertise and reputation in the field of guidance, navigation, and control systems. \n              “What NASA has meant to us is a steady stream of hard problems to work on. The skills we learned and technologies we developed from our work with NASA we then turn around and apply as broadly as possible,” says Sargent. Beyond aircraft, Draper has applied the DFBW technology to a range of unmanned underwater vehicles and the U.S. Navy’s Seawolf class submarines. “A redundant, fault tolerant, ‘swim-by-wire’ system,” Sargent says. And Draper recently delivered a DFBW system to Orbital Sciences for the company’s launch vehicle and Cygnus capsule, being developed in support of NASA’s Commercial Orbital Transportation Services (COTS) program.\n               “You can draw direct heritage from the F-8 system to the systems that fly the Space Shuttle and the International Space Station, and now we’ve taken that technology into the COTS program. That says a lot for the power of what was done back then,” Sargent says.\n              Szalai recalls countless hours in the desert where Dryden is located, standing up in a lean-to hangar with the F-8 Iron Bird simulator and a computer test set, working out software anomalies, trudging up and down the steps to the cockpit to work with the pilots in training. The hangar was drafty, dusty. Sand slid in under the roll-down door. \n              “One of the values of flight research is that reality meets with dreams and visions,” Szalai says. “They meet and they clash. You have to solve the real world issues. You can’t always take a picture of the spinoff. Sometimes it’s showing that you can do something.”\n            \n             \n            \n              Fly-by-Wire Systems Enable Safer, More Efficient Flight\n            \n              NASA Technology\n              In 1961, not long after NASA received the imperative from President John F. Kennedy to land a man on the Moon within the decade, then-NASA administrator James Webb posed a question to Charles Stark “Doc” Draper, head of the Massachusetts Institute of Technology (MIT) Instrumentation Lab. Webb wanted to know if it was possible to create a guidance system that could lead a man to the Moon and return him safely to Earth.\n                \n              \n              Doc Draper had pioneered the field of inertial navigation—the use of instruments such as gyroscopes and accelerometers to provide guidance for a vehicle—and the Lab had developed the guidance systems for the Nation’s first ballistic missiles and even conducted work in the 1950s on an autonomous probe that could find its way to Mars and back.\n              Doc Draper’s answer was a definitive “Yes.” \n              Known today as Draper Laboratory, an independent, nonprofit institution based in Cambridge, Massachusetts, the MIT Instrumentation Laboratory became the first major contractor for the Apollo program. Working with other contractors, the lab developed the Apollo Primary Guidance, Navigation, and Control System (PGNCS, pronounced “pings”). Consisting of an inertial measurement unit, optical and other components, the system had at its heart the Apollo Guidance Computer. Designed and programmed by the Lab and largely built by Raytheon, the computer would be the brain for both the Apollo Command Module and the Lunar Module that would deliver the first astronauts to the Moon’s surface. To do this, it had to be faultless.\n              “It had to work and it had to work flawlessly. There was no possibility for repair,” says Darryl Sargent, vice president of programs for Draper. \n              And it did. Throughout the course of the Apollo program, the computer never experienced a failure. In addition to enabling the PGNCS system that in turn enabled the Moon landings, the computer also contributed to the rescue of Apollo 13 through the use of a program that helped push the damaged Command Module into a safe course back to Earth. \n              Meanwhile, at NASA’s Flight Research Center in California (now known as Dryden Flight Research Center), aeronautics engineers were asking questions about how computers could contribute to flight on Earth—questions that the Apollo Guidance Computer would help answer. \n              Partnership\n              \n                \n                \n                  \n                \n                \n                  The Primary Guidance, Navigation, and Control System of the Apollo Lunar Module. The display and keyboard (DSKY, pronounced “diskey”) interface used by the astronauts to input commands can be seen in the bottom center of the image. \n                \n              \n              At that point, mechanically controlled aircraft—in which the vehicle’s control surfaces are operated through cables and pushrods connecting the aerodynamic surfaces to the pilot’s control sticks and rudder pedals—were the norm in aviation. In 1970, a Dryden team visited NASA Headquarters proposing an advanced aircraft controlled by an analog fly-by-wire system with no mechanical backup. \n              The idea of flying an aircraft electronically was not a new one. In a fly-by-wire system, a computer collects sensor data from the pilot’s controls and sends those signals via wires to actuators that decode the signals and move the aircraft’s control surfaces accordingly. Dryden researchers had developed significant experience in electronic flight controls through the development of experimental aircraft; in fact, the Lunar Landing Training Vehicle NASA used to train the Apollo spacecraft commanders employed an analog fly-by-wire system with no mechanical backup—making it the first genuine fly-by-wire vehicle. But these systems all used analog computers, as opposed to digital ones. Electronic analog computers use variations in the physical properties of electricity to represent numbers; digital computers use binary code. Though slower for certain functions than their analog counterparts, digital computers can store large quantities of data and can be programmed with complex software. \n              While the actual aircraft the Dryden team proposed proved too futuristic to pursue, the question was raised, “What about a digital fly-by-wire system?” \n              \n                \n                \n                  \n                \n                \n                  In 1994, the Boeing 777 became the second commercial airliner to fly using DFBW. For commercial aircraft, the replacement of heavy mechanical systems with DFBW controls provides greater fuel efficiency or the ability to carry more passengers or cargo.\n                    \n                  Image courtesy of Kevin Koske\n                \n              \n              “The answer was that there were no flight qualified digital computers for airplanes,” says Ken Szalai, then a young engineer at Dryden. An objection was raised by a well-known figure (and former Dryden test pilot) in what was then NASA’s Office of Advanced Research and Technology: Neil Armstrong. He had recently flown to the Moon and back with his life entrusted to the guidance of a digital computer. Szalai approached Draper Laboratory, the architect of the Apollo PGNCS, to see whether it could be adapted to test the feasibility of digital fly-by-wire for aircraft. The answer, again, was “Yes.”\n              Through Armstrong’s support, and that of U.S. Navy Vice Admiral Donald Engen, Dryden acquired a trio of F-8C Crusaders from the Navy and, working with Draper, the Center installed an adapted extra Apollo PGNCS on one of the planes, which became the Digital Fly-by-Wire (DFBW) research aircraft. Another of the F-8s was converted into an “Iron Bird” ground-based simulator for testing the flight software and training pilots, and the third F-8 was used to familiarize test pilots with the aircraft. \n              “The Apollo system wasn’t an ideal configuration for airplane control,” says Philip Felleman, who was the DFBW program manager for Draper. “But it did have one big thing going for it: It was highly reliable.” \n              The DFBW program (also commonly known as the F-8 program) was divided into two phases. In Phase I, the objective was to demonstrate the viability of flying an aircraft by digital computer alone. The first use of an analog fly-by-wire system in an aircraft was in early May of 1972 by the U.S. Air Force YF-4E Control Configured Vehicle. About three weeks later, on May 25, 1972, Gary Krier piloted the DFBW research aircraft on the first flight of an aircraft controlled by digital computer. The plane had no mechanical backup, only a three-computer analog emergency system. The backup system was not needed for that flight, nor any other for the length of the program. \n              \n                More than 30 successful flights later, Phase I finished having proven a digital computer could be used to fly an aircraft. The next question was how to make it practical. Commercial digital computers did not have the reliability of the Apollo Guidance Computer. A DFBW system would require more than just one or even two computers to operate with any acceptable assurance of safety. In Phase II of the DFBW program, Dryden collaborated with Draper, Langley Research Center, and others to create the hardware and software necessary for a highly reliable, fault-tolerant, three-computer DFBW system.\n              \n              \n                \n                \n                  \n                \n                \n                  The Northrop Grumman B-2 Spirit is one of the aircraft designs enabled by DFBW technology.\n                \n              \n              “The big job was to be able to manage the redundancy, to be able to tolerate a failure and still be able to fly,” says Felleman. To do that, Szalai says, “We worked untold hours to develop the logic schemes, and then we had to test it and verify that it worked in all the various combinations.” \n              Draper, meanwhile, was also working with NASA on the guidance, navigation, and control system for an entirely new kind of aircraft: the Space Shuttle. Employing a quad-redundant digital fly-by-wire system, the shuttle benefited from the work done during the DFBW program, which in one case identified a hardware issue with the flight computers (both programs used IBM AP-101s), and in another helped solve a potentially hazardous problem with pilot-induced oscillation that occurred during the final test flight of the Space Shuttle Enterprise. \n              “There was feedback between the programs, mostly from us to the shuttle program because we were doing everything first,” says Felleman. \n              The DFBW program’s final flight occurred on \n                April 2, 1985—the last of more than 200 successful flights that collectively provided the impetus for changing the way aircraft are designed and flown around the world. \n              Benefits\n              “Some of the techniques we developed at that time are still being used, and that spawned the digital fly-by-wire revolution,” says Szalai, who went on to become Dryden’s center director before retiring in 1998. “We communicated with all of the major airframe manufacturers and were able to transfer a lot of the technology.” \n              \n                \n                \n                  \n                \n                \n                  The U.S. Navy’s Seawolf class submarines feature a “swim-by-wire” system adapted by NASA partner Draper Laboratory from the Lab’s work during the DFBW program.\n                \n              \n              The first commercial airliner to fly with DFBW was the Airbus 320 in 1987, followed by Boeing’s 777 in 1994. Today, the technology features in a number of aircraft from both manufacturers. For commercial aircraft, the technology replaces heavy mechanical systems, allowing airlines to benefit from greater fuel efficiency or carry more passengers and cargo. The heightened responsiveness of DFBW-enabled aircraft allows pilots to provide a smoother flight, and the system’s redundancies help ensure safe operation of the vehicle. Mechanical maintenance needs are also reduced, saving costs and time spent on upkeep and repairs of the mechanical systems and reducing the chance of failures. \n              “Now, when you fly any major, large airplane, you’re flying a digital fly-by-wire system based on the technology from the F-8 program,” says Sargent. Even smaller aircraft are now incorporating the technology; in 2005, the Dassault Falcon 7X became the first business jet with a DFBW system.\n              One of the biggest contributions to aviation to emerge from the DFBW program is the ability to support entirely new forms of aircraft, says Szalai. The enhanced control capabilities of a DFBW system allow pilots to fly aerodynamically unstable aircraft that could not be controlled otherwise. While current aircraft are still designed as aerodynamically stable to at least some degree, unstable aircraft promise higher performance—such as increased maneuverability in fighter jets and minimized drag and increased range in civil transport—and future aircraft may capitalize on this benefit.\n              “Digital fly-by-wire has unshackled designers from the rules of the 1950s and 1960s, so you end up with vehicles like the Space Shuttle, the B-2 bomber, and the F-117. You couldn’t have these kinds of aircraft without a fly-by-wire system,” says Szalai. In addition to those, Szalai notes, many other military aircraft benefit from DFBW systems, including the F/A-18 and F-22. The F-16 began with an analog fly-by-wire system—the first production aircraft with fly-by-wire—and later switched to DFBW controls. \n              The benefits of digital computer vehicle control systems as demonstrated by the DFBW program are not limited to the skies, however. The electronic cruise control features found in many automobiles are enabled by drive-by-wire technology, as are antilock braking and electronic stability control systems, both of which significantly enhance safety. Auto and motorcycle manufacturers have also incorporated electronic throttles into their vehicles—the first being the BMW 7 series in 1988—eliminating moving mechanical systems between the accelerator and the engine. \n              For Draper, the outcomes of the DFBW program have served to enhance the Lab’s expertise and reputation in the field of guidance, navigation, and control systems. \n              “What NASA has meant to us is a steady stream of hard problems to work on. The skills we learned and technologies we developed from our work with NASA we then turn around and apply as broadly as possible,” says Sargent. Beyond aircraft, Draper has applied the DFBW technology to a range of unmanned underwater vehicles and the U.S. Navy’s Seawolf class submarines. “A redundant, fault tolerant, ‘swim-by-wire’ system,” Sargent says. And Draper recently delivered a DFBW system to Orbital Sciences for the company’s launch vehicle and Cygnus capsule, being developed in support of NASA’s Commercial Orbital Transportation Services (COTS) program.\n               “You can draw direct heritage from the F-8 system to the systems that fly the Space Shuttle and the International Space Station, and now we’ve taken that technology into the COTS program. That says a lot for the power of what was done back then,” Sargent says.\n              Szalai recalls countless hours in the desert where Dryden is located, standing up in a lean-to hangar with the F-8 Iron Bird simulator and a computer test set, working out software anomalies, trudging up and down the steps to the cockpit to work with the pilots in training. The hangar was drafty, dusty. Sand slid in under the roll-down door. \n              “One of the values of flight research is that reality meets with dreams and visions,” Szalai says. “They meet and they clash. You have to solve the real world issues. You can’t always take a picture of the spinoff. Sometimes it’s showing that you can do something.”\n            "},{"href":"http://spinoff.nasa.gov/Spinoff2011/ps_1.html","text":"Modified Fittings Enhance Industrial Safety","image":"http://spinoff.nasa.gov/Spinoff2011/Images/ps-1_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                NASA Technology\n                \n                Kennedy Space Center is not only home to one of the largest buildings in the world—the massive Vehicle Assembly Building—it also hosts a number of one-of-a-kind facilities. The more than 30-mile-long campus has witnessed every launch from the Space Shuttle Launch Pad, as well as many homecomings at the Shuttle Landing Facility. Just as important, the Space Station Processing Facility (SSPF) has seen each element of the International Space Station (ISS) that passes through Kennedy before it goes into orbit. \n                \n                \n                  \n                  \n                    \n                  \n                  \n                    In the Space Station Processing Facility at Kennedy Space Center, an overhead crane lowers the International Space Station’s Tranquility module. It is here where NASA engineers made a particular modification to some fittings that is now incorporated into commercial fittings for the petroleum and chemical industries. \n                  \n                \n                \n                The SSPF is where ISS components are checked, tested, and adjusted before being packed into the space shuttle for transport. In an environment like the SSPF—spanning 457,000 square feet of processing areas, operational control rooms, laboratories, logistics areas, and office space—large workstands and equipment used to support the processing of ISS components need to be moved around the facility. One of the devices employed for this task is an air pallet. An air pallet moves on cushions of air instead of wheels. Compressed air inflates the cushions underneath the pallet and is then expelled through exhaust holes. This forms a thin film of air between the cushions and the floor, lifting the platform off the floor and making it easy to move the heavy workstands, equipment, and ISS components.\n                Concerned with the safety of the connections on the pressurized air hoses used for the air pallets, engineers at Kennedy modified an existing commercial cam and groove fitting to control the air supply hose in the event of an accidental release of a pressurized hose. This modification prevented the hose from detaching and, propelled by compressed air, striking workers or equipment. \n                “At the time, these were not available on commercial coupling halves, so NASA made a modification and then put them into use. If a worker were to accidentally try to remove a pressurized hose from the pallet, it no longer rapidly separated, and it safely relieved the pressure,” says Paul Schwindt, an engineer at Kennedy who together with Alan Littlefield, also an engineer at Kennedy, designed the modification.\n                \n                Partnership \n                \n                Years after NASA modified the coupling halves, an engineer at an Enid, Oklahoma-based business, PT Coupling Company, was looking for a solution for one of the company’s customers working in Alaska’s North Slope. The customer had some incidents on a pipeline where fittings under pressure were disconnected and resulted in injuries to the workers. \n                To address the problem, the company developed some prototypes, but nothing worked well, says Kyle Eckhardt, the engineer at PT Coupling. “I was trying to come up with a solution when I came across the NASA fitting description while doing some research online. It was simple, practical, and it really worked,” he says.\n                Eckhardt contacted Pasquale Ferrari, a technology transfer agent at Kennedy, and then signed an agreement to transfer the hardware modification. “It’s something that NASA made that nobody else was making,” says Ferrari. “Part of NASA’s mission is to move technology, and that is what we did.” \n                Benefits\n                PT Coupling made additional changes to the NASA-modified fittings. These included removing a catch slot on the front of the adapter, developing different hardware sizes (2- and 3-inch sizes), and using new materials. “NASA’s fitting was aerospace grade and very expensive. We came up with materials that had the same properties but were more common,” says Eckhardt. By 2011, PT Coupling started offering a promising new product for the petroleum and chemical industries called PT Pressure Safe. \n                \n                \n                  \n                  \n                    \n                  \n                  \n                    The PT Pressure Safe cam and groove system from PT Coupling Company utilizes technology transferred from NASA. The system prevents personal injury and property damage by ensuring the coupling halves on a delivery system do not disconnect while under pressure.\n                  \n                \n                \n                As a manufacturer and distributor of industrial fittings for liquid and dry material transfer applications, PT Coupling makes cam and groove couplings. Such fittings are made up of two parts: a male (adapter/plug) and female (coupler/socket) that work together. The male adapter and female coupler are easily connected to make contact with the gasket, and then two arms on the coupler are depressed simultaneously to produce a seal. To release the seal, the arms are lifted. A main benefit of the fittings is quick connection and disconnection without using hand tools or threaded connections.\n                “As quick release fittings, they are designed for when hoses are constantly changed. Threaded fittings take more time to tighten and loosen. With cam and groove, you simply actuate the two arms to connect or disconnect the fitting,” says Eckhardt. \n                While these cam and groove fittings are quick and easy to connect and disconnect, they can be dangerous if disconnected under pressure. The new PT Pressure Safe fittings, based on the NASA-modified coupling halves, solve this problem by capturing the energy and releasing it in a controlled and safe manner.\n                Available for most cam and groove styles, PT Pressure Safe automatically prevents rapid separation of the fittings in a fluid or dry material delivery system. Based on the NASA hardware modifications, PT Pressure Safe will not allow a user to close the arms on the coupler until the two pieces are locked and rotated 45 degrees. If released under pressure, the modification ensures the coupling halves will not disconnect. Once the pressure in the delivery system is sufficiently low, the adaptor can be rotated and be safely disengaged. According to Eckhardt, the simplicity of the design is what makes the fittings so unique and versatile.\n                “In the event that the hose connections are opened under pressure, the PT Pressure Safe will prevent the fittings from separating completely. The feature allows the operator to safely open the fittings under pressure by preventing rapid separation of the coupler and adapter, protecting the operator and surrounding equipment from personal injury and damage,” says Eckhardt. “Anyone concerned with safety with cam and groove fittings would want to use PT Pressure Safe.”\n                 Potential customers for the PT Pressure Safe are the petroleum and chemical industries, and any industry that transports liquid under pressure. The company currently offers 2- and 3-inch sizes, but can develop and manufacture most sizes.\n                For such a small piece of hardware, the fittings have the potential to make a big difference. As Eckhardt says, “NASA allowed us to have the technology and offer a brand new product line to our customers, which could make industry much safer.”\n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                NASA Technology\n                \n                Kennedy Space Center is not only home to one of the largest buildings in the world—the massive Vehicle Assembly Building—it also hosts a number of one-of-a-kind facilities. The more than 30-mile-long campus has witnessed every launch from the Space Shuttle Launch Pad, as well as many homecomings at the Shuttle Landing Facility. Just as important, the Space Station Processing Facility (SSPF) has seen each element of the International Space Station (ISS) that passes through Kennedy before it goes into orbit. \n                \n                \n                  \n                  \n                    \n                  \n                  \n                    In the Space Station Processing Facility at Kennedy Space Center, an overhead crane lowers the International Space Station’s Tranquility module. It is here where NASA engineers made a particular modification to some fittings that is now incorporated into commercial fittings for the petroleum and chemical industries. \n                  \n                \n                \n                The SSPF is where ISS components are checked, tested, and adjusted before being packed into the space shuttle for transport. In an environment like the SSPF—spanning 457,000 square feet of processing areas, operational control rooms, laboratories, logistics areas, and office space—large workstands and equipment used to support the processing of ISS components need to be moved around the facility. One of the devices employed for this task is an air pallet. An air pallet moves on cushions of air instead of wheels. Compressed air inflates the cushions underneath the pallet and is then expelled through exhaust holes. This forms a thin film of air between the cushions and the floor, lifting the platform off the floor and making it easy to move the heavy workstands, equipment, and ISS components.\n                Concerned with the safety of the connections on the pressurized air hoses used for the air pallets, engineers at Kennedy modified an existing commercial cam and groove fitting to control the air supply hose in the event of an accidental release of a pressurized hose. This modification prevented the hose from detaching and, propelled by compressed air, striking workers or equipment. \n                “At the time, these were not available on commercial coupling halves, so NASA made a modification and then put them into use. If a worker were to accidentally try to remove a pressurized hose from the pallet, it no longer rapidly separated, and it safely relieved the pressure,” says Paul Schwindt, an engineer at Kennedy who together with Alan Littlefield, also an engineer at Kennedy, designed the modification.\n                \n                Partnership \n                \n                Years after NASA modified the coupling halves, an engineer at an Enid, Oklahoma-based business, PT Coupling Company, was looking for a solution for one of the company’s customers working in Alaska’s North Slope. The customer had some incidents on a pipeline where fittings under pressure were disconnected and resulted in injuries to the workers. \n                To address the problem, the company developed some prototypes, but nothing worked well, says Kyle Eckhardt, the engineer at PT Coupling. “I was trying to come up with a solution when I came across the NASA fitting description while doing some research online. It was simple, practical, and it really worked,” he says.\n                Eckhardt contacted Pasquale Ferrari, a technology transfer agent at Kennedy, and then signed an agreement to transfer the hardware modification. “It’s something that NASA made that nobody else was making,” says Ferrari. “Part of NASA’s mission is to move technology, and that is what we did.” \n                Benefits\n                PT Coupling made additional changes to the NASA-modified fittings. These included removing a catch slot on the front of the adapter, developing different hardware sizes (2- and 3-inch sizes), and using new materials. “NASA’s fitting was aerospace grade and very expensive. We came up with materials that had the same properties but were more common,” says Eckhardt. By 2011, PT Coupling started offering a promising new product for the petroleum and chemical industries called PT Pressure Safe. \n                \n                \n                  \n                  \n                    \n                  \n                  \n                    The PT Pressure Safe cam and groove system from PT Coupling Company utilizes technology transferred from NASA. The system prevents personal injury and property damage by ensuring the coupling halves on a delivery system do not disconnect while under pressure.\n                  \n                \n                \n                As a manufacturer and distributor of industrial fittings for liquid and dry material transfer applications, PT Coupling makes cam and groove couplings. Such fittings are made up of two parts: a male (adapter/plug) and female (coupler/socket) that work together. The male adapter and female coupler are easily connected to make contact with the gasket, and then two arms on the coupler are depressed simultaneously to produce a seal. To release the seal, the arms are lifted. A main benefit of the fittings is quick connection and disconnection without using hand tools or threaded connections.\n                “As quick release fittings, they are designed for when hoses are constantly changed. Threaded fittings take more time to tighten and loosen. With cam and groove, you simply actuate the two arms to connect or disconnect the fitting,” says Eckhardt. \n                While these cam and groove fittings are quick and easy to connect and disconnect, they can be dangerous if disconnected under pressure. The new PT Pressure Safe fittings, based on the NASA-modified coupling halves, solve this problem by capturing the energy and releasing it in a controlled and safe manner.\n                Available for most cam and groove styles, PT Pressure Safe automatically prevents rapid separation of the fittings in a fluid or dry material delivery system. Based on the NASA hardware modifications, PT Pressure Safe will not allow a user to close the arms on the coupler until the two pieces are locked and rotated 45 degrees. If released under pressure, the modification ensures the coupling halves will not disconnect. Once the pressure in the delivery system is sufficiently low, the adaptor can be rotated and be safely disengaged. According to Eckhardt, the simplicity of the design is what makes the fittings so unique and versatile.\n                “In the event that the hose connections are opened under pressure, the PT Pressure Safe will prevent the fittings from separating completely. The feature allows the operator to safely open the fittings under pressure by preventing rapid separation of the coupler and adapter, protecting the operator and surrounding equipment from personal injury and damage,” says Eckhardt. “Anyone concerned with safety with cam and groove fittings would want to use PT Pressure Safe.”\n                 Potential customers for the PT Pressure Safe are the petroleum and chemical industries, and any industry that transports liquid under pressure. The company currently offers 2- and 3-inch sizes, but can develop and manufacture most sizes.\n                For such a small piece of hardware, the fittings have the potential to make a big difference. As Eckhardt says, “NASA allowed us to have the technology and offer a brand new product line to our customers, which could make industry much safer.”\n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                NASA Technology\n                \n                Kennedy Space Center is not only home to one of the largest buildings in the world—the massive Vehicle Assembly Building—it also hosts a number of one-of-a-kind facilities. The more than 30-mile-long campus has witnessed every launch from the Space Shuttle Launch Pad, as well as many homecomings at the Shuttle Landing Facility. Just as important, the Space Station Processing Facility (SSPF) has seen each element of the International Space Station (ISS) that passes through Kennedy before it goes into orbit. \n                \n                \n                  \n                  \n                    \n                  \n                  \n                    In the Space Station Processing Facility at Kennedy Space Center, an overhead crane lowers the International Space Station’s Tranquility module. It is here where NASA engineers made a particular modification to some fittings that is now incorporated into commercial fittings for the petroleum and chemical industries. \n                  \n                \n                \n                The SSPF is where ISS components are checked, tested, and adjusted before being packed into the space shuttle for transport. In an environment like the SSPF—spanning 457,000 square feet of processing areas, operational control rooms, laboratories, logistics areas, and office space—large workstands and equipment used to support the processing of ISS components need to be moved around the facility. One of the devices employed for this task is an air pallet. An air pallet moves on cushions of air instead of wheels. Compressed air inflates the cushions underneath the pallet and is then expelled through exhaust holes. This forms a thin film of air between the cushions and the floor, lifting the platform off the floor and making it easy to move the heavy workstands, equipment, and ISS components.\n                Concerned with the safety of the connections on the pressurized air hoses used for the air pallets, engineers at Kennedy modified an existing commercial cam and groove fitting to control the air supply hose in the event of an accidental release of a pressurized hose. This modification prevented the hose from detaching and, propelled by compressed air, striking workers or equipment. \n                “At the time, these were not available on commercial coupling halves, so NASA made a modification and then put them into use. If a worker were to accidentally try to remove a pressurized hose from the pallet, it no longer rapidly separated, and it safely relieved the pressure,” says Paul Schwindt, an engineer at Kennedy who together with Alan Littlefield, also an engineer at Kennedy, designed the modification.\n                \n                Partnership \n                \n                Years after NASA modified the coupling halves, an engineer at an Enid, Oklahoma-based business, PT Coupling Company, was looking for a solution for one of the company’s customers working in Alaska’s North Slope. The customer had some incidents on a pipeline where fittings under pressure were disconnected and resulted in injuries to the workers. \n                To address the problem, the company developed some prototypes, but nothing worked well, says Kyle Eckhardt, the engineer at PT Coupling. “I was trying to come up with a solution when I came across the NASA fitting description while doing some research online. It was simple, practical, and it really worked,” he says.\n                Eckhardt contacted Pasquale Ferrari, a technology transfer agent at Kennedy, and then signed an agreement to transfer the hardware modification. “It’s something that NASA made that nobody else was making,” says Ferrari. “Part of NASA’s mission is to move technology, and that is what we did.” \n                Benefits\n                PT Coupling made additional changes to the NASA-modified fittings. These included removing a catch slot on the front of the adapter, developing different hardware sizes (2- and 3-inch sizes), and using new materials. “NASA’s fitting was aerospace grade and very expensive. We came up with materials that had the same properties but were more common,” says Eckhardt. By 2011, PT Coupling started offering a promising new product for the petroleum and chemical industries called PT Pressure Safe. \n                \n                \n                  \n                  \n                    \n                  \n                  \n                    The PT Pressure Safe cam and groove system from PT Coupling Company utilizes technology transferred from NASA. The system prevents personal injury and property damage by ensuring the coupling halves on a delivery system do not disconnect while under pressure.\n                  \n                \n                \n                As a manufacturer and distributor of industrial fittings for liquid and dry material transfer applications, PT Coupling makes cam and groove couplings. Such fittings are made up of two parts: a male (adapter/plug) and female (coupler/socket) that work together. The male adapter and female coupler are easily connected to make contact with the gasket, and then two arms on the coupler are depressed simultaneously to produce a seal. To release the seal, the arms are lifted. A main benefit of the fittings is quick connection and disconnection without using hand tools or threaded connections.\n                “As quick release fittings, they are designed for when hoses are constantly changed. Threaded fittings take more time to tighten and loosen. With cam and groove, you simply actuate the two arms to connect or disconnect the fitting,” says Eckhardt. \n                While these cam and groove fittings are quick and easy to connect and disconnect, they can be dangerous if disconnected under pressure. The new PT Pressure Safe fittings, based on the NASA-modified coupling halves, solve this problem by capturing the energy and releasing it in a controlled and safe manner.\n                Available for most cam and groove styles, PT Pressure Safe automatically prevents rapid separation of the fittings in a fluid or dry material delivery system. Based on the NASA hardware modifications, PT Pressure Safe will not allow a user to close the arms on the coupler until the two pieces are locked and rotated 45 degrees. If released under pressure, the modification ensures the coupling halves will not disconnect. Once the pressure in the delivery system is sufficiently low, the adaptor can be rotated and be safely disengaged. According to Eckhardt, the simplicity of the design is what makes the fittings so unique and versatile.\n                “In the event that the hose connections are opened under pressure, the PT Pressure Safe will prevent the fittings from separating completely. The feature allows the operator to safely open the fittings under pressure by preventing rapid separation of the coupler and adapter, protecting the operator and surrounding equipment from personal injury and damage,” says Eckhardt. “Anyone concerned with safety with cam and groove fittings would want to use PT Pressure Safe.”\n                 Potential customers for the PT Pressure Safe are the petroleum and chemical industries, and any industry that transports liquid under pressure. The company currently offers 2- and 3-inch sizes, but can develop and manufacture most sizes.\n                For such a small piece of hardware, the fittings have the potential to make a big difference. As Eckhardt says, “NASA allowed us to have the technology and offer a brand new product line to our customers, which could make industry much safer.”\n                \n              \n            \n            \n          \n        \n          \n            \n              \n                NASA Technology\n                \n                Kennedy Space Center is not only home to one of the largest buildings in the world—the massive Vehicle Assembly Building—it also hosts a number of one-of-a-kind facilities. The more than 30-mile-long campus has witnessed every launch from the Space Shuttle Launch Pad, as well as many homecomings at the Shuttle Landing Facility. Just as important, the Space Station Processing Facility (SSPF) has seen each element of the International Space Station (ISS) that passes through Kennedy before it goes into orbit. \n                \n                \n                  \n                  \n                    \n                  \n                  \n                    In the Space Station Processing Facility at Kennedy Space Center, an overhead crane lowers the International Space Station’s Tranquility module. It is here where NASA engineers made a particular modification to some fittings that is now incorporated into commercial fittings for the petroleum and chemical industries. \n                  \n                \n                \n                The SSPF is where ISS components are checked, tested, and adjusted before being packed into the space shuttle for transport. In an environment like the SSPF—spanning 457,000 square feet of processing areas, operational control rooms, laboratories, logistics areas, and office space—large workstands and equipment used to support the processing of ISS components need to be moved around the facility. One of the devices employed for this task is an air pallet. An air pallet moves on cushions of air instead of wheels. Compressed air inflates the cushions underneath the pallet and is then expelled through exhaust holes. This forms a thin film of air between the cushions and the floor, lifting the platform off the floor and making it easy to move the heavy workstands, equipment, and ISS components.\n                Concerned with the safety of the connections on the pressurized air hoses used for the air pallets, engineers at Kennedy modified an existing commercial cam and groove fitting to control the air supply hose in the event of an accidental release of a pressurized hose. This modification prevented the hose from detaching and, propelled by compressed air, striking workers or equipment. \n                “At the time, these were not available on commercial coupling halves, so NASA made a modification and then put them into use. If a worker were to accidentally try to remove a pressurized hose from the pallet, it no longer rapidly separated, and it safely relieved the pressure,” says Paul Schwindt, an engineer at Kennedy who together with Alan Littlefield, also an engineer at Kennedy, designed the modification.\n                \n                Partnership \n                \n                Years after NASA modified the coupling halves, an engineer at an Enid, Oklahoma-based business, PT Coupling Company, was looking for a solution for one of the company’s customers working in Alaska’s North Slope. The customer had some incidents on a pipeline where fittings under pressure were disconnected and resulted in injuries to the workers. \n                To address the problem, the company developed some prototypes, but nothing worked well, says Kyle Eckhardt, the engineer at PT Coupling. “I was trying to come up with a solution when I came across the NASA fitting description while doing some research online. It was simple, practical, and it really worked,” he says.\n                Eckhardt contacted Pasquale Ferrari, a technology transfer agent at Kennedy, and then signed an agreement to transfer the hardware modification. “It’s something that NASA made that nobody else was making,” says Ferrari. “Part of NASA’s mission is to move technology, and that is what we did.” \n                Benefits\n                PT Coupling made additional changes to the NASA-modified fittings. These included removing a catch slot on the front of the adapter, developing different hardware sizes (2- and 3-inch sizes), and using new materials. “NASA’s fitting was aerospace grade and very expensive. We came up with materials that had the same properties but were more common,” says Eckhardt. By 2011, PT Coupling started offering a promising new product for the petroleum and chemical industries called PT Pressure Safe. \n                \n                \n                  \n                  \n                    \n                  \n                  \n                    The PT Pressure Safe cam and groove system from PT Coupling Company utilizes technology transferred from NASA. The system prevents personal injury and property damage by ensuring the coupling halves on a delivery system do not disconnect while under pressure.\n                  \n                \n                \n                As a manufacturer and distributor of industrial fittings for liquid and dry material transfer applications, PT Coupling makes cam and groove couplings. Such fittings are made up of two parts: a male (adapter/plug) and female (coupler/socket) that work together. The male adapter and female coupler are easily connected to make contact with the gasket, and then two arms on the coupler are depressed simultaneously to produce a seal. To release the seal, the arms are lifted. A main benefit of the fittings is quick connection and disconnection without using hand tools or threaded connections.\n                “As quick release fittings, they are designed for when hoses are constantly changed. Threaded fittings take more time to tighten and loosen. With cam and groove, you simply actuate the two arms to connect or disconnect the fitting,” says Eckhardt. \n                While these cam and groove fittings are quick and easy to connect and disconnect, they can be dangerous if disconnected under pressure. The new PT Pressure Safe fittings, based on the NASA-modified coupling halves, solve this problem by capturing the energy and releasing it in a controlled and safe manner.\n                Available for most cam and groove styles, PT Pressure Safe automatically prevents rapid separation of the fittings in a fluid or dry material delivery system. Based on the NASA hardware modifications, PT Pressure Safe will not allow a user to close the arms on the coupler until the two pieces are locked and rotated 45 degrees. If released under pressure, the modification ensures the coupling halves will not disconnect. Once the pressure in the delivery system is sufficiently low, the adaptor can be rotated and be safely disengaged. According to Eckhardt, the simplicity of the design is what makes the fittings so unique and versatile.\n                “In the event that the hose connections are opened under pressure, the PT Pressure Safe will prevent the fittings from separating completely. The feature allows the operator to safely open the fittings under pressure by preventing rapid separation of the coupler and adapter, protecting the operator and surrounding equipment from personal injury and damage,” says Eckhardt. “Anyone concerned with safety with cam and groove fittings would want to use PT Pressure Safe.”\n                 Potential customers for the PT Pressure Safe are the petroleum and chemical industries, and any industry that transports liquid under pressure. The company currently offers 2- and 3-inch sizes, but can develop and manufacture most sizes.\n                For such a small piece of hardware, the fittings have the potential to make a big difference. As Eckhardt says, “NASA allowed us to have the technology and offer a brand new product line to our customers, which could make industry much safer.”\n                \n              \n            \n            \n          \n            \n              \n                NASA Technology\n                \n                Kennedy Space Center is not only home to one of the largest buildings in the world—the massive Vehicle Assembly Building—it also hosts a number of one-of-a-kind facilities. The more than 30-mile-long campus has witnessed every launch from the Space Shuttle Launch Pad, as well as many homecomings at the Shuttle Landing Facility. Just as important, the Space Station Processing Facility (SSPF) has seen each element of the International Space Station (ISS) that passes through Kennedy before it goes into orbit. \n                \n                \n                  \n                  \n                    \n                  \n                  \n                    In the Space Station Processing Facility at Kennedy Space Center, an overhead crane lowers the International Space Station’s Tranquility module. It is here where NASA engineers made a particular modification to some fittings that is now incorporated into commercial fittings for the petroleum and chemical industries. \n                  \n                \n                \n                The SSPF is where ISS components are checked, tested, and adjusted before being packed into the space shuttle for transport. In an environment like the SSPF—spanning 457,000 square feet of processing areas, operational control rooms, laboratories, logistics areas, and office space—large workstands and equipment used to support the processing of ISS components need to be moved around the facility. One of the devices employed for this task is an air pallet. An air pallet moves on cushions of air instead of wheels. Compressed air inflates the cushions underneath the pallet and is then expelled through exhaust holes. This forms a thin film of air between the cushions and the floor, lifting the platform off the floor and making it easy to move the heavy workstands, equipment, and ISS components.\n                Concerned with the safety of the connections on the pressurized air hoses used for the air pallets, engineers at Kennedy modified an existing commercial cam and groove fitting to control the air supply hose in the event of an accidental release of a pressurized hose. This modification prevented the hose from detaching and, propelled by compressed air, striking workers or equipment. \n                “At the time, these were not available on commercial coupling halves, so NASA made a modification and then put them into use. If a worker were to accidentally try to remove a pressurized hose from the pallet, it no longer rapidly separated, and it safely relieved the pressure,” says Paul Schwindt, an engineer at Kennedy who together with Alan Littlefield, also an engineer at Kennedy, designed the modification.\n                \n                Partnership \n                \n                Years after NASA modified the coupling halves, an engineer at an Enid, Oklahoma-based business, PT Coupling Company, was looking for a solution for one of the company’s customers working in Alaska’s North Slope. The customer had some incidents on a pipeline where fittings under pressure were disconnected and resulted in injuries to the workers. \n                To address the problem, the company developed some prototypes, but nothing worked well, says Kyle Eckhardt, the engineer at PT Coupling. “I was trying to come up with a solution when I came across the NASA fitting description while doing some research online. It was simple, practical, and it really worked,” he says.\n                Eckhardt contacted Pasquale Ferrari, a technology transfer agent at Kennedy, and then signed an agreement to transfer the hardware modification. “It’s something that NASA made that nobody else was making,” says Ferrari. “Part of NASA’s mission is to move technology, and that is what we did.” \n                Benefits\n                PT Coupling made additional changes to the NASA-modified fittings. These included removing a catch slot on the front of the adapter, developing different hardware sizes (2- and 3-inch sizes), and using new materials. “NASA’s fitting was aerospace grade and very expensive. We came up with materials that had the same properties but were more common,” says Eckhardt. By 2011, PT Coupling started offering a promising new product for the petroleum and chemical industries called PT Pressure Safe. \n                \n                \n                  \n                  \n                    \n                  \n                  \n                    The PT Pressure Safe cam and groove system from PT Coupling Company utilizes technology transferred from NASA. The system prevents personal injury and property damage by ensuring the coupling halves on a delivery system do not disconnect while under pressure.\n                  \n                \n                \n                As a manufacturer and distributor of industrial fittings for liquid and dry material transfer applications, PT Coupling makes cam and groove couplings. Such fittings are made up of two parts: a male (adapter/plug) and female (coupler/socket) that work together. The male adapter and female coupler are easily connected to make contact with the gasket, and then two arms on the coupler are depressed simultaneously to produce a seal. To release the seal, the arms are lifted. A main benefit of the fittings is quick connection and disconnection without using hand tools or threaded connections.\n                “As quick release fittings, they are designed for when hoses are constantly changed. Threaded fittings take more time to tighten and loosen. With cam and groove, you simply actuate the two arms to connect or disconnect the fitting,” says Eckhardt. \n                While these cam and groove fittings are quick and easy to connect and disconnect, they can be dangerous if disconnected under pressure. The new PT Pressure Safe fittings, based on the NASA-modified coupling halves, solve this problem by capturing the energy and releasing it in a controlled and safe manner.\n                Available for most cam and groove styles, PT Pressure Safe automatically prevents rapid separation of the fittings in a fluid or dry material delivery system. Based on the NASA hardware modifications, PT Pressure Safe will not allow a user to close the arms on the coupler until the two pieces are locked and rotated 45 degrees. If released under pressure, the modification ensures the coupling halves will not disconnect. Once the pressure in the delivery system is sufficiently low, the adaptor can be rotated and be safely disengaged. According to Eckhardt, the simplicity of the design is what makes the fittings so unique and versatile.\n                “In the event that the hose connections are opened under pressure, the PT Pressure Safe will prevent the fittings from separating completely. The feature allows the operator to safely open the fittings under pressure by preventing rapid separation of the coupler and adapter, protecting the operator and surrounding equipment from personal injury and damage,” says Eckhardt. “Anyone concerned with safety with cam and groove fittings would want to use PT Pressure Safe.”\n                 Potential customers for the PT Pressure Safe are the petroleum and chemical industries, and any industry that transports liquid under pressure. The company currently offers 2- and 3-inch sizes, but can develop and manufacture most sizes.\n                For such a small piece of hardware, the fittings have the potential to make a big difference. As Eckhardt says, “NASA allowed us to have the technology and offer a brand new product line to our customers, which could make industry much safer.”\n                \n              \n            \n            \n              \n                NASA Technology\n                \n                Kennedy Space Center is not only home to one of the largest buildings in the world—the massive Vehicle Assembly Building—it also hosts a number of one-of-a-kind facilities. The more than 30-mile-long campus has witnessed every launch from the Space Shuttle Launch Pad, as well as many homecomings at the Shuttle Landing Facility. Just as important, the Space Station Processing Facility (SSPF) has seen each element of the International Space Station (ISS) that passes through Kennedy before it goes into orbit. \n                \n                \n                  \n                  \n                    \n                  \n                  \n                    In the Space Station Processing Facility at Kennedy Space Center, an overhead crane lowers the International Space Station’s Tranquility module. It is here where NASA engineers made a particular modification to some fittings that is now incorporated into commercial fittings for the petroleum and chemical industries. \n                  \n                \n                \n                The SSPF is where ISS components are checked, tested, and adjusted before being packed into the space shuttle for transport. In an environment like the SSPF—spanning 457,000 square feet of processing areas, operational control rooms, laboratories, logistics areas, and office space—large workstands and equipment used to support the processing of ISS components need to be moved around the facility. One of the devices employed for this task is an air pallet. An air pallet moves on cushions of air instead of wheels. Compressed air inflates the cushions underneath the pallet and is then expelled through exhaust holes. This forms a thin film of air between the cushions and the floor, lifting the platform off the floor and making it easy to move the heavy workstands, equipment, and ISS components.\n                Concerned with the safety of the connections on the pressurized air hoses used for the air pallets, engineers at Kennedy modified an existing commercial cam and groove fitting to control the air supply hose in the event of an accidental release of a pressurized hose. This modification prevented the hose from detaching and, propelled by compressed air, striking workers or equipment. \n                “At the time, these were not available on commercial coupling halves, so NASA made a modification and then put them into use. If a worker were to accidentally try to remove a pressurized hose from the pallet, it no longer rapidly separated, and it safely relieved the pressure,” says Paul Schwindt, an engineer at Kennedy who together with Alan Littlefield, also an engineer at Kennedy, designed the modification.\n                \n                Partnership \n                \n                Years after NASA modified the coupling halves, an engineer at an Enid, Oklahoma-based business, PT Coupling Company, was looking for a solution for one of the company’s customers working in Alaska’s North Slope. The customer had some incidents on a pipeline where fittings under pressure were disconnected and resulted in injuries to the workers. \n                To address the problem, the company developed some prototypes, but nothing worked well, says Kyle Eckhardt, the engineer at PT Coupling. “I was trying to come up with a solution when I came across the NASA fitting description while doing some research online. It was simple, practical, and it really worked,” he says.\n                Eckhardt contacted Pasquale Ferrari, a technology transfer agent at Kennedy, and then signed an agreement to transfer the hardware modification. “It’s something that NASA made that nobody else was making,” says Ferrari. “Part of NASA’s mission is to move technology, and that is what we did.” \n                Benefits\n                PT Coupling made additional changes to the NASA-modified fittings. These included removing a catch slot on the front of the adapter, developing different hardware sizes (2- and 3-inch sizes), and using new materials. “NASA’s fitting was aerospace grade and very expensive. We came up with materials that had the same properties but were more common,” says Eckhardt. By 2011, PT Coupling started offering a promising new product for the petroleum and chemical industries called PT Pressure Safe. \n                \n                \n                  \n                  \n                    \n                  \n                  \n                    The PT Pressure Safe cam and groove system from PT Coupling Company utilizes technology transferred from NASA. The system prevents personal injury and property damage by ensuring the coupling halves on a delivery system do not disconnect while under pressure.\n                  \n                \n                \n                As a manufacturer and distributor of industrial fittings for liquid and dry material transfer applications, PT Coupling makes cam and groove couplings. Such fittings are made up of two parts: a male (adapter/plug) and female (coupler/socket) that work together. The male adapter and female coupler are easily connected to make contact with the gasket, and then two arms on the coupler are depressed simultaneously to produce a seal. To release the seal, the arms are lifted. A main benefit of the fittings is quick connection and disconnection without using hand tools or threaded connections.\n                “As quick release fittings, they are designed for when hoses are constantly changed. Threaded fittings take more time to tighten and loosen. With cam and groove, you simply actuate the two arms to connect or disconnect the fitting,” says Eckhardt. \n                While these cam and groove fittings are quick and easy to connect and disconnect, they can be dangerous if disconnected under pressure. The new PT Pressure Safe fittings, based on the NASA-modified coupling halves, solve this problem by capturing the energy and releasing it in a controlled and safe manner.\n                Available for most cam and groove styles, PT Pressure Safe automatically prevents rapid separation of the fittings in a fluid or dry material delivery system. Based on the NASA hardware modifications, PT Pressure Safe will not allow a user to close the arms on the coupler until the two pieces are locked and rotated 45 degrees. If released under pressure, the modification ensures the coupling halves will not disconnect. Once the pressure in the delivery system is sufficiently low, the adaptor can be rotated and be safely disengaged. According to Eckhardt, the simplicity of the design is what makes the fittings so unique and versatile.\n                “In the event that the hose connections are opened under pressure, the PT Pressure Safe will prevent the fittings from separating completely. The feature allows the operator to safely open the fittings under pressure by preventing rapid separation of the coupler and adapter, protecting the operator and surrounding equipment from personal injury and damage,” says Eckhardt. “Anyone concerned with safety with cam and groove fittings would want to use PT Pressure Safe.”\n                 Potential customers for the PT Pressure Safe are the petroleum and chemical industries, and any industry that transports liquid under pressure. The company currently offers 2- and 3-inch sizes, but can develop and manufacture most sizes.\n                For such a small piece of hardware, the fittings have the potential to make a big difference. As Eckhardt says, “NASA allowed us to have the technology and offer a brand new product line to our customers, which could make industry much safer.”\n                \n              NASA Technology\n                Kennedy Space Center is not only home to one of the largest buildings in the world—the massive Vehicle Assembly Building—it also hosts a number of one-of-a-kind facilities. The more than 30-mile-long campus has witnessed every launch from the Space Shuttle Launch Pad, as well as many homecomings at the Shuttle Landing Facility. Just as important, the Space Station Processing Facility (SSPF) has seen each element of the International Space Station (ISS) that passes through Kennedy before it goes into orbit. \n                \n                The SSPF is where ISS components are checked, tested, and adjusted before being packed into the space shuttle for transport. In an environment like the SSPF—spanning 457,000 square feet of processing areas, operational control rooms, laboratories, logistics areas, and office space—large workstands and equipment used to support the processing of ISS components need to be moved around the facility. One of the devices employed for this task is an air pallet. An air pallet moves on cushions of air instead of wheels. Compressed air inflates the cushions underneath the pallet and is then expelled through exhaust holes. This forms a thin film of air between the cushions and the floor, lifting the platform off the floor and making it easy to move the heavy workstands, equipment, and ISS components.\n                Concerned with the safety of the connections on the pressurized air hoses used for the air pallets, engineers at Kennedy modified an existing commercial cam and groove fitting to control the air supply hose in the event of an accidental release of a pressurized hose. This modification prevented the hose from detaching and, propelled by compressed air, striking workers or equipment. \n                “At the time, these were not available on commercial coupling halves, so NASA made a modification and then put them into use. If a worker were to accidentally try to remove a pressurized hose from the pallet, it no longer rapidly separated, and it safely relieved the pressure,” says Paul Schwindt, an engineer at Kennedy who together with Alan Littlefield, also an engineer at Kennedy, designed the modification.\n                \n                Years after NASA modified the coupling halves, an engineer at an Enid, Oklahoma-based business, PT Coupling Company, was looking for a solution for one of the company’s customers working in Alaska’s North Slope. The customer had some incidents on a pipeline where fittings under pressure were disconnected and resulted in injuries to the workers. \n                To address the problem, the company developed some prototypes, but nothing worked well, says Kyle Eckhardt, the engineer at PT Coupling. “I was trying to come up with a solution when I came across the NASA fitting description while doing some research online. It was simple, practical, and it really worked,” he says.\n                Eckhardt contacted Pasquale Ferrari, a technology transfer agent at Kennedy, and then signed an agreement to transfer the hardware modification. “It’s something that NASA made that nobody else was making,” says Ferrari. “Part of NASA’s mission is to move technology, and that is what we did.” \n                Benefits\n                PT Coupling made additional changes to the NASA-modified fittings. These included removing a catch slot on the front of the adapter, developing different hardware sizes (2- and 3-inch sizes), and using new materials. “NASA’s fitting was aerospace grade and very expensive. We came up with materials that had the same properties but were more common,” says Eckhardt. By 2011, PT Coupling started offering a promising new product for the petroleum and chemical industries called PT Pressure Safe. \n                \n                As a manufacturer and distributor of industrial fittings for liquid and dry material transfer applications, PT Coupling makes cam and groove couplings. Such fittings are made up of two parts: a male (adapter/plug) and female (coupler/socket) that work together. The male adapter and female coupler are easily connected to make contact with the gasket, and then two arms on the coupler are depressed simultaneously to produce a seal. To release the seal, the arms are lifted. A main benefit of the fittings is quick connection and disconnection without using hand tools or threaded connections.\n                “As quick release fittings, they are designed for when hoses are constantly changed. Threaded fittings take more time to tighten and loosen. With cam and groove, you simply actuate the two arms to connect or disconnect the fitting,” says Eckhardt. \n                While these cam and groove fittings are quick and easy to connect and disconnect, they can be dangerous if disconnected under pressure. The new PT Pressure Safe fittings, based on the NASA-modified coupling halves, solve this problem by capturing the energy and releasing it in a controlled and safe manner.\n                Available for most cam and groove styles, PT Pressure Safe automatically prevents rapid separation of the fittings in a fluid or dry material delivery system. Based on the NASA hardware modifications, PT Pressure Safe will not allow a user to close the arms on the coupler until the two pieces are locked and rotated 45 degrees. If released under pressure, the modification ensures the coupling halves will not disconnect. Once the pressure in the delivery system is sufficiently low, the adaptor can be rotated and be safely disengaged. According to Eckhardt, the simplicity of the design is what makes the fittings so unique and versatile.\n                “In the event that the hose connections are opened under pressure, the PT Pressure Safe will prevent the fittings from separating completely. The feature allows the operator to safely open the fittings under pressure by preventing rapid separation of the coupler and adapter, protecting the operator and surrounding equipment from personal injury and damage,” says Eckhardt. “Anyone concerned with safety with cam and groove fittings would want to use PT Pressure Safe.”\n                 Potential customers for the PT Pressure Safe are the petroleum and chemical industries, and any industry that transports liquid under pressure. The company currently offers 2- and 3-inch sizes, but can develop and manufacture most sizes.\n                For such a small piece of hardware, the fittings have the potential to make a big difference. As Eckhardt says, “NASA allowed us to have the technology and offer a brand new product line to our customers, which could make industry much safer.”\n                "},{"href":"http://spinoff.nasa.gov/Spinoff2011/ps_2.html","text":"Simulation Tools Model Icing for Aircraft Design","image":"http://spinoff.nasa.gov/Spinoff2011/Images/ps-3_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Here’s a simple science experiment to try: Place an unopened bottle of distilled water in your freezer. After 2–3 hours, if the water is pure enough, you will notice that it has not frozen. Carefully pour the water into a bowl with a piece of ice in it. When it strikes the ice, the water will instantly freeze.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Supercooled large droplet conditions caused the buildup of ice on this aircraft. Using the NASA LEWICE software, aircraft manufacturers can model the ice accretion and the various shapes the ice can form (such as the inset example) on aircraft surfaces. \n                    \n                  \n                  One of the most basic and commonly known scientific facts is that water freezes at around 32 °F. But this is not always the case. Water lacking any impurities for ice crystals to form around can be supercooled to even lower temperatures without freezing. High in the atmosphere, water droplets can achieve this delicate, supercooled state. When a plane flies through clouds containing these droplets, the water can strike the airframe and, like the supercooled water hitting the ice in the experiment above, freeze instantly. The ice buildup alters the aerodynamics of the plane—reducing lift and increasing drag—affecting its performance and presenting a safety issue if the plane can no longer fly effectively. In certain circumstances, ice can form inside aircraft engines, another potential hazard.\n                  NASA has long studied ways of detecting and countering atmospheric icing conditions as part of the Agency’s efforts to enhance aviation safety. To do this, the Icing Branch at Glenn Research Center utilizes a number of world-class tools, including the Center’s Icing Research Tunnel and the NASA 607 icing research aircraft, a “flying laboratory” for studying icing conditions. The branch has also developed a suite of software programs to help aircraft and icing protection system designers understand the behavior of ice accumulation on various surfaces and in various conditions. \n                  One of these innovations is the LEWICE ice accretion simulation software. Initially developed in the 1980s (when Glenn was known as Lewis Research Center), LEWICE has become one of the most widely used tools in icing research and aircraft design and certification. LEWICE has been transformed over the years from strictly a research tool to one used routinely by industry and other government agencies. Glenn contractor William Wright has been the architect of this development, supported by a team of researchers investigating icing physics, creating validation data, and ensuring development according to standard software engineering practices. The program provides a virtual simulation environment for determining where water droplets strike an airfoil in flight, what kind of ice would result, and what shape that ice would take. Users can enter geometries for specific, two-dimensional cross sections of an airfoil or other airframe surface and then apply a range of inputs—different droplet sizes, temperatures, airspeeds, and more—to model how ice would build up on the surface in various conditions. The program’s versatility, ease of use, and speed—LEWICE can run through complex icing simulations in only a few minutes—have contributed to it becoming a popular resource in the aviation industry. \n                  “LEWICE is considered the premier code in the world for doing ice-shape generation,” says Mark Potapczuk, an aerospace engineer at Glenn who has coordinated the development of the LEWICE code over the years. \n                  The software is available to U.S. users at no cost from Glenn, and is distributed to everyone from graduate students at universities to multimillion-dollar companies. One such user has capitalized on the capabilities of LEWICE, developing a toolset with the potential to enhance the utility of the NASA-developed software.\n                  Partnership\n                   “I execute literally thousands of runs of LEWICE every year,” says David Parkins, founder and president of American Kestrel Company LLC. Based in Ithaca, New York, American Kestrel provides research and development and consulting services to aircraft manufacturers in the field of aviation safety and icing. Parkins has long used the NASA software to help his company’s customers design safe aircraft that can meet rigorous certification standards for flight in icing conditions. He saw room for improvement with the program’s user interface, however, and began developing tools to facilitate the plotting and running of the code. Parkins shared the results with Glenn, and the Center formed a partnership with American Kestrel through a Space Act Agreement, allowing the company to distribute LEWICE internationally with the company’s new interface. \n                  Benefits\n                  American Kestrel’s LEWICE Interface (LEWINT) combines LEWICE with an enhanced user interface, icing analysis tools, and automated plotting. Since 2007, the company has licensed its LEWINT product to 25 customers for applications including developing certified aircraft and analyzing wind turbines for icing issues.\n                  “Within the United States, every airframer uses LEWICE from Glenn, or LEWINT from American Kestrel,” Parkins says. A key to the technology’s ubiquity, he says, is the years of icing data Glenn has accumulated using its various research tools. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Ice buildup on airfoils can drastically affect the aerodynamics of an aircraft, leading to potentially hazardous flight conditions.\n                    \n                  \n                  “LEWICE is a unique code in that it has one of the world’s most extensive validation sets,” he says, explaining that Glenn has used its icing flight test bed and icing wind tunnel not only to help refine and develop LEWICE but to validate the code’s results. “Glenn has some of the best icing researchers in the world at one of the best icing facilities in the world working on that software, and they have evolved it into a very robust tool.” \n                  To help design and certify an aircraft or icing protection system for flight, manufacturers need to know how ice accumulates on their particular designs. Through using LEWICE or LEWINT in conjunction with tunnel and flight tests, engineers can determine the kinds of ice shapes that form on their designs in varying conditions. How these shapes impact the aircraft’s aerodynamics helps the engineers determine any design alterations needed to ensure safe flight. Parkins estimates that using the technology in this process saves American Kestrel’s customers hundreds of thousands of dollars in costs by reducing tunnel testing and precluding expensive, late stage design changes.\n                  “It’s a tool that helps reduce risk substantially and provides a lot of confidence that you have a design that is going to succeed,” he says.\n                  Glenn continues to evolve LEWICE to address new areas of icing research, including large supercooled droplets and engine icing. As useful a tool as LEWICE has been, Parkins says, its importance will only continue to grow.\n                  “The modern certification process has resulted in aircraft that are safer in icing conditions than anything we’ve ever developed,” he says. “LEWICE has been a key part of that.” \n                  \n                \n            \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Here’s a simple science experiment to try: Place an unopened bottle of distilled water in your freezer. After 2–3 hours, if the water is pure enough, you will notice that it has not frozen. Carefully pour the water into a bowl with a piece of ice in it. When it strikes the ice, the water will instantly freeze.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Supercooled large droplet conditions caused the buildup of ice on this aircraft. Using the NASA LEWICE software, aircraft manufacturers can model the ice accretion and the various shapes the ice can form (such as the inset example) on aircraft surfaces. \n                    \n                  \n                  One of the most basic and commonly known scientific facts is that water freezes at around 32 °F. But this is not always the case. Water lacking any impurities for ice crystals to form around can be supercooled to even lower temperatures without freezing. High in the atmosphere, water droplets can achieve this delicate, supercooled state. When a plane flies through clouds containing these droplets, the water can strike the airframe and, like the supercooled water hitting the ice in the experiment above, freeze instantly. The ice buildup alters the aerodynamics of the plane—reducing lift and increasing drag—affecting its performance and presenting a safety issue if the plane can no longer fly effectively. In certain circumstances, ice can form inside aircraft engines, another potential hazard.\n                  NASA has long studied ways of detecting and countering atmospheric icing conditions as part of the Agency’s efforts to enhance aviation safety. To do this, the Icing Branch at Glenn Research Center utilizes a number of world-class tools, including the Center’s Icing Research Tunnel and the NASA 607 icing research aircraft, a “flying laboratory” for studying icing conditions. The branch has also developed a suite of software programs to help aircraft and icing protection system designers understand the behavior of ice accumulation on various surfaces and in various conditions. \n                  One of these innovations is the LEWICE ice accretion simulation software. Initially developed in the 1980s (when Glenn was known as Lewis Research Center), LEWICE has become one of the most widely used tools in icing research and aircraft design and certification. LEWICE has been transformed over the years from strictly a research tool to one used routinely by industry and other government agencies. Glenn contractor William Wright has been the architect of this development, supported by a team of researchers investigating icing physics, creating validation data, and ensuring development according to standard software engineering practices. The program provides a virtual simulation environment for determining where water droplets strike an airfoil in flight, what kind of ice would result, and what shape that ice would take. Users can enter geometries for specific, two-dimensional cross sections of an airfoil or other airframe surface and then apply a range of inputs—different droplet sizes, temperatures, airspeeds, and more—to model how ice would build up on the surface in various conditions. The program’s versatility, ease of use, and speed—LEWICE can run through complex icing simulations in only a few minutes—have contributed to it becoming a popular resource in the aviation industry. \n                  “LEWICE is considered the premier code in the world for doing ice-shape generation,” says Mark Potapczuk, an aerospace engineer at Glenn who has coordinated the development of the LEWICE code over the years. \n                  The software is available to U.S. users at no cost from Glenn, and is distributed to everyone from graduate students at universities to multimillion-dollar companies. One such user has capitalized on the capabilities of LEWICE, developing a toolset with the potential to enhance the utility of the NASA-developed software.\n                  Partnership\n                   “I execute literally thousands of runs of LEWICE every year,” says David Parkins, founder and president of American Kestrel Company LLC. Based in Ithaca, New York, American Kestrel provides research and development and consulting services to aircraft manufacturers in the field of aviation safety and icing. Parkins has long used the NASA software to help his company’s customers design safe aircraft that can meet rigorous certification standards for flight in icing conditions. He saw room for improvement with the program’s user interface, however, and began developing tools to facilitate the plotting and running of the code. Parkins shared the results with Glenn, and the Center formed a partnership with American Kestrel through a Space Act Agreement, allowing the company to distribute LEWICE internationally with the company’s new interface. \n                  Benefits\n                  American Kestrel’s LEWICE Interface (LEWINT) combines LEWICE with an enhanced user interface, icing analysis tools, and automated plotting. Since 2007, the company has licensed its LEWINT product to 25 customers for applications including developing certified aircraft and analyzing wind turbines for icing issues.\n                  “Within the United States, every airframer uses LEWICE from Glenn, or LEWINT from American Kestrel,” Parkins says. A key to the technology’s ubiquity, he says, is the years of icing data Glenn has accumulated using its various research tools. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Ice buildup on airfoils can drastically affect the aerodynamics of an aircraft, leading to potentially hazardous flight conditions.\n                    \n                  \n                  “LEWICE is a unique code in that it has one of the world’s most extensive validation sets,” he says, explaining that Glenn has used its icing flight test bed and icing wind tunnel not only to help refine and develop LEWICE but to validate the code’s results. “Glenn has some of the best icing researchers in the world at one of the best icing facilities in the world working on that software, and they have evolved it into a very robust tool.” \n                  To help design and certify an aircraft or icing protection system for flight, manufacturers need to know how ice accumulates on their particular designs. Through using LEWICE or LEWINT in conjunction with tunnel and flight tests, engineers can determine the kinds of ice shapes that form on their designs in varying conditions. How these shapes impact the aircraft’s aerodynamics helps the engineers determine any design alterations needed to ensure safe flight. Parkins estimates that using the technology in this process saves American Kestrel’s customers hundreds of thousands of dollars in costs by reducing tunnel testing and precluding expensive, late stage design changes.\n                  “It’s a tool that helps reduce risk substantially and provides a lot of confidence that you have a design that is going to succeed,” he says.\n                  Glenn continues to evolve LEWICE to address new areas of icing research, including large supercooled droplets and engine icing. As useful a tool as LEWICE has been, Parkins says, its importance will only continue to grow.\n                  “The modern certification process has resulted in aircraft that are safer in icing conditions than anything we’ve ever developed,” he says. “LEWICE has been a key part of that.” \n                  \n                \n            \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Here’s a simple science experiment to try: Place an unopened bottle of distilled water in your freezer. After 2–3 hours, if the water is pure enough, you will notice that it has not frozen. Carefully pour the water into a bowl with a piece of ice in it. When it strikes the ice, the water will instantly freeze.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Supercooled large droplet conditions caused the buildup of ice on this aircraft. Using the NASA LEWICE software, aircraft manufacturers can model the ice accretion and the various shapes the ice can form (such as the inset example) on aircraft surfaces. \n                    \n                  \n                  One of the most basic and commonly known scientific facts is that water freezes at around 32 °F. But this is not always the case. Water lacking any impurities for ice crystals to form around can be supercooled to even lower temperatures without freezing. High in the atmosphere, water droplets can achieve this delicate, supercooled state. When a plane flies through clouds containing these droplets, the water can strike the airframe and, like the supercooled water hitting the ice in the experiment above, freeze instantly. The ice buildup alters the aerodynamics of the plane—reducing lift and increasing drag—affecting its performance and presenting a safety issue if the plane can no longer fly effectively. In certain circumstances, ice can form inside aircraft engines, another potential hazard.\n                  NASA has long studied ways of detecting and countering atmospheric icing conditions as part of the Agency’s efforts to enhance aviation safety. To do this, the Icing Branch at Glenn Research Center utilizes a number of world-class tools, including the Center’s Icing Research Tunnel and the NASA 607 icing research aircraft, a “flying laboratory” for studying icing conditions. The branch has also developed a suite of software programs to help aircraft and icing protection system designers understand the behavior of ice accumulation on various surfaces and in various conditions. \n                  One of these innovations is the LEWICE ice accretion simulation software. Initially developed in the 1980s (when Glenn was known as Lewis Research Center), LEWICE has become one of the most widely used tools in icing research and aircraft design and certification. LEWICE has been transformed over the years from strictly a research tool to one used routinely by industry and other government agencies. Glenn contractor William Wright has been the architect of this development, supported by a team of researchers investigating icing physics, creating validation data, and ensuring development according to standard software engineering practices. The program provides a virtual simulation environment for determining where water droplets strike an airfoil in flight, what kind of ice would result, and what shape that ice would take. Users can enter geometries for specific, two-dimensional cross sections of an airfoil or other airframe surface and then apply a range of inputs—different droplet sizes, temperatures, airspeeds, and more—to model how ice would build up on the surface in various conditions. The program’s versatility, ease of use, and speed—LEWICE can run through complex icing simulations in only a few minutes—have contributed to it becoming a popular resource in the aviation industry. \n                  “LEWICE is considered the premier code in the world for doing ice-shape generation,” says Mark Potapczuk, an aerospace engineer at Glenn who has coordinated the development of the LEWICE code over the years. \n                  The software is available to U.S. users at no cost from Glenn, and is distributed to everyone from graduate students at universities to multimillion-dollar companies. One such user has capitalized on the capabilities of LEWICE, developing a toolset with the potential to enhance the utility of the NASA-developed software.\n                  Partnership\n                   “I execute literally thousands of runs of LEWICE every year,” says David Parkins, founder and president of American Kestrel Company LLC. Based in Ithaca, New York, American Kestrel provides research and development and consulting services to aircraft manufacturers in the field of aviation safety and icing. Parkins has long used the NASA software to help his company’s customers design safe aircraft that can meet rigorous certification standards for flight in icing conditions. He saw room for improvement with the program’s user interface, however, and began developing tools to facilitate the plotting and running of the code. Parkins shared the results with Glenn, and the Center formed a partnership with American Kestrel through a Space Act Agreement, allowing the company to distribute LEWICE internationally with the company’s new interface. \n                  Benefits\n                  American Kestrel’s LEWICE Interface (LEWINT) combines LEWICE with an enhanced user interface, icing analysis tools, and automated plotting. Since 2007, the company has licensed its LEWINT product to 25 customers for applications including developing certified aircraft and analyzing wind turbines for icing issues.\n                  “Within the United States, every airframer uses LEWICE from Glenn, or LEWINT from American Kestrel,” Parkins says. A key to the technology’s ubiquity, he says, is the years of icing data Glenn has accumulated using its various research tools. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Ice buildup on airfoils can drastically affect the aerodynamics of an aircraft, leading to potentially hazardous flight conditions.\n                    \n                  \n                  “LEWICE is a unique code in that it has one of the world’s most extensive validation sets,” he says, explaining that Glenn has used its icing flight test bed and icing wind tunnel not only to help refine and develop LEWICE but to validate the code’s results. “Glenn has some of the best icing researchers in the world at one of the best icing facilities in the world working on that software, and they have evolved it into a very robust tool.” \n                  To help design and certify an aircraft or icing protection system for flight, manufacturers need to know how ice accumulates on their particular designs. Through using LEWICE or LEWINT in conjunction with tunnel and flight tests, engineers can determine the kinds of ice shapes that form on their designs in varying conditions. How these shapes impact the aircraft’s aerodynamics helps the engineers determine any design alterations needed to ensure safe flight. Parkins estimates that using the technology in this process saves American Kestrel’s customers hundreds of thousands of dollars in costs by reducing tunnel testing and precluding expensive, late stage design changes.\n                  “It’s a tool that helps reduce risk substantially and provides a lot of confidence that you have a design that is going to succeed,” he says.\n                  Glenn continues to evolve LEWICE to address new areas of icing research, including large supercooled droplets and engine icing. As useful a tool as LEWICE has been, Parkins says, its importance will only continue to grow.\n                  “The modern certification process has resulted in aircraft that are safer in icing conditions than anything we’ve ever developed,” he says. “LEWICE has been a key part of that.” \n                  \n                \n            \n            \n            \n          \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Here’s a simple science experiment to try: Place an unopened bottle of distilled water in your freezer. After 2–3 hours, if the water is pure enough, you will notice that it has not frozen. Carefully pour the water into a bowl with a piece of ice in it. When it strikes the ice, the water will instantly freeze.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Supercooled large droplet conditions caused the buildup of ice on this aircraft. Using the NASA LEWICE software, aircraft manufacturers can model the ice accretion and the various shapes the ice can form (such as the inset example) on aircraft surfaces. \n                    \n                  \n                  One of the most basic and commonly known scientific facts is that water freezes at around 32 °F. But this is not always the case. Water lacking any impurities for ice crystals to form around can be supercooled to even lower temperatures without freezing. High in the atmosphere, water droplets can achieve this delicate, supercooled state. When a plane flies through clouds containing these droplets, the water can strike the airframe and, like the supercooled water hitting the ice in the experiment above, freeze instantly. The ice buildup alters the aerodynamics of the plane—reducing lift and increasing drag—affecting its performance and presenting a safety issue if the plane can no longer fly effectively. In certain circumstances, ice can form inside aircraft engines, another potential hazard.\n                  NASA has long studied ways of detecting and countering atmospheric icing conditions as part of the Agency’s efforts to enhance aviation safety. To do this, the Icing Branch at Glenn Research Center utilizes a number of world-class tools, including the Center’s Icing Research Tunnel and the NASA 607 icing research aircraft, a “flying laboratory” for studying icing conditions. The branch has also developed a suite of software programs to help aircraft and icing protection system designers understand the behavior of ice accumulation on various surfaces and in various conditions. \n                  One of these innovations is the LEWICE ice accretion simulation software. Initially developed in the 1980s (when Glenn was known as Lewis Research Center), LEWICE has become one of the most widely used tools in icing research and aircraft design and certification. LEWICE has been transformed over the years from strictly a research tool to one used routinely by industry and other government agencies. Glenn contractor William Wright has been the architect of this development, supported by a team of researchers investigating icing physics, creating validation data, and ensuring development according to standard software engineering practices. The program provides a virtual simulation environment for determining where water droplets strike an airfoil in flight, what kind of ice would result, and what shape that ice would take. Users can enter geometries for specific, two-dimensional cross sections of an airfoil or other airframe surface and then apply a range of inputs—different droplet sizes, temperatures, airspeeds, and more—to model how ice would build up on the surface in various conditions. The program’s versatility, ease of use, and speed—LEWICE can run through complex icing simulations in only a few minutes—have contributed to it becoming a popular resource in the aviation industry. \n                  “LEWICE is considered the premier code in the world for doing ice-shape generation,” says Mark Potapczuk, an aerospace engineer at Glenn who has coordinated the development of the LEWICE code over the years. \n                  The software is available to U.S. users at no cost from Glenn, and is distributed to everyone from graduate students at universities to multimillion-dollar companies. One such user has capitalized on the capabilities of LEWICE, developing a toolset with the potential to enhance the utility of the NASA-developed software.\n                  Partnership\n                   “I execute literally thousands of runs of LEWICE every year,” says David Parkins, founder and president of American Kestrel Company LLC. Based in Ithaca, New York, American Kestrel provides research and development and consulting services to aircraft manufacturers in the field of aviation safety and icing. Parkins has long used the NASA software to help his company’s customers design safe aircraft that can meet rigorous certification standards for flight in icing conditions. He saw room for improvement with the program’s user interface, however, and began developing tools to facilitate the plotting and running of the code. Parkins shared the results with Glenn, and the Center formed a partnership with American Kestrel through a Space Act Agreement, allowing the company to distribute LEWICE internationally with the company’s new interface. \n                  Benefits\n                  American Kestrel’s LEWICE Interface (LEWINT) combines LEWICE with an enhanced user interface, icing analysis tools, and automated plotting. Since 2007, the company has licensed its LEWINT product to 25 customers for applications including developing certified aircraft and analyzing wind turbines for icing issues.\n                  “Within the United States, every airframer uses LEWICE from Glenn, or LEWINT from American Kestrel,” Parkins says. A key to the technology’s ubiquity, he says, is the years of icing data Glenn has accumulated using its various research tools. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Ice buildup on airfoils can drastically affect the aerodynamics of an aircraft, leading to potentially hazardous flight conditions.\n                    \n                  \n                  “LEWICE is a unique code in that it has one of the world’s most extensive validation sets,” he says, explaining that Glenn has used its icing flight test bed and icing wind tunnel not only to help refine and develop LEWICE but to validate the code’s results. “Glenn has some of the best icing researchers in the world at one of the best icing facilities in the world working on that software, and they have evolved it into a very robust tool.” \n                  To help design and certify an aircraft or icing protection system for flight, manufacturers need to know how ice accumulates on their particular designs. Through using LEWICE or LEWINT in conjunction with tunnel and flight tests, engineers can determine the kinds of ice shapes that form on their designs in varying conditions. How these shapes impact the aircraft’s aerodynamics helps the engineers determine any design alterations needed to ensure safe flight. Parkins estimates that using the technology in this process saves American Kestrel’s customers hundreds of thousands of dollars in costs by reducing tunnel testing and precluding expensive, late stage design changes.\n                  “It’s a tool that helps reduce risk substantially and provides a lot of confidence that you have a design that is going to succeed,” he says.\n                  Glenn continues to evolve LEWICE to address new areas of icing research, including large supercooled droplets and engine icing. As useful a tool as LEWICE has been, Parkins says, its importance will only continue to grow.\n                  “The modern certification process has resulted in aircraft that are safer in icing conditions than anything we’ve ever developed,” he says. “LEWICE has been a key part of that.” \n                  \n                \n            \n            \n            \n          \n            \n              \n                \n                  NASA Technology\n                  Here’s a simple science experiment to try: Place an unopened bottle of distilled water in your freezer. After 2–3 hours, if the water is pure enough, you will notice that it has not frozen. Carefully pour the water into a bowl with a piece of ice in it. When it strikes the ice, the water will instantly freeze.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Supercooled large droplet conditions caused the buildup of ice on this aircraft. Using the NASA LEWICE software, aircraft manufacturers can model the ice accretion and the various shapes the ice can form (such as the inset example) on aircraft surfaces. \n                    \n                  \n                  One of the most basic and commonly known scientific facts is that water freezes at around 32 °F. But this is not always the case. Water lacking any impurities for ice crystals to form around can be supercooled to even lower temperatures without freezing. High in the atmosphere, water droplets can achieve this delicate, supercooled state. When a plane flies through clouds containing these droplets, the water can strike the airframe and, like the supercooled water hitting the ice in the experiment above, freeze instantly. The ice buildup alters the aerodynamics of the plane—reducing lift and increasing drag—affecting its performance and presenting a safety issue if the plane can no longer fly effectively. In certain circumstances, ice can form inside aircraft engines, another potential hazard.\n                  NASA has long studied ways of detecting and countering atmospheric icing conditions as part of the Agency’s efforts to enhance aviation safety. To do this, the Icing Branch at Glenn Research Center utilizes a number of world-class tools, including the Center’s Icing Research Tunnel and the NASA 607 icing research aircraft, a “flying laboratory” for studying icing conditions. The branch has also developed a suite of software programs to help aircraft and icing protection system designers understand the behavior of ice accumulation on various surfaces and in various conditions. \n                  One of these innovations is the LEWICE ice accretion simulation software. Initially developed in the 1980s (when Glenn was known as Lewis Research Center), LEWICE has become one of the most widely used tools in icing research and aircraft design and certification. LEWICE has been transformed over the years from strictly a research tool to one used routinely by industry and other government agencies. Glenn contractor William Wright has been the architect of this development, supported by a team of researchers investigating icing physics, creating validation data, and ensuring development according to standard software engineering practices. The program provides a virtual simulation environment for determining where water droplets strike an airfoil in flight, what kind of ice would result, and what shape that ice would take. Users can enter geometries for specific, two-dimensional cross sections of an airfoil or other airframe surface and then apply a range of inputs—different droplet sizes, temperatures, airspeeds, and more—to model how ice would build up on the surface in various conditions. The program’s versatility, ease of use, and speed—LEWICE can run through complex icing simulations in only a few minutes—have contributed to it becoming a popular resource in the aviation industry. \n                  “LEWICE is considered the premier code in the world for doing ice-shape generation,” says Mark Potapczuk, an aerospace engineer at Glenn who has coordinated the development of the LEWICE code over the years. \n                  The software is available to U.S. users at no cost from Glenn, and is distributed to everyone from graduate students at universities to multimillion-dollar companies. One such user has capitalized on the capabilities of LEWICE, developing a toolset with the potential to enhance the utility of the NASA-developed software.\n                  Partnership\n                   “I execute literally thousands of runs of LEWICE every year,” says David Parkins, founder and president of American Kestrel Company LLC. Based in Ithaca, New York, American Kestrel provides research and development and consulting services to aircraft manufacturers in the field of aviation safety and icing. Parkins has long used the NASA software to help his company’s customers design safe aircraft that can meet rigorous certification standards for flight in icing conditions. He saw room for improvement with the program’s user interface, however, and began developing tools to facilitate the plotting and running of the code. Parkins shared the results with Glenn, and the Center formed a partnership with American Kestrel through a Space Act Agreement, allowing the company to distribute LEWICE internationally with the company’s new interface. \n                  Benefits\n                  American Kestrel’s LEWICE Interface (LEWINT) combines LEWICE with an enhanced user interface, icing analysis tools, and automated plotting. Since 2007, the company has licensed its LEWINT product to 25 customers for applications including developing certified aircraft and analyzing wind turbines for icing issues.\n                  “Within the United States, every airframer uses LEWICE from Glenn, or LEWINT from American Kestrel,” Parkins says. A key to the technology’s ubiquity, he says, is the years of icing data Glenn has accumulated using its various research tools. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Ice buildup on airfoils can drastically affect the aerodynamics of an aircraft, leading to potentially hazardous flight conditions.\n                    \n                  \n                  “LEWICE is a unique code in that it has one of the world’s most extensive validation sets,” he says, explaining that Glenn has used its icing flight test bed and icing wind tunnel not only to help refine and develop LEWICE but to validate the code’s results. “Glenn has some of the best icing researchers in the world at one of the best icing facilities in the world working on that software, and they have evolved it into a very robust tool.” \n                  To help design and certify an aircraft or icing protection system for flight, manufacturers need to know how ice accumulates on their particular designs. Through using LEWICE or LEWINT in conjunction with tunnel and flight tests, engineers can determine the kinds of ice shapes that form on their designs in varying conditions. How these shapes impact the aircraft’s aerodynamics helps the engineers determine any design alterations needed to ensure safe flight. Parkins estimates that using the technology in this process saves American Kestrel’s customers hundreds of thousands of dollars in costs by reducing tunnel testing and precluding expensive, late stage design changes.\n                  “It’s a tool that helps reduce risk substantially and provides a lot of confidence that you have a design that is going to succeed,” he says.\n                  Glenn continues to evolve LEWICE to address new areas of icing research, including large supercooled droplets and engine icing. As useful a tool as LEWICE has been, Parkins says, its importance will only continue to grow.\n                  “The modern certification process has resulted in aircraft that are safer in icing conditions than anything we’ve ever developed,” he says. “LEWICE has been a key part of that.” \n                  \n                \n            \n            \n            \n              \n                \n                  NASA Technology\n                  Here’s a simple science experiment to try: Place an unopened bottle of distilled water in your freezer. After 2–3 hours, if the water is pure enough, you will notice that it has not frozen. Carefully pour the water into a bowl with a piece of ice in it. When it strikes the ice, the water will instantly freeze.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Supercooled large droplet conditions caused the buildup of ice on this aircraft. Using the NASA LEWICE software, aircraft manufacturers can model the ice accretion and the various shapes the ice can form (such as the inset example) on aircraft surfaces. \n                    \n                  \n                  One of the most basic and commonly known scientific facts is that water freezes at around 32 °F. But this is not always the case. Water lacking any impurities for ice crystals to form around can be supercooled to even lower temperatures without freezing. High in the atmosphere, water droplets can achieve this delicate, supercooled state. When a plane flies through clouds containing these droplets, the water can strike the airframe and, like the supercooled water hitting the ice in the experiment above, freeze instantly. The ice buildup alters the aerodynamics of the plane—reducing lift and increasing drag—affecting its performance and presenting a safety issue if the plane can no longer fly effectively. In certain circumstances, ice can form inside aircraft engines, another potential hazard.\n                  NASA has long studied ways of detecting and countering atmospheric icing conditions as part of the Agency’s efforts to enhance aviation safety. To do this, the Icing Branch at Glenn Research Center utilizes a number of world-class tools, including the Center’s Icing Research Tunnel and the NASA 607 icing research aircraft, a “flying laboratory” for studying icing conditions. The branch has also developed a suite of software programs to help aircraft and icing protection system designers understand the behavior of ice accumulation on various surfaces and in various conditions. \n                  One of these innovations is the LEWICE ice accretion simulation software. Initially developed in the 1980s (when Glenn was known as Lewis Research Center), LEWICE has become one of the most widely used tools in icing research and aircraft design and certification. LEWICE has been transformed over the years from strictly a research tool to one used routinely by industry and other government agencies. Glenn contractor William Wright has been the architect of this development, supported by a team of researchers investigating icing physics, creating validation data, and ensuring development according to standard software engineering practices. The program provides a virtual simulation environment for determining where water droplets strike an airfoil in flight, what kind of ice would result, and what shape that ice would take. Users can enter geometries for specific, two-dimensional cross sections of an airfoil or other airframe surface and then apply a range of inputs—different droplet sizes, temperatures, airspeeds, and more—to model how ice would build up on the surface in various conditions. The program’s versatility, ease of use, and speed—LEWICE can run through complex icing simulations in only a few minutes—have contributed to it becoming a popular resource in the aviation industry. \n                  “LEWICE is considered the premier code in the world for doing ice-shape generation,” says Mark Potapczuk, an aerospace engineer at Glenn who has coordinated the development of the LEWICE code over the years. \n                  The software is available to U.S. users at no cost from Glenn, and is distributed to everyone from graduate students at universities to multimillion-dollar companies. One such user has capitalized on the capabilities of LEWICE, developing a toolset with the potential to enhance the utility of the NASA-developed software.\n                  Partnership\n                   “I execute literally thousands of runs of LEWICE every year,” says David Parkins, founder and president of American Kestrel Company LLC. Based in Ithaca, New York, American Kestrel provides research and development and consulting services to aircraft manufacturers in the field of aviation safety and icing. Parkins has long used the NASA software to help his company’s customers design safe aircraft that can meet rigorous certification standards for flight in icing conditions. He saw room for improvement with the program’s user interface, however, and began developing tools to facilitate the plotting and running of the code. Parkins shared the results with Glenn, and the Center formed a partnership with American Kestrel through a Space Act Agreement, allowing the company to distribute LEWICE internationally with the company’s new interface. \n                  Benefits\n                  American Kestrel’s LEWICE Interface (LEWINT) combines LEWICE with an enhanced user interface, icing analysis tools, and automated plotting. Since 2007, the company has licensed its LEWINT product to 25 customers for applications including developing certified aircraft and analyzing wind turbines for icing issues.\n                  “Within the United States, every airframer uses LEWICE from Glenn, or LEWINT from American Kestrel,” Parkins says. A key to the technology’s ubiquity, he says, is the years of icing data Glenn has accumulated using its various research tools. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Ice buildup on airfoils can drastically affect the aerodynamics of an aircraft, leading to potentially hazardous flight conditions.\n                    \n                  \n                  “LEWICE is a unique code in that it has one of the world’s most extensive validation sets,” he says, explaining that Glenn has used its icing flight test bed and icing wind tunnel not only to help refine and develop LEWICE but to validate the code’s results. “Glenn has some of the best icing researchers in the world at one of the best icing facilities in the world working on that software, and they have evolved it into a very robust tool.” \n                  To help design and certify an aircraft or icing protection system for flight, manufacturers need to know how ice accumulates on their particular designs. Through using LEWICE or LEWINT in conjunction with tunnel and flight tests, engineers can determine the kinds of ice shapes that form on their designs in varying conditions. How these shapes impact the aircraft’s aerodynamics helps the engineers determine any design alterations needed to ensure safe flight. Parkins estimates that using the technology in this process saves American Kestrel’s customers hundreds of thousands of dollars in costs by reducing tunnel testing and precluding expensive, late stage design changes.\n                  “It’s a tool that helps reduce risk substantially and provides a lot of confidence that you have a design that is going to succeed,” he says.\n                  Glenn continues to evolve LEWICE to address new areas of icing research, including large supercooled droplets and engine icing. As useful a tool as LEWICE has been, Parkins says, its importance will only continue to grow.\n                  “The modern certification process has resulted in aircraft that are safer in icing conditions than anything we’ve ever developed,” he says. “LEWICE has been a key part of that.” \n                  \n                \n            \n                  NASA Technology\n                  Here’s a simple science experiment to try: Place an unopened bottle of distilled water in your freezer. After 2–3 hours, if the water is pure enough, you will notice that it has not frozen. Carefully pour the water into a bowl with a piece of ice in it. When it strikes the ice, the water will instantly freeze.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Supercooled large droplet conditions caused the buildup of ice on this aircraft. Using the NASA LEWICE software, aircraft manufacturers can model the ice accretion and the various shapes the ice can form (such as the inset example) on aircraft surfaces. \n                    \n                  \n                  One of the most basic and commonly known scientific facts is that water freezes at around 32 °F. But this is not always the case. Water lacking any impurities for ice crystals to form around can be supercooled to even lower temperatures without freezing. High in the atmosphere, water droplets can achieve this delicate, supercooled state. When a plane flies through clouds containing these droplets, the water can strike the airframe and, like the supercooled water hitting the ice in the experiment above, freeze instantly. The ice buildup alters the aerodynamics of the plane—reducing lift and increasing drag—affecting its performance and presenting a safety issue if the plane can no longer fly effectively. In certain circumstances, ice can form inside aircraft engines, another potential hazard.\n                  NASA has long studied ways of detecting and countering atmospheric icing conditions as part of the Agency’s efforts to enhance aviation safety. To do this, the Icing Branch at Glenn Research Center utilizes a number of world-class tools, including the Center’s Icing Research Tunnel and the NASA 607 icing research aircraft, a “flying laboratory” for studying icing conditions. The branch has also developed a suite of software programs to help aircraft and icing protection system designers understand the behavior of ice accumulation on various surfaces and in various conditions. \n                  One of these innovations is the LEWICE ice accretion simulation software. Initially developed in the 1980s (when Glenn was known as Lewis Research Center), LEWICE has become one of the most widely used tools in icing research and aircraft design and certification. LEWICE has been transformed over the years from strictly a research tool to one used routinely by industry and other government agencies. Glenn contractor William Wright has been the architect of this development, supported by a team of researchers investigating icing physics, creating validation data, and ensuring development according to standard software engineering practices. The program provides a virtual simulation environment for determining where water droplets strike an airfoil in flight, what kind of ice would result, and what shape that ice would take. Users can enter geometries for specific, two-dimensional cross sections of an airfoil or other airframe surface and then apply a range of inputs—different droplet sizes, temperatures, airspeeds, and more—to model how ice would build up on the surface in various conditions. The program’s versatility, ease of use, and speed—LEWICE can run through complex icing simulations in only a few minutes—have contributed to it becoming a popular resource in the aviation industry. \n                  “LEWICE is considered the premier code in the world for doing ice-shape generation,” says Mark Potapczuk, an aerospace engineer at Glenn who has coordinated the development of the LEWICE code over the years. \n                  The software is available to U.S. users at no cost from Glenn, and is distributed to everyone from graduate students at universities to multimillion-dollar companies. One such user has capitalized on the capabilities of LEWICE, developing a toolset with the potential to enhance the utility of the NASA-developed software.\n                  Partnership\n                   “I execute literally thousands of runs of LEWICE every year,” says David Parkins, founder and president of American Kestrel Company LLC. Based in Ithaca, New York, American Kestrel provides research and development and consulting services to aircraft manufacturers in the field of aviation safety and icing. Parkins has long used the NASA software to help his company’s customers design safe aircraft that can meet rigorous certification standards for flight in icing conditions. He saw room for improvement with the program’s user interface, however, and began developing tools to facilitate the plotting and running of the code. Parkins shared the results with Glenn, and the Center formed a partnership with American Kestrel through a Space Act Agreement, allowing the company to distribute LEWICE internationally with the company’s new interface. \n                  Benefits\n                  American Kestrel’s LEWICE Interface (LEWINT) combines LEWICE with an enhanced user interface, icing analysis tools, and automated plotting. Since 2007, the company has licensed its LEWINT product to 25 customers for applications including developing certified aircraft and analyzing wind turbines for icing issues.\n                  “Within the United States, every airframer uses LEWICE from Glenn, or LEWINT from American Kestrel,” Parkins says. A key to the technology’s ubiquity, he says, is the years of icing data Glenn has accumulated using its various research tools. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Ice buildup on airfoils can drastically affect the aerodynamics of an aircraft, leading to potentially hazardous flight conditions.\n                    \n                  \n                  “LEWICE is a unique code in that it has one of the world’s most extensive validation sets,” he says, explaining that Glenn has used its icing flight test bed and icing wind tunnel not only to help refine and develop LEWICE but to validate the code’s results. “Glenn has some of the best icing researchers in the world at one of the best icing facilities in the world working on that software, and they have evolved it into a very robust tool.” \n                  To help design and certify an aircraft or icing protection system for flight, manufacturers need to know how ice accumulates on their particular designs. Through using LEWICE or LEWINT in conjunction with tunnel and flight tests, engineers can determine the kinds of ice shapes that form on their designs in varying conditions. How these shapes impact the aircraft’s aerodynamics helps the engineers determine any design alterations needed to ensure safe flight. Parkins estimates that using the technology in this process saves American Kestrel’s customers hundreds of thousands of dollars in costs by reducing tunnel testing and precluding expensive, late stage design changes.\n                  “It’s a tool that helps reduce risk substantially and provides a lot of confidence that you have a design that is going to succeed,” he says.\n                  Glenn continues to evolve LEWICE to address new areas of icing research, including large supercooled droplets and engine icing. As useful a tool as LEWICE has been, Parkins says, its importance will only continue to grow.\n                  “The modern certification process has resulted in aircraft that are safer in icing conditions than anything we’ve ever developed,” he says. “LEWICE has been a key part of that.” \n                  "},{"href":"http://spinoff.nasa.gov/Spinoff2011/ps_3.html","text":"Information Systems Coordinate Emergency Management","image":"http://spinoff.nasa.gov/Spinoff2011/Images/ps_5_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  The rescue crews have been searching for the woman for nearly a week. Hurricane Katrina devastated Hancock County, the southernmost point in Mississippi, and the woman had stayed through the storm in her beach house. There is little hope of finding her alive; the search teams know she is gone because the house is gone. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Hurricane Katrina caused damage to NASA facilities, including Stennis Space Center and the Michoud Assembly Facility, pictured here.\n                    \n                  \n                  Late at night in the art classroom of the school that is serving as the county’s emergency operations center, Craig Harvey is discussing the search with the center’s commander. Harvey is the Chief Operating Officer of a unique company called NVision Solutions Inc., based at NASA’s Stennis Space Center in Bay St. Louis, only a couple of miles away. He and his entire staff have set up a volunteer operation in the art room, supporting the emergency management efforts using technology and capabilities the company developed through its NASA partnerships. As he talks to the commander, Harvey feels an idea taking shape that might lead them to the woman’s location. Working with surface elevation data and hydrological principles, Harvey creates a map showing how the floodwaters from the storm would have flowed along the topography of the region around the woman’s former home. \n                  Using the map, search crews find the woman’s body in 15 minutes. \n                  Recovering individuals who have been lost is a sad reality of emergency management in the wake of a disaster like Hurricane Katrina in 2005. But the sooner answers can be provided, the sooner a community’s overall recovery can take place. When damage is extensive, resources are scattered, and people are in dire need of food, shelter, and medical assistance, the speed and efficiency of emergency operations can be the key to limiting the impact of a disaster and speeding the process of recovery. And a key to quick and effective emergency planning and response is geographic information.\n                  With a host of Earth-observing satellites orbiting the globe at all times, NASA generates an unmatched wealth of data about our ever-changing planet. This information can be captured, analyzed, and visualized by geographic information systems (GIS) to produce maps, charts, and other tools that can reveal information essential to a wide variety of applications—including emergency management. Knowing precise, real-time information about the size, location, environmental conditions, and resulting damage of an event like a flood or wildfire—as well as the location and numbers of emergency responders and other resources—contributes directly to the effectiveness of disaster mitigation. The need for such information is also evident when responding to homeland security threats, such as a terrorist attack. \n                  Recognizing the value of its geospatial information resources for this and other purposes, in 1998 Stennis and the state of Mississippi partnered to form what became the Enterprise for Innovative Geospatial Solutions (EIGS) industry cluster, supporting the growth of remote sensing and GIS-based research and business. As part of EIGS, several companies partnered with NASA through dual use and Small Business Innovation Research (SBIR) contracts. Among those was NVision. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      NVision Solutions Inc.’s NASA-derived REACT system provides officials with information on everything from the number and location of emergency workers to shelter capacities to water levels—through any computer and even handheld devices in the field. \n                    \n                  \n                  Founded in 2002 through a technology incubator under EIGS, NVision sought to capitalize on the geospatial information Stennis could offer. \n                  “We started the company with two people in an empty office, no money, and a single piece of paper with a logo we thought looked cool,” says Harvey. “We were local people who saw the opportunity.” The opportunity, he explains, was employing NASA’s constantly updated geographic data to provide essential, practical information to users in real time. \n                  NVision—a minority, woman-owned firm—engaged with Stennis through multiple dual-use and SBIR projects. An initial outcome was a precision agriculture system that harnessed NASA satellite data, research, and algorithms to allow farmers to generate efficient strategies for treating crops with fertilizers, pesticides, and other crop control chemicals. (The technology was commercialized through InTime Inc. of Cleveland, Mississippi—another NASA partner with origins at Stennis.) That work found a new application in 2003, when Louisiana’s St. Tammany parish suffered flooding in the wake of Tropical Storm Bill. To answer the parish’s need for more efficient acquisition of flooding estimates and damage assessments, NVision applied elements of its precision agriculture system to create a real-time flood alert system—a system the parish still uses today. With additional NASA assistance, the company further developed the St. Tammany emergency response system and realized the significance of this new direction.\n                  “We didn’t have that much farther to go to have a comprehensive emergency management system,” Harvey says. This was the beginning of NVision’s Real-Time Emergency Action Coordination Tool (REACT).\n                  When Hurricane Katrina struck the Gulf Coast in 2005, NVision immediately volunteered its GIS-based emergency management expertise to assist in Hancock County’s recovery efforts. Using NASA data from Stennis, the company churned out thousands of unique, custom maps per week to support emergency operations needs. The experience the company gained during Katrina translated into even more robust, comprehensive emergency management capabilities. (The solution Harvey devised to find the missing woman, for example, became a search and rescue tool now used as standard practice on the Gulf Coast.) \n                  When Stennis constructed a new emergency operations center following Katrina, NVision tailored its REACT system to NASA’s specifications. The NASA-derived technology ended up perfectly suiting NASA’s own needs, says Ron Magee, emergency director at Stennis.\n                  “The REACT system pulls from our GIS systems so it has the most current mapping and data layers that are associated with geographic coordinates,” he explains. “It gives us a one-stop shop where we can have all of the information at our fingertips.” \n                  Those capabilities impressed emergency managers at other NASA centers, and through a Phase III SBIR agreement, the REACT system was established at NASA Headquarters and every NASA center nationwide, allowing the Agency to launch coordinated responses in the event of an emergency situation. \n                  Benefits\n                  NASA, however, is far from the only beneficiary of the REACT technology. Today, REACT is NVision’s flagship product and has resulted in more than $2 million in revenue. Recently designated by the Department of Homeland Security (DHS) as a Qualified Anti-Terrorism Technology, REACT is currently in use by varied organizations throughout the country for a broad spectrum of emergency management applications. \n                  Simply put, REACT is a Web-based information system for enhancing decision making before, during, and after emergency situations. \n                  \n                    \n                    \n                      \n                    \n                    \n                      NVision developed its touchscreen tabletop technology to support its REACT system, but the technology’s applications extend beyond this original purpose. \n                    \n                  \n                  “REACT looks at an emergency in a comprehensive way,” Harvey says. “What sets it apart is that it is all handled with a geospatial perspective.” Accessible through any computer and even handheld devices for use by emergency workers in the field, the system provides a Common Operating Picture combining everything from water levels to the location of police cars to the number and current capacity of shelters and hospitals, and more—all in real time. “We’ve got satellites, river gauges, housing data, tax base data, elevation data,” says Harvey. \n                  REACT also functions as an effective emergency management training tool and, in nonemergency circumstances, as a facility management system for running the day-to-day operations of a building or campus. Incorporating the DHS National Incident Management System and Incident Command System, REACT even encompasses standardized government elements such as forms, allowing officials to quickly access and complete necessary paperwork. The goal is to provide emergency managers with all of the tools for making and executing informed decisions, even under duress. \n                  “It really boils down to this: Quicker, more efficient decisions save lives,” Harvey says. \n                  REACT has been used for emergency response to Hurricanes Ivan, Katrina, Gustav, and Ike. The Hancock County Emergency Operations Center, Mississippi National Guard, and the Environmental Protection Agency used the system during the 2010 Deepwater Horizon oil spill, tracking the extent of the spill, the location of oil booms, and air and water quality monitoring efforts. The National Center for Spectator Sports Safety and Security employs REACT as a counterterrorism solution for large stadiums and venues, and the U.S. Navy’s Center for Asymmetric Warfare has standardized the NASA-derived technology for use during its large scale military training exercises. The benefits to these and other REACT users include significant cost reductions; Harvey notes that the U.S. Coast Guard has recognized multimillions of dollars in savings from response initiatives employing the REACT system. \n                  The company has also developed new technologies in support of REACT, including a touchscreen tabletop device that allows REACT users to easily access and manipulate the information the system provides. The technology has attracted attention for uses beyond REACT, including military command briefings in the field, and has generated about $500,000 in revenue for the company.\n                  NVision now expects REACT to become a national standard within 5 years. \n                  “We’re talking with other states now that are looking to deploy REACT at state or regional levels,” Harvey says. “It’s been a long haul to get this credibility. It’s what NASA brings to the table for us.” Harvey notes that while the company started in 2002 with no investment, by 2008 it employed 52 workers. That number is now close to 75, and the company offers an average salary of $60,000. \n                  “These are Mississippi people getting high-tech jobs to support NASA Stennis initiatives,” Harvey says. \n                  In the meantime, the EIGS cluster Stennis helped to found recently became a wholly private, self-funded venture, managed by the Magnolia Business Alliance. NVision is a leader of the alliance, which will support the ongoing growth of the Mississippi geospatial industry.\n                   “NASA was financially supporting development, lowering the barriers of high tech companies to get involved in geosciences, and creating a service industry for the commercial remote sensing program at Stennis,” Harvey says. “It worked.” \n                   In the meantime, Stennis is now better equipped in the event of another disaster on the magnitude of Hurricane Katrina. \n                  “We’re pretty much whole again and prepared for the next storm,” says Magee. “REACT is a part of that.”\n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  The rescue crews have been searching for the woman for nearly a week. Hurricane Katrina devastated Hancock County, the southernmost point in Mississippi, and the woman had stayed through the storm in her beach house. There is little hope of finding her alive; the search teams know she is gone because the house is gone. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Hurricane Katrina caused damage to NASA facilities, including Stennis Space Center and the Michoud Assembly Facility, pictured here.\n                    \n                  \n                  Late at night in the art classroom of the school that is serving as the county’s emergency operations center, Craig Harvey is discussing the search with the center’s commander. Harvey is the Chief Operating Officer of a unique company called NVision Solutions Inc., based at NASA’s Stennis Space Center in Bay St. Louis, only a couple of miles away. He and his entire staff have set up a volunteer operation in the art room, supporting the emergency management efforts using technology and capabilities the company developed through its NASA partnerships. As he talks to the commander, Harvey feels an idea taking shape that might lead them to the woman’s location. Working with surface elevation data and hydrological principles, Harvey creates a map showing how the floodwaters from the storm would have flowed along the topography of the region around the woman’s former home. \n                  Using the map, search crews find the woman’s body in 15 minutes. \n                  Recovering individuals who have been lost is a sad reality of emergency management in the wake of a disaster like Hurricane Katrina in 2005. But the sooner answers can be provided, the sooner a community’s overall recovery can take place. When damage is extensive, resources are scattered, and people are in dire need of food, shelter, and medical assistance, the speed and efficiency of emergency operations can be the key to limiting the impact of a disaster and speeding the process of recovery. And a key to quick and effective emergency planning and response is geographic information.\n                  With a host of Earth-observing satellites orbiting the globe at all times, NASA generates an unmatched wealth of data about our ever-changing planet. This information can be captured, analyzed, and visualized by geographic information systems (GIS) to produce maps, charts, and other tools that can reveal information essential to a wide variety of applications—including emergency management. Knowing precise, real-time information about the size, location, environmental conditions, and resulting damage of an event like a flood or wildfire—as well as the location and numbers of emergency responders and other resources—contributes directly to the effectiveness of disaster mitigation. The need for such information is also evident when responding to homeland security threats, such as a terrorist attack. \n                  Recognizing the value of its geospatial information resources for this and other purposes, in 1998 Stennis and the state of Mississippi partnered to form what became the Enterprise for Innovative Geospatial Solutions (EIGS) industry cluster, supporting the growth of remote sensing and GIS-based research and business. As part of EIGS, several companies partnered with NASA through dual use and Small Business Innovation Research (SBIR) contracts. Among those was NVision. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      NVision Solutions Inc.’s NASA-derived REACT system provides officials with information on everything from the number and location of emergency workers to shelter capacities to water levels—through any computer and even handheld devices in the field. \n                    \n                  \n                  Founded in 2002 through a technology incubator under EIGS, NVision sought to capitalize on the geospatial information Stennis could offer. \n                  “We started the company with two people in an empty office, no money, and a single piece of paper with a logo we thought looked cool,” says Harvey. “We were local people who saw the opportunity.” The opportunity, he explains, was employing NASA’s constantly updated geographic data to provide essential, practical information to users in real time. \n                  NVision—a minority, woman-owned firm—engaged with Stennis through multiple dual-use and SBIR projects. An initial outcome was a precision agriculture system that harnessed NASA satellite data, research, and algorithms to allow farmers to generate efficient strategies for treating crops with fertilizers, pesticides, and other crop control chemicals. (The technology was commercialized through InTime Inc. of Cleveland, Mississippi—another NASA partner with origins at Stennis.) That work found a new application in 2003, when Louisiana’s St. Tammany parish suffered flooding in the wake of Tropical Storm Bill. To answer the parish’s need for more efficient acquisition of flooding estimates and damage assessments, NVision applied elements of its precision agriculture system to create a real-time flood alert system—a system the parish still uses today. With additional NASA assistance, the company further developed the St. Tammany emergency response system and realized the significance of this new direction.\n                  “We didn’t have that much farther to go to have a comprehensive emergency management system,” Harvey says. This was the beginning of NVision’s Real-Time Emergency Action Coordination Tool (REACT).\n                  When Hurricane Katrina struck the Gulf Coast in 2005, NVision immediately volunteered its GIS-based emergency management expertise to assist in Hancock County’s recovery efforts. Using NASA data from Stennis, the company churned out thousands of unique, custom maps per week to support emergency operations needs. The experience the company gained during Katrina translated into even more robust, comprehensive emergency management capabilities. (The solution Harvey devised to find the missing woman, for example, became a search and rescue tool now used as standard practice on the Gulf Coast.) \n                  When Stennis constructed a new emergency operations center following Katrina, NVision tailored its REACT system to NASA’s specifications. The NASA-derived technology ended up perfectly suiting NASA’s own needs, says Ron Magee, emergency director at Stennis.\n                  “The REACT system pulls from our GIS systems so it has the most current mapping and data layers that are associated with geographic coordinates,” he explains. “It gives us a one-stop shop where we can have all of the information at our fingertips.” \n                  Those capabilities impressed emergency managers at other NASA centers, and through a Phase III SBIR agreement, the REACT system was established at NASA Headquarters and every NASA center nationwide, allowing the Agency to launch coordinated responses in the event of an emergency situation. \n                  Benefits\n                  NASA, however, is far from the only beneficiary of the REACT technology. Today, REACT is NVision’s flagship product and has resulted in more than $2 million in revenue. Recently designated by the Department of Homeland Security (DHS) as a Qualified Anti-Terrorism Technology, REACT is currently in use by varied organizations throughout the country for a broad spectrum of emergency management applications. \n                  Simply put, REACT is a Web-based information system for enhancing decision making before, during, and after emergency situations. \n                  \n                    \n                    \n                      \n                    \n                    \n                      NVision developed its touchscreen tabletop technology to support its REACT system, but the technology’s applications extend beyond this original purpose. \n                    \n                  \n                  “REACT looks at an emergency in a comprehensive way,” Harvey says. “What sets it apart is that it is all handled with a geospatial perspective.” Accessible through any computer and even handheld devices for use by emergency workers in the field, the system provides a Common Operating Picture combining everything from water levels to the location of police cars to the number and current capacity of shelters and hospitals, and more—all in real time. “We’ve got satellites, river gauges, housing data, tax base data, elevation data,” says Harvey. \n                  REACT also functions as an effective emergency management training tool and, in nonemergency circumstances, as a facility management system for running the day-to-day operations of a building or campus. Incorporating the DHS National Incident Management System and Incident Command System, REACT even encompasses standardized government elements such as forms, allowing officials to quickly access and complete necessary paperwork. The goal is to provide emergency managers with all of the tools for making and executing informed decisions, even under duress. \n                  “It really boils down to this: Quicker, more efficient decisions save lives,” Harvey says. \n                  REACT has been used for emergency response to Hurricanes Ivan, Katrina, Gustav, and Ike. The Hancock County Emergency Operations Center, Mississippi National Guard, and the Environmental Protection Agency used the system during the 2010 Deepwater Horizon oil spill, tracking the extent of the spill, the location of oil booms, and air and water quality monitoring efforts. The National Center for Spectator Sports Safety and Security employs REACT as a counterterrorism solution for large stadiums and venues, and the U.S. Navy’s Center for Asymmetric Warfare has standardized the NASA-derived technology for use during its large scale military training exercises. The benefits to these and other REACT users include significant cost reductions; Harvey notes that the U.S. Coast Guard has recognized multimillions of dollars in savings from response initiatives employing the REACT system. \n                  The company has also developed new technologies in support of REACT, including a touchscreen tabletop device that allows REACT users to easily access and manipulate the information the system provides. The technology has attracted attention for uses beyond REACT, including military command briefings in the field, and has generated about $500,000 in revenue for the company.\n                  NVision now expects REACT to become a national standard within 5 years. \n                  “We’re talking with other states now that are looking to deploy REACT at state or regional levels,” Harvey says. “It’s been a long haul to get this credibility. It’s what NASA brings to the table for us.” Harvey notes that while the company started in 2002 with no investment, by 2008 it employed 52 workers. That number is now close to 75, and the company offers an average salary of $60,000. \n                  “These are Mississippi people getting high-tech jobs to support NASA Stennis initiatives,” Harvey says. \n                  In the meantime, the EIGS cluster Stennis helped to found recently became a wholly private, self-funded venture, managed by the Magnolia Business Alliance. NVision is a leader of the alliance, which will support the ongoing growth of the Mississippi geospatial industry.\n                   “NASA was financially supporting development, lowering the barriers of high tech companies to get involved in geosciences, and creating a service industry for the commercial remote sensing program at Stennis,” Harvey says. “It worked.” \n                   In the meantime, Stennis is now better equipped in the event of another disaster on the magnitude of Hurricane Katrina. \n                  “We’re pretty much whole again and prepared for the next storm,” says Magee. “REACT is a part of that.”\n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  The rescue crews have been searching for the woman for nearly a week. Hurricane Katrina devastated Hancock County, the southernmost point in Mississippi, and the woman had stayed through the storm in her beach house. There is little hope of finding her alive; the search teams know she is gone because the house is gone. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Hurricane Katrina caused damage to NASA facilities, including Stennis Space Center and the Michoud Assembly Facility, pictured here.\n                    \n                  \n                  Late at night in the art classroom of the school that is serving as the county’s emergency operations center, Craig Harvey is discussing the search with the center’s commander. Harvey is the Chief Operating Officer of a unique company called NVision Solutions Inc., based at NASA’s Stennis Space Center in Bay St. Louis, only a couple of miles away. He and his entire staff have set up a volunteer operation in the art room, supporting the emergency management efforts using technology and capabilities the company developed through its NASA partnerships. As he talks to the commander, Harvey feels an idea taking shape that might lead them to the woman’s location. Working with surface elevation data and hydrological principles, Harvey creates a map showing how the floodwaters from the storm would have flowed along the topography of the region around the woman’s former home. \n                  Using the map, search crews find the woman’s body in 15 minutes. \n                  Recovering individuals who have been lost is a sad reality of emergency management in the wake of a disaster like Hurricane Katrina in 2005. But the sooner answers can be provided, the sooner a community’s overall recovery can take place. When damage is extensive, resources are scattered, and people are in dire need of food, shelter, and medical assistance, the speed and efficiency of emergency operations can be the key to limiting the impact of a disaster and speeding the process of recovery. And a key to quick and effective emergency planning and response is geographic information.\n                  With a host of Earth-observing satellites orbiting the globe at all times, NASA generates an unmatched wealth of data about our ever-changing planet. This information can be captured, analyzed, and visualized by geographic information systems (GIS) to produce maps, charts, and other tools that can reveal information essential to a wide variety of applications—including emergency management. Knowing precise, real-time information about the size, location, environmental conditions, and resulting damage of an event like a flood or wildfire—as well as the location and numbers of emergency responders and other resources—contributes directly to the effectiveness of disaster mitigation. The need for such information is also evident when responding to homeland security threats, such as a terrorist attack. \n                  Recognizing the value of its geospatial information resources for this and other purposes, in 1998 Stennis and the state of Mississippi partnered to form what became the Enterprise for Innovative Geospatial Solutions (EIGS) industry cluster, supporting the growth of remote sensing and GIS-based research and business. As part of EIGS, several companies partnered with NASA through dual use and Small Business Innovation Research (SBIR) contracts. Among those was NVision. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      NVision Solutions Inc.’s NASA-derived REACT system provides officials with information on everything from the number and location of emergency workers to shelter capacities to water levels—through any computer and even handheld devices in the field. \n                    \n                  \n                  Founded in 2002 through a technology incubator under EIGS, NVision sought to capitalize on the geospatial information Stennis could offer. \n                  “We started the company with two people in an empty office, no money, and a single piece of paper with a logo we thought looked cool,” says Harvey. “We were local people who saw the opportunity.” The opportunity, he explains, was employing NASA’s constantly updated geographic data to provide essential, practical information to users in real time. \n                  NVision—a minority, woman-owned firm—engaged with Stennis through multiple dual-use and SBIR projects. An initial outcome was a precision agriculture system that harnessed NASA satellite data, research, and algorithms to allow farmers to generate efficient strategies for treating crops with fertilizers, pesticides, and other crop control chemicals. (The technology was commercialized through InTime Inc. of Cleveland, Mississippi—another NASA partner with origins at Stennis.) That work found a new application in 2003, when Louisiana’s St. Tammany parish suffered flooding in the wake of Tropical Storm Bill. To answer the parish’s need for more efficient acquisition of flooding estimates and damage assessments, NVision applied elements of its precision agriculture system to create a real-time flood alert system—a system the parish still uses today. With additional NASA assistance, the company further developed the St. Tammany emergency response system and realized the significance of this new direction.\n                  “We didn’t have that much farther to go to have a comprehensive emergency management system,” Harvey says. This was the beginning of NVision’s Real-Time Emergency Action Coordination Tool (REACT).\n                  When Hurricane Katrina struck the Gulf Coast in 2005, NVision immediately volunteered its GIS-based emergency management expertise to assist in Hancock County’s recovery efforts. Using NASA data from Stennis, the company churned out thousands of unique, custom maps per week to support emergency operations needs. The experience the company gained during Katrina translated into even more robust, comprehensive emergency management capabilities. (The solution Harvey devised to find the missing woman, for example, became a search and rescue tool now used as standard practice on the Gulf Coast.) \n                  When Stennis constructed a new emergency operations center following Katrina, NVision tailored its REACT system to NASA’s specifications. The NASA-derived technology ended up perfectly suiting NASA’s own needs, says Ron Magee, emergency director at Stennis.\n                  “The REACT system pulls from our GIS systems so it has the most current mapping and data layers that are associated with geographic coordinates,” he explains. “It gives us a one-stop shop where we can have all of the information at our fingertips.” \n                  Those capabilities impressed emergency managers at other NASA centers, and through a Phase III SBIR agreement, the REACT system was established at NASA Headquarters and every NASA center nationwide, allowing the Agency to launch coordinated responses in the event of an emergency situation. \n                  Benefits\n                  NASA, however, is far from the only beneficiary of the REACT technology. Today, REACT is NVision’s flagship product and has resulted in more than $2 million in revenue. Recently designated by the Department of Homeland Security (DHS) as a Qualified Anti-Terrorism Technology, REACT is currently in use by varied organizations throughout the country for a broad spectrum of emergency management applications. \n                  Simply put, REACT is a Web-based information system for enhancing decision making before, during, and after emergency situations. \n                  \n                    \n                    \n                      \n                    \n                    \n                      NVision developed its touchscreen tabletop technology to support its REACT system, but the technology’s applications extend beyond this original purpose. \n                    \n                  \n                  “REACT looks at an emergency in a comprehensive way,” Harvey says. “What sets it apart is that it is all handled with a geospatial perspective.” Accessible through any computer and even handheld devices for use by emergency workers in the field, the system provides a Common Operating Picture combining everything from water levels to the location of police cars to the number and current capacity of shelters and hospitals, and more—all in real time. “We’ve got satellites, river gauges, housing data, tax base data, elevation data,” says Harvey. \n                  REACT also functions as an effective emergency management training tool and, in nonemergency circumstances, as a facility management system for running the day-to-day operations of a building or campus. Incorporating the DHS National Incident Management System and Incident Command System, REACT even encompasses standardized government elements such as forms, allowing officials to quickly access and complete necessary paperwork. The goal is to provide emergency managers with all of the tools for making and executing informed decisions, even under duress. \n                  “It really boils down to this: Quicker, more efficient decisions save lives,” Harvey says. \n                  REACT has been used for emergency response to Hurricanes Ivan, Katrina, Gustav, and Ike. The Hancock County Emergency Operations Center, Mississippi National Guard, and the Environmental Protection Agency used the system during the 2010 Deepwater Horizon oil spill, tracking the extent of the spill, the location of oil booms, and air and water quality monitoring efforts. The National Center for Spectator Sports Safety and Security employs REACT as a counterterrorism solution for large stadiums and venues, and the U.S. Navy’s Center for Asymmetric Warfare has standardized the NASA-derived technology for use during its large scale military training exercises. The benefits to these and other REACT users include significant cost reductions; Harvey notes that the U.S. Coast Guard has recognized multimillions of dollars in savings from response initiatives employing the REACT system. \n                  The company has also developed new technologies in support of REACT, including a touchscreen tabletop device that allows REACT users to easily access and manipulate the information the system provides. The technology has attracted attention for uses beyond REACT, including military command briefings in the field, and has generated about $500,000 in revenue for the company.\n                  NVision now expects REACT to become a national standard within 5 years. \n                  “We’re talking with other states now that are looking to deploy REACT at state or regional levels,” Harvey says. “It’s been a long haul to get this credibility. It’s what NASA brings to the table for us.” Harvey notes that while the company started in 2002 with no investment, by 2008 it employed 52 workers. That number is now close to 75, and the company offers an average salary of $60,000. \n                  “These are Mississippi people getting high-tech jobs to support NASA Stennis initiatives,” Harvey says. \n                  In the meantime, the EIGS cluster Stennis helped to found recently became a wholly private, self-funded venture, managed by the Magnolia Business Alliance. NVision is a leader of the alliance, which will support the ongoing growth of the Mississippi geospatial industry.\n                   “NASA was financially supporting development, lowering the barriers of high tech companies to get involved in geosciences, and creating a service industry for the commercial remote sensing program at Stennis,” Harvey says. “It worked.” \n                   In the meantime, Stennis is now better equipped in the event of another disaster on the magnitude of Hurricane Katrina. \n                  “We’re pretty much whole again and prepared for the next storm,” says Magee. “REACT is a part of that.”\n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  NASA Technology\n                  The rescue crews have been searching for the woman for nearly a week. Hurricane Katrina devastated Hancock County, the southernmost point in Mississippi, and the woman had stayed through the storm in her beach house. There is little hope of finding her alive; the search teams know she is gone because the house is gone. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Hurricane Katrina caused damage to NASA facilities, including Stennis Space Center and the Michoud Assembly Facility, pictured here.\n                    \n                  \n                  Late at night in the art classroom of the school that is serving as the county’s emergency operations center, Craig Harvey is discussing the search with the center’s commander. Harvey is the Chief Operating Officer of a unique company called NVision Solutions Inc., based at NASA’s Stennis Space Center in Bay St. Louis, only a couple of miles away. He and his entire staff have set up a volunteer operation in the art room, supporting the emergency management efforts using technology and capabilities the company developed through its NASA partnerships. As he talks to the commander, Harvey feels an idea taking shape that might lead them to the woman’s location. Working with surface elevation data and hydrological principles, Harvey creates a map showing how the floodwaters from the storm would have flowed along the topography of the region around the woman’s former home. \n                  Using the map, search crews find the woman’s body in 15 minutes. \n                  Recovering individuals who have been lost is a sad reality of emergency management in the wake of a disaster like Hurricane Katrina in 2005. But the sooner answers can be provided, the sooner a community’s overall recovery can take place. When damage is extensive, resources are scattered, and people are in dire need of food, shelter, and medical assistance, the speed and efficiency of emergency operations can be the key to limiting the impact of a disaster and speeding the process of recovery. And a key to quick and effective emergency planning and response is geographic information.\n                  With a host of Earth-observing satellites orbiting the globe at all times, NASA generates an unmatched wealth of data about our ever-changing planet. This information can be captured, analyzed, and visualized by geographic information systems (GIS) to produce maps, charts, and other tools that can reveal information essential to a wide variety of applications—including emergency management. Knowing precise, real-time information about the size, location, environmental conditions, and resulting damage of an event like a flood or wildfire—as well as the location and numbers of emergency responders and other resources—contributes directly to the effectiveness of disaster mitigation. The need for such information is also evident when responding to homeland security threats, such as a terrorist attack. \n                  Recognizing the value of its geospatial information resources for this and other purposes, in 1998 Stennis and the state of Mississippi partnered to form what became the Enterprise for Innovative Geospatial Solutions (EIGS) industry cluster, supporting the growth of remote sensing and GIS-based research and business. As part of EIGS, several companies partnered with NASA through dual use and Small Business Innovation Research (SBIR) contracts. Among those was NVision. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      NVision Solutions Inc.’s NASA-derived REACT system provides officials with information on everything from the number and location of emergency workers to shelter capacities to water levels—through any computer and even handheld devices in the field. \n                    \n                  \n                  Founded in 2002 through a technology incubator under EIGS, NVision sought to capitalize on the geospatial information Stennis could offer. \n                  “We started the company with two people in an empty office, no money, and a single piece of paper with a logo we thought looked cool,” says Harvey. “We were local people who saw the opportunity.” The opportunity, he explains, was employing NASA’s constantly updated geographic data to provide essential, practical information to users in real time. \n                  NVision—a minority, woman-owned firm—engaged with Stennis through multiple dual-use and SBIR projects. An initial outcome was a precision agriculture system that harnessed NASA satellite data, research, and algorithms to allow farmers to generate efficient strategies for treating crops with fertilizers, pesticides, and other crop control chemicals. (The technology was commercialized through InTime Inc. of Cleveland, Mississippi—another NASA partner with origins at Stennis.) That work found a new application in 2003, when Louisiana’s St. Tammany parish suffered flooding in the wake of Tropical Storm Bill. To answer the parish’s need for more efficient acquisition of flooding estimates and damage assessments, NVision applied elements of its precision agriculture system to create a real-time flood alert system—a system the parish still uses today. With additional NASA assistance, the company further developed the St. Tammany emergency response system and realized the significance of this new direction.\n                  “We didn’t have that much farther to go to have a comprehensive emergency management system,” Harvey says. This was the beginning of NVision’s Real-Time Emergency Action Coordination Tool (REACT).\n                  When Hurricane Katrina struck the Gulf Coast in 2005, NVision immediately volunteered its GIS-based emergency management expertise to assist in Hancock County’s recovery efforts. Using NASA data from Stennis, the company churned out thousands of unique, custom maps per week to support emergency operations needs. The experience the company gained during Katrina translated into even more robust, comprehensive emergency management capabilities. (The solution Harvey devised to find the missing woman, for example, became a search and rescue tool now used as standard practice on the Gulf Coast.) \n                  When Stennis constructed a new emergency operations center following Katrina, NVision tailored its REACT system to NASA’s specifications. The NASA-derived technology ended up perfectly suiting NASA’s own needs, says Ron Magee, emergency director at Stennis.\n                  “The REACT system pulls from our GIS systems so it has the most current mapping and data layers that are associated with geographic coordinates,” he explains. “It gives us a one-stop shop where we can have all of the information at our fingertips.” \n                  Those capabilities impressed emergency managers at other NASA centers, and through a Phase III SBIR agreement, the REACT system was established at NASA Headquarters and every NASA center nationwide, allowing the Agency to launch coordinated responses in the event of an emergency situation. \n                  Benefits\n                  NASA, however, is far from the only beneficiary of the REACT technology. Today, REACT is NVision’s flagship product and has resulted in more than $2 million in revenue. Recently designated by the Department of Homeland Security (DHS) as a Qualified Anti-Terrorism Technology, REACT is currently in use by varied organizations throughout the country for a broad spectrum of emergency management applications. \n                  Simply put, REACT is a Web-based information system for enhancing decision making before, during, and after emergency situations. \n                  \n                    \n                    \n                      \n                    \n                    \n                      NVision developed its touchscreen tabletop technology to support its REACT system, but the technology’s applications extend beyond this original purpose. \n                    \n                  \n                  “REACT looks at an emergency in a comprehensive way,” Harvey says. “What sets it apart is that it is all handled with a geospatial perspective.” Accessible through any computer and even handheld devices for use by emergency workers in the field, the system provides a Common Operating Picture combining everything from water levels to the location of police cars to the number and current capacity of shelters and hospitals, and more—all in real time. “We’ve got satellites, river gauges, housing data, tax base data, elevation data,” says Harvey. \n                  REACT also functions as an effective emergency management training tool and, in nonemergency circumstances, as a facility management system for running the day-to-day operations of a building or campus. Incorporating the DHS National Incident Management System and Incident Command System, REACT even encompasses standardized government elements such as forms, allowing officials to quickly access and complete necessary paperwork. The goal is to provide emergency managers with all of the tools for making and executing informed decisions, even under duress. \n                  “It really boils down to this: Quicker, more efficient decisions save lives,” Harvey says. \n                  REACT has been used for emergency response to Hurricanes Ivan, Katrina, Gustav, and Ike. The Hancock County Emergency Operations Center, Mississippi National Guard, and the Environmental Protection Agency used the system during the 2010 Deepwater Horizon oil spill, tracking the extent of the spill, the location of oil booms, and air and water quality monitoring efforts. The National Center for Spectator Sports Safety and Security employs REACT as a counterterrorism solution for large stadiums and venues, and the U.S. Navy’s Center for Asymmetric Warfare has standardized the NASA-derived technology for use during its large scale military training exercises. The benefits to these and other REACT users include significant cost reductions; Harvey notes that the U.S. Coast Guard has recognized multimillions of dollars in savings from response initiatives employing the REACT system. \n                  The company has also developed new technologies in support of REACT, including a touchscreen tabletop device that allows REACT users to easily access and manipulate the information the system provides. The technology has attracted attention for uses beyond REACT, including military command briefings in the field, and has generated about $500,000 in revenue for the company.\n                  NVision now expects REACT to become a national standard within 5 years. \n                  “We’re talking with other states now that are looking to deploy REACT at state or regional levels,” Harvey says. “It’s been a long haul to get this credibility. It’s what NASA brings to the table for us.” Harvey notes that while the company started in 2002 with no investment, by 2008 it employed 52 workers. That number is now close to 75, and the company offers an average salary of $60,000. \n                  “These are Mississippi people getting high-tech jobs to support NASA Stennis initiatives,” Harvey says. \n                  In the meantime, the EIGS cluster Stennis helped to found recently became a wholly private, self-funded venture, managed by the Magnolia Business Alliance. NVision is a leader of the alliance, which will support the ongoing growth of the Mississippi geospatial industry.\n                   “NASA was financially supporting development, lowering the barriers of high tech companies to get involved in geosciences, and creating a service industry for the commercial remote sensing program at Stennis,” Harvey says. “It worked.” \n                   In the meantime, Stennis is now better equipped in the event of another disaster on the magnitude of Hurricane Katrina. \n                  “We’re pretty much whole again and prepared for the next storm,” says Magee. “REACT is a part of that.”\n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  NASA Technology\n                  The rescue crews have been searching for the woman for nearly a week. Hurricane Katrina devastated Hancock County, the southernmost point in Mississippi, and the woman had stayed through the storm in her beach house. There is little hope of finding her alive; the search teams know she is gone because the house is gone. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Hurricane Katrina caused damage to NASA facilities, including Stennis Space Center and the Michoud Assembly Facility, pictured here.\n                    \n                  \n                  Late at night in the art classroom of the school that is serving as the county’s emergency operations center, Craig Harvey is discussing the search with the center’s commander. Harvey is the Chief Operating Officer of a unique company called NVision Solutions Inc., based at NASA’s Stennis Space Center in Bay St. Louis, only a couple of miles away. He and his entire staff have set up a volunteer operation in the art room, supporting the emergency management efforts using technology and capabilities the company developed through its NASA partnerships. As he talks to the commander, Harvey feels an idea taking shape that might lead them to the woman’s location. Working with surface elevation data and hydrological principles, Harvey creates a map showing how the floodwaters from the storm would have flowed along the topography of the region around the woman’s former home. \n                  Using the map, search crews find the woman’s body in 15 minutes. \n                  Recovering individuals who have been lost is a sad reality of emergency management in the wake of a disaster like Hurricane Katrina in 2005. But the sooner answers can be provided, the sooner a community’s overall recovery can take place. When damage is extensive, resources are scattered, and people are in dire need of food, shelter, and medical assistance, the speed and efficiency of emergency operations can be the key to limiting the impact of a disaster and speeding the process of recovery. And a key to quick and effective emergency planning and response is geographic information.\n                  With a host of Earth-observing satellites orbiting the globe at all times, NASA generates an unmatched wealth of data about our ever-changing planet. This information can be captured, analyzed, and visualized by geographic information systems (GIS) to produce maps, charts, and other tools that can reveal information essential to a wide variety of applications—including emergency management. Knowing precise, real-time information about the size, location, environmental conditions, and resulting damage of an event like a flood or wildfire—as well as the location and numbers of emergency responders and other resources—contributes directly to the effectiveness of disaster mitigation. The need for such information is also evident when responding to homeland security threats, such as a terrorist attack. \n                  Recognizing the value of its geospatial information resources for this and other purposes, in 1998 Stennis and the state of Mississippi partnered to form what became the Enterprise for Innovative Geospatial Solutions (EIGS) industry cluster, supporting the growth of remote sensing and GIS-based research and business. As part of EIGS, several companies partnered with NASA through dual use and Small Business Innovation Research (SBIR) contracts. Among those was NVision. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      NVision Solutions Inc.’s NASA-derived REACT system provides officials with information on everything from the number and location of emergency workers to shelter capacities to water levels—through any computer and even handheld devices in the field. \n                    \n                  \n                  Founded in 2002 through a technology incubator under EIGS, NVision sought to capitalize on the geospatial information Stennis could offer. \n                  “We started the company with two people in an empty office, no money, and a single piece of paper with a logo we thought looked cool,” says Harvey. “We were local people who saw the opportunity.” The opportunity, he explains, was employing NASA’s constantly updated geographic data to provide essential, practical information to users in real time. \n                  NVision—a minority, woman-owned firm—engaged with Stennis through multiple dual-use and SBIR projects. An initial outcome was a precision agriculture system that harnessed NASA satellite data, research, and algorithms to allow farmers to generate efficient strategies for treating crops with fertilizers, pesticides, and other crop control chemicals. (The technology was commercialized through InTime Inc. of Cleveland, Mississippi—another NASA partner with origins at Stennis.) That work found a new application in 2003, when Louisiana’s St. Tammany parish suffered flooding in the wake of Tropical Storm Bill. To answer the parish’s need for more efficient acquisition of flooding estimates and damage assessments, NVision applied elements of its precision agriculture system to create a real-time flood alert system—a system the parish still uses today. With additional NASA assistance, the company further developed the St. Tammany emergency response system and realized the significance of this new direction.\n                  “We didn’t have that much farther to go to have a comprehensive emergency management system,” Harvey says. This was the beginning of NVision’s Real-Time Emergency Action Coordination Tool (REACT).\n                  When Hurricane Katrina struck the Gulf Coast in 2005, NVision immediately volunteered its GIS-based emergency management expertise to assist in Hancock County’s recovery efforts. Using NASA data from Stennis, the company churned out thousands of unique, custom maps per week to support emergency operations needs. The experience the company gained during Katrina translated into even more robust, comprehensive emergency management capabilities. (The solution Harvey devised to find the missing woman, for example, became a search and rescue tool now used as standard practice on the Gulf Coast.) \n                  When Stennis constructed a new emergency operations center following Katrina, NVision tailored its REACT system to NASA’s specifications. The NASA-derived technology ended up perfectly suiting NASA’s own needs, says Ron Magee, emergency director at Stennis.\n                  “The REACT system pulls from our GIS systems so it has the most current mapping and data layers that are associated with geographic coordinates,” he explains. “It gives us a one-stop shop where we can have all of the information at our fingertips.” \n                  Those capabilities impressed emergency managers at other NASA centers, and through a Phase III SBIR agreement, the REACT system was established at NASA Headquarters and every NASA center nationwide, allowing the Agency to launch coordinated responses in the event of an emergency situation. \n                  Benefits\n                  NASA, however, is far from the only beneficiary of the REACT technology. Today, REACT is NVision’s flagship product and has resulted in more than $2 million in revenue. Recently designated by the Department of Homeland Security (DHS) as a Qualified Anti-Terrorism Technology, REACT is currently in use by varied organizations throughout the country for a broad spectrum of emergency management applications. \n                  Simply put, REACT is a Web-based information system for enhancing decision making before, during, and after emergency situations. \n                  \n                    \n                    \n                      \n                    \n                    \n                      NVision developed its touchscreen tabletop technology to support its REACT system, but the technology’s applications extend beyond this original purpose. \n                    \n                  \n                  “REACT looks at an emergency in a comprehensive way,” Harvey says. “What sets it apart is that it is all handled with a geospatial perspective.” Accessible through any computer and even handheld devices for use by emergency workers in the field, the system provides a Common Operating Picture combining everything from water levels to the location of police cars to the number and current capacity of shelters and hospitals, and more—all in real time. “We’ve got satellites, river gauges, housing data, tax base data, elevation data,” says Harvey. \n                  REACT also functions as an effective emergency management training tool and, in nonemergency circumstances, as a facility management system for running the day-to-day operations of a building or campus. Incorporating the DHS National Incident Management System and Incident Command System, REACT even encompasses standardized government elements such as forms, allowing officials to quickly access and complete necessary paperwork. The goal is to provide emergency managers with all of the tools for making and executing informed decisions, even under duress. \n                  “It really boils down to this: Quicker, more efficient decisions save lives,” Harvey says. \n                  REACT has been used for emergency response to Hurricanes Ivan, Katrina, Gustav, and Ike. The Hancock County Emergency Operations Center, Mississippi National Guard, and the Environmental Protection Agency used the system during the 2010 Deepwater Horizon oil spill, tracking the extent of the spill, the location of oil booms, and air and water quality monitoring efforts. The National Center for Spectator Sports Safety and Security employs REACT as a counterterrorism solution for large stadiums and venues, and the U.S. Navy’s Center for Asymmetric Warfare has standardized the NASA-derived technology for use during its large scale military training exercises. The benefits to these and other REACT users include significant cost reductions; Harvey notes that the U.S. Coast Guard has recognized multimillions of dollars in savings from response initiatives employing the REACT system. \n                  The company has also developed new technologies in support of REACT, including a touchscreen tabletop device that allows REACT users to easily access and manipulate the information the system provides. The technology has attracted attention for uses beyond REACT, including military command briefings in the field, and has generated about $500,000 in revenue for the company.\n                  NVision now expects REACT to become a national standard within 5 years. \n                  “We’re talking with other states now that are looking to deploy REACT at state or regional levels,” Harvey says. “It’s been a long haul to get this credibility. It’s what NASA brings to the table for us.” Harvey notes that while the company started in 2002 with no investment, by 2008 it employed 52 workers. That number is now close to 75, and the company offers an average salary of $60,000. \n                  “These are Mississippi people getting high-tech jobs to support NASA Stennis initiatives,” Harvey says. \n                  In the meantime, the EIGS cluster Stennis helped to found recently became a wholly private, self-funded venture, managed by the Magnolia Business Alliance. NVision is a leader of the alliance, which will support the ongoing growth of the Mississippi geospatial industry.\n                   “NASA was financially supporting development, lowering the barriers of high tech companies to get involved in geosciences, and creating a service industry for the commercial remote sensing program at Stennis,” Harvey says. “It worked.” \n                   In the meantime, Stennis is now better equipped in the event of another disaster on the magnitude of Hurricane Katrina. \n                  “We’re pretty much whole again and prepared for the next storm,” says Magee. “REACT is a part of that.”\n                  \n                \n              \n            \n            \n              \n                \n                  NASA Technology\n                  The rescue crews have been searching for the woman for nearly a week. Hurricane Katrina devastated Hancock County, the southernmost point in Mississippi, and the woman had stayed through the storm in her beach house. There is little hope of finding her alive; the search teams know she is gone because the house is gone. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Hurricane Katrina caused damage to NASA facilities, including Stennis Space Center and the Michoud Assembly Facility, pictured here.\n                    \n                  \n                  Late at night in the art classroom of the school that is serving as the county’s emergency operations center, Craig Harvey is discussing the search with the center’s commander. Harvey is the Chief Operating Officer of a unique company called NVision Solutions Inc., based at NASA’s Stennis Space Center in Bay St. Louis, only a couple of miles away. He and his entire staff have set up a volunteer operation in the art room, supporting the emergency management efforts using technology and capabilities the company developed through its NASA partnerships. As he talks to the commander, Harvey feels an idea taking shape that might lead them to the woman’s location. Working with surface elevation data and hydrological principles, Harvey creates a map showing how the floodwaters from the storm would have flowed along the topography of the region around the woman’s former home. \n                  Using the map, search crews find the woman’s body in 15 minutes. \n                  Recovering individuals who have been lost is a sad reality of emergency management in the wake of a disaster like Hurricane Katrina in 2005. But the sooner answers can be provided, the sooner a community’s overall recovery can take place. When damage is extensive, resources are scattered, and people are in dire need of food, shelter, and medical assistance, the speed and efficiency of emergency operations can be the key to limiting the impact of a disaster and speeding the process of recovery. And a key to quick and effective emergency planning and response is geographic information.\n                  With a host of Earth-observing satellites orbiting the globe at all times, NASA generates an unmatched wealth of data about our ever-changing planet. This information can be captured, analyzed, and visualized by geographic information systems (GIS) to produce maps, charts, and other tools that can reveal information essential to a wide variety of applications—including emergency management. Knowing precise, real-time information about the size, location, environmental conditions, and resulting damage of an event like a flood or wildfire—as well as the location and numbers of emergency responders and other resources—contributes directly to the effectiveness of disaster mitigation. The need for such information is also evident when responding to homeland security threats, such as a terrorist attack. \n                  Recognizing the value of its geospatial information resources for this and other purposes, in 1998 Stennis and the state of Mississippi partnered to form what became the Enterprise for Innovative Geospatial Solutions (EIGS) industry cluster, supporting the growth of remote sensing and GIS-based research and business. As part of EIGS, several companies partnered with NASA through dual use and Small Business Innovation Research (SBIR) contracts. Among those was NVision. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      NVision Solutions Inc.’s NASA-derived REACT system provides officials with information on everything from the number and location of emergency workers to shelter capacities to water levels—through any computer and even handheld devices in the field. \n                    \n                  \n                  Founded in 2002 through a technology incubator under EIGS, NVision sought to capitalize on the geospatial information Stennis could offer. \n                  “We started the company with two people in an empty office, no money, and a single piece of paper with a logo we thought looked cool,” says Harvey. “We were local people who saw the opportunity.” The opportunity, he explains, was employing NASA’s constantly updated geographic data to provide essential, practical information to users in real time. \n                  NVision—a minority, woman-owned firm—engaged with Stennis through multiple dual-use and SBIR projects. An initial outcome was a precision agriculture system that harnessed NASA satellite data, research, and algorithms to allow farmers to generate efficient strategies for treating crops with fertilizers, pesticides, and other crop control chemicals. (The technology was commercialized through InTime Inc. of Cleveland, Mississippi—another NASA partner with origins at Stennis.) That work found a new application in 2003, when Louisiana’s St. Tammany parish suffered flooding in the wake of Tropical Storm Bill. To answer the parish’s need for more efficient acquisition of flooding estimates and damage assessments, NVision applied elements of its precision agriculture system to create a real-time flood alert system—a system the parish still uses today. With additional NASA assistance, the company further developed the St. Tammany emergency response system and realized the significance of this new direction.\n                  “We didn’t have that much farther to go to have a comprehensive emergency management system,” Harvey says. This was the beginning of NVision’s Real-Time Emergency Action Coordination Tool (REACT).\n                  When Hurricane Katrina struck the Gulf Coast in 2005, NVision immediately volunteered its GIS-based emergency management expertise to assist in Hancock County’s recovery efforts. Using NASA data from Stennis, the company churned out thousands of unique, custom maps per week to support emergency operations needs. The experience the company gained during Katrina translated into even more robust, comprehensive emergency management capabilities. (The solution Harvey devised to find the missing woman, for example, became a search and rescue tool now used as standard practice on the Gulf Coast.) \n                  When Stennis constructed a new emergency operations center following Katrina, NVision tailored its REACT system to NASA’s specifications. The NASA-derived technology ended up perfectly suiting NASA’s own needs, says Ron Magee, emergency director at Stennis.\n                  “The REACT system pulls from our GIS systems so it has the most current mapping and data layers that are associated with geographic coordinates,” he explains. “It gives us a one-stop shop where we can have all of the information at our fingertips.” \n                  Those capabilities impressed emergency managers at other NASA centers, and through a Phase III SBIR agreement, the REACT system was established at NASA Headquarters and every NASA center nationwide, allowing the Agency to launch coordinated responses in the event of an emergency situation. \n                  Benefits\n                  NASA, however, is far from the only beneficiary of the REACT technology. Today, REACT is NVision’s flagship product and has resulted in more than $2 million in revenue. Recently designated by the Department of Homeland Security (DHS) as a Qualified Anti-Terrorism Technology, REACT is currently in use by varied organizations throughout the country for a broad spectrum of emergency management applications. \n                  Simply put, REACT is a Web-based information system for enhancing decision making before, during, and after emergency situations. \n                  \n                    \n                    \n                      \n                    \n                    \n                      NVision developed its touchscreen tabletop technology to support its REACT system, but the technology’s applications extend beyond this original purpose. \n                    \n                  \n                  “REACT looks at an emergency in a comprehensive way,” Harvey says. “What sets it apart is that it is all handled with a geospatial perspective.” Accessible through any computer and even handheld devices for use by emergency workers in the field, the system provides a Common Operating Picture combining everything from water levels to the location of police cars to the number and current capacity of shelters and hospitals, and more—all in real time. “We’ve got satellites, river gauges, housing data, tax base data, elevation data,” says Harvey. \n                  REACT also functions as an effective emergency management training tool and, in nonemergency circumstances, as a facility management system for running the day-to-day operations of a building or campus. Incorporating the DHS National Incident Management System and Incident Command System, REACT even encompasses standardized government elements such as forms, allowing officials to quickly access and complete necessary paperwork. The goal is to provide emergency managers with all of the tools for making and executing informed decisions, even under duress. \n                  “It really boils down to this: Quicker, more efficient decisions save lives,” Harvey says. \n                  REACT has been used for emergency response to Hurricanes Ivan, Katrina, Gustav, and Ike. The Hancock County Emergency Operations Center, Mississippi National Guard, and the Environmental Protection Agency used the system during the 2010 Deepwater Horizon oil spill, tracking the extent of the spill, the location of oil booms, and air and water quality monitoring efforts. The National Center for Spectator Sports Safety and Security employs REACT as a counterterrorism solution for large stadiums and venues, and the U.S. Navy’s Center for Asymmetric Warfare has standardized the NASA-derived technology for use during its large scale military training exercises. The benefits to these and other REACT users include significant cost reductions; Harvey notes that the U.S. Coast Guard has recognized multimillions of dollars in savings from response initiatives employing the REACT system. \n                  The company has also developed new technologies in support of REACT, including a touchscreen tabletop device that allows REACT users to easily access and manipulate the information the system provides. The technology has attracted attention for uses beyond REACT, including military command briefings in the field, and has generated about $500,000 in revenue for the company.\n                  NVision now expects REACT to become a national standard within 5 years. \n                  “We’re talking with other states now that are looking to deploy REACT at state or regional levels,” Harvey says. “It’s been a long haul to get this credibility. It’s what NASA brings to the table for us.” Harvey notes that while the company started in 2002 with no investment, by 2008 it employed 52 workers. That number is now close to 75, and the company offers an average salary of $60,000. \n                  “These are Mississippi people getting high-tech jobs to support NASA Stennis initiatives,” Harvey says. \n                  In the meantime, the EIGS cluster Stennis helped to found recently became a wholly private, self-funded venture, managed by the Magnolia Business Alliance. NVision is a leader of the alliance, which will support the ongoing growth of the Mississippi geospatial industry.\n                   “NASA was financially supporting development, lowering the barriers of high tech companies to get involved in geosciences, and creating a service industry for the commercial remote sensing program at Stennis,” Harvey says. “It worked.” \n                   In the meantime, Stennis is now better equipped in the event of another disaster on the magnitude of Hurricane Katrina. \n                  “We’re pretty much whole again and prepared for the next storm,” says Magee. “REACT is a part of that.”\n                  \n                \n              \n                  NASA Technology\n                  The rescue crews have been searching for the woman for nearly a week. Hurricane Katrina devastated Hancock County, the southernmost point in Mississippi, and the woman had stayed through the storm in her beach house. There is little hope of finding her alive; the search teams know she is gone because the house is gone. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Hurricane Katrina caused damage to NASA facilities, including Stennis Space Center and the Michoud Assembly Facility, pictured here.\n                    \n                  \n                  Late at night in the art classroom of the school that is serving as the county’s emergency operations center, Craig Harvey is discussing the search with the center’s commander. Harvey is the Chief Operating Officer of a unique company called NVision Solutions Inc., based at NASA’s Stennis Space Center in Bay St. Louis, only a couple of miles away. He and his entire staff have set up a volunteer operation in the art room, supporting the emergency management efforts using technology and capabilities the company developed through its NASA partnerships. As he talks to the commander, Harvey feels an idea taking shape that might lead them to the woman’s location. Working with surface elevation data and hydrological principles, Harvey creates a map showing how the floodwaters from the storm would have flowed along the topography of the region around the woman’s former home. \n                  Using the map, search crews find the woman’s body in 15 minutes. \n                  Recovering individuals who have been lost is a sad reality of emergency management in the wake of a disaster like Hurricane Katrina in 2005. But the sooner answers can be provided, the sooner a community’s overall recovery can take place. When damage is extensive, resources are scattered, and people are in dire need of food, shelter, and medical assistance, the speed and efficiency of emergency operations can be the key to limiting the impact of a disaster and speeding the process of recovery. And a key to quick and effective emergency planning and response is geographic information.\n                  With a host of Earth-observing satellites orbiting the globe at all times, NASA generates an unmatched wealth of data about our ever-changing planet. This information can be captured, analyzed, and visualized by geographic information systems (GIS) to produce maps, charts, and other tools that can reveal information essential to a wide variety of applications—including emergency management. Knowing precise, real-time information about the size, location, environmental conditions, and resulting damage of an event like a flood or wildfire—as well as the location and numbers of emergency responders and other resources—contributes directly to the effectiveness of disaster mitigation. The need for such information is also evident when responding to homeland security threats, such as a terrorist attack. \n                  Recognizing the value of its geospatial information resources for this and other purposes, in 1998 Stennis and the state of Mississippi partnered to form what became the Enterprise for Innovative Geospatial Solutions (EIGS) industry cluster, supporting the growth of remote sensing and GIS-based research and business. As part of EIGS, several companies partnered with NASA through dual use and Small Business Innovation Research (SBIR) contracts. Among those was NVision. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      NVision Solutions Inc.’s NASA-derived REACT system provides officials with information on everything from the number and location of emergency workers to shelter capacities to water levels—through any computer and even handheld devices in the field. \n                    \n                  \n                  Founded in 2002 through a technology incubator under EIGS, NVision sought to capitalize on the geospatial information Stennis could offer. \n                  “We started the company with two people in an empty office, no money, and a single piece of paper with a logo we thought looked cool,” says Harvey. “We were local people who saw the opportunity.” The opportunity, he explains, was employing NASA’s constantly updated geographic data to provide essential, practical information to users in real time. \n                  NVision—a minority, woman-owned firm—engaged with Stennis through multiple dual-use and SBIR projects. An initial outcome was a precision agriculture system that harnessed NASA satellite data, research, and algorithms to allow farmers to generate efficient strategies for treating crops with fertilizers, pesticides, and other crop control chemicals. (The technology was commercialized through InTime Inc. of Cleveland, Mississippi—another NASA partner with origins at Stennis.) That work found a new application in 2003, when Louisiana’s St. Tammany parish suffered flooding in the wake of Tropical Storm Bill. To answer the parish’s need for more efficient acquisition of flooding estimates and damage assessments, NVision applied elements of its precision agriculture system to create a real-time flood alert system—a system the parish still uses today. With additional NASA assistance, the company further developed the St. Tammany emergency response system and realized the significance of this new direction.\n                  “We didn’t have that much farther to go to have a comprehensive emergency management system,” Harvey says. This was the beginning of NVision’s Real-Time Emergency Action Coordination Tool (REACT).\n                  When Hurricane Katrina struck the Gulf Coast in 2005, NVision immediately volunteered its GIS-based emergency management expertise to assist in Hancock County’s recovery efforts. Using NASA data from Stennis, the company churned out thousands of unique, custom maps per week to support emergency operations needs. The experience the company gained during Katrina translated into even more robust, comprehensive emergency management capabilities. (The solution Harvey devised to find the missing woman, for example, became a search and rescue tool now used as standard practice on the Gulf Coast.) \n                  When Stennis constructed a new emergency operations center following Katrina, NVision tailored its REACT system to NASA’s specifications. The NASA-derived technology ended up perfectly suiting NASA’s own needs, says Ron Magee, emergency director at Stennis.\n                  “The REACT system pulls from our GIS systems so it has the most current mapping and data layers that are associated with geographic coordinates,” he explains. “It gives us a one-stop shop where we can have all of the information at our fingertips.” \n                  Those capabilities impressed emergency managers at other NASA centers, and through a Phase III SBIR agreement, the REACT system was established at NASA Headquarters and every NASA center nationwide, allowing the Agency to launch coordinated responses in the event of an emergency situation. \n                  Benefits\n                  NASA, however, is far from the only beneficiary of the REACT technology. Today, REACT is NVision’s flagship product and has resulted in more than $2 million in revenue. Recently designated by the Department of Homeland Security (DHS) as a Qualified Anti-Terrorism Technology, REACT is currently in use by varied organizations throughout the country for a broad spectrum of emergency management applications. \n                  Simply put, REACT is a Web-based information system for enhancing decision making before, during, and after emergency situations. \n                  \n                    \n                    \n                      \n                    \n                    \n                      NVision developed its touchscreen tabletop technology to support its REACT system, but the technology’s applications extend beyond this original purpose. \n                    \n                  \n                  “REACT looks at an emergency in a comprehensive way,” Harvey says. “What sets it apart is that it is all handled with a geospatial perspective.” Accessible through any computer and even handheld devices for use by emergency workers in the field, the system provides a Common Operating Picture combining everything from water levels to the location of police cars to the number and current capacity of shelters and hospitals, and more—all in real time. “We’ve got satellites, river gauges, housing data, tax base data, elevation data,” says Harvey. \n                  REACT also functions as an effective emergency management training tool and, in nonemergency circumstances, as a facility management system for running the day-to-day operations of a building or campus. Incorporating the DHS National Incident Management System and Incident Command System, REACT even encompasses standardized government elements such as forms, allowing officials to quickly access and complete necessary paperwork. The goal is to provide emergency managers with all of the tools for making and executing informed decisions, even under duress. \n                  “It really boils down to this: Quicker, more efficient decisions save lives,” Harvey says. \n                  REACT has been used for emergency response to Hurricanes Ivan, Katrina, Gustav, and Ike. The Hancock County Emergency Operations Center, Mississippi National Guard, and the Environmental Protection Agency used the system during the 2010 Deepwater Horizon oil spill, tracking the extent of the spill, the location of oil booms, and air and water quality monitoring efforts. The National Center for Spectator Sports Safety and Security employs REACT as a counterterrorism solution for large stadiums and venues, and the U.S. Navy’s Center for Asymmetric Warfare has standardized the NASA-derived technology for use during its large scale military training exercises. The benefits to these and other REACT users include significant cost reductions; Harvey notes that the U.S. Coast Guard has recognized multimillions of dollars in savings from response initiatives employing the REACT system. \n                  The company has also developed new technologies in support of REACT, including a touchscreen tabletop device that allows REACT users to easily access and manipulate the information the system provides. The technology has attracted attention for uses beyond REACT, including military command briefings in the field, and has generated about $500,000 in revenue for the company.\n                  NVision now expects REACT to become a national standard within 5 years. \n                  “We’re talking with other states now that are looking to deploy REACT at state or regional levels,” Harvey says. “It’s been a long haul to get this credibility. It’s what NASA brings to the table for us.” Harvey notes that while the company started in 2002 with no investment, by 2008 it employed 52 workers. That number is now close to 75, and the company offers an average salary of $60,000. \n                  “These are Mississippi people getting high-tech jobs to support NASA Stennis initiatives,” Harvey says. \n                  In the meantime, the EIGS cluster Stennis helped to found recently became a wholly private, self-funded venture, managed by the Magnolia Business Alliance. NVision is a leader of the alliance, which will support the ongoing growth of the Mississippi geospatial industry.\n                   “NASA was financially supporting development, lowering the barriers of high tech companies to get involved in geosciences, and creating a service industry for the commercial remote sensing program at Stennis,” Harvey says. “It worked.” \n                   In the meantime, Stennis is now better equipped in the event of another disaster on the magnitude of Hurricane Katrina. \n                  “We’re pretty much whole again and prepared for the next storm,” says Magee. “REACT is a part of that.”\n                  "},{"href":"http://spinoff.nasa.gov/Spinoff2011/ps_4.html","text":"Imaging Systems Provide Maps for U.S. Soldiers","image":"http://spinoff.nasa.gov/Spinoff2011/Images/ps_8_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    NASA Technology\n                    \n                      \n                      \n                        \n                      \n                      \n                        This mock-up of the Landsat Data Continuity Mission is essentially a full scale model of the actual satellite, which is scheduled for launch in 2012. The mock-up enables engineers to check that all components seat and connect correctly.\n                          \n                        Image courtesy of Orbital Sciences Corporation\n                      \n                    \n                    Spanning nearly four decades, the remarkable Landsat program has continuously provided data about the Earth’s surface, including detailed maps of vegetation, land use, forest extent and health, surface water, population distribution, as well as how these features have changed over time. Managed by NASA and the U.S. Geological Survey, Landsat’s series of satellites obtain data through passive remote sensing, or the use of sensors to read the energy reflected or emitted from the Earth’s surface. After the data from the sensors is processed and analyzed, it can be applied to create information-rich images of the planet. \n                    While the Landsat program has launched seven satellites since 1972, only Landsat 5 and 7 are currently operating. The next spacecraft in line to ensure continuity of data for years to come is the Landsat Data Continuity Mission (LDCM). Planned for launch in 2012, LDCM will take measurements of the Earth in visible, near-infrared, shortwave infrared, and thermal infrared bands. In addition to widespread use for land use planning and monitoring on local to regional scales, support for disaster response and evaluations, as well as water use monitoring, LDCM measurements will directly serve NASA’s research in the areas of climate, the carbon cycle, ecosystems, the water cycle, biogeochemistry, and Earth’s surface and interior.\n                    Partnership \n                    As part of its continuing efforts to develop improved remote sensing technology for monitoring the Earth, NASA’s Goddard Space Flight Center has worked with Flight Landata Inc., based in North Andover, Massachusetts, to refine and test a lightweight spectral imaging instrument for airborne applications. Over the last 10 years, Flight Landata has received numerous Small Business Innovative Research (SBIR) awards to support the technology’s development. \n                    Several advancements for the imaging technology have been made through the SBIRs, including a smaller computer processor for the imaging system, increased sensitivity in the detector system, and a stabilized gimbal system to maintain the unit’s image fidelity despite movement of the aircraft. In 2005, as part of a combined Phase III SBIR with Goddard and the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), Flight Landata demonstrated the operational capability of a suite of remote sensing instruments in Arizona and California. The demonstration was a success, and afterwards, the company continued to refine the capabilities of the technology. \n                    In 2002, Flight Landata was selected by the Small Business Administration as a winner of the prestigious “Tibbetts Award” in recognition of small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program. By 2006, Flight Landata’s sensor system had incorporated a variety of the refinements and improvements made possible by working with Goddard and the Army, and the system won the Army’s “Greatest Invention of the Year” award. \n                    Benefits\n                    Today, Flight Landata continues to work with NASA through the SBIR program to advance remote sensing technology, but the company also commercially offers the design, integration, and deployment of NASA-enhanced airborne sensor systems, platforms, and collection services. “After developing systems for the government, we were asked if we could deploy, fly, and maintain the systems for the Army. For the last several years, this business has been rapidly growing,” says Petra Botha, Flight Landata’s vice president of finance and administration. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The BuckEye system from Flight Landata Inc. is used for mapping, targeting, damage assessment, and improvised explosive device defeat missions, among others. Over the last 10 years, Flight Landata has received numerous SBIR awards to support the technology’s development.\n                      \n                    \n                    Flight Landata not only supplies the sensor system, it also provides pilots, sensor operators, on-site logistics, and maintenance of the system. The BuckEye EO (electro-optical) instrument suite is flown on the company’s fleet of King Air 100 aircraft to collect extremely high spatial resolution images in three spectral bands. The image data are combined with line scan light detection and ranging (LIDAR) technology to achieve 3D images and to produce digital elevation models quickly. \n                    For the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), BuckEye addresses a need for unclassified high-resolution geospatial data for tactical missions for intelligence, surveillance, and reconnaissance. The AGC strives to make Buckeye data available to U.S. fighting forces and supporting agencies in a timely fashion. The information can improve the soldiers’ situational awareness by providing highly accurate imagery that can be used to produce current, high-resolution reference graphics and image maps for terrain analysis and operating environment visualization. \n                    As soon as imagery and LIDAR are received at the AGC, they are checked for quality and adjusted to eliminate any distortion due to the camera, lens, or topography. Then the images are combined into large mosaics. The resulting information is available online or through the AGC’s Dissemination Team, including GeoPDF Mapbooks, DVDs, and through high-resolution Urban Tactical Planner databases. \n                    In 2005, BuckEye was deployed to Iraq on a fixed-wing aircraft for an urban mapping mission. In addition to a digital color camera, the LIDAR sensor collected high-resolution, high-accuracy elevation data to provide images of urban landscapes and complex terrain. By 2010, the BuckEye had collected over 85,000 square kilometers of data over urban areas and along main supply routes in Iraq, including over 2,000 tiles of LIDAR elevation data at 1-meter resolution, and 1,800,000 color images at \n                      10- to 15-centimeter resolution. \n                    Between 2006 and 2010, three systems were deployed by Flight Landata to Afghanistan, where a majority of the imagery is quickly processed to provide rapid tactical information. To date, over 40,000 square kilometers of data have been collected. In addition, an Unmanned Aerial System, equipped with a miniaturized LIDAR sensor and BuckEye sensors, is currently operating in western Afghanistan. \n                    According to Petra, one of the reasons the system is so unique is that the imagery it produces is unclassified, so every soldier can see the details of the environment that are critical to planning operations. “It is a unique capability to provide this class of product to soldiers on the front lines,” says Botha. “Had it not been for the NASA technology contracts, BuckEye might not have been deployed to support the war fighter at a critical time in the conflict.” \n                    Now, BuckEye will be used to support the next Landsat Mission. Flight Landata’s airborne system and data reduction technology will be fused with NASA’s thermal infrared sensor technology to provide multispectral images that parallel the ones that will be produced by the sensors onboard LDCM. This data will directly support the calibration of the LDCM instruments. As Peter Shu, an engineer at Goddard who has worked on the remote sensing technology with Flight Landata through the SBIR program, says, “This is a consequence of the SBIR work with Flight Landata. Now we are using it to help in the development of the Landsat program.”\n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    NASA Technology\n                    \n                      \n                      \n                        \n                      \n                      \n                        This mock-up of the Landsat Data Continuity Mission is essentially a full scale model of the actual satellite, which is scheduled for launch in 2012. The mock-up enables engineers to check that all components seat and connect correctly.\n                          \n                        Image courtesy of Orbital Sciences Corporation\n                      \n                    \n                    Spanning nearly four decades, the remarkable Landsat program has continuously provided data about the Earth’s surface, including detailed maps of vegetation, land use, forest extent and health, surface water, population distribution, as well as how these features have changed over time. Managed by NASA and the U.S. Geological Survey, Landsat’s series of satellites obtain data through passive remote sensing, or the use of sensors to read the energy reflected or emitted from the Earth’s surface. After the data from the sensors is processed and analyzed, it can be applied to create information-rich images of the planet. \n                    While the Landsat program has launched seven satellites since 1972, only Landsat 5 and 7 are currently operating. The next spacecraft in line to ensure continuity of data for years to come is the Landsat Data Continuity Mission (LDCM). Planned for launch in 2012, LDCM will take measurements of the Earth in visible, near-infrared, shortwave infrared, and thermal infrared bands. In addition to widespread use for land use planning and monitoring on local to regional scales, support for disaster response and evaluations, as well as water use monitoring, LDCM measurements will directly serve NASA’s research in the areas of climate, the carbon cycle, ecosystems, the water cycle, biogeochemistry, and Earth’s surface and interior.\n                    Partnership \n                    As part of its continuing efforts to develop improved remote sensing technology for monitoring the Earth, NASA’s Goddard Space Flight Center has worked with Flight Landata Inc., based in North Andover, Massachusetts, to refine and test a lightweight spectral imaging instrument for airborne applications. Over the last 10 years, Flight Landata has received numerous Small Business Innovative Research (SBIR) awards to support the technology’s development. \n                    Several advancements for the imaging technology have been made through the SBIRs, including a smaller computer processor for the imaging system, increased sensitivity in the detector system, and a stabilized gimbal system to maintain the unit’s image fidelity despite movement of the aircraft. In 2005, as part of a combined Phase III SBIR with Goddard and the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), Flight Landata demonstrated the operational capability of a suite of remote sensing instruments in Arizona and California. The demonstration was a success, and afterwards, the company continued to refine the capabilities of the technology. \n                    In 2002, Flight Landata was selected by the Small Business Administration as a winner of the prestigious “Tibbetts Award” in recognition of small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program. By 2006, Flight Landata’s sensor system had incorporated a variety of the refinements and improvements made possible by working with Goddard and the Army, and the system won the Army’s “Greatest Invention of the Year” award. \n                    Benefits\n                    Today, Flight Landata continues to work with NASA through the SBIR program to advance remote sensing technology, but the company also commercially offers the design, integration, and deployment of NASA-enhanced airborne sensor systems, platforms, and collection services. “After developing systems for the government, we were asked if we could deploy, fly, and maintain the systems for the Army. For the last several years, this business has been rapidly growing,” says Petra Botha, Flight Landata’s vice president of finance and administration. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The BuckEye system from Flight Landata Inc. is used for mapping, targeting, damage assessment, and improvised explosive device defeat missions, among others. Over the last 10 years, Flight Landata has received numerous SBIR awards to support the technology’s development.\n                      \n                    \n                    Flight Landata not only supplies the sensor system, it also provides pilots, sensor operators, on-site logistics, and maintenance of the system. The BuckEye EO (electro-optical) instrument suite is flown on the company’s fleet of King Air 100 aircraft to collect extremely high spatial resolution images in three spectral bands. The image data are combined with line scan light detection and ranging (LIDAR) technology to achieve 3D images and to produce digital elevation models quickly. \n                    For the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), BuckEye addresses a need for unclassified high-resolution geospatial data for tactical missions for intelligence, surveillance, and reconnaissance. The AGC strives to make Buckeye data available to U.S. fighting forces and supporting agencies in a timely fashion. The information can improve the soldiers’ situational awareness by providing highly accurate imagery that can be used to produce current, high-resolution reference graphics and image maps for terrain analysis and operating environment visualization. \n                    As soon as imagery and LIDAR are received at the AGC, they are checked for quality and adjusted to eliminate any distortion due to the camera, lens, or topography. Then the images are combined into large mosaics. The resulting information is available online or through the AGC’s Dissemination Team, including GeoPDF Mapbooks, DVDs, and through high-resolution Urban Tactical Planner databases. \n                    In 2005, BuckEye was deployed to Iraq on a fixed-wing aircraft for an urban mapping mission. In addition to a digital color camera, the LIDAR sensor collected high-resolution, high-accuracy elevation data to provide images of urban landscapes and complex terrain. By 2010, the BuckEye had collected over 85,000 square kilometers of data over urban areas and along main supply routes in Iraq, including over 2,000 tiles of LIDAR elevation data at 1-meter resolution, and 1,800,000 color images at \n                      10- to 15-centimeter resolution. \n                    Between 2006 and 2010, three systems were deployed by Flight Landata to Afghanistan, where a majority of the imagery is quickly processed to provide rapid tactical information. To date, over 40,000 square kilometers of data have been collected. In addition, an Unmanned Aerial System, equipped with a miniaturized LIDAR sensor and BuckEye sensors, is currently operating in western Afghanistan. \n                    According to Petra, one of the reasons the system is so unique is that the imagery it produces is unclassified, so every soldier can see the details of the environment that are critical to planning operations. “It is a unique capability to provide this class of product to soldiers on the front lines,” says Botha. “Had it not been for the NASA technology contracts, BuckEye might not have been deployed to support the war fighter at a critical time in the conflict.” \n                    Now, BuckEye will be used to support the next Landsat Mission. Flight Landata’s airborne system and data reduction technology will be fused with NASA’s thermal infrared sensor technology to provide multispectral images that parallel the ones that will be produced by the sensors onboard LDCM. This data will directly support the calibration of the LDCM instruments. As Peter Shu, an engineer at Goddard who has worked on the remote sensing technology with Flight Landata through the SBIR program, says, “This is a consequence of the SBIR work with Flight Landata. Now we are using it to help in the development of the Landsat program.”\n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  \n                    NASA Technology\n                    \n                      \n                      \n                        \n                      \n                      \n                        This mock-up of the Landsat Data Continuity Mission is essentially a full scale model of the actual satellite, which is scheduled for launch in 2012. The mock-up enables engineers to check that all components seat and connect correctly.\n                          \n                        Image courtesy of Orbital Sciences Corporation\n                      \n                    \n                    Spanning nearly four decades, the remarkable Landsat program has continuously provided data about the Earth’s surface, including detailed maps of vegetation, land use, forest extent and health, surface water, population distribution, as well as how these features have changed over time. Managed by NASA and the U.S. Geological Survey, Landsat’s series of satellites obtain data through passive remote sensing, or the use of sensors to read the energy reflected or emitted from the Earth’s surface. After the data from the sensors is processed and analyzed, it can be applied to create information-rich images of the planet. \n                    While the Landsat program has launched seven satellites since 1972, only Landsat 5 and 7 are currently operating. The next spacecraft in line to ensure continuity of data for years to come is the Landsat Data Continuity Mission (LDCM). Planned for launch in 2012, LDCM will take measurements of the Earth in visible, near-infrared, shortwave infrared, and thermal infrared bands. In addition to widespread use for land use planning and monitoring on local to regional scales, support for disaster response and evaluations, as well as water use monitoring, LDCM measurements will directly serve NASA’s research in the areas of climate, the carbon cycle, ecosystems, the water cycle, biogeochemistry, and Earth’s surface and interior.\n                    Partnership \n                    As part of its continuing efforts to develop improved remote sensing technology for monitoring the Earth, NASA’s Goddard Space Flight Center has worked with Flight Landata Inc., based in North Andover, Massachusetts, to refine and test a lightweight spectral imaging instrument for airborne applications. Over the last 10 years, Flight Landata has received numerous Small Business Innovative Research (SBIR) awards to support the technology’s development. \n                    Several advancements for the imaging technology have been made through the SBIRs, including a smaller computer processor for the imaging system, increased sensitivity in the detector system, and a stabilized gimbal system to maintain the unit’s image fidelity despite movement of the aircraft. In 2005, as part of a combined Phase III SBIR with Goddard and the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), Flight Landata demonstrated the operational capability of a suite of remote sensing instruments in Arizona and California. The demonstration was a success, and afterwards, the company continued to refine the capabilities of the technology. \n                    In 2002, Flight Landata was selected by the Small Business Administration as a winner of the prestigious “Tibbetts Award” in recognition of small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program. By 2006, Flight Landata’s sensor system had incorporated a variety of the refinements and improvements made possible by working with Goddard and the Army, and the system won the Army’s “Greatest Invention of the Year” award. \n                    Benefits\n                    Today, Flight Landata continues to work with NASA through the SBIR program to advance remote sensing technology, but the company also commercially offers the design, integration, and deployment of NASA-enhanced airborne sensor systems, platforms, and collection services. “After developing systems for the government, we were asked if we could deploy, fly, and maintain the systems for the Army. For the last several years, this business has been rapidly growing,” says Petra Botha, Flight Landata’s vice president of finance and administration. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The BuckEye system from Flight Landata Inc. is used for mapping, targeting, damage assessment, and improvised explosive device defeat missions, among others. Over the last 10 years, Flight Landata has received numerous SBIR awards to support the technology’s development.\n                      \n                    \n                    Flight Landata not only supplies the sensor system, it also provides pilots, sensor operators, on-site logistics, and maintenance of the system. The BuckEye EO (electro-optical) instrument suite is flown on the company’s fleet of King Air 100 aircraft to collect extremely high spatial resolution images in three spectral bands. The image data are combined with line scan light detection and ranging (LIDAR) technology to achieve 3D images and to produce digital elevation models quickly. \n                    For the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), BuckEye addresses a need for unclassified high-resolution geospatial data for tactical missions for intelligence, surveillance, and reconnaissance. The AGC strives to make Buckeye data available to U.S. fighting forces and supporting agencies in a timely fashion. The information can improve the soldiers’ situational awareness by providing highly accurate imagery that can be used to produce current, high-resolution reference graphics and image maps for terrain analysis and operating environment visualization. \n                    As soon as imagery and LIDAR are received at the AGC, they are checked for quality and adjusted to eliminate any distortion due to the camera, lens, or topography. Then the images are combined into large mosaics. The resulting information is available online or through the AGC’s Dissemination Team, including GeoPDF Mapbooks, DVDs, and through high-resolution Urban Tactical Planner databases. \n                    In 2005, BuckEye was deployed to Iraq on a fixed-wing aircraft for an urban mapping mission. In addition to a digital color camera, the LIDAR sensor collected high-resolution, high-accuracy elevation data to provide images of urban landscapes and complex terrain. By 2010, the BuckEye had collected over 85,000 square kilometers of data over urban areas and along main supply routes in Iraq, including over 2,000 tiles of LIDAR elevation data at 1-meter resolution, and 1,800,000 color images at \n                      10- to 15-centimeter resolution. \n                    Between 2006 and 2010, three systems were deployed by Flight Landata to Afghanistan, where a majority of the imagery is quickly processed to provide rapid tactical information. To date, over 40,000 square kilometers of data have been collected. In addition, an Unmanned Aerial System, equipped with a miniaturized LIDAR sensor and BuckEye sensors, is currently operating in western Afghanistan. \n                    According to Petra, one of the reasons the system is so unique is that the imagery it produces is unclassified, so every soldier can see the details of the environment that are critical to planning operations. “It is a unique capability to provide this class of product to soldiers on the front lines,” says Botha. “Had it not been for the NASA technology contracts, BuckEye might not have been deployed to support the war fighter at a critical time in the conflict.” \n                    Now, BuckEye will be used to support the next Landsat Mission. Flight Landata’s airborne system and data reduction technology will be fused with NASA’s thermal infrared sensor technology to provide multispectral images that parallel the ones that will be produced by the sensors onboard LDCM. This data will directly support the calibration of the LDCM instruments. As Peter Shu, an engineer at Goddard who has worked on the remote sensing technology with Flight Landata through the SBIR program, says, “This is a consequence of the SBIR work with Flight Landata. Now we are using it to help in the development of the Landsat program.”\n                    \n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  \n                    NASA Technology\n                    \n                      \n                      \n                        \n                      \n                      \n                        This mock-up of the Landsat Data Continuity Mission is essentially a full scale model of the actual satellite, which is scheduled for launch in 2012. The mock-up enables engineers to check that all components seat and connect correctly.\n                          \n                        Image courtesy of Orbital Sciences Corporation\n                      \n                    \n                    Spanning nearly four decades, the remarkable Landsat program has continuously provided data about the Earth’s surface, including detailed maps of vegetation, land use, forest extent and health, surface water, population distribution, as well as how these features have changed over time. Managed by NASA and the U.S. Geological Survey, Landsat’s series of satellites obtain data through passive remote sensing, or the use of sensors to read the energy reflected or emitted from the Earth’s surface. After the data from the sensors is processed and analyzed, it can be applied to create information-rich images of the planet. \n                    While the Landsat program has launched seven satellites since 1972, only Landsat 5 and 7 are currently operating. The next spacecraft in line to ensure continuity of data for years to come is the Landsat Data Continuity Mission (LDCM). Planned for launch in 2012, LDCM will take measurements of the Earth in visible, near-infrared, shortwave infrared, and thermal infrared bands. In addition to widespread use for land use planning and monitoring on local to regional scales, support for disaster response and evaluations, as well as water use monitoring, LDCM measurements will directly serve NASA’s research in the areas of climate, the carbon cycle, ecosystems, the water cycle, biogeochemistry, and Earth’s surface and interior.\n                    Partnership \n                    As part of its continuing efforts to develop improved remote sensing technology for monitoring the Earth, NASA’s Goddard Space Flight Center has worked with Flight Landata Inc., based in North Andover, Massachusetts, to refine and test a lightweight spectral imaging instrument for airborne applications. Over the last 10 years, Flight Landata has received numerous Small Business Innovative Research (SBIR) awards to support the technology’s development. \n                    Several advancements for the imaging technology have been made through the SBIRs, including a smaller computer processor for the imaging system, increased sensitivity in the detector system, and a stabilized gimbal system to maintain the unit’s image fidelity despite movement of the aircraft. In 2005, as part of a combined Phase III SBIR with Goddard and the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), Flight Landata demonstrated the operational capability of a suite of remote sensing instruments in Arizona and California. The demonstration was a success, and afterwards, the company continued to refine the capabilities of the technology. \n                    In 2002, Flight Landata was selected by the Small Business Administration as a winner of the prestigious “Tibbetts Award” in recognition of small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program. By 2006, Flight Landata’s sensor system had incorporated a variety of the refinements and improvements made possible by working with Goddard and the Army, and the system won the Army’s “Greatest Invention of the Year” award. \n                    Benefits\n                    Today, Flight Landata continues to work with NASA through the SBIR program to advance remote sensing technology, but the company also commercially offers the design, integration, and deployment of NASA-enhanced airborne sensor systems, platforms, and collection services. “After developing systems for the government, we were asked if we could deploy, fly, and maintain the systems for the Army. For the last several years, this business has been rapidly growing,” says Petra Botha, Flight Landata’s vice president of finance and administration. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The BuckEye system from Flight Landata Inc. is used for mapping, targeting, damage assessment, and improvised explosive device defeat missions, among others. Over the last 10 years, Flight Landata has received numerous SBIR awards to support the technology’s development.\n                      \n                    \n                    Flight Landata not only supplies the sensor system, it also provides pilots, sensor operators, on-site logistics, and maintenance of the system. The BuckEye EO (electro-optical) instrument suite is flown on the company’s fleet of King Air 100 aircraft to collect extremely high spatial resolution images in three spectral bands. The image data are combined with line scan light detection and ranging (LIDAR) technology to achieve 3D images and to produce digital elevation models quickly. \n                    For the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), BuckEye addresses a need for unclassified high-resolution geospatial data for tactical missions for intelligence, surveillance, and reconnaissance. The AGC strives to make Buckeye data available to U.S. fighting forces and supporting agencies in a timely fashion. The information can improve the soldiers’ situational awareness by providing highly accurate imagery that can be used to produce current, high-resolution reference graphics and image maps for terrain analysis and operating environment visualization. \n                    As soon as imagery and LIDAR are received at the AGC, they are checked for quality and adjusted to eliminate any distortion due to the camera, lens, or topography. Then the images are combined into large mosaics. The resulting information is available online or through the AGC’s Dissemination Team, including GeoPDF Mapbooks, DVDs, and through high-resolution Urban Tactical Planner databases. \n                    In 2005, BuckEye was deployed to Iraq on a fixed-wing aircraft for an urban mapping mission. In addition to a digital color camera, the LIDAR sensor collected high-resolution, high-accuracy elevation data to provide images of urban landscapes and complex terrain. By 2010, the BuckEye had collected over 85,000 square kilometers of data over urban areas and along main supply routes in Iraq, including over 2,000 tiles of LIDAR elevation data at 1-meter resolution, and 1,800,000 color images at \n                      10- to 15-centimeter resolution. \n                    Between 2006 and 2010, three systems were deployed by Flight Landata to Afghanistan, where a majority of the imagery is quickly processed to provide rapid tactical information. To date, over 40,000 square kilometers of data have been collected. In addition, an Unmanned Aerial System, equipped with a miniaturized LIDAR sensor and BuckEye sensors, is currently operating in western Afghanistan. \n                    According to Petra, one of the reasons the system is so unique is that the imagery it produces is unclassified, so every soldier can see the details of the environment that are critical to planning operations. “It is a unique capability to provide this class of product to soldiers on the front lines,” says Botha. “Had it not been for the NASA technology contracts, BuckEye might not have been deployed to support the war fighter at a critical time in the conflict.” \n                    Now, BuckEye will be used to support the next Landsat Mission. Flight Landata’s airborne system and data reduction technology will be fused with NASA’s thermal infrared sensor technology to provide multispectral images that parallel the ones that will be produced by the sensors onboard LDCM. This data will directly support the calibration of the LDCM instruments. As Peter Shu, an engineer at Goddard who has worked on the remote sensing technology with Flight Landata through the SBIR program, says, “This is a consequence of the SBIR work with Flight Landata. Now we are using it to help in the development of the Landsat program.”\n                    \n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  \n                    NASA Technology\n                    \n                      \n                      \n                        \n                      \n                      \n                        This mock-up of the Landsat Data Continuity Mission is essentially a full scale model of the actual satellite, which is scheduled for launch in 2012. The mock-up enables engineers to check that all components seat and connect correctly.\n                          \n                        Image courtesy of Orbital Sciences Corporation\n                      \n                    \n                    Spanning nearly four decades, the remarkable Landsat program has continuously provided data about the Earth’s surface, including detailed maps of vegetation, land use, forest extent and health, surface water, population distribution, as well as how these features have changed over time. Managed by NASA and the U.S. Geological Survey, Landsat’s series of satellites obtain data through passive remote sensing, or the use of sensors to read the energy reflected or emitted from the Earth’s surface. After the data from the sensors is processed and analyzed, it can be applied to create information-rich images of the planet. \n                    While the Landsat program has launched seven satellites since 1972, only Landsat 5 and 7 are currently operating. The next spacecraft in line to ensure continuity of data for years to come is the Landsat Data Continuity Mission (LDCM). Planned for launch in 2012, LDCM will take measurements of the Earth in visible, near-infrared, shortwave infrared, and thermal infrared bands. In addition to widespread use for land use planning and monitoring on local to regional scales, support for disaster response and evaluations, as well as water use monitoring, LDCM measurements will directly serve NASA’s research in the areas of climate, the carbon cycle, ecosystems, the water cycle, biogeochemistry, and Earth’s surface and interior.\n                    Partnership \n                    As part of its continuing efforts to develop improved remote sensing technology for monitoring the Earth, NASA’s Goddard Space Flight Center has worked with Flight Landata Inc., based in North Andover, Massachusetts, to refine and test a lightweight spectral imaging instrument for airborne applications. Over the last 10 years, Flight Landata has received numerous Small Business Innovative Research (SBIR) awards to support the technology’s development. \n                    Several advancements for the imaging technology have been made through the SBIRs, including a smaller computer processor for the imaging system, increased sensitivity in the detector system, and a stabilized gimbal system to maintain the unit’s image fidelity despite movement of the aircraft. In 2005, as part of a combined Phase III SBIR with Goddard and the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), Flight Landata demonstrated the operational capability of a suite of remote sensing instruments in Arizona and California. The demonstration was a success, and afterwards, the company continued to refine the capabilities of the technology. \n                    In 2002, Flight Landata was selected by the Small Business Administration as a winner of the prestigious “Tibbetts Award” in recognition of small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program. By 2006, Flight Landata’s sensor system had incorporated a variety of the refinements and improvements made possible by working with Goddard and the Army, and the system won the Army’s “Greatest Invention of the Year” award. \n                    Benefits\n                    Today, Flight Landata continues to work with NASA through the SBIR program to advance remote sensing technology, but the company also commercially offers the design, integration, and deployment of NASA-enhanced airborne sensor systems, platforms, and collection services. “After developing systems for the government, we were asked if we could deploy, fly, and maintain the systems for the Army. For the last several years, this business has been rapidly growing,” says Petra Botha, Flight Landata’s vice president of finance and administration. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The BuckEye system from Flight Landata Inc. is used for mapping, targeting, damage assessment, and improvised explosive device defeat missions, among others. Over the last 10 years, Flight Landata has received numerous SBIR awards to support the technology’s development.\n                      \n                    \n                    Flight Landata not only supplies the sensor system, it also provides pilots, sensor operators, on-site logistics, and maintenance of the system. The BuckEye EO (electro-optical) instrument suite is flown on the company’s fleet of King Air 100 aircraft to collect extremely high spatial resolution images in three spectral bands. The image data are combined with line scan light detection and ranging (LIDAR) technology to achieve 3D images and to produce digital elevation models quickly. \n                    For the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), BuckEye addresses a need for unclassified high-resolution geospatial data for tactical missions for intelligence, surveillance, and reconnaissance. The AGC strives to make Buckeye data available to U.S. fighting forces and supporting agencies in a timely fashion. The information can improve the soldiers’ situational awareness by providing highly accurate imagery that can be used to produce current, high-resolution reference graphics and image maps for terrain analysis and operating environment visualization. \n                    As soon as imagery and LIDAR are received at the AGC, they are checked for quality and adjusted to eliminate any distortion due to the camera, lens, or topography. Then the images are combined into large mosaics. The resulting information is available online or through the AGC’s Dissemination Team, including GeoPDF Mapbooks, DVDs, and through high-resolution Urban Tactical Planner databases. \n                    In 2005, BuckEye was deployed to Iraq on a fixed-wing aircraft for an urban mapping mission. In addition to a digital color camera, the LIDAR sensor collected high-resolution, high-accuracy elevation data to provide images of urban landscapes and complex terrain. By 2010, the BuckEye had collected over 85,000 square kilometers of data over urban areas and along main supply routes in Iraq, including over 2,000 tiles of LIDAR elevation data at 1-meter resolution, and 1,800,000 color images at \n                      10- to 15-centimeter resolution. \n                    Between 2006 and 2010, three systems were deployed by Flight Landata to Afghanistan, where a majority of the imagery is quickly processed to provide rapid tactical information. To date, over 40,000 square kilometers of data have been collected. In addition, an Unmanned Aerial System, equipped with a miniaturized LIDAR sensor and BuckEye sensors, is currently operating in western Afghanistan. \n                    According to Petra, one of the reasons the system is so unique is that the imagery it produces is unclassified, so every soldier can see the details of the environment that are critical to planning operations. “It is a unique capability to provide this class of product to soldiers on the front lines,” says Botha. “Had it not been for the NASA technology contracts, BuckEye might not have been deployed to support the war fighter at a critical time in the conflict.” \n                    Now, BuckEye will be used to support the next Landsat Mission. Flight Landata’s airborne system and data reduction technology will be fused with NASA’s thermal infrared sensor technology to provide multispectral images that parallel the ones that will be produced by the sensors onboard LDCM. This data will directly support the calibration of the LDCM instruments. As Peter Shu, an engineer at Goddard who has worked on the remote sensing technology with Flight Landata through the SBIR program, says, “This is a consequence of the SBIR work with Flight Landata. Now we are using it to help in the development of the Landsat program.”\n                    \n                  \n                \n              \n            \n            \n              \n                \n                  \n                    NASA Technology\n                    \n                      \n                      \n                        \n                      \n                      \n                        This mock-up of the Landsat Data Continuity Mission is essentially a full scale model of the actual satellite, which is scheduled for launch in 2012. The mock-up enables engineers to check that all components seat and connect correctly.\n                          \n                        Image courtesy of Orbital Sciences Corporation\n                      \n                    \n                    Spanning nearly four decades, the remarkable Landsat program has continuously provided data about the Earth’s surface, including detailed maps of vegetation, land use, forest extent and health, surface water, population distribution, as well as how these features have changed over time. Managed by NASA and the U.S. Geological Survey, Landsat’s series of satellites obtain data through passive remote sensing, or the use of sensors to read the energy reflected or emitted from the Earth’s surface. After the data from the sensors is processed and analyzed, it can be applied to create information-rich images of the planet. \n                    While the Landsat program has launched seven satellites since 1972, only Landsat 5 and 7 are currently operating. The next spacecraft in line to ensure continuity of data for years to come is the Landsat Data Continuity Mission (LDCM). Planned for launch in 2012, LDCM will take measurements of the Earth in visible, near-infrared, shortwave infrared, and thermal infrared bands. In addition to widespread use for land use planning and monitoring on local to regional scales, support for disaster response and evaluations, as well as water use monitoring, LDCM measurements will directly serve NASA’s research in the areas of climate, the carbon cycle, ecosystems, the water cycle, biogeochemistry, and Earth’s surface and interior.\n                    Partnership \n                    As part of its continuing efforts to develop improved remote sensing technology for monitoring the Earth, NASA’s Goddard Space Flight Center has worked with Flight Landata Inc., based in North Andover, Massachusetts, to refine and test a lightweight spectral imaging instrument for airborne applications. Over the last 10 years, Flight Landata has received numerous Small Business Innovative Research (SBIR) awards to support the technology’s development. \n                    Several advancements for the imaging technology have been made through the SBIRs, including a smaller computer processor for the imaging system, increased sensitivity in the detector system, and a stabilized gimbal system to maintain the unit’s image fidelity despite movement of the aircraft. In 2005, as part of a combined Phase III SBIR with Goddard and the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), Flight Landata demonstrated the operational capability of a suite of remote sensing instruments in Arizona and California. The demonstration was a success, and afterwards, the company continued to refine the capabilities of the technology. \n                    In 2002, Flight Landata was selected by the Small Business Administration as a winner of the prestigious “Tibbetts Award” in recognition of small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program. By 2006, Flight Landata’s sensor system had incorporated a variety of the refinements and improvements made possible by working with Goddard and the Army, and the system won the Army’s “Greatest Invention of the Year” award. \n                    Benefits\n                    Today, Flight Landata continues to work with NASA through the SBIR program to advance remote sensing technology, but the company also commercially offers the design, integration, and deployment of NASA-enhanced airborne sensor systems, platforms, and collection services. “After developing systems for the government, we were asked if we could deploy, fly, and maintain the systems for the Army. For the last several years, this business has been rapidly growing,” says Petra Botha, Flight Landata’s vice president of finance and administration. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The BuckEye system from Flight Landata Inc. is used for mapping, targeting, damage assessment, and improvised explosive device defeat missions, among others. Over the last 10 years, Flight Landata has received numerous SBIR awards to support the technology’s development.\n                      \n                    \n                    Flight Landata not only supplies the sensor system, it also provides pilots, sensor operators, on-site logistics, and maintenance of the system. The BuckEye EO (electro-optical) instrument suite is flown on the company’s fleet of King Air 100 aircraft to collect extremely high spatial resolution images in three spectral bands. The image data are combined with line scan light detection and ranging (LIDAR) technology to achieve 3D images and to produce digital elevation models quickly. \n                    For the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), BuckEye addresses a need for unclassified high-resolution geospatial data for tactical missions for intelligence, surveillance, and reconnaissance. The AGC strives to make Buckeye data available to U.S. fighting forces and supporting agencies in a timely fashion. The information can improve the soldiers’ situational awareness by providing highly accurate imagery that can be used to produce current, high-resolution reference graphics and image maps for terrain analysis and operating environment visualization. \n                    As soon as imagery and LIDAR are received at the AGC, they are checked for quality and adjusted to eliminate any distortion due to the camera, lens, or topography. Then the images are combined into large mosaics. The resulting information is available online or through the AGC’s Dissemination Team, including GeoPDF Mapbooks, DVDs, and through high-resolution Urban Tactical Planner databases. \n                    In 2005, BuckEye was deployed to Iraq on a fixed-wing aircraft for an urban mapping mission. In addition to a digital color camera, the LIDAR sensor collected high-resolution, high-accuracy elevation data to provide images of urban landscapes and complex terrain. By 2010, the BuckEye had collected over 85,000 square kilometers of data over urban areas and along main supply routes in Iraq, including over 2,000 tiles of LIDAR elevation data at 1-meter resolution, and 1,800,000 color images at \n                      10- to 15-centimeter resolution. \n                    Between 2006 and 2010, three systems were deployed by Flight Landata to Afghanistan, where a majority of the imagery is quickly processed to provide rapid tactical information. To date, over 40,000 square kilometers of data have been collected. In addition, an Unmanned Aerial System, equipped with a miniaturized LIDAR sensor and BuckEye sensors, is currently operating in western Afghanistan. \n                    According to Petra, one of the reasons the system is so unique is that the imagery it produces is unclassified, so every soldier can see the details of the environment that are critical to planning operations. “It is a unique capability to provide this class of product to soldiers on the front lines,” says Botha. “Had it not been for the NASA technology contracts, BuckEye might not have been deployed to support the war fighter at a critical time in the conflict.” \n                    Now, BuckEye will be used to support the next Landsat Mission. Flight Landata’s airborne system and data reduction technology will be fused with NASA’s thermal infrared sensor technology to provide multispectral images that parallel the ones that will be produced by the sensors onboard LDCM. This data will directly support the calibration of the LDCM instruments. As Peter Shu, an engineer at Goddard who has worked on the remote sensing technology with Flight Landata through the SBIR program, says, “This is a consequence of the SBIR work with Flight Landata. Now we are using it to help in the development of the Landsat program.”\n                    \n                  \n                \n              \n                  \n                    NASA Technology\n                    \n                      \n                      \n                        \n                      \n                      \n                        This mock-up of the Landsat Data Continuity Mission is essentially a full scale model of the actual satellite, which is scheduled for launch in 2012. The mock-up enables engineers to check that all components seat and connect correctly.\n                          \n                        Image courtesy of Orbital Sciences Corporation\n                      \n                    \n                    Spanning nearly four decades, the remarkable Landsat program has continuously provided data about the Earth’s surface, including detailed maps of vegetation, land use, forest extent and health, surface water, population distribution, as well as how these features have changed over time. Managed by NASA and the U.S. Geological Survey, Landsat’s series of satellites obtain data through passive remote sensing, or the use of sensors to read the energy reflected or emitted from the Earth’s surface. After the data from the sensors is processed and analyzed, it can be applied to create information-rich images of the planet. \n                    While the Landsat program has launched seven satellites since 1972, only Landsat 5 and 7 are currently operating. The next spacecraft in line to ensure continuity of data for years to come is the Landsat Data Continuity Mission (LDCM). Planned for launch in 2012, LDCM will take measurements of the Earth in visible, near-infrared, shortwave infrared, and thermal infrared bands. In addition to widespread use for land use planning and monitoring on local to regional scales, support for disaster response and evaluations, as well as water use monitoring, LDCM measurements will directly serve NASA’s research in the areas of climate, the carbon cycle, ecosystems, the water cycle, biogeochemistry, and Earth’s surface and interior.\n                    Partnership \n                    As part of its continuing efforts to develop improved remote sensing technology for monitoring the Earth, NASA’s Goddard Space Flight Center has worked with Flight Landata Inc., based in North Andover, Massachusetts, to refine and test a lightweight spectral imaging instrument for airborne applications. Over the last 10 years, Flight Landata has received numerous Small Business Innovative Research (SBIR) awards to support the technology’s development. \n                    Several advancements for the imaging technology have been made through the SBIRs, including a smaller computer processor for the imaging system, increased sensitivity in the detector system, and a stabilized gimbal system to maintain the unit’s image fidelity despite movement of the aircraft. In 2005, as part of a combined Phase III SBIR with Goddard and the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), Flight Landata demonstrated the operational capability of a suite of remote sensing instruments in Arizona and California. The demonstration was a success, and afterwards, the company continued to refine the capabilities of the technology. \n                    In 2002, Flight Landata was selected by the Small Business Administration as a winner of the prestigious “Tibbetts Award” in recognition of small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program. By 2006, Flight Landata’s sensor system had incorporated a variety of the refinements and improvements made possible by working with Goddard and the Army, and the system won the Army’s “Greatest Invention of the Year” award. \n                    Benefits\n                    Today, Flight Landata continues to work with NASA through the SBIR program to advance remote sensing technology, but the company also commercially offers the design, integration, and deployment of NASA-enhanced airborne sensor systems, platforms, and collection services. “After developing systems for the government, we were asked if we could deploy, fly, and maintain the systems for the Army. For the last several years, this business has been rapidly growing,” says Petra Botha, Flight Landata’s vice president of finance and administration. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The BuckEye system from Flight Landata Inc. is used for mapping, targeting, damage assessment, and improvised explosive device defeat missions, among others. Over the last 10 years, Flight Landata has received numerous SBIR awards to support the technology’s development.\n                      \n                    \n                    Flight Landata not only supplies the sensor system, it also provides pilots, sensor operators, on-site logistics, and maintenance of the system. The BuckEye EO (electro-optical) instrument suite is flown on the company’s fleet of King Air 100 aircraft to collect extremely high spatial resolution images in three spectral bands. The image data are combined with line scan light detection and ranging (LIDAR) technology to achieve 3D images and to produce digital elevation models quickly. \n                    For the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), BuckEye addresses a need for unclassified high-resolution geospatial data for tactical missions for intelligence, surveillance, and reconnaissance. The AGC strives to make Buckeye data available to U.S. fighting forces and supporting agencies in a timely fashion. The information can improve the soldiers’ situational awareness by providing highly accurate imagery that can be used to produce current, high-resolution reference graphics and image maps for terrain analysis and operating environment visualization. \n                    As soon as imagery and LIDAR are received at the AGC, they are checked for quality and adjusted to eliminate any distortion due to the camera, lens, or topography. Then the images are combined into large mosaics. The resulting information is available online or through the AGC’s Dissemination Team, including GeoPDF Mapbooks, DVDs, and through high-resolution Urban Tactical Planner databases. \n                    In 2005, BuckEye was deployed to Iraq on a fixed-wing aircraft for an urban mapping mission. In addition to a digital color camera, the LIDAR sensor collected high-resolution, high-accuracy elevation data to provide images of urban landscapes and complex terrain. By 2010, the BuckEye had collected over 85,000 square kilometers of data over urban areas and along main supply routes in Iraq, including over 2,000 tiles of LIDAR elevation data at 1-meter resolution, and 1,800,000 color images at \n                      10- to 15-centimeter resolution. \n                    Between 2006 and 2010, three systems were deployed by Flight Landata to Afghanistan, where a majority of the imagery is quickly processed to provide rapid tactical information. To date, over 40,000 square kilometers of data have been collected. In addition, an Unmanned Aerial System, equipped with a miniaturized LIDAR sensor and BuckEye sensors, is currently operating in western Afghanistan. \n                    According to Petra, one of the reasons the system is so unique is that the imagery it produces is unclassified, so every soldier can see the details of the environment that are critical to planning operations. “It is a unique capability to provide this class of product to soldiers on the front lines,” says Botha. “Had it not been for the NASA technology contracts, BuckEye might not have been deployed to support the war fighter at a critical time in the conflict.” \n                    Now, BuckEye will be used to support the next Landsat Mission. Flight Landata’s airborne system and data reduction technology will be fused with NASA’s thermal infrared sensor technology to provide multispectral images that parallel the ones that will be produced by the sensors onboard LDCM. This data will directly support the calibration of the LDCM instruments. As Peter Shu, an engineer at Goddard who has worked on the remote sensing technology with Flight Landata through the SBIR program, says, “This is a consequence of the SBIR work with Flight Landata. Now we are using it to help in the development of the Landsat program.”\n                    \n                  \n                    NASA Technology\n                    \n                      \n                      \n                        \n                      \n                      \n                        This mock-up of the Landsat Data Continuity Mission is essentially a full scale model of the actual satellite, which is scheduled for launch in 2012. The mock-up enables engineers to check that all components seat and connect correctly.\n                          \n                        Image courtesy of Orbital Sciences Corporation\n                      \n                    \n                    Spanning nearly four decades, the remarkable Landsat program has continuously provided data about the Earth’s surface, including detailed maps of vegetation, land use, forest extent and health, surface water, population distribution, as well as how these features have changed over time. Managed by NASA and the U.S. Geological Survey, Landsat’s series of satellites obtain data through passive remote sensing, or the use of sensors to read the energy reflected or emitted from the Earth’s surface. After the data from the sensors is processed and analyzed, it can be applied to create information-rich images of the planet. \n                    While the Landsat program has launched seven satellites since 1972, only Landsat 5 and 7 are currently operating. The next spacecraft in line to ensure continuity of data for years to come is the Landsat Data Continuity Mission (LDCM). Planned for launch in 2012, LDCM will take measurements of the Earth in visible, near-infrared, shortwave infrared, and thermal infrared bands. In addition to widespread use for land use planning and monitoring on local to regional scales, support for disaster response and evaluations, as well as water use monitoring, LDCM measurements will directly serve NASA’s research in the areas of climate, the carbon cycle, ecosystems, the water cycle, biogeochemistry, and Earth’s surface and interior.\n                    Partnership \n                    As part of its continuing efforts to develop improved remote sensing technology for monitoring the Earth, NASA’s Goddard Space Flight Center has worked with Flight Landata Inc., based in North Andover, Massachusetts, to refine and test a lightweight spectral imaging instrument for airborne applications. Over the last 10 years, Flight Landata has received numerous Small Business Innovative Research (SBIR) awards to support the technology’s development. \n                    Several advancements for the imaging technology have been made through the SBIRs, including a smaller computer processor for the imaging system, increased sensitivity in the detector system, and a stabilized gimbal system to maintain the unit’s image fidelity despite movement of the aircraft. In 2005, as part of a combined Phase III SBIR with Goddard and the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), Flight Landata demonstrated the operational capability of a suite of remote sensing instruments in Arizona and California. The demonstration was a success, and afterwards, the company continued to refine the capabilities of the technology. \n                    In 2002, Flight Landata was selected by the Small Business Administration as a winner of the prestigious “Tibbetts Award” in recognition of small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program. By 2006, Flight Landata’s sensor system had incorporated a variety of the refinements and improvements made possible by working with Goddard and the Army, and the system won the Army’s “Greatest Invention of the Year” award. \n                    Benefits\n                    Today, Flight Landata continues to work with NASA through the SBIR program to advance remote sensing technology, but the company also commercially offers the design, integration, and deployment of NASA-enhanced airborne sensor systems, platforms, and collection services. “After developing systems for the government, we were asked if we could deploy, fly, and maintain the systems for the Army. For the last several years, this business has been rapidly growing,” says Petra Botha, Flight Landata’s vice president of finance and administration. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The BuckEye system from Flight Landata Inc. is used for mapping, targeting, damage assessment, and improvised explosive device defeat missions, among others. Over the last 10 years, Flight Landata has received numerous SBIR awards to support the technology’s development.\n                      \n                    \n                    Flight Landata not only supplies the sensor system, it also provides pilots, sensor operators, on-site logistics, and maintenance of the system. The BuckEye EO (electro-optical) instrument suite is flown on the company’s fleet of King Air 100 aircraft to collect extremely high spatial resolution images in three spectral bands. The image data are combined with line scan light detection and ranging (LIDAR) technology to achieve 3D images and to produce digital elevation models quickly. \n                    For the U.S. Army Corps of Engineers’ Army Geospatial Center (AGC), BuckEye addresses a need for unclassified high-resolution geospatial data for tactical missions for intelligence, surveillance, and reconnaissance. The AGC strives to make Buckeye data available to U.S. fighting forces and supporting agencies in a timely fashion. The information can improve the soldiers’ situational awareness by providing highly accurate imagery that can be used to produce current, high-resolution reference graphics and image maps for terrain analysis and operating environment visualization. \n                    As soon as imagery and LIDAR are received at the AGC, they are checked for quality and adjusted to eliminate any distortion due to the camera, lens, or topography. Then the images are combined into large mosaics. The resulting information is available online or through the AGC’s Dissemination Team, including GeoPDF Mapbooks, DVDs, and through high-resolution Urban Tactical Planner databases. \n                    In 2005, BuckEye was deployed to Iraq on a fixed-wing aircraft for an urban mapping mission. In addition to a digital color camera, the LIDAR sensor collected high-resolution, high-accuracy elevation data to provide images of urban landscapes and complex terrain. By 2010, the BuckEye had collected over 85,000 square kilometers of data over urban areas and along main supply routes in Iraq, including over 2,000 tiles of LIDAR elevation data at 1-meter resolution, and 1,800,000 color images at \n                      10- to 15-centimeter resolution. \n                    Between 2006 and 2010, three systems were deployed by Flight Landata to Afghanistan, where a majority of the imagery is quickly processed to provide rapid tactical information. To date, over 40,000 square kilometers of data have been collected. In addition, an Unmanned Aerial System, equipped with a miniaturized LIDAR sensor and BuckEye sensors, is currently operating in western Afghanistan. \n                    According to Petra, one of the reasons the system is so unique is that the imagery it produces is unclassified, so every soldier can see the details of the environment that are critical to planning operations. “It is a unique capability to provide this class of product to soldiers on the front lines,” says Botha. “Had it not been for the NASA technology contracts, BuckEye might not have been deployed to support the war fighter at a critical time in the conflict.” \n                    Now, BuckEye will be used to support the next Landsat Mission. Flight Landata’s airborne system and data reduction technology will be fused with NASA’s thermal infrared sensor technology to provide multispectral images that parallel the ones that will be produced by the sensors onboard LDCM. This data will directly support the calibration of the LDCM instruments. As Peter Shu, an engineer at Goddard who has worked on the remote sensing technology with Flight Landata through the SBIR program, says, “This is a consequence of the SBIR work with Flight Landata. Now we are using it to help in the development of the Landsat program.”\n                    "},{"href":"http://spinoff.nasa.gov/Spinoff2011/ps_5.html","text":"High-Pressure Systems Suppress Fires \n                in Seconds","image":"http://spinoff.nasa.gov/Spinoff2011/Images/ps_10a_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through NASA’s SBIR program, Orbital Technologies Corporation, or ORBITEC, developed vortex combustion technology representing a new approach to rocket engine design. ORBITEC’s NASA work led to advancements in fire suppression systems by the company’s subsidiary, HMA Fire. \n                        \n                      \n                      Much deserved attention is given to the feats of innovation that allow humans to live in space and robotic explorers to beam never-before-seen images back to Earth. In the background of these accomplishments is a technology that makes it all possible—the rockets that propel NASA’s space exploration efforts skyward. \n                      Marshall Space Flight Center has been at the heart of the Agency’s rocketry and spacecraft propulsion efforts since its founding in 1960. Located at the Redstone Arsenal near Huntsville, Alabama, the Center has a legacy of success stretching back to the Saturn rockets that carried the Apollo astronauts into space. Even before Marshall was established, Redstone was the site of significant advances in American rocketry under the guidance of famous rocket engineer Werner Von Braun; these included the Juno I rocket that successfully carried the United States’ first satellite, Explorer 1, into orbit in 1958. And from the first orbital test flight of the Space Shuttle Columbia through the final flights of the shuttle program this year, these vehicles have been enabled by the solid rocket boosters, external tank, and orbiter main engines created at Marshall.\n                      Today, Marshall continues to host innovation in rocket and spacecraft propulsion at state-of-the-art facilities such as the Propulsion Research Laboratory. Like many of its past successes, some of the Center’s current advancements are being made with the help of private industry partners. The efforts have led not only to new propulsion technologies, but to terrestrial benefits in a seemingly unrelated field—in this case, firefighting. \n                      Partnership\n                      Orbital Technologies Corporation (ORBITEC) of Madison, Wisconsin has been a longtime NASA partner, working with the Agency on numerous projects—many through the Small Business Innovation Research (SBIR) program—on a range of space exploration needs, from growing crops in space (Spinoff 2010) to advancing rocket engines. \n                      Through the SBIR program, ORBITEC has collaborated with several NASA Centers, including Marshall, to develop products such as a cool-wall vortex combustion chamber that represents a new way in rocket engine design. By feeding liquid or gas oxidizer into the combustion chamber in a manner that generates a swirling vortex flow, the design confines the mixing and burning of the propellant to the core of the chamber, keeping the walls free from volatile thermal stresses. This process increases the durability and lifespan of the engine while allowing for smaller, cost-effective, and even reusable engine designs. Through further SBIR contracts with Marshall, ORBITEC applied this innovation to an advanced vortex hybrid rocket engine that combines solid and liquid fuel to power a low-cost, highly reliable, and versatile propulsion option. The company is planning an initial test flight of the engine on a commercial rocket system for 2011. \n                      Rory Groonwald, chief engineer for ORBITEC subsidiary HMA Fire, saw potential in much of ORBITEC’s propulsion technologies beyond space exploration. Through extensive work with the U.S. Air Force Fire Rescue Research Group to develop means for more effectively extinguishing hydrocarbon-based fuel fires, HMA developed fire suppression systems that utilized ultra-high pressure (UHP) for firefighting. Groonwald was exploring ways to improve the efficiency of fire suppression systems by reducing the time and amount of water needed to extinguish a fire. \n                      “We were trying to make something more effective and safer for firefighters to use,” Groonwald says. \n                      The idea of management of high pressure flows, like ORBITEC does with rocket engine design, repeatedly came to mind. Working with its partners, HMA incorporated elements derived from ORBITEC’s propulsion work into its design for fire suppression, and the improvements significantly enhanced the performance of HMA’s UHP systems. For example, the company studied how to better manage the flow of a liquid to create an energetic blanket of fine water droplets. Through iterative design and testing, they optimized a method for providing a continuous and effective stream that uses much less suppressant. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s Hydrus systems provide a versatile range of firefighting solutions, including the skid-mounted mobile unit seen here, which can be loaded onto a variety of vehicles.\n                        \n                      \n                      HMA’s propulsion-inspired design is only one of the benefits the company’s UHP suppression systems provide to firefighters. The systems introduce an approach to fire suppression that is complementary to—and in a number of cases superior to—traditional firefighting methods.\n                      “The fire industry still has a mentality of ‘surround and drown’—the more water you put around a fire, the faster the fire will go out,” Groonwald says. “But that is not necessarily true.”\n                      One series of tests using empty houses at Vandenberg Air Force Base compared an HMA system with a 20-gallon-per-minute, 1,400 pound-per-square-inch (psi) discharge capability (at the pump) versus a standard 100-gallon-per-minute, 125 psi standard hand line—the kind that typically takes a few firemen to control. The standard line extinguished a set fire in a living room in 1 minute and 45 seconds using 220 gallons of water. The HMA system extinguished an identical fire in 17.3 seconds using 13.6 gallons—with a hose requiring only one person to manage.\n                      “[The HMA system] sucked the life out of the fire and did it faster than anything I’ve ever seen before,” says Devin Misiewicz, captain of the Vandenberg Air Force Base Fire Department. \n                      The key to the HMA system is the pressure of its discharge, which results in smaller droplets dispersed on the fire. The smaller droplets create a greater total surface area contacting the flames—four times the total surface area of the larger droplets from standard, low pressure systems. In addition to helping rapidly extinguish a fire, HMA’s UHP approach also quickly reduces the temperature around a blaze—in the case of the Vandenberg test from 1,400 °F to below 250 °F within 60 seconds, about 2 minutes and 30 seconds faster than the standard equipment—and results in less smoke. \n                      “What this does is create a safer environment for the firefighters to conduct an offensive suppression attack on the fire,” says Groonwald. Using less water also reduces one of the major sources \n                        of damage from a fire situation: the water itself. \n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s fire suppression technology is ideal for a host of firefighting applications, including combating wildfires in areas unreachable by standard fire trucks. Here, HMA’s L3 (light, lean, and lethal) vehicle demonstrates these capabilities. \n                        \n                      \n                      HMA’s Hydrus systems are commercially available in a range of platforms. The T4 and T6 First Responder Emergency Systems incorporate the system into easily maneuverable, all-terrain vehicles. Along with the company’s Proteus Series Brush Trucks and skid-mounted mobile units that can be loaded onto any number of vehicles, HMA’s systems provide a quick-response firefighting tool for a range of fire situations. Carrying their own water sources, these systems are ideal for fighting wildfires in areas unreachable by standard fire trucks. The systems’ high pressure discharge can also penetrate 7 inches into the ground if desired, cooling lingering embers and heat sources that can reignite a wildland-type fire. The UHP systems are also highly effective against hydrocarbon fuel-based car fires and have been repeatedly proven to extinguish fully engulfed cars in 9 seconds.\n                      While Groonwald says that HMA’s systems are not intended to replace standard firefighting technology in all cases, they can be installed on fire trucks as a first attack tool complementing traditional low pressure, high volume systems. \n                      “Our systems become a force multiplier,” says Groonwald. “You can do more safely with the same amount of people.” \n                      Government partnerships like those between HMA and ORBITEC, NASA, and the Air Force have supported the research and development leading to the creation of these game-changing firefighting tools, says Marty Gustafson, ORBITEC engineer and applications research manager.\n                      “This is where the government-industry partnerships make a difference,” she says. “They allow you to prove out a technology in a way that gives you instant credibility.” \n                      The experts are buying in: The U.S. military employs 4 UHP units at the forward operating base near Kabul in Afghanistan to help combat fuel fires and firebomb attacks. The Navy utilizes the systems in the Middle East, and 12 Air Force bases in the United States employ the technology. Alaska is also examining the systems for remote towns, where they can be used by operators without firefighting training, and the Mojave Air and Space Port in California features the technology on a specially designed rapid response rescue truck. Plus, municipal fire departments are interested in the technology’s NASA-enhanced capabilities, meaning cities and towns nationwide could soon benefit from another example of space exploration technology improving daily life.\n                      Hydrus™, T4™, T6™, and Proteus™ are trademarks of Orbital Technologies Corporation.\n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through NASA’s SBIR program, Orbital Technologies Corporation, or ORBITEC, developed vortex combustion technology representing a new approach to rocket engine design. ORBITEC’s NASA work led to advancements in fire suppression systems by the company’s subsidiary, HMA Fire. \n                        \n                      \n                      Much deserved attention is given to the feats of innovation that allow humans to live in space and robotic explorers to beam never-before-seen images back to Earth. In the background of these accomplishments is a technology that makes it all possible—the rockets that propel NASA’s space exploration efforts skyward. \n                      Marshall Space Flight Center has been at the heart of the Agency’s rocketry and spacecraft propulsion efforts since its founding in 1960. Located at the Redstone Arsenal near Huntsville, Alabama, the Center has a legacy of success stretching back to the Saturn rockets that carried the Apollo astronauts into space. Even before Marshall was established, Redstone was the site of significant advances in American rocketry under the guidance of famous rocket engineer Werner Von Braun; these included the Juno I rocket that successfully carried the United States’ first satellite, Explorer 1, into orbit in 1958. And from the first orbital test flight of the Space Shuttle Columbia through the final flights of the shuttle program this year, these vehicles have been enabled by the solid rocket boosters, external tank, and orbiter main engines created at Marshall.\n                      Today, Marshall continues to host innovation in rocket and spacecraft propulsion at state-of-the-art facilities such as the Propulsion Research Laboratory. Like many of its past successes, some of the Center’s current advancements are being made with the help of private industry partners. The efforts have led not only to new propulsion technologies, but to terrestrial benefits in a seemingly unrelated field—in this case, firefighting. \n                      Partnership\n                      Orbital Technologies Corporation (ORBITEC) of Madison, Wisconsin has been a longtime NASA partner, working with the Agency on numerous projects—many through the Small Business Innovation Research (SBIR) program—on a range of space exploration needs, from growing crops in space (Spinoff 2010) to advancing rocket engines. \n                      Through the SBIR program, ORBITEC has collaborated with several NASA Centers, including Marshall, to develop products such as a cool-wall vortex combustion chamber that represents a new way in rocket engine design. By feeding liquid or gas oxidizer into the combustion chamber in a manner that generates a swirling vortex flow, the design confines the mixing and burning of the propellant to the core of the chamber, keeping the walls free from volatile thermal stresses. This process increases the durability and lifespan of the engine while allowing for smaller, cost-effective, and even reusable engine designs. Through further SBIR contracts with Marshall, ORBITEC applied this innovation to an advanced vortex hybrid rocket engine that combines solid and liquid fuel to power a low-cost, highly reliable, and versatile propulsion option. The company is planning an initial test flight of the engine on a commercial rocket system for 2011. \n                      Rory Groonwald, chief engineer for ORBITEC subsidiary HMA Fire, saw potential in much of ORBITEC’s propulsion technologies beyond space exploration. Through extensive work with the U.S. Air Force Fire Rescue Research Group to develop means for more effectively extinguishing hydrocarbon-based fuel fires, HMA developed fire suppression systems that utilized ultra-high pressure (UHP) for firefighting. Groonwald was exploring ways to improve the efficiency of fire suppression systems by reducing the time and amount of water needed to extinguish a fire. \n                      “We were trying to make something more effective and safer for firefighters to use,” Groonwald says. \n                      The idea of management of high pressure flows, like ORBITEC does with rocket engine design, repeatedly came to mind. Working with its partners, HMA incorporated elements derived from ORBITEC’s propulsion work into its design for fire suppression, and the improvements significantly enhanced the performance of HMA’s UHP systems. For example, the company studied how to better manage the flow of a liquid to create an energetic blanket of fine water droplets. Through iterative design and testing, they optimized a method for providing a continuous and effective stream that uses much less suppressant. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s Hydrus systems provide a versatile range of firefighting solutions, including the skid-mounted mobile unit seen here, which can be loaded onto a variety of vehicles.\n                        \n                      \n                      HMA’s propulsion-inspired design is only one of the benefits the company’s UHP suppression systems provide to firefighters. The systems introduce an approach to fire suppression that is complementary to—and in a number of cases superior to—traditional firefighting methods.\n                      “The fire industry still has a mentality of ‘surround and drown’—the more water you put around a fire, the faster the fire will go out,” Groonwald says. “But that is not necessarily true.”\n                      One series of tests using empty houses at Vandenberg Air Force Base compared an HMA system with a 20-gallon-per-minute, 1,400 pound-per-square-inch (psi) discharge capability (at the pump) versus a standard 100-gallon-per-minute, 125 psi standard hand line—the kind that typically takes a few firemen to control. The standard line extinguished a set fire in a living room in 1 minute and 45 seconds using 220 gallons of water. The HMA system extinguished an identical fire in 17.3 seconds using 13.6 gallons—with a hose requiring only one person to manage.\n                      “[The HMA system] sucked the life out of the fire and did it faster than anything I’ve ever seen before,” says Devin Misiewicz, captain of the Vandenberg Air Force Base Fire Department. \n                      The key to the HMA system is the pressure of its discharge, which results in smaller droplets dispersed on the fire. The smaller droplets create a greater total surface area contacting the flames—four times the total surface area of the larger droplets from standard, low pressure systems. In addition to helping rapidly extinguish a fire, HMA’s UHP approach also quickly reduces the temperature around a blaze—in the case of the Vandenberg test from 1,400 °F to below 250 °F within 60 seconds, about 2 minutes and 30 seconds faster than the standard equipment—and results in less smoke. \n                      “What this does is create a safer environment for the firefighters to conduct an offensive suppression attack on the fire,” says Groonwald. Using less water also reduces one of the major sources \n                        of damage from a fire situation: the water itself. \n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s fire suppression technology is ideal for a host of firefighting applications, including combating wildfires in areas unreachable by standard fire trucks. Here, HMA’s L3 (light, lean, and lethal) vehicle demonstrates these capabilities. \n                        \n                      \n                      HMA’s Hydrus systems are commercially available in a range of platforms. The T4 and T6 First Responder Emergency Systems incorporate the system into easily maneuverable, all-terrain vehicles. Along with the company’s Proteus Series Brush Trucks and skid-mounted mobile units that can be loaded onto any number of vehicles, HMA’s systems provide a quick-response firefighting tool for a range of fire situations. Carrying their own water sources, these systems are ideal for fighting wildfires in areas unreachable by standard fire trucks. The systems’ high pressure discharge can also penetrate 7 inches into the ground if desired, cooling lingering embers and heat sources that can reignite a wildland-type fire. The UHP systems are also highly effective against hydrocarbon fuel-based car fires and have been repeatedly proven to extinguish fully engulfed cars in 9 seconds.\n                      While Groonwald says that HMA’s systems are not intended to replace standard firefighting technology in all cases, they can be installed on fire trucks as a first attack tool complementing traditional low pressure, high volume systems. \n                      “Our systems become a force multiplier,” says Groonwald. “You can do more safely with the same amount of people.” \n                      Government partnerships like those between HMA and ORBITEC, NASA, and the Air Force have supported the research and development leading to the creation of these game-changing firefighting tools, says Marty Gustafson, ORBITEC engineer and applications research manager.\n                      “This is where the government-industry partnerships make a difference,” she says. “They allow you to prove out a technology in a way that gives you instant credibility.” \n                      The experts are buying in: The U.S. military employs 4 UHP units at the forward operating base near Kabul in Afghanistan to help combat fuel fires and firebomb attacks. The Navy utilizes the systems in the Middle East, and 12 Air Force bases in the United States employ the technology. Alaska is also examining the systems for remote towns, where they can be used by operators without firefighting training, and the Mojave Air and Space Port in California features the technology on a specially designed rapid response rescue truck. Plus, municipal fire departments are interested in the technology’s NASA-enhanced capabilities, meaning cities and towns nationwide could soon benefit from another example of space exploration technology improving daily life.\n                      Hydrus™, T4™, T6™, and Proteus™ are trademarks of Orbital Technologies Corporation.\n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through NASA’s SBIR program, Orbital Technologies Corporation, or ORBITEC, developed vortex combustion technology representing a new approach to rocket engine design. ORBITEC’s NASA work led to advancements in fire suppression systems by the company’s subsidiary, HMA Fire. \n                        \n                      \n                      Much deserved attention is given to the feats of innovation that allow humans to live in space and robotic explorers to beam never-before-seen images back to Earth. In the background of these accomplishments is a technology that makes it all possible—the rockets that propel NASA’s space exploration efforts skyward. \n                      Marshall Space Flight Center has been at the heart of the Agency’s rocketry and spacecraft propulsion efforts since its founding in 1960. Located at the Redstone Arsenal near Huntsville, Alabama, the Center has a legacy of success stretching back to the Saturn rockets that carried the Apollo astronauts into space. Even before Marshall was established, Redstone was the site of significant advances in American rocketry under the guidance of famous rocket engineer Werner Von Braun; these included the Juno I rocket that successfully carried the United States’ first satellite, Explorer 1, into orbit in 1958. And from the first orbital test flight of the Space Shuttle Columbia through the final flights of the shuttle program this year, these vehicles have been enabled by the solid rocket boosters, external tank, and orbiter main engines created at Marshall.\n                      Today, Marshall continues to host innovation in rocket and spacecraft propulsion at state-of-the-art facilities such as the Propulsion Research Laboratory. Like many of its past successes, some of the Center’s current advancements are being made with the help of private industry partners. The efforts have led not only to new propulsion technologies, but to terrestrial benefits in a seemingly unrelated field—in this case, firefighting. \n                      Partnership\n                      Orbital Technologies Corporation (ORBITEC) of Madison, Wisconsin has been a longtime NASA partner, working with the Agency on numerous projects—many through the Small Business Innovation Research (SBIR) program—on a range of space exploration needs, from growing crops in space (Spinoff 2010) to advancing rocket engines. \n                      Through the SBIR program, ORBITEC has collaborated with several NASA Centers, including Marshall, to develop products such as a cool-wall vortex combustion chamber that represents a new way in rocket engine design. By feeding liquid or gas oxidizer into the combustion chamber in a manner that generates a swirling vortex flow, the design confines the mixing and burning of the propellant to the core of the chamber, keeping the walls free from volatile thermal stresses. This process increases the durability and lifespan of the engine while allowing for smaller, cost-effective, and even reusable engine designs. Through further SBIR contracts with Marshall, ORBITEC applied this innovation to an advanced vortex hybrid rocket engine that combines solid and liquid fuel to power a low-cost, highly reliable, and versatile propulsion option. The company is planning an initial test flight of the engine on a commercial rocket system for 2011. \n                      Rory Groonwald, chief engineer for ORBITEC subsidiary HMA Fire, saw potential in much of ORBITEC’s propulsion technologies beyond space exploration. Through extensive work with the U.S. Air Force Fire Rescue Research Group to develop means for more effectively extinguishing hydrocarbon-based fuel fires, HMA developed fire suppression systems that utilized ultra-high pressure (UHP) for firefighting. Groonwald was exploring ways to improve the efficiency of fire suppression systems by reducing the time and amount of water needed to extinguish a fire. \n                      “We were trying to make something more effective and safer for firefighters to use,” Groonwald says. \n                      The idea of management of high pressure flows, like ORBITEC does with rocket engine design, repeatedly came to mind. Working with its partners, HMA incorporated elements derived from ORBITEC’s propulsion work into its design for fire suppression, and the improvements significantly enhanced the performance of HMA’s UHP systems. For example, the company studied how to better manage the flow of a liquid to create an energetic blanket of fine water droplets. Through iterative design and testing, they optimized a method for providing a continuous and effective stream that uses much less suppressant. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s Hydrus systems provide a versatile range of firefighting solutions, including the skid-mounted mobile unit seen here, which can be loaded onto a variety of vehicles.\n                        \n                      \n                      HMA’s propulsion-inspired design is only one of the benefits the company’s UHP suppression systems provide to firefighters. The systems introduce an approach to fire suppression that is complementary to—and in a number of cases superior to—traditional firefighting methods.\n                      “The fire industry still has a mentality of ‘surround and drown’—the more water you put around a fire, the faster the fire will go out,” Groonwald says. “But that is not necessarily true.”\n                      One series of tests using empty houses at Vandenberg Air Force Base compared an HMA system with a 20-gallon-per-minute, 1,400 pound-per-square-inch (psi) discharge capability (at the pump) versus a standard 100-gallon-per-minute, 125 psi standard hand line—the kind that typically takes a few firemen to control. The standard line extinguished a set fire in a living room in 1 minute and 45 seconds using 220 gallons of water. The HMA system extinguished an identical fire in 17.3 seconds using 13.6 gallons—with a hose requiring only one person to manage.\n                      “[The HMA system] sucked the life out of the fire and did it faster than anything I’ve ever seen before,” says Devin Misiewicz, captain of the Vandenberg Air Force Base Fire Department. \n                      The key to the HMA system is the pressure of its discharge, which results in smaller droplets dispersed on the fire. The smaller droplets create a greater total surface area contacting the flames—four times the total surface area of the larger droplets from standard, low pressure systems. In addition to helping rapidly extinguish a fire, HMA’s UHP approach also quickly reduces the temperature around a blaze—in the case of the Vandenberg test from 1,400 °F to below 250 °F within 60 seconds, about 2 minutes and 30 seconds faster than the standard equipment—and results in less smoke. \n                      “What this does is create a safer environment for the firefighters to conduct an offensive suppression attack on the fire,” says Groonwald. Using less water also reduces one of the major sources \n                        of damage from a fire situation: the water itself. \n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s fire suppression technology is ideal for a host of firefighting applications, including combating wildfires in areas unreachable by standard fire trucks. Here, HMA’s L3 (light, lean, and lethal) vehicle demonstrates these capabilities. \n                        \n                      \n                      HMA’s Hydrus systems are commercially available in a range of platforms. The T4 and T6 First Responder Emergency Systems incorporate the system into easily maneuverable, all-terrain vehicles. Along with the company’s Proteus Series Brush Trucks and skid-mounted mobile units that can be loaded onto any number of vehicles, HMA’s systems provide a quick-response firefighting tool for a range of fire situations. Carrying their own water sources, these systems are ideal for fighting wildfires in areas unreachable by standard fire trucks. The systems’ high pressure discharge can also penetrate 7 inches into the ground if desired, cooling lingering embers and heat sources that can reignite a wildland-type fire. The UHP systems are also highly effective against hydrocarbon fuel-based car fires and have been repeatedly proven to extinguish fully engulfed cars in 9 seconds.\n                      While Groonwald says that HMA’s systems are not intended to replace standard firefighting technology in all cases, they can be installed on fire trucks as a first attack tool complementing traditional low pressure, high volume systems. \n                      “Our systems become a force multiplier,” says Groonwald. “You can do more safely with the same amount of people.” \n                      Government partnerships like those between HMA and ORBITEC, NASA, and the Air Force have supported the research and development leading to the creation of these game-changing firefighting tools, says Marty Gustafson, ORBITEC engineer and applications research manager.\n                      “This is where the government-industry partnerships make a difference,” she says. “They allow you to prove out a technology in a way that gives you instant credibility.” \n                      The experts are buying in: The U.S. military employs 4 UHP units at the forward operating base near Kabul in Afghanistan to help combat fuel fires and firebomb attacks. The Navy utilizes the systems in the Middle East, and 12 Air Force bases in the United States employ the technology. Alaska is also examining the systems for remote towns, where they can be used by operators without firefighting training, and the Mojave Air and Space Port in California features the technology on a specially designed rapid response rescue truck. Plus, municipal fire departments are interested in the technology’s NASA-enhanced capabilities, meaning cities and towns nationwide could soon benefit from another example of space exploration technology improving daily life.\n                      Hydrus™, T4™, T6™, and Proteus™ are trademarks of Orbital Technologies Corporation.\n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through NASA’s SBIR program, Orbital Technologies Corporation, or ORBITEC, developed vortex combustion technology representing a new approach to rocket engine design. ORBITEC’s NASA work led to advancements in fire suppression systems by the company’s subsidiary, HMA Fire. \n                        \n                      \n                      Much deserved attention is given to the feats of innovation that allow humans to live in space and robotic explorers to beam never-before-seen images back to Earth. In the background of these accomplishments is a technology that makes it all possible—the rockets that propel NASA’s space exploration efforts skyward. \n                      Marshall Space Flight Center has been at the heart of the Agency’s rocketry and spacecraft propulsion efforts since its founding in 1960. Located at the Redstone Arsenal near Huntsville, Alabama, the Center has a legacy of success stretching back to the Saturn rockets that carried the Apollo astronauts into space. Even before Marshall was established, Redstone was the site of significant advances in American rocketry under the guidance of famous rocket engineer Werner Von Braun; these included the Juno I rocket that successfully carried the United States’ first satellite, Explorer 1, into orbit in 1958. And from the first orbital test flight of the Space Shuttle Columbia through the final flights of the shuttle program this year, these vehicles have been enabled by the solid rocket boosters, external tank, and orbiter main engines created at Marshall.\n                      Today, Marshall continues to host innovation in rocket and spacecraft propulsion at state-of-the-art facilities such as the Propulsion Research Laboratory. Like many of its past successes, some of the Center’s current advancements are being made with the help of private industry partners. The efforts have led not only to new propulsion technologies, but to terrestrial benefits in a seemingly unrelated field—in this case, firefighting. \n                      Partnership\n                      Orbital Technologies Corporation (ORBITEC) of Madison, Wisconsin has been a longtime NASA partner, working with the Agency on numerous projects—many through the Small Business Innovation Research (SBIR) program—on a range of space exploration needs, from growing crops in space (Spinoff 2010) to advancing rocket engines. \n                      Through the SBIR program, ORBITEC has collaborated with several NASA Centers, including Marshall, to develop products such as a cool-wall vortex combustion chamber that represents a new way in rocket engine design. By feeding liquid or gas oxidizer into the combustion chamber in a manner that generates a swirling vortex flow, the design confines the mixing and burning of the propellant to the core of the chamber, keeping the walls free from volatile thermal stresses. This process increases the durability and lifespan of the engine while allowing for smaller, cost-effective, and even reusable engine designs. Through further SBIR contracts with Marshall, ORBITEC applied this innovation to an advanced vortex hybrid rocket engine that combines solid and liquid fuel to power a low-cost, highly reliable, and versatile propulsion option. The company is planning an initial test flight of the engine on a commercial rocket system for 2011. \n                      Rory Groonwald, chief engineer for ORBITEC subsidiary HMA Fire, saw potential in much of ORBITEC’s propulsion technologies beyond space exploration. Through extensive work with the U.S. Air Force Fire Rescue Research Group to develop means for more effectively extinguishing hydrocarbon-based fuel fires, HMA developed fire suppression systems that utilized ultra-high pressure (UHP) for firefighting. Groonwald was exploring ways to improve the efficiency of fire suppression systems by reducing the time and amount of water needed to extinguish a fire. \n                      “We were trying to make something more effective and safer for firefighters to use,” Groonwald says. \n                      The idea of management of high pressure flows, like ORBITEC does with rocket engine design, repeatedly came to mind. Working with its partners, HMA incorporated elements derived from ORBITEC’s propulsion work into its design for fire suppression, and the improvements significantly enhanced the performance of HMA’s UHP systems. For example, the company studied how to better manage the flow of a liquid to create an energetic blanket of fine water droplets. Through iterative design and testing, they optimized a method for providing a continuous and effective stream that uses much less suppressant. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s Hydrus systems provide a versatile range of firefighting solutions, including the skid-mounted mobile unit seen here, which can be loaded onto a variety of vehicles.\n                        \n                      \n                      HMA’s propulsion-inspired design is only one of the benefits the company’s UHP suppression systems provide to firefighters. The systems introduce an approach to fire suppression that is complementary to—and in a number of cases superior to—traditional firefighting methods.\n                      “The fire industry still has a mentality of ‘surround and drown’—the more water you put around a fire, the faster the fire will go out,” Groonwald says. “But that is not necessarily true.”\n                      One series of tests using empty houses at Vandenberg Air Force Base compared an HMA system with a 20-gallon-per-minute, 1,400 pound-per-square-inch (psi) discharge capability (at the pump) versus a standard 100-gallon-per-minute, 125 psi standard hand line—the kind that typically takes a few firemen to control. The standard line extinguished a set fire in a living room in 1 minute and 45 seconds using 220 gallons of water. The HMA system extinguished an identical fire in 17.3 seconds using 13.6 gallons—with a hose requiring only one person to manage.\n                      “[The HMA system] sucked the life out of the fire and did it faster than anything I’ve ever seen before,” says Devin Misiewicz, captain of the Vandenberg Air Force Base Fire Department. \n                      The key to the HMA system is the pressure of its discharge, which results in smaller droplets dispersed on the fire. The smaller droplets create a greater total surface area contacting the flames—four times the total surface area of the larger droplets from standard, low pressure systems. In addition to helping rapidly extinguish a fire, HMA’s UHP approach also quickly reduces the temperature around a blaze—in the case of the Vandenberg test from 1,400 °F to below 250 °F within 60 seconds, about 2 minutes and 30 seconds faster than the standard equipment—and results in less smoke. \n                      “What this does is create a safer environment for the firefighters to conduct an offensive suppression attack on the fire,” says Groonwald. Using less water also reduces one of the major sources \n                        of damage from a fire situation: the water itself. \n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s fire suppression technology is ideal for a host of firefighting applications, including combating wildfires in areas unreachable by standard fire trucks. Here, HMA’s L3 (light, lean, and lethal) vehicle demonstrates these capabilities. \n                        \n                      \n                      HMA’s Hydrus systems are commercially available in a range of platforms. The T4 and T6 First Responder Emergency Systems incorporate the system into easily maneuverable, all-terrain vehicles. Along with the company’s Proteus Series Brush Trucks and skid-mounted mobile units that can be loaded onto any number of vehicles, HMA’s systems provide a quick-response firefighting tool for a range of fire situations. Carrying their own water sources, these systems are ideal for fighting wildfires in areas unreachable by standard fire trucks. The systems’ high pressure discharge can also penetrate 7 inches into the ground if desired, cooling lingering embers and heat sources that can reignite a wildland-type fire. The UHP systems are also highly effective against hydrocarbon fuel-based car fires and have been repeatedly proven to extinguish fully engulfed cars in 9 seconds.\n                      While Groonwald says that HMA’s systems are not intended to replace standard firefighting technology in all cases, they can be installed on fire trucks as a first attack tool complementing traditional low pressure, high volume systems. \n                      “Our systems become a force multiplier,” says Groonwald. “You can do more safely with the same amount of people.” \n                      Government partnerships like those between HMA and ORBITEC, NASA, and the Air Force have supported the research and development leading to the creation of these game-changing firefighting tools, says Marty Gustafson, ORBITEC engineer and applications research manager.\n                      “This is where the government-industry partnerships make a difference,” she says. “They allow you to prove out a technology in a way that gives you instant credibility.” \n                      The experts are buying in: The U.S. military employs 4 UHP units at the forward operating base near Kabul in Afghanistan to help combat fuel fires and firebomb attacks. The Navy utilizes the systems in the Middle East, and 12 Air Force bases in the United States employ the technology. Alaska is also examining the systems for remote towns, where they can be used by operators without firefighting training, and the Mojave Air and Space Port in California features the technology on a specially designed rapid response rescue truck. Plus, municipal fire departments are interested in the technology’s NASA-enhanced capabilities, meaning cities and towns nationwide could soon benefit from another example of space exploration technology improving daily life.\n                      Hydrus™, T4™, T6™, and Proteus™ are trademarks of Orbital Technologies Corporation.\n                      \n                    \n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through NASA’s SBIR program, Orbital Technologies Corporation, or ORBITEC, developed vortex combustion technology representing a new approach to rocket engine design. ORBITEC’s NASA work led to advancements in fire suppression systems by the company’s subsidiary, HMA Fire. \n                        \n                      \n                      Much deserved attention is given to the feats of innovation that allow humans to live in space and robotic explorers to beam never-before-seen images back to Earth. In the background of these accomplishments is a technology that makes it all possible—the rockets that propel NASA’s space exploration efforts skyward. \n                      Marshall Space Flight Center has been at the heart of the Agency’s rocketry and spacecraft propulsion efforts since its founding in 1960. Located at the Redstone Arsenal near Huntsville, Alabama, the Center has a legacy of success stretching back to the Saturn rockets that carried the Apollo astronauts into space. Even before Marshall was established, Redstone was the site of significant advances in American rocketry under the guidance of famous rocket engineer Werner Von Braun; these included the Juno I rocket that successfully carried the United States’ first satellite, Explorer 1, into orbit in 1958. And from the first orbital test flight of the Space Shuttle Columbia through the final flights of the shuttle program this year, these vehicles have been enabled by the solid rocket boosters, external tank, and orbiter main engines created at Marshall.\n                      Today, Marshall continues to host innovation in rocket and spacecraft propulsion at state-of-the-art facilities such as the Propulsion Research Laboratory. Like many of its past successes, some of the Center’s current advancements are being made with the help of private industry partners. The efforts have led not only to new propulsion technologies, but to terrestrial benefits in a seemingly unrelated field—in this case, firefighting. \n                      Partnership\n                      Orbital Technologies Corporation (ORBITEC) of Madison, Wisconsin has been a longtime NASA partner, working with the Agency on numerous projects—many through the Small Business Innovation Research (SBIR) program—on a range of space exploration needs, from growing crops in space (Spinoff 2010) to advancing rocket engines. \n                      Through the SBIR program, ORBITEC has collaborated with several NASA Centers, including Marshall, to develop products such as a cool-wall vortex combustion chamber that represents a new way in rocket engine design. By feeding liquid or gas oxidizer into the combustion chamber in a manner that generates a swirling vortex flow, the design confines the mixing and burning of the propellant to the core of the chamber, keeping the walls free from volatile thermal stresses. This process increases the durability and lifespan of the engine while allowing for smaller, cost-effective, and even reusable engine designs. Through further SBIR contracts with Marshall, ORBITEC applied this innovation to an advanced vortex hybrid rocket engine that combines solid and liquid fuel to power a low-cost, highly reliable, and versatile propulsion option. The company is planning an initial test flight of the engine on a commercial rocket system for 2011. \n                      Rory Groonwald, chief engineer for ORBITEC subsidiary HMA Fire, saw potential in much of ORBITEC’s propulsion technologies beyond space exploration. Through extensive work with the U.S. Air Force Fire Rescue Research Group to develop means for more effectively extinguishing hydrocarbon-based fuel fires, HMA developed fire suppression systems that utilized ultra-high pressure (UHP) for firefighting. Groonwald was exploring ways to improve the efficiency of fire suppression systems by reducing the time and amount of water needed to extinguish a fire. \n                      “We were trying to make something more effective and safer for firefighters to use,” Groonwald says. \n                      The idea of management of high pressure flows, like ORBITEC does with rocket engine design, repeatedly came to mind. Working with its partners, HMA incorporated elements derived from ORBITEC’s propulsion work into its design for fire suppression, and the improvements significantly enhanced the performance of HMA’s UHP systems. For example, the company studied how to better manage the flow of a liquid to create an energetic blanket of fine water droplets. Through iterative design and testing, they optimized a method for providing a continuous and effective stream that uses much less suppressant. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s Hydrus systems provide a versatile range of firefighting solutions, including the skid-mounted mobile unit seen here, which can be loaded onto a variety of vehicles.\n                        \n                      \n                      HMA’s propulsion-inspired design is only one of the benefits the company’s UHP suppression systems provide to firefighters. The systems introduce an approach to fire suppression that is complementary to—and in a number of cases superior to—traditional firefighting methods.\n                      “The fire industry still has a mentality of ‘surround and drown’—the more water you put around a fire, the faster the fire will go out,” Groonwald says. “But that is not necessarily true.”\n                      One series of tests using empty houses at Vandenberg Air Force Base compared an HMA system with a 20-gallon-per-minute, 1,400 pound-per-square-inch (psi) discharge capability (at the pump) versus a standard 100-gallon-per-minute, 125 psi standard hand line—the kind that typically takes a few firemen to control. The standard line extinguished a set fire in a living room in 1 minute and 45 seconds using 220 gallons of water. The HMA system extinguished an identical fire in 17.3 seconds using 13.6 gallons—with a hose requiring only one person to manage.\n                      “[The HMA system] sucked the life out of the fire and did it faster than anything I’ve ever seen before,” says Devin Misiewicz, captain of the Vandenberg Air Force Base Fire Department. \n                      The key to the HMA system is the pressure of its discharge, which results in smaller droplets dispersed on the fire. The smaller droplets create a greater total surface area contacting the flames—four times the total surface area of the larger droplets from standard, low pressure systems. In addition to helping rapidly extinguish a fire, HMA’s UHP approach also quickly reduces the temperature around a blaze—in the case of the Vandenberg test from 1,400 °F to below 250 °F within 60 seconds, about 2 minutes and 30 seconds faster than the standard equipment—and results in less smoke. \n                      “What this does is create a safer environment for the firefighters to conduct an offensive suppression attack on the fire,” says Groonwald. Using less water also reduces one of the major sources \n                        of damage from a fire situation: the water itself. \n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s fire suppression technology is ideal for a host of firefighting applications, including combating wildfires in areas unreachable by standard fire trucks. Here, HMA’s L3 (light, lean, and lethal) vehicle demonstrates these capabilities. \n                        \n                      \n                      HMA’s Hydrus systems are commercially available in a range of platforms. The T4 and T6 First Responder Emergency Systems incorporate the system into easily maneuverable, all-terrain vehicles. Along with the company’s Proteus Series Brush Trucks and skid-mounted mobile units that can be loaded onto any number of vehicles, HMA’s systems provide a quick-response firefighting tool for a range of fire situations. Carrying their own water sources, these systems are ideal for fighting wildfires in areas unreachable by standard fire trucks. The systems’ high pressure discharge can also penetrate 7 inches into the ground if desired, cooling lingering embers and heat sources that can reignite a wildland-type fire. The UHP systems are also highly effective against hydrocarbon fuel-based car fires and have been repeatedly proven to extinguish fully engulfed cars in 9 seconds.\n                      While Groonwald says that HMA’s systems are not intended to replace standard firefighting technology in all cases, they can be installed on fire trucks as a first attack tool complementing traditional low pressure, high volume systems. \n                      “Our systems become a force multiplier,” says Groonwald. “You can do more safely with the same amount of people.” \n                      Government partnerships like those between HMA and ORBITEC, NASA, and the Air Force have supported the research and development leading to the creation of these game-changing firefighting tools, says Marty Gustafson, ORBITEC engineer and applications research manager.\n                      “This is where the government-industry partnerships make a difference,” she says. “They allow you to prove out a technology in a way that gives you instant credibility.” \n                      The experts are buying in: The U.S. military employs 4 UHP units at the forward operating base near Kabul in Afghanistan to help combat fuel fires and firebomb attacks. The Navy utilizes the systems in the Middle East, and 12 Air Force bases in the United States employ the technology. Alaska is also examining the systems for remote towns, where they can be used by operators without firefighting training, and the Mojave Air and Space Port in California features the technology on a specially designed rapid response rescue truck. Plus, municipal fire departments are interested in the technology’s NASA-enhanced capabilities, meaning cities and towns nationwide could soon benefit from another example of space exploration technology improving daily life.\n                      Hydrus™, T4™, T6™, and Proteus™ are trademarks of Orbital Technologies Corporation.\n                      \n                    \n                  \n                \n              \n            \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through NASA’s SBIR program, Orbital Technologies Corporation, or ORBITEC, developed vortex combustion technology representing a new approach to rocket engine design. ORBITEC’s NASA work led to advancements in fire suppression systems by the company’s subsidiary, HMA Fire. \n                        \n                      \n                      Much deserved attention is given to the feats of innovation that allow humans to live in space and robotic explorers to beam never-before-seen images back to Earth. In the background of these accomplishments is a technology that makes it all possible—the rockets that propel NASA’s space exploration efforts skyward. \n                      Marshall Space Flight Center has been at the heart of the Agency’s rocketry and spacecraft propulsion efforts since its founding in 1960. Located at the Redstone Arsenal near Huntsville, Alabama, the Center has a legacy of success stretching back to the Saturn rockets that carried the Apollo astronauts into space. Even before Marshall was established, Redstone was the site of significant advances in American rocketry under the guidance of famous rocket engineer Werner Von Braun; these included the Juno I rocket that successfully carried the United States’ first satellite, Explorer 1, into orbit in 1958. And from the first orbital test flight of the Space Shuttle Columbia through the final flights of the shuttle program this year, these vehicles have been enabled by the solid rocket boosters, external tank, and orbiter main engines created at Marshall.\n                      Today, Marshall continues to host innovation in rocket and spacecraft propulsion at state-of-the-art facilities such as the Propulsion Research Laboratory. Like many of its past successes, some of the Center’s current advancements are being made with the help of private industry partners. The efforts have led not only to new propulsion technologies, but to terrestrial benefits in a seemingly unrelated field—in this case, firefighting. \n                      Partnership\n                      Orbital Technologies Corporation (ORBITEC) of Madison, Wisconsin has been a longtime NASA partner, working with the Agency on numerous projects—many through the Small Business Innovation Research (SBIR) program—on a range of space exploration needs, from growing crops in space (Spinoff 2010) to advancing rocket engines. \n                      Through the SBIR program, ORBITEC has collaborated with several NASA Centers, including Marshall, to develop products such as a cool-wall vortex combustion chamber that represents a new way in rocket engine design. By feeding liquid or gas oxidizer into the combustion chamber in a manner that generates a swirling vortex flow, the design confines the mixing and burning of the propellant to the core of the chamber, keeping the walls free from volatile thermal stresses. This process increases the durability and lifespan of the engine while allowing for smaller, cost-effective, and even reusable engine designs. Through further SBIR contracts with Marshall, ORBITEC applied this innovation to an advanced vortex hybrid rocket engine that combines solid and liquid fuel to power a low-cost, highly reliable, and versatile propulsion option. The company is planning an initial test flight of the engine on a commercial rocket system for 2011. \n                      Rory Groonwald, chief engineer for ORBITEC subsidiary HMA Fire, saw potential in much of ORBITEC’s propulsion technologies beyond space exploration. Through extensive work with the U.S. Air Force Fire Rescue Research Group to develop means for more effectively extinguishing hydrocarbon-based fuel fires, HMA developed fire suppression systems that utilized ultra-high pressure (UHP) for firefighting. Groonwald was exploring ways to improve the efficiency of fire suppression systems by reducing the time and amount of water needed to extinguish a fire. \n                      “We were trying to make something more effective and safer for firefighters to use,” Groonwald says. \n                      The idea of management of high pressure flows, like ORBITEC does with rocket engine design, repeatedly came to mind. Working with its partners, HMA incorporated elements derived from ORBITEC’s propulsion work into its design for fire suppression, and the improvements significantly enhanced the performance of HMA’s UHP systems. For example, the company studied how to better manage the flow of a liquid to create an energetic blanket of fine water droplets. Through iterative design and testing, they optimized a method for providing a continuous and effective stream that uses much less suppressant. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s Hydrus systems provide a versatile range of firefighting solutions, including the skid-mounted mobile unit seen here, which can be loaded onto a variety of vehicles.\n                        \n                      \n                      HMA’s propulsion-inspired design is only one of the benefits the company’s UHP suppression systems provide to firefighters. The systems introduce an approach to fire suppression that is complementary to—and in a number of cases superior to—traditional firefighting methods.\n                      “The fire industry still has a mentality of ‘surround and drown’—the more water you put around a fire, the faster the fire will go out,” Groonwald says. “But that is not necessarily true.”\n                      One series of tests using empty houses at Vandenberg Air Force Base compared an HMA system with a 20-gallon-per-minute, 1,400 pound-per-square-inch (psi) discharge capability (at the pump) versus a standard 100-gallon-per-minute, 125 psi standard hand line—the kind that typically takes a few firemen to control. The standard line extinguished a set fire in a living room in 1 minute and 45 seconds using 220 gallons of water. The HMA system extinguished an identical fire in 17.3 seconds using 13.6 gallons—with a hose requiring only one person to manage.\n                      “[The HMA system] sucked the life out of the fire and did it faster than anything I’ve ever seen before,” says Devin Misiewicz, captain of the Vandenberg Air Force Base Fire Department. \n                      The key to the HMA system is the pressure of its discharge, which results in smaller droplets dispersed on the fire. The smaller droplets create a greater total surface area contacting the flames—four times the total surface area of the larger droplets from standard, low pressure systems. In addition to helping rapidly extinguish a fire, HMA’s UHP approach also quickly reduces the temperature around a blaze—in the case of the Vandenberg test from 1,400 °F to below 250 °F within 60 seconds, about 2 minutes and 30 seconds faster than the standard equipment—and results in less smoke. \n                      “What this does is create a safer environment for the firefighters to conduct an offensive suppression attack on the fire,” says Groonwald. Using less water also reduces one of the major sources \n                        of damage from a fire situation: the water itself. \n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s fire suppression technology is ideal for a host of firefighting applications, including combating wildfires in areas unreachable by standard fire trucks. Here, HMA’s L3 (light, lean, and lethal) vehicle demonstrates these capabilities. \n                        \n                      \n                      HMA’s Hydrus systems are commercially available in a range of platforms. The T4 and T6 First Responder Emergency Systems incorporate the system into easily maneuverable, all-terrain vehicles. Along with the company’s Proteus Series Brush Trucks and skid-mounted mobile units that can be loaded onto any number of vehicles, HMA’s systems provide a quick-response firefighting tool for a range of fire situations. Carrying their own water sources, these systems are ideal for fighting wildfires in areas unreachable by standard fire trucks. The systems’ high pressure discharge can also penetrate 7 inches into the ground if desired, cooling lingering embers and heat sources that can reignite a wildland-type fire. The UHP systems are also highly effective against hydrocarbon fuel-based car fires and have been repeatedly proven to extinguish fully engulfed cars in 9 seconds.\n                      While Groonwald says that HMA’s systems are not intended to replace standard firefighting technology in all cases, they can be installed on fire trucks as a first attack tool complementing traditional low pressure, high volume systems. \n                      “Our systems become a force multiplier,” says Groonwald. “You can do more safely with the same amount of people.” \n                      Government partnerships like those between HMA and ORBITEC, NASA, and the Air Force have supported the research and development leading to the creation of these game-changing firefighting tools, says Marty Gustafson, ORBITEC engineer and applications research manager.\n                      “This is where the government-industry partnerships make a difference,” she says. “They allow you to prove out a technology in a way that gives you instant credibility.” \n                      The experts are buying in: The U.S. military employs 4 UHP units at the forward operating base near Kabul in Afghanistan to help combat fuel fires and firebomb attacks. The Navy utilizes the systems in the Middle East, and 12 Air Force bases in the United States employ the technology. Alaska is also examining the systems for remote towns, where they can be used by operators without firefighting training, and the Mojave Air and Space Port in California features the technology on a specially designed rapid response rescue truck. Plus, municipal fire departments are interested in the technology’s NASA-enhanced capabilities, meaning cities and towns nationwide could soon benefit from another example of space exploration technology improving daily life.\n                      Hydrus™, T4™, T6™, and Proteus™ are trademarks of Orbital Technologies Corporation.\n                      \n                    \n                  \n                \n              \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through NASA’s SBIR program, Orbital Technologies Corporation, or ORBITEC, developed vortex combustion technology representing a new approach to rocket engine design. ORBITEC’s NASA work led to advancements in fire suppression systems by the company’s subsidiary, HMA Fire. \n                        \n                      \n                      Much deserved attention is given to the feats of innovation that allow humans to live in space and robotic explorers to beam never-before-seen images back to Earth. In the background of these accomplishments is a technology that makes it all possible—the rockets that propel NASA’s space exploration efforts skyward. \n                      Marshall Space Flight Center has been at the heart of the Agency’s rocketry and spacecraft propulsion efforts since its founding in 1960. Located at the Redstone Arsenal near Huntsville, Alabama, the Center has a legacy of success stretching back to the Saturn rockets that carried the Apollo astronauts into space. Even before Marshall was established, Redstone was the site of significant advances in American rocketry under the guidance of famous rocket engineer Werner Von Braun; these included the Juno I rocket that successfully carried the United States’ first satellite, Explorer 1, into orbit in 1958. And from the first orbital test flight of the Space Shuttle Columbia through the final flights of the shuttle program this year, these vehicles have been enabled by the solid rocket boosters, external tank, and orbiter main engines created at Marshall.\n                      Today, Marshall continues to host innovation in rocket and spacecraft propulsion at state-of-the-art facilities such as the Propulsion Research Laboratory. Like many of its past successes, some of the Center’s current advancements are being made with the help of private industry partners. The efforts have led not only to new propulsion technologies, but to terrestrial benefits in a seemingly unrelated field—in this case, firefighting. \n                      Partnership\n                      Orbital Technologies Corporation (ORBITEC) of Madison, Wisconsin has been a longtime NASA partner, working with the Agency on numerous projects—many through the Small Business Innovation Research (SBIR) program—on a range of space exploration needs, from growing crops in space (Spinoff 2010) to advancing rocket engines. \n                      Through the SBIR program, ORBITEC has collaborated with several NASA Centers, including Marshall, to develop products such as a cool-wall vortex combustion chamber that represents a new way in rocket engine design. By feeding liquid or gas oxidizer into the combustion chamber in a manner that generates a swirling vortex flow, the design confines the mixing and burning of the propellant to the core of the chamber, keeping the walls free from volatile thermal stresses. This process increases the durability and lifespan of the engine while allowing for smaller, cost-effective, and even reusable engine designs. Through further SBIR contracts with Marshall, ORBITEC applied this innovation to an advanced vortex hybrid rocket engine that combines solid and liquid fuel to power a low-cost, highly reliable, and versatile propulsion option. The company is planning an initial test flight of the engine on a commercial rocket system for 2011. \n                      Rory Groonwald, chief engineer for ORBITEC subsidiary HMA Fire, saw potential in much of ORBITEC’s propulsion technologies beyond space exploration. Through extensive work with the U.S. Air Force Fire Rescue Research Group to develop means for more effectively extinguishing hydrocarbon-based fuel fires, HMA developed fire suppression systems that utilized ultra-high pressure (UHP) for firefighting. Groonwald was exploring ways to improve the efficiency of fire suppression systems by reducing the time and amount of water needed to extinguish a fire. \n                      “We were trying to make something more effective and safer for firefighters to use,” Groonwald says. \n                      The idea of management of high pressure flows, like ORBITEC does with rocket engine design, repeatedly came to mind. Working with its partners, HMA incorporated elements derived from ORBITEC’s propulsion work into its design for fire suppression, and the improvements significantly enhanced the performance of HMA’s UHP systems. For example, the company studied how to better manage the flow of a liquid to create an energetic blanket of fine water droplets. Through iterative design and testing, they optimized a method for providing a continuous and effective stream that uses much less suppressant. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s Hydrus systems provide a versatile range of firefighting solutions, including the skid-mounted mobile unit seen here, which can be loaded onto a variety of vehicles.\n                        \n                      \n                      HMA’s propulsion-inspired design is only one of the benefits the company’s UHP suppression systems provide to firefighters. The systems introduce an approach to fire suppression that is complementary to—and in a number of cases superior to—traditional firefighting methods.\n                      “The fire industry still has a mentality of ‘surround and drown’—the more water you put around a fire, the faster the fire will go out,” Groonwald says. “But that is not necessarily true.”\n                      One series of tests using empty houses at Vandenberg Air Force Base compared an HMA system with a 20-gallon-per-minute, 1,400 pound-per-square-inch (psi) discharge capability (at the pump) versus a standard 100-gallon-per-minute, 125 psi standard hand line—the kind that typically takes a few firemen to control. The standard line extinguished a set fire in a living room in 1 minute and 45 seconds using 220 gallons of water. The HMA system extinguished an identical fire in 17.3 seconds using 13.6 gallons—with a hose requiring only one person to manage.\n                      “[The HMA system] sucked the life out of the fire and did it faster than anything I’ve ever seen before,” says Devin Misiewicz, captain of the Vandenberg Air Force Base Fire Department. \n                      The key to the HMA system is the pressure of its discharge, which results in smaller droplets dispersed on the fire. The smaller droplets create a greater total surface area contacting the flames—four times the total surface area of the larger droplets from standard, low pressure systems. In addition to helping rapidly extinguish a fire, HMA’s UHP approach also quickly reduces the temperature around a blaze—in the case of the Vandenberg test from 1,400 °F to below 250 °F within 60 seconds, about 2 minutes and 30 seconds faster than the standard equipment—and results in less smoke. \n                      “What this does is create a safer environment for the firefighters to conduct an offensive suppression attack on the fire,” says Groonwald. Using less water also reduces one of the major sources \n                        of damage from a fire situation: the water itself. \n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s fire suppression technology is ideal for a host of firefighting applications, including combating wildfires in areas unreachable by standard fire trucks. Here, HMA’s L3 (light, lean, and lethal) vehicle demonstrates these capabilities. \n                        \n                      \n                      HMA’s Hydrus systems are commercially available in a range of platforms. The T4 and T6 First Responder Emergency Systems incorporate the system into easily maneuverable, all-terrain vehicles. Along with the company’s Proteus Series Brush Trucks and skid-mounted mobile units that can be loaded onto any number of vehicles, HMA’s systems provide a quick-response firefighting tool for a range of fire situations. Carrying their own water sources, these systems are ideal for fighting wildfires in areas unreachable by standard fire trucks. The systems’ high pressure discharge can also penetrate 7 inches into the ground if desired, cooling lingering embers and heat sources that can reignite a wildland-type fire. The UHP systems are also highly effective against hydrocarbon fuel-based car fires and have been repeatedly proven to extinguish fully engulfed cars in 9 seconds.\n                      While Groonwald says that HMA’s systems are not intended to replace standard firefighting technology in all cases, they can be installed on fire trucks as a first attack tool complementing traditional low pressure, high volume systems. \n                      “Our systems become a force multiplier,” says Groonwald. “You can do more safely with the same amount of people.” \n                      Government partnerships like those between HMA and ORBITEC, NASA, and the Air Force have supported the research and development leading to the creation of these game-changing firefighting tools, says Marty Gustafson, ORBITEC engineer and applications research manager.\n                      “This is where the government-industry partnerships make a difference,” she says. “They allow you to prove out a technology in a way that gives you instant credibility.” \n                      The experts are buying in: The U.S. military employs 4 UHP units at the forward operating base near Kabul in Afghanistan to help combat fuel fires and firebomb attacks. The Navy utilizes the systems in the Middle East, and 12 Air Force bases in the United States employ the technology. Alaska is also examining the systems for remote towns, where they can be used by operators without firefighting training, and the Mojave Air and Space Port in California features the technology on a specially designed rapid response rescue truck. Plus, municipal fire departments are interested in the technology’s NASA-enhanced capabilities, meaning cities and towns nationwide could soon benefit from another example of space exploration technology improving daily life.\n                      Hydrus™, T4™, T6™, and Proteus™ are trademarks of Orbital Technologies Corporation.\n                      \n                    \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through NASA’s SBIR program, Orbital Technologies Corporation, or ORBITEC, developed vortex combustion technology representing a new approach to rocket engine design. ORBITEC’s NASA work led to advancements in fire suppression systems by the company’s subsidiary, HMA Fire. \n                        \n                      \n                      Much deserved attention is given to the feats of innovation that allow humans to live in space and robotic explorers to beam never-before-seen images back to Earth. In the background of these accomplishments is a technology that makes it all possible—the rockets that propel NASA’s space exploration efforts skyward. \n                      Marshall Space Flight Center has been at the heart of the Agency’s rocketry and spacecraft propulsion efforts since its founding in 1960. Located at the Redstone Arsenal near Huntsville, Alabama, the Center has a legacy of success stretching back to the Saturn rockets that carried the Apollo astronauts into space. Even before Marshall was established, Redstone was the site of significant advances in American rocketry under the guidance of famous rocket engineer Werner Von Braun; these included the Juno I rocket that successfully carried the United States’ first satellite, Explorer 1, into orbit in 1958. And from the first orbital test flight of the Space Shuttle Columbia through the final flights of the shuttle program this year, these vehicles have been enabled by the solid rocket boosters, external tank, and orbiter main engines created at Marshall.\n                      Today, Marshall continues to host innovation in rocket and spacecraft propulsion at state-of-the-art facilities such as the Propulsion Research Laboratory. Like many of its past successes, some of the Center’s current advancements are being made with the help of private industry partners. The efforts have led not only to new propulsion technologies, but to terrestrial benefits in a seemingly unrelated field—in this case, firefighting. \n                      Partnership\n                      Orbital Technologies Corporation (ORBITEC) of Madison, Wisconsin has been a longtime NASA partner, working with the Agency on numerous projects—many through the Small Business Innovation Research (SBIR) program—on a range of space exploration needs, from growing crops in space (Spinoff 2010) to advancing rocket engines. \n                      Through the SBIR program, ORBITEC has collaborated with several NASA Centers, including Marshall, to develop products such as a cool-wall vortex combustion chamber that represents a new way in rocket engine design. By feeding liquid or gas oxidizer into the combustion chamber in a manner that generates a swirling vortex flow, the design confines the mixing and burning of the propellant to the core of the chamber, keeping the walls free from volatile thermal stresses. This process increases the durability and lifespan of the engine while allowing for smaller, cost-effective, and even reusable engine designs. Through further SBIR contracts with Marshall, ORBITEC applied this innovation to an advanced vortex hybrid rocket engine that combines solid and liquid fuel to power a low-cost, highly reliable, and versatile propulsion option. The company is planning an initial test flight of the engine on a commercial rocket system for 2011. \n                      Rory Groonwald, chief engineer for ORBITEC subsidiary HMA Fire, saw potential in much of ORBITEC’s propulsion technologies beyond space exploration. Through extensive work with the U.S. Air Force Fire Rescue Research Group to develop means for more effectively extinguishing hydrocarbon-based fuel fires, HMA developed fire suppression systems that utilized ultra-high pressure (UHP) for firefighting. Groonwald was exploring ways to improve the efficiency of fire suppression systems by reducing the time and amount of water needed to extinguish a fire. \n                      “We were trying to make something more effective and safer for firefighters to use,” Groonwald says. \n                      The idea of management of high pressure flows, like ORBITEC does with rocket engine design, repeatedly came to mind. Working with its partners, HMA incorporated elements derived from ORBITEC’s propulsion work into its design for fire suppression, and the improvements significantly enhanced the performance of HMA’s UHP systems. For example, the company studied how to better manage the flow of a liquid to create an energetic blanket of fine water droplets. Through iterative design and testing, they optimized a method for providing a continuous and effective stream that uses much less suppressant. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s Hydrus systems provide a versatile range of firefighting solutions, including the skid-mounted mobile unit seen here, which can be loaded onto a variety of vehicles.\n                        \n                      \n                      HMA’s propulsion-inspired design is only one of the benefits the company’s UHP suppression systems provide to firefighters. The systems introduce an approach to fire suppression that is complementary to—and in a number of cases superior to—traditional firefighting methods.\n                      “The fire industry still has a mentality of ‘surround and drown’—the more water you put around a fire, the faster the fire will go out,” Groonwald says. “But that is not necessarily true.”\n                      One series of tests using empty houses at Vandenberg Air Force Base compared an HMA system with a 20-gallon-per-minute, 1,400 pound-per-square-inch (psi) discharge capability (at the pump) versus a standard 100-gallon-per-minute, 125 psi standard hand line—the kind that typically takes a few firemen to control. The standard line extinguished a set fire in a living room in 1 minute and 45 seconds using 220 gallons of water. The HMA system extinguished an identical fire in 17.3 seconds using 13.6 gallons—with a hose requiring only one person to manage.\n                      “[The HMA system] sucked the life out of the fire and did it faster than anything I’ve ever seen before,” says Devin Misiewicz, captain of the Vandenberg Air Force Base Fire Department. \n                      The key to the HMA system is the pressure of its discharge, which results in smaller droplets dispersed on the fire. The smaller droplets create a greater total surface area contacting the flames—four times the total surface area of the larger droplets from standard, low pressure systems. In addition to helping rapidly extinguish a fire, HMA’s UHP approach also quickly reduces the temperature around a blaze—in the case of the Vandenberg test from 1,400 °F to below 250 °F within 60 seconds, about 2 minutes and 30 seconds faster than the standard equipment—and results in less smoke. \n                      “What this does is create a safer environment for the firefighters to conduct an offensive suppression attack on the fire,” says Groonwald. Using less water also reduces one of the major sources \n                        of damage from a fire situation: the water itself. \n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s fire suppression technology is ideal for a host of firefighting applications, including combating wildfires in areas unreachable by standard fire trucks. Here, HMA’s L3 (light, lean, and lethal) vehicle demonstrates these capabilities. \n                        \n                      \n                      HMA’s Hydrus systems are commercially available in a range of platforms. The T4 and T6 First Responder Emergency Systems incorporate the system into easily maneuverable, all-terrain vehicles. Along with the company’s Proteus Series Brush Trucks and skid-mounted mobile units that can be loaded onto any number of vehicles, HMA’s systems provide a quick-response firefighting tool for a range of fire situations. Carrying their own water sources, these systems are ideal for fighting wildfires in areas unreachable by standard fire trucks. The systems’ high pressure discharge can also penetrate 7 inches into the ground if desired, cooling lingering embers and heat sources that can reignite a wildland-type fire. The UHP systems are also highly effective against hydrocarbon fuel-based car fires and have been repeatedly proven to extinguish fully engulfed cars in 9 seconds.\n                      While Groonwald says that HMA’s systems are not intended to replace standard firefighting technology in all cases, they can be installed on fire trucks as a first attack tool complementing traditional low pressure, high volume systems. \n                      “Our systems become a force multiplier,” says Groonwald. “You can do more safely with the same amount of people.” \n                      Government partnerships like those between HMA and ORBITEC, NASA, and the Air Force have supported the research and development leading to the creation of these game-changing firefighting tools, says Marty Gustafson, ORBITEC engineer and applications research manager.\n                      “This is where the government-industry partnerships make a difference,” she says. “They allow you to prove out a technology in a way that gives you instant credibility.” \n                      The experts are buying in: The U.S. military employs 4 UHP units at the forward operating base near Kabul in Afghanistan to help combat fuel fires and firebomb attacks. The Navy utilizes the systems in the Middle East, and 12 Air Force bases in the United States employ the technology. Alaska is also examining the systems for remote towns, where they can be used by operators without firefighting training, and the Mojave Air and Space Port in California features the technology on a specially designed rapid response rescue truck. Plus, municipal fire departments are interested in the technology’s NASA-enhanced capabilities, meaning cities and towns nationwide could soon benefit from another example of space exploration technology improving daily life.\n                      Hydrus™, T4™, T6™, and Proteus™ are trademarks of Orbital Technologies Corporation.\n                      \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through NASA’s SBIR program, Orbital Technologies Corporation, or ORBITEC, developed vortex combustion technology representing a new approach to rocket engine design. ORBITEC’s NASA work led to advancements in fire suppression systems by the company’s subsidiary, HMA Fire. \n                        \n                      \n                      Much deserved attention is given to the feats of innovation that allow humans to live in space and robotic explorers to beam never-before-seen images back to Earth. In the background of these accomplishments is a technology that makes it all possible—the rockets that propel NASA’s space exploration efforts skyward. \n                      Marshall Space Flight Center has been at the heart of the Agency’s rocketry and spacecraft propulsion efforts since its founding in 1960. Located at the Redstone Arsenal near Huntsville, Alabama, the Center has a legacy of success stretching back to the Saturn rockets that carried the Apollo astronauts into space. Even before Marshall was established, Redstone was the site of significant advances in American rocketry under the guidance of famous rocket engineer Werner Von Braun; these included the Juno I rocket that successfully carried the United States’ first satellite, Explorer 1, into orbit in 1958. And from the first orbital test flight of the Space Shuttle Columbia through the final flights of the shuttle program this year, these vehicles have been enabled by the solid rocket boosters, external tank, and orbiter main engines created at Marshall.\n                      Today, Marshall continues to host innovation in rocket and spacecraft propulsion at state-of-the-art facilities such as the Propulsion Research Laboratory. Like many of its past successes, some of the Center’s current advancements are being made with the help of private industry partners. The efforts have led not only to new propulsion technologies, but to terrestrial benefits in a seemingly unrelated field—in this case, firefighting. \n                      Partnership\n                      Orbital Technologies Corporation (ORBITEC) of Madison, Wisconsin has been a longtime NASA partner, working with the Agency on numerous projects—many through the Small Business Innovation Research (SBIR) program—on a range of space exploration needs, from growing crops in space (Spinoff 2010) to advancing rocket engines. \n                      Through the SBIR program, ORBITEC has collaborated with several NASA Centers, including Marshall, to develop products such as a cool-wall vortex combustion chamber that represents a new way in rocket engine design. By feeding liquid or gas oxidizer into the combustion chamber in a manner that generates a swirling vortex flow, the design confines the mixing and burning of the propellant to the core of the chamber, keeping the walls free from volatile thermal stresses. This process increases the durability and lifespan of the engine while allowing for smaller, cost-effective, and even reusable engine designs. Through further SBIR contracts with Marshall, ORBITEC applied this innovation to an advanced vortex hybrid rocket engine that combines solid and liquid fuel to power a low-cost, highly reliable, and versatile propulsion option. The company is planning an initial test flight of the engine on a commercial rocket system for 2011. \n                      Rory Groonwald, chief engineer for ORBITEC subsidiary HMA Fire, saw potential in much of ORBITEC’s propulsion technologies beyond space exploration. Through extensive work with the U.S. Air Force Fire Rescue Research Group to develop means for more effectively extinguishing hydrocarbon-based fuel fires, HMA developed fire suppression systems that utilized ultra-high pressure (UHP) for firefighting. Groonwald was exploring ways to improve the efficiency of fire suppression systems by reducing the time and amount of water needed to extinguish a fire. \n                      “We were trying to make something more effective and safer for firefighters to use,” Groonwald says. \n                      The idea of management of high pressure flows, like ORBITEC does with rocket engine design, repeatedly came to mind. Working with its partners, HMA incorporated elements derived from ORBITEC’s propulsion work into its design for fire suppression, and the improvements significantly enhanced the performance of HMA’s UHP systems. For example, the company studied how to better manage the flow of a liquid to create an energetic blanket of fine water droplets. Through iterative design and testing, they optimized a method for providing a continuous and effective stream that uses much less suppressant. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s Hydrus systems provide a versatile range of firefighting solutions, including the skid-mounted mobile unit seen here, which can be loaded onto a variety of vehicles.\n                        \n                      \n                      HMA’s propulsion-inspired design is only one of the benefits the company’s UHP suppression systems provide to firefighters. The systems introduce an approach to fire suppression that is complementary to—and in a number of cases superior to—traditional firefighting methods.\n                      “The fire industry still has a mentality of ‘surround and drown’—the more water you put around a fire, the faster the fire will go out,” Groonwald says. “But that is not necessarily true.”\n                      One series of tests using empty houses at Vandenberg Air Force Base compared an HMA system with a 20-gallon-per-minute, 1,400 pound-per-square-inch (psi) discharge capability (at the pump) versus a standard 100-gallon-per-minute, 125 psi standard hand line—the kind that typically takes a few firemen to control. The standard line extinguished a set fire in a living room in 1 minute and 45 seconds using 220 gallons of water. The HMA system extinguished an identical fire in 17.3 seconds using 13.6 gallons—with a hose requiring only one person to manage.\n                      “[The HMA system] sucked the life out of the fire and did it faster than anything I’ve ever seen before,” says Devin Misiewicz, captain of the Vandenberg Air Force Base Fire Department. \n                      The key to the HMA system is the pressure of its discharge, which results in smaller droplets dispersed on the fire. The smaller droplets create a greater total surface area contacting the flames—four times the total surface area of the larger droplets from standard, low pressure systems. In addition to helping rapidly extinguish a fire, HMA’s UHP approach also quickly reduces the temperature around a blaze—in the case of the Vandenberg test from 1,400 °F to below 250 °F within 60 seconds, about 2 minutes and 30 seconds faster than the standard equipment—and results in less smoke. \n                      “What this does is create a safer environment for the firefighters to conduct an offensive suppression attack on the fire,” says Groonwald. Using less water also reduces one of the major sources \n                        of damage from a fire situation: the water itself. \n                      \n                        \n                        \n                          \n                        \n                        \n                          HMA’s fire suppression technology is ideal for a host of firefighting applications, including combating wildfires in areas unreachable by standard fire trucks. Here, HMA’s L3 (light, lean, and lethal) vehicle demonstrates these capabilities. \n                        \n                      \n                      HMA’s Hydrus systems are commercially available in a range of platforms. The T4 and T6 First Responder Emergency Systems incorporate the system into easily maneuverable, all-terrain vehicles. Along with the company’s Proteus Series Brush Trucks and skid-mounted mobile units that can be loaded onto any number of vehicles, HMA’s systems provide a quick-response firefighting tool for a range of fire situations. Carrying their own water sources, these systems are ideal for fighting wildfires in areas unreachable by standard fire trucks. The systems’ high pressure discharge can also penetrate 7 inches into the ground if desired, cooling lingering embers and heat sources that can reignite a wildland-type fire. The UHP systems are also highly effective against hydrocarbon fuel-based car fires and have been repeatedly proven to extinguish fully engulfed cars in 9 seconds.\n                      While Groonwald says that HMA’s systems are not intended to replace standard firefighting technology in all cases, they can be installed on fire trucks as a first attack tool complementing traditional low pressure, high volume systems. \n                      “Our systems become a force multiplier,” says Groonwald. “You can do more safely with the same amount of people.” \n                      Government partnerships like those between HMA and ORBITEC, NASA, and the Air Force have supported the research and development leading to the creation of these game-changing firefighting tools, says Marty Gustafson, ORBITEC engineer and applications research manager.\n                      “This is where the government-industry partnerships make a difference,” she says. “They allow you to prove out a technology in a way that gives you instant credibility.” \n                      The experts are buying in: The U.S. military employs 4 UHP units at the forward operating base near Kabul in Afghanistan to help combat fuel fires and firebomb attacks. The Navy utilizes the systems in the Middle East, and 12 Air Force bases in the United States employ the technology. Alaska is also examining the systems for remote towns, where they can be used by operators without firefighting training, and the Mojave Air and Space Port in California features the technology on a specially designed rapid response rescue truck. Plus, municipal fire departments are interested in the technology’s NASA-enhanced capabilities, meaning cities and towns nationwide could soon benefit from another example of space exploration technology improving daily life.\n                      Hydrus™, T4™, T6™, and Proteus™ are trademarks of Orbital Technologies Corporation.\n                      "},{"href":"http://spinoff.nasa.gov/Spinoff2011/ps_6.html","text":"Alloy-Enhanced Fans Maintain Fresh Air in Tunnels","image":"http://spinoff.nasa.gov/Spinoff2011/Images/PS_12_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            Jonathan Lee is one of the inventors of MSFC-398, a high-strength aluminum alloy.\n                          \n                        \n                        The Partnership for Next Generation Vehicles (PNGV) is not a NASA initiative to develop powerful new rockets and spacecraft, even though it may sound like one. PNGV was a partnership established by the Clinton administration between the Federal government and the U.S. Council for Automotive Research to develop technologies that improve fuel efficiency and reduce emissions from cars and trucks. More than 20 Federal laboratories from the Departments of Commerce, Energy, Transportation, and Defense; the Environmental Protection Agency; the National Science Foundation; and NASA were all involved in PNGV, in addition to more than 350 automotive suppliers, universities, and small businesses.\n                        In support of this tremendous effort, Jonathan Lee, a materials engineer at Marshall Space Flight Center, worked with a major automobile manufacturer in 1995 to develop a strong aluminum alloy for high temperature applications. The aim was to use the alloy for manufacturing parts for an internal combustion engine, as well as for NASA’s propulsion applications. When funding from PNGV ended, Marshall continued to support the alloy’s development with help from NASA’s Innovative Partnerships Program (now the Office of the Chief Technologist). Together with PoShou Chen, a scientist with Morgan Research Corporation, Lee invented a high-strength aluminum alloy called MSFC-398 that, when tested, was three to four times stronger than conventional aluminum alloys at high temperatures. \n                        By the late 1990s, Lee says, NASA’s scientists had successfully developed and patented this technology, which has great potential applications not for just automotive, but also for aerospace, marine, and commercial applications.\n                        Partnership\n                        After Marshall made the technology available for licensing in 2001, Bombardier Recreational Products Inc. licensed the alloy to cast parts for outboard marine engines (Spinoff 2004 and 2008). By 2005, the alloy had won Marshall’s “Invention of the Year” award, and a year later, the National Federal Laboratory Consortium recognized the alloy with an “Excellence in Technology Transfer” award. \n                        The most recent success of this technology, however, was in 2010. Twin City Fan Companies Ltd. in Minneapolis, Minnesota, licensed the alloy to make impellers (blades and hubs) for safety ventilation fans in rail and road tunnels. “We wanted a high temperature alloy that would have the strength and properties needed for safety fan impellers at very high temperatures. We found the NASA alloy, and upon further investigation, we knew that it was the right path for us,” says Dan Hartlein, executive vice president at Twin City Fan Companies Ltd.\n                        The division of Twin City Fan Companies Ltd. that is marketing the first fans made with the NASA aluminum alloy is Clarage, which is based in Pulaski, Tennessee. However, Michael Barry, president and COO of Twin City Fan Companies Ltd., finds there are broad application possibilities for all of the company’s global brands, including Twin City Fan and Blower and Aerovent. “Twin City Fan is a global American company. It gives us great pride to be able to utilize the special technology created by a technology leader like NASA,” says Barry.\n                        Benefits \n                        Twin City Fan licensed the NASA alloy with a specific application in mind: tunnel safety fans for the European market, where fans must be able to operate in 752 ˚F for two hours in order to be certified for use. The reason for the high temperature requirement is the fan must be able to operate successfully when there is a fire in a road or rail tunnel. When spinning in one direction, the fan provides clean air to the people inside; when spinning the other direction, it removes the smoke and gasses from the fire. \n                        \n                          \n                          \n                            \n                          \n                          \n                            Clarage, a division of Twin City Fan Companies Ltd., is using MSFC-398 to make the impellers of tunnel safety fans for road and \\\n                              rail tunnels. \n                          \n                        \n                        Before the NASA alloy, there were two ways to meet these temperature requirements, says Hartlein. One method was to use existing aluminum to make a bigger fan that spins more slowly. The drawback to this approach was that a bigger fan requires more space. “If we use the NASA alloy, the fan is smaller relative to the competition, and the tunnel can be smaller as well. Even if you can take a foot out of the construction of a new tunnel, there are massive potential savings,” says Hartlein. “In addition, the properties of this material allow us to run even hotter, leading to safety smoke exhaust at temperatures beyond what tunnel designers anticipated.”\n                        The other solution, Hartlein says, was to make the fan blades out of steel, but this required a specialized motor to turn and reverse the fan. “Steel weighs roughly three times more than aluminum. If it is three times as heavy on the rotating parts, the bearings are heavier, the shaft is heavier, and the motor is heavier—a lot comes with it. The motivation and opportunity for us to use aluminum, where in the past we would have had to use steel, is quite attractive to us. We can lower the cost of the overall product and provide better performance through the use of this alloy. We are just beginning to find applications that will provide value to our industry using this alloy.”\n                        “I am honored to know that my\n                          innovation has moved beyond NASA to\n                          benefit private companies and their customers\n                          in a way that can significantly improve the\n                          quality of our daily lives.”\n                          —Jonathan Lee, Marshall Space Flight Center\n                        While Twin City Fan Company has purchased the tools to produce 3 sizes of the fan, it plans to manufacture 12 different sizes in total. In 2011, Clarage sold the first of its fans made with the NASA alloy to a company testing the fans to certify them to European standards. Hartlein says he has met with a major engineering company in the United States, and the representatives are very interested in the capabilities of new fans. “We are bidding many projects now and should be shipping our first projects by the end of the year,” he says. \n                        According to Hartlein, the tunnel industry is busy and is projected to continue growing. “If you look around major metropolitan areas, there’s no place to put traffic, so it goes underground. This is driving a busy tunnel ventilation market,” he says. There are also opportunities for installing fans in existing tunnels due to stricter air quality standards. \n                        As this innovative application of NASA technology is projected to keep people safer, it is also helping the inventor of the technology answer an important question. “One of the most frequently asked question that I have encountered over the years is, ‘What does the Space Program do for me?’ Unfortunately, few people are aware of the benefits that NASA technology provides to our society,” says Lee. “I am honored to know that my innovation has moved beyond NASA to benefit private companies and their customers in a way that can significantly improve the quality of our daily lives.”\n                        \n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            Jonathan Lee is one of the inventors of MSFC-398, a high-strength aluminum alloy.\n                          \n                        \n                        The Partnership for Next Generation Vehicles (PNGV) is not a NASA initiative to develop powerful new rockets and spacecraft, even though it may sound like one. PNGV was a partnership established by the Clinton administration between the Federal government and the U.S. Council for Automotive Research to develop technologies that improve fuel efficiency and reduce emissions from cars and trucks. More than 20 Federal laboratories from the Departments of Commerce, Energy, Transportation, and Defense; the Environmental Protection Agency; the National Science Foundation; and NASA were all involved in PNGV, in addition to more than 350 automotive suppliers, universities, and small businesses.\n                        In support of this tremendous effort, Jonathan Lee, a materials engineer at Marshall Space Flight Center, worked with a major automobile manufacturer in 1995 to develop a strong aluminum alloy for high temperature applications. The aim was to use the alloy for manufacturing parts for an internal combustion engine, as well as for NASA’s propulsion applications. When funding from PNGV ended, Marshall continued to support the alloy’s development with help from NASA’s Innovative Partnerships Program (now the Office of the Chief Technologist). Together with PoShou Chen, a scientist with Morgan Research Corporation, Lee invented a high-strength aluminum alloy called MSFC-398 that, when tested, was three to four times stronger than conventional aluminum alloys at high temperatures. \n                        By the late 1990s, Lee says, NASA’s scientists had successfully developed and patented this technology, which has great potential applications not for just automotive, but also for aerospace, marine, and commercial applications.\n                        Partnership\n                        After Marshall made the technology available for licensing in 2001, Bombardier Recreational Products Inc. licensed the alloy to cast parts for outboard marine engines (Spinoff 2004 and 2008). By 2005, the alloy had won Marshall’s “Invention of the Year” award, and a year later, the National Federal Laboratory Consortium recognized the alloy with an “Excellence in Technology Transfer” award. \n                        The most recent success of this technology, however, was in 2010. Twin City Fan Companies Ltd. in Minneapolis, Minnesota, licensed the alloy to make impellers (blades and hubs) for safety ventilation fans in rail and road tunnels. “We wanted a high temperature alloy that would have the strength and properties needed for safety fan impellers at very high temperatures. We found the NASA alloy, and upon further investigation, we knew that it was the right path for us,” says Dan Hartlein, executive vice president at Twin City Fan Companies Ltd.\n                        The division of Twin City Fan Companies Ltd. that is marketing the first fans made with the NASA aluminum alloy is Clarage, which is based in Pulaski, Tennessee. However, Michael Barry, president and COO of Twin City Fan Companies Ltd., finds there are broad application possibilities for all of the company’s global brands, including Twin City Fan and Blower and Aerovent. “Twin City Fan is a global American company. It gives us great pride to be able to utilize the special technology created by a technology leader like NASA,” says Barry.\n                        Benefits \n                        Twin City Fan licensed the NASA alloy with a specific application in mind: tunnel safety fans for the European market, where fans must be able to operate in 752 ˚F for two hours in order to be certified for use. The reason for the high temperature requirement is the fan must be able to operate successfully when there is a fire in a road or rail tunnel. When spinning in one direction, the fan provides clean air to the people inside; when spinning the other direction, it removes the smoke and gasses from the fire. \n                        \n                          \n                          \n                            \n                          \n                          \n                            Clarage, a division of Twin City Fan Companies Ltd., is using MSFC-398 to make the impellers of tunnel safety fans for road and \\\n                              rail tunnels. \n                          \n                        \n                        Before the NASA alloy, there were two ways to meet these temperature requirements, says Hartlein. One method was to use existing aluminum to make a bigger fan that spins more slowly. The drawback to this approach was that a bigger fan requires more space. “If we use the NASA alloy, the fan is smaller relative to the competition, and the tunnel can be smaller as well. Even if you can take a foot out of the construction of a new tunnel, there are massive potential savings,” says Hartlein. “In addition, the properties of this material allow us to run even hotter, leading to safety smoke exhaust at temperatures beyond what tunnel designers anticipated.”\n                        The other solution, Hartlein says, was to make the fan blades out of steel, but this required a specialized motor to turn and reverse the fan. “Steel weighs roughly three times more than aluminum. If it is three times as heavy on the rotating parts, the bearings are heavier, the shaft is heavier, and the motor is heavier—a lot comes with it. The motivation and opportunity for us to use aluminum, where in the past we would have had to use steel, is quite attractive to us. We can lower the cost of the overall product and provide better performance through the use of this alloy. We are just beginning to find applications that will provide value to our industry using this alloy.”\n                        “I am honored to know that my\n                          innovation has moved beyond NASA to\n                          benefit private companies and their customers\n                          in a way that can significantly improve the\n                          quality of our daily lives.”\n                          —Jonathan Lee, Marshall Space Flight Center\n                        While Twin City Fan Company has purchased the tools to produce 3 sizes of the fan, it plans to manufacture 12 different sizes in total. In 2011, Clarage sold the first of its fans made with the NASA alloy to a company testing the fans to certify them to European standards. Hartlein says he has met with a major engineering company in the United States, and the representatives are very interested in the capabilities of new fans. “We are bidding many projects now and should be shipping our first projects by the end of the year,” he says. \n                        According to Hartlein, the tunnel industry is busy and is projected to continue growing. “If you look around major metropolitan areas, there’s no place to put traffic, so it goes underground. This is driving a busy tunnel ventilation market,” he says. There are also opportunities for installing fans in existing tunnels due to stricter air quality standards. \n                        As this innovative application of NASA technology is projected to keep people safer, it is also helping the inventor of the technology answer an important question. “One of the most frequently asked question that I have encountered over the years is, ‘What does the Space Program do for me?’ Unfortunately, few people are aware of the benefits that NASA technology provides to our society,” says Lee. “I am honored to know that my innovation has moved beyond NASA to benefit private companies and their customers in a way that can significantly improve the quality of our daily lives.”\n                        \n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            Jonathan Lee is one of the inventors of MSFC-398, a high-strength aluminum alloy.\n                          \n                        \n                        The Partnership for Next Generation Vehicles (PNGV) is not a NASA initiative to develop powerful new rockets and spacecraft, even though it may sound like one. PNGV was a partnership established by the Clinton administration between the Federal government and the U.S. Council for Automotive Research to develop technologies that improve fuel efficiency and reduce emissions from cars and trucks. More than 20 Federal laboratories from the Departments of Commerce, Energy, Transportation, and Defense; the Environmental Protection Agency; the National Science Foundation; and NASA were all involved in PNGV, in addition to more than 350 automotive suppliers, universities, and small businesses.\n                        In support of this tremendous effort, Jonathan Lee, a materials engineer at Marshall Space Flight Center, worked with a major automobile manufacturer in 1995 to develop a strong aluminum alloy for high temperature applications. The aim was to use the alloy for manufacturing parts for an internal combustion engine, as well as for NASA’s propulsion applications. When funding from PNGV ended, Marshall continued to support the alloy’s development with help from NASA’s Innovative Partnerships Program (now the Office of the Chief Technologist). Together with PoShou Chen, a scientist with Morgan Research Corporation, Lee invented a high-strength aluminum alloy called MSFC-398 that, when tested, was three to four times stronger than conventional aluminum alloys at high temperatures. \n                        By the late 1990s, Lee says, NASA’s scientists had successfully developed and patented this technology, which has great potential applications not for just automotive, but also for aerospace, marine, and commercial applications.\n                        Partnership\n                        After Marshall made the technology available for licensing in 2001, Bombardier Recreational Products Inc. licensed the alloy to cast parts for outboard marine engines (Spinoff 2004 and 2008). By 2005, the alloy had won Marshall’s “Invention of the Year” award, and a year later, the National Federal Laboratory Consortium recognized the alloy with an “Excellence in Technology Transfer” award. \n                        The most recent success of this technology, however, was in 2010. Twin City Fan Companies Ltd. in Minneapolis, Minnesota, licensed the alloy to make impellers (blades and hubs) for safety ventilation fans in rail and road tunnels. “We wanted a high temperature alloy that would have the strength and properties needed for safety fan impellers at very high temperatures. We found the NASA alloy, and upon further investigation, we knew that it was the right path for us,” says Dan Hartlein, executive vice president at Twin City Fan Companies Ltd.\n                        The division of Twin City Fan Companies Ltd. that is marketing the first fans made with the NASA aluminum alloy is Clarage, which is based in Pulaski, Tennessee. However, Michael Barry, president and COO of Twin City Fan Companies Ltd., finds there are broad application possibilities for all of the company’s global brands, including Twin City Fan and Blower and Aerovent. “Twin City Fan is a global American company. It gives us great pride to be able to utilize the special technology created by a technology leader like NASA,” says Barry.\n                        Benefits \n                        Twin City Fan licensed the NASA alloy with a specific application in mind: tunnel safety fans for the European market, where fans must be able to operate in 752 ˚F for two hours in order to be certified for use. The reason for the high temperature requirement is the fan must be able to operate successfully when there is a fire in a road or rail tunnel. When spinning in one direction, the fan provides clean air to the people inside; when spinning the other direction, it removes the smoke and gasses from the fire. \n                        \n                          \n                          \n                            \n                          \n                          \n                            Clarage, a division of Twin City Fan Companies Ltd., is using MSFC-398 to make the impellers of tunnel safety fans for road and \\\n                              rail tunnels. \n                          \n                        \n                        Before the NASA alloy, there were two ways to meet these temperature requirements, says Hartlein. One method was to use existing aluminum to make a bigger fan that spins more slowly. The drawback to this approach was that a bigger fan requires more space. “If we use the NASA alloy, the fan is smaller relative to the competition, and the tunnel can be smaller as well. Even if you can take a foot out of the construction of a new tunnel, there are massive potential savings,” says Hartlein. “In addition, the properties of this material allow us to run even hotter, leading to safety smoke exhaust at temperatures beyond what tunnel designers anticipated.”\n                        The other solution, Hartlein says, was to make the fan blades out of steel, but this required a specialized motor to turn and reverse the fan. “Steel weighs roughly three times more than aluminum. If it is three times as heavy on the rotating parts, the bearings are heavier, the shaft is heavier, and the motor is heavier—a lot comes with it. The motivation and opportunity for us to use aluminum, where in the past we would have had to use steel, is quite attractive to us. We can lower the cost of the overall product and provide better performance through the use of this alloy. We are just beginning to find applications that will provide value to our industry using this alloy.”\n                        “I am honored to know that my\n                          innovation has moved beyond NASA to\n                          benefit private companies and their customers\n                          in a way that can significantly improve the\n                          quality of our daily lives.”\n                          —Jonathan Lee, Marshall Space Flight Center\n                        While Twin City Fan Company has purchased the tools to produce 3 sizes of the fan, it plans to manufacture 12 different sizes in total. In 2011, Clarage sold the first of its fans made with the NASA alloy to a company testing the fans to certify them to European standards. Hartlein says he has met with a major engineering company in the United States, and the representatives are very interested in the capabilities of new fans. “We are bidding many projects now and should be shipping our first projects by the end of the year,” he says. \n                        According to Hartlein, the tunnel industry is busy and is projected to continue growing. “If you look around major metropolitan areas, there’s no place to put traffic, so it goes underground. This is driving a busy tunnel ventilation market,” he says. There are also opportunities for installing fans in existing tunnels due to stricter air quality standards. \n                        As this innovative application of NASA technology is projected to keep people safer, it is also helping the inventor of the technology answer an important question. “One of the most frequently asked question that I have encountered over the years is, ‘What does the Space Program do for me?’ Unfortunately, few people are aware of the benefits that NASA technology provides to our society,” says Lee. “I am honored to know that my innovation has moved beyond NASA to benefit private companies and their customers in a way that can significantly improve the quality of our daily lives.”\n                        \n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            Jonathan Lee is one of the inventors of MSFC-398, a high-strength aluminum alloy.\n                          \n                        \n                        The Partnership for Next Generation Vehicles (PNGV) is not a NASA initiative to develop powerful new rockets and spacecraft, even though it may sound like one. PNGV was a partnership established by the Clinton administration between the Federal government and the U.S. Council for Automotive Research to develop technologies that improve fuel efficiency and reduce emissions from cars and trucks. More than 20 Federal laboratories from the Departments of Commerce, Energy, Transportation, and Defense; the Environmental Protection Agency; the National Science Foundation; and NASA were all involved in PNGV, in addition to more than 350 automotive suppliers, universities, and small businesses.\n                        In support of this tremendous effort, Jonathan Lee, a materials engineer at Marshall Space Flight Center, worked with a major automobile manufacturer in 1995 to develop a strong aluminum alloy for high temperature applications. The aim was to use the alloy for manufacturing parts for an internal combustion engine, as well as for NASA’s propulsion applications. When funding from PNGV ended, Marshall continued to support the alloy’s development with help from NASA’s Innovative Partnerships Program (now the Office of the Chief Technologist). Together with PoShou Chen, a scientist with Morgan Research Corporation, Lee invented a high-strength aluminum alloy called MSFC-398 that, when tested, was three to four times stronger than conventional aluminum alloys at high temperatures. \n                        By the late 1990s, Lee says, NASA’s scientists had successfully developed and patented this technology, which has great potential applications not for just automotive, but also for aerospace, marine, and commercial applications.\n                        Partnership\n                        After Marshall made the technology available for licensing in 2001, Bombardier Recreational Products Inc. licensed the alloy to cast parts for outboard marine engines (Spinoff 2004 and 2008). By 2005, the alloy had won Marshall’s “Invention of the Year” award, and a year later, the National Federal Laboratory Consortium recognized the alloy with an “Excellence in Technology Transfer” award. \n                        The most recent success of this technology, however, was in 2010. Twin City Fan Companies Ltd. in Minneapolis, Minnesota, licensed the alloy to make impellers (blades and hubs) for safety ventilation fans in rail and road tunnels. “We wanted a high temperature alloy that would have the strength and properties needed for safety fan impellers at very high temperatures. We found the NASA alloy, and upon further investigation, we knew that it was the right path for us,” says Dan Hartlein, executive vice president at Twin City Fan Companies Ltd.\n                        The division of Twin City Fan Companies Ltd. that is marketing the first fans made with the NASA aluminum alloy is Clarage, which is based in Pulaski, Tennessee. However, Michael Barry, president and COO of Twin City Fan Companies Ltd., finds there are broad application possibilities for all of the company’s global brands, including Twin City Fan and Blower and Aerovent. “Twin City Fan is a global American company. It gives us great pride to be able to utilize the special technology created by a technology leader like NASA,” says Barry.\n                        Benefits \n                        Twin City Fan licensed the NASA alloy with a specific application in mind: tunnel safety fans for the European market, where fans must be able to operate in 752 ˚F for two hours in order to be certified for use. The reason for the high temperature requirement is the fan must be able to operate successfully when there is a fire in a road or rail tunnel. When spinning in one direction, the fan provides clean air to the people inside; when spinning the other direction, it removes the smoke and gasses from the fire. \n                        \n                          \n                          \n                            \n                          \n                          \n                            Clarage, a division of Twin City Fan Companies Ltd., is using MSFC-398 to make the impellers of tunnel safety fans for road and \\\n                              rail tunnels. \n                          \n                        \n                        Before the NASA alloy, there were two ways to meet these temperature requirements, says Hartlein. One method was to use existing aluminum to make a bigger fan that spins more slowly. The drawback to this approach was that a bigger fan requires more space. “If we use the NASA alloy, the fan is smaller relative to the competition, and the tunnel can be smaller as well. Even if you can take a foot out of the construction of a new tunnel, there are massive potential savings,” says Hartlein. “In addition, the properties of this material allow us to run even hotter, leading to safety smoke exhaust at temperatures beyond what tunnel designers anticipated.”\n                        The other solution, Hartlein says, was to make the fan blades out of steel, but this required a specialized motor to turn and reverse the fan. “Steel weighs roughly three times more than aluminum. If it is three times as heavy on the rotating parts, the bearings are heavier, the shaft is heavier, and the motor is heavier—a lot comes with it. The motivation and opportunity for us to use aluminum, where in the past we would have had to use steel, is quite attractive to us. We can lower the cost of the overall product and provide better performance through the use of this alloy. We are just beginning to find applications that will provide value to our industry using this alloy.”\n                        “I am honored to know that my\n                          innovation has moved beyond NASA to\n                          benefit private companies and their customers\n                          in a way that can significantly improve the\n                          quality of our daily lives.”\n                          —Jonathan Lee, Marshall Space Flight Center\n                        While Twin City Fan Company has purchased the tools to produce 3 sizes of the fan, it plans to manufacture 12 different sizes in total. In 2011, Clarage sold the first of its fans made with the NASA alloy to a company testing the fans to certify them to European standards. Hartlein says he has met with a major engineering company in the United States, and the representatives are very interested in the capabilities of new fans. “We are bidding many projects now and should be shipping our first projects by the end of the year,” he says. \n                        According to Hartlein, the tunnel industry is busy and is projected to continue growing. “If you look around major metropolitan areas, there’s no place to put traffic, so it goes underground. This is driving a busy tunnel ventilation market,” he says. There are also opportunities for installing fans in existing tunnels due to stricter air quality standards. \n                        As this innovative application of NASA technology is projected to keep people safer, it is also helping the inventor of the technology answer an important question. “One of the most frequently asked question that I have encountered over the years is, ‘What does the Space Program do for me?’ Unfortunately, few people are aware of the benefits that NASA technology provides to our society,” says Lee. “I am honored to know that my innovation has moved beyond NASA to benefit private companies and their customers in a way that can significantly improve the quality of our daily lives.”\n                        \n                      \n                    \n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  \n                    \n                      \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            Jonathan Lee is one of the inventors of MSFC-398, a high-strength aluminum alloy.\n                          \n                        \n                        The Partnership for Next Generation Vehicles (PNGV) is not a NASA initiative to develop powerful new rockets and spacecraft, even though it may sound like one. PNGV was a partnership established by the Clinton administration between the Federal government and the U.S. Council for Automotive Research to develop technologies that improve fuel efficiency and reduce emissions from cars and trucks. More than 20 Federal laboratories from the Departments of Commerce, Energy, Transportation, and Defense; the Environmental Protection Agency; the National Science Foundation; and NASA were all involved in PNGV, in addition to more than 350 automotive suppliers, universities, and small businesses.\n                        In support of this tremendous effort, Jonathan Lee, a materials engineer at Marshall Space Flight Center, worked with a major automobile manufacturer in 1995 to develop a strong aluminum alloy for high temperature applications. The aim was to use the alloy for manufacturing parts for an internal combustion engine, as well as for NASA’s propulsion applications. When funding from PNGV ended, Marshall continued to support the alloy’s development with help from NASA’s Innovative Partnerships Program (now the Office of the Chief Technologist). Together with PoShou Chen, a scientist with Morgan Research Corporation, Lee invented a high-strength aluminum alloy called MSFC-398 that, when tested, was three to four times stronger than conventional aluminum alloys at high temperatures. \n                        By the late 1990s, Lee says, NASA’s scientists had successfully developed and patented this technology, which has great potential applications not for just automotive, but also for aerospace, marine, and commercial applications.\n                        Partnership\n                        After Marshall made the technology available for licensing in 2001, Bombardier Recreational Products Inc. licensed the alloy to cast parts for outboard marine engines (Spinoff 2004 and 2008). By 2005, the alloy had won Marshall’s “Invention of the Year” award, and a year later, the National Federal Laboratory Consortium recognized the alloy with an “Excellence in Technology Transfer” award. \n                        The most recent success of this technology, however, was in 2010. Twin City Fan Companies Ltd. in Minneapolis, Minnesota, licensed the alloy to make impellers (blades and hubs) for safety ventilation fans in rail and road tunnels. “We wanted a high temperature alloy that would have the strength and properties needed for safety fan impellers at very high temperatures. We found the NASA alloy, and upon further investigation, we knew that it was the right path for us,” says Dan Hartlein, executive vice president at Twin City Fan Companies Ltd.\n                        The division of Twin City Fan Companies Ltd. that is marketing the first fans made with the NASA aluminum alloy is Clarage, which is based in Pulaski, Tennessee. However, Michael Barry, president and COO of Twin City Fan Companies Ltd., finds there are broad application possibilities for all of the company’s global brands, including Twin City Fan and Blower and Aerovent. “Twin City Fan is a global American company. It gives us great pride to be able to utilize the special technology created by a technology leader like NASA,” says Barry.\n                        Benefits \n                        Twin City Fan licensed the NASA alloy with a specific application in mind: tunnel safety fans for the European market, where fans must be able to operate in 752 ˚F for two hours in order to be certified for use. The reason for the high temperature requirement is the fan must be able to operate successfully when there is a fire in a road or rail tunnel. When spinning in one direction, the fan provides clean air to the people inside; when spinning the other direction, it removes the smoke and gasses from the fire. \n                        \n                          \n                          \n                            \n                          \n                          \n                            Clarage, a division of Twin City Fan Companies Ltd., is using MSFC-398 to make the impellers of tunnel safety fans for road and \\\n                              rail tunnels. \n                          \n                        \n                        Before the NASA alloy, there were two ways to meet these temperature requirements, says Hartlein. One method was to use existing aluminum to make a bigger fan that spins more slowly. The drawback to this approach was that a bigger fan requires more space. “If we use the NASA alloy, the fan is smaller relative to the competition, and the tunnel can be smaller as well. Even if you can take a foot out of the construction of a new tunnel, there are massive potential savings,” says Hartlein. “In addition, the properties of this material allow us to run even hotter, leading to safety smoke exhaust at temperatures beyond what tunnel designers anticipated.”\n                        The other solution, Hartlein says, was to make the fan blades out of steel, but this required a specialized motor to turn and reverse the fan. “Steel weighs roughly three times more than aluminum. If it is three times as heavy on the rotating parts, the bearings are heavier, the shaft is heavier, and the motor is heavier—a lot comes with it. The motivation and opportunity for us to use aluminum, where in the past we would have had to use steel, is quite attractive to us. We can lower the cost of the overall product and provide better performance through the use of this alloy. We are just beginning to find applications that will provide value to our industry using this alloy.”\n                        “I am honored to know that my\n                          innovation has moved beyond NASA to\n                          benefit private companies and their customers\n                          in a way that can significantly improve the\n                          quality of our daily lives.”\n                          —Jonathan Lee, Marshall Space Flight Center\n                        While Twin City Fan Company has purchased the tools to produce 3 sizes of the fan, it plans to manufacture 12 different sizes in total. In 2011, Clarage sold the first of its fans made with the NASA alloy to a company testing the fans to certify them to European standards. Hartlein says he has met with a major engineering company in the United States, and the representatives are very interested in the capabilities of new fans. “We are bidding many projects now and should be shipping our first projects by the end of the year,” he says. \n                        According to Hartlein, the tunnel industry is busy and is projected to continue growing. “If you look around major metropolitan areas, there’s no place to put traffic, so it goes underground. This is driving a busy tunnel ventilation market,” he says. There are also opportunities for installing fans in existing tunnels due to stricter air quality standards. \n                        As this innovative application of NASA technology is projected to keep people safer, it is also helping the inventor of the technology answer an important question. “One of the most frequently asked question that I have encountered over the years is, ‘What does the Space Program do for me?’ Unfortunately, few people are aware of the benefits that NASA technology provides to our society,” says Lee. “I am honored to know that my innovation has moved beyond NASA to benefit private companies and their customers in a way that can significantly improve the quality of our daily lives.”\n                        \n                      \n                    \n                  \n                \n              \n            \n            \n              \n                \n                  \n                    \n                      \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            Jonathan Lee is one of the inventors of MSFC-398, a high-strength aluminum alloy.\n                          \n                        \n                        The Partnership for Next Generation Vehicles (PNGV) is not a NASA initiative to develop powerful new rockets and spacecraft, even though it may sound like one. PNGV was a partnership established by the Clinton administration between the Federal government and the U.S. Council for Automotive Research to develop technologies that improve fuel efficiency and reduce emissions from cars and trucks. More than 20 Federal laboratories from the Departments of Commerce, Energy, Transportation, and Defense; the Environmental Protection Agency; the National Science Foundation; and NASA were all involved in PNGV, in addition to more than 350 automotive suppliers, universities, and small businesses.\n                        In support of this tremendous effort, Jonathan Lee, a materials engineer at Marshall Space Flight Center, worked with a major automobile manufacturer in 1995 to develop a strong aluminum alloy for high temperature applications. The aim was to use the alloy for manufacturing parts for an internal combustion engine, as well as for NASA’s propulsion applications. When funding from PNGV ended, Marshall continued to support the alloy’s development with help from NASA’s Innovative Partnerships Program (now the Office of the Chief Technologist). Together with PoShou Chen, a scientist with Morgan Research Corporation, Lee invented a high-strength aluminum alloy called MSFC-398 that, when tested, was three to four times stronger than conventional aluminum alloys at high temperatures. \n                        By the late 1990s, Lee says, NASA’s scientists had successfully developed and patented this technology, which has great potential applications not for just automotive, but also for aerospace, marine, and commercial applications.\n                        Partnership\n                        After Marshall made the technology available for licensing in 2001, Bombardier Recreational Products Inc. licensed the alloy to cast parts for outboard marine engines (Spinoff 2004 and 2008). By 2005, the alloy had won Marshall’s “Invention of the Year” award, and a year later, the National Federal Laboratory Consortium recognized the alloy with an “Excellence in Technology Transfer” award. \n                        The most recent success of this technology, however, was in 2010. Twin City Fan Companies Ltd. in Minneapolis, Minnesota, licensed the alloy to make impellers (blades and hubs) for safety ventilation fans in rail and road tunnels. “We wanted a high temperature alloy that would have the strength and properties needed for safety fan impellers at very high temperatures. We found the NASA alloy, and upon further investigation, we knew that it was the right path for us,” says Dan Hartlein, executive vice president at Twin City Fan Companies Ltd.\n                        The division of Twin City Fan Companies Ltd. that is marketing the first fans made with the NASA aluminum alloy is Clarage, which is based in Pulaski, Tennessee. However, Michael Barry, president and COO of Twin City Fan Companies Ltd., finds there are broad application possibilities for all of the company’s global brands, including Twin City Fan and Blower and Aerovent. “Twin City Fan is a global American company. It gives us great pride to be able to utilize the special technology created by a technology leader like NASA,” says Barry.\n                        Benefits \n                        Twin City Fan licensed the NASA alloy with a specific application in mind: tunnel safety fans for the European market, where fans must be able to operate in 752 ˚F for two hours in order to be certified for use. The reason for the high temperature requirement is the fan must be able to operate successfully when there is a fire in a road or rail tunnel. When spinning in one direction, the fan provides clean air to the people inside; when spinning the other direction, it removes the smoke and gasses from the fire. \n                        \n                          \n                          \n                            \n                          \n                          \n                            Clarage, a division of Twin City Fan Companies Ltd., is using MSFC-398 to make the impellers of tunnel safety fans for road and \\\n                              rail tunnels. \n                          \n                        \n                        Before the NASA alloy, there were two ways to meet these temperature requirements, says Hartlein. One method was to use existing aluminum to make a bigger fan that spins more slowly. The drawback to this approach was that a bigger fan requires more space. “If we use the NASA alloy, the fan is smaller relative to the competition, and the tunnel can be smaller as well. Even if you can take a foot out of the construction of a new tunnel, there are massive potential savings,” says Hartlein. “In addition, the properties of this material allow us to run even hotter, leading to safety smoke exhaust at temperatures beyond what tunnel designers anticipated.”\n                        The other solution, Hartlein says, was to make the fan blades out of steel, but this required a specialized motor to turn and reverse the fan. “Steel weighs roughly three times more than aluminum. If it is three times as heavy on the rotating parts, the bearings are heavier, the shaft is heavier, and the motor is heavier—a lot comes with it. The motivation and opportunity for us to use aluminum, where in the past we would have had to use steel, is quite attractive to us. We can lower the cost of the overall product and provide better performance through the use of this alloy. We are just beginning to find applications that will provide value to our industry using this alloy.”\n                        “I am honored to know that my\n                          innovation has moved beyond NASA to\n                          benefit private companies and their customers\n                          in a way that can significantly improve the\n                          quality of our daily lives.”\n                          —Jonathan Lee, Marshall Space Flight Center\n                        While Twin City Fan Company has purchased the tools to produce 3 sizes of the fan, it plans to manufacture 12 different sizes in total. In 2011, Clarage sold the first of its fans made with the NASA alloy to a company testing the fans to certify them to European standards. Hartlein says he has met with a major engineering company in the United States, and the representatives are very interested in the capabilities of new fans. “We are bidding many projects now and should be shipping our first projects by the end of the year,” he says. \n                        According to Hartlein, the tunnel industry is busy and is projected to continue growing. “If you look around major metropolitan areas, there’s no place to put traffic, so it goes underground. This is driving a busy tunnel ventilation market,” he says. There are also opportunities for installing fans in existing tunnels due to stricter air quality standards. \n                        As this innovative application of NASA technology is projected to keep people safer, it is also helping the inventor of the technology answer an important question. “One of the most frequently asked question that I have encountered over the years is, ‘What does the Space Program do for me?’ Unfortunately, few people are aware of the benefits that NASA technology provides to our society,” says Lee. “I am honored to know that my innovation has moved beyond NASA to benefit private companies and their customers in a way that can significantly improve the quality of our daily lives.”\n                        \n                      \n                    \n                  \n                \n              \n                  \n                    \n                      \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            Jonathan Lee is one of the inventors of MSFC-398, a high-strength aluminum alloy.\n                          \n                        \n                        The Partnership for Next Generation Vehicles (PNGV) is not a NASA initiative to develop powerful new rockets and spacecraft, even though it may sound like one. PNGV was a partnership established by the Clinton administration between the Federal government and the U.S. Council for Automotive Research to develop technologies that improve fuel efficiency and reduce emissions from cars and trucks. More than 20 Federal laboratories from the Departments of Commerce, Energy, Transportation, and Defense; the Environmental Protection Agency; the National Science Foundation; and NASA were all involved in PNGV, in addition to more than 350 automotive suppliers, universities, and small businesses.\n                        In support of this tremendous effort, Jonathan Lee, a materials engineer at Marshall Space Flight Center, worked with a major automobile manufacturer in 1995 to develop a strong aluminum alloy for high temperature applications. The aim was to use the alloy for manufacturing parts for an internal combustion engine, as well as for NASA’s propulsion applications. When funding from PNGV ended, Marshall continued to support the alloy’s development with help from NASA’s Innovative Partnerships Program (now the Office of the Chief Technologist). Together with PoShou Chen, a scientist with Morgan Research Corporation, Lee invented a high-strength aluminum alloy called MSFC-398 that, when tested, was three to four times stronger than conventional aluminum alloys at high temperatures. \n                        By the late 1990s, Lee says, NASA’s scientists had successfully developed and patented this technology, which has great potential applications not for just automotive, but also for aerospace, marine, and commercial applications.\n                        Partnership\n                        After Marshall made the technology available for licensing in 2001, Bombardier Recreational Products Inc. licensed the alloy to cast parts for outboard marine engines (Spinoff 2004 and 2008). By 2005, the alloy had won Marshall’s “Invention of the Year” award, and a year later, the National Federal Laboratory Consortium recognized the alloy with an “Excellence in Technology Transfer” award. \n                        The most recent success of this technology, however, was in 2010. Twin City Fan Companies Ltd. in Minneapolis, Minnesota, licensed the alloy to make impellers (blades and hubs) for safety ventilation fans in rail and road tunnels. “We wanted a high temperature alloy that would have the strength and properties needed for safety fan impellers at very high temperatures. We found the NASA alloy, and upon further investigation, we knew that it was the right path for us,” says Dan Hartlein, executive vice president at Twin City Fan Companies Ltd.\n                        The division of Twin City Fan Companies Ltd. that is marketing the first fans made with the NASA aluminum alloy is Clarage, which is based in Pulaski, Tennessee. However, Michael Barry, president and COO of Twin City Fan Companies Ltd., finds there are broad application possibilities for all of the company’s global brands, including Twin City Fan and Blower and Aerovent. “Twin City Fan is a global American company. It gives us great pride to be able to utilize the special technology created by a technology leader like NASA,” says Barry.\n                        Benefits \n                        Twin City Fan licensed the NASA alloy with a specific application in mind: tunnel safety fans for the European market, where fans must be able to operate in 752 ˚F for two hours in order to be certified for use. The reason for the high temperature requirement is the fan must be able to operate successfully when there is a fire in a road or rail tunnel. When spinning in one direction, the fan provides clean air to the people inside; when spinning the other direction, it removes the smoke and gasses from the fire. \n                        \n                          \n                          \n                            \n                          \n                          \n                            Clarage, a division of Twin City Fan Companies Ltd., is using MSFC-398 to make the impellers of tunnel safety fans for road and \\\n                              rail tunnels. \n                          \n                        \n                        Before the NASA alloy, there were two ways to meet these temperature requirements, says Hartlein. One method was to use existing aluminum to make a bigger fan that spins more slowly. The drawback to this approach was that a bigger fan requires more space. “If we use the NASA alloy, the fan is smaller relative to the competition, and the tunnel can be smaller as well. Even if you can take a foot out of the construction of a new tunnel, there are massive potential savings,” says Hartlein. “In addition, the properties of this material allow us to run even hotter, leading to safety smoke exhaust at temperatures beyond what tunnel designers anticipated.”\n                        The other solution, Hartlein says, was to make the fan blades out of steel, but this required a specialized motor to turn and reverse the fan. “Steel weighs roughly three times more than aluminum. If it is three times as heavy on the rotating parts, the bearings are heavier, the shaft is heavier, and the motor is heavier—a lot comes with it. The motivation and opportunity for us to use aluminum, where in the past we would have had to use steel, is quite attractive to us. We can lower the cost of the overall product and provide better performance through the use of this alloy. We are just beginning to find applications that will provide value to our industry using this alloy.”\n                        “I am honored to know that my\n                          innovation has moved beyond NASA to\n                          benefit private companies and their customers\n                          in a way that can significantly improve the\n                          quality of our daily lives.”\n                          —Jonathan Lee, Marshall Space Flight Center\n                        While Twin City Fan Company has purchased the tools to produce 3 sizes of the fan, it plans to manufacture 12 different sizes in total. In 2011, Clarage sold the first of its fans made with the NASA alloy to a company testing the fans to certify them to European standards. Hartlein says he has met with a major engineering company in the United States, and the representatives are very interested in the capabilities of new fans. “We are bidding many projects now and should be shipping our first projects by the end of the year,” he says. \n                        According to Hartlein, the tunnel industry is busy and is projected to continue growing. “If you look around major metropolitan areas, there’s no place to put traffic, so it goes underground. This is driving a busy tunnel ventilation market,” he says. There are also opportunities for installing fans in existing tunnels due to stricter air quality standards. \n                        As this innovative application of NASA technology is projected to keep people safer, it is also helping the inventor of the technology answer an important question. “One of the most frequently asked question that I have encountered over the years is, ‘What does the Space Program do for me?’ Unfortunately, few people are aware of the benefits that NASA technology provides to our society,” says Lee. “I am honored to know that my innovation has moved beyond NASA to benefit private companies and their customers in a way that can significantly improve the quality of our daily lives.”\n                        \n                      \n                    \n                  \n                    \n                      \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            Jonathan Lee is one of the inventors of MSFC-398, a high-strength aluminum alloy.\n                          \n                        \n                        The Partnership for Next Generation Vehicles (PNGV) is not a NASA initiative to develop powerful new rockets and spacecraft, even though it may sound like one. PNGV was a partnership established by the Clinton administration between the Federal government and the U.S. Council for Automotive Research to develop technologies that improve fuel efficiency and reduce emissions from cars and trucks. More than 20 Federal laboratories from the Departments of Commerce, Energy, Transportation, and Defense; the Environmental Protection Agency; the National Science Foundation; and NASA were all involved in PNGV, in addition to more than 350 automotive suppliers, universities, and small businesses.\n                        In support of this tremendous effort, Jonathan Lee, a materials engineer at Marshall Space Flight Center, worked with a major automobile manufacturer in 1995 to develop a strong aluminum alloy for high temperature applications. The aim was to use the alloy for manufacturing parts for an internal combustion engine, as well as for NASA’s propulsion applications. When funding from PNGV ended, Marshall continued to support the alloy’s development with help from NASA’s Innovative Partnerships Program (now the Office of the Chief Technologist). Together with PoShou Chen, a scientist with Morgan Research Corporation, Lee invented a high-strength aluminum alloy called MSFC-398 that, when tested, was three to four times stronger than conventional aluminum alloys at high temperatures. \n                        By the late 1990s, Lee says, NASA’s scientists had successfully developed and patented this technology, which has great potential applications not for just automotive, but also for aerospace, marine, and commercial applications.\n                        Partnership\n                        After Marshall made the technology available for licensing in 2001, Bombardier Recreational Products Inc. licensed the alloy to cast parts for outboard marine engines (Spinoff 2004 and 2008). By 2005, the alloy had won Marshall’s “Invention of the Year” award, and a year later, the National Federal Laboratory Consortium recognized the alloy with an “Excellence in Technology Transfer” award. \n                        The most recent success of this technology, however, was in 2010. Twin City Fan Companies Ltd. in Minneapolis, Minnesota, licensed the alloy to make impellers (blades and hubs) for safety ventilation fans in rail and road tunnels. “We wanted a high temperature alloy that would have the strength and properties needed for safety fan impellers at very high temperatures. We found the NASA alloy, and upon further investigation, we knew that it was the right path for us,” says Dan Hartlein, executive vice president at Twin City Fan Companies Ltd.\n                        The division of Twin City Fan Companies Ltd. that is marketing the first fans made with the NASA aluminum alloy is Clarage, which is based in Pulaski, Tennessee. However, Michael Barry, president and COO of Twin City Fan Companies Ltd., finds there are broad application possibilities for all of the company’s global brands, including Twin City Fan and Blower and Aerovent. “Twin City Fan is a global American company. It gives us great pride to be able to utilize the special technology created by a technology leader like NASA,” says Barry.\n                        Benefits \n                        Twin City Fan licensed the NASA alloy with a specific application in mind: tunnel safety fans for the European market, where fans must be able to operate in 752 ˚F for two hours in order to be certified for use. The reason for the high temperature requirement is the fan must be able to operate successfully when there is a fire in a road or rail tunnel. When spinning in one direction, the fan provides clean air to the people inside; when spinning the other direction, it removes the smoke and gasses from the fire. \n                        \n                          \n                          \n                            \n                          \n                          \n                            Clarage, a division of Twin City Fan Companies Ltd., is using MSFC-398 to make the impellers of tunnel safety fans for road and \\\n                              rail tunnels. \n                          \n                        \n                        Before the NASA alloy, there were two ways to meet these temperature requirements, says Hartlein. One method was to use existing aluminum to make a bigger fan that spins more slowly. The drawback to this approach was that a bigger fan requires more space. “If we use the NASA alloy, the fan is smaller relative to the competition, and the tunnel can be smaller as well. Even if you can take a foot out of the construction of a new tunnel, there are massive potential savings,” says Hartlein. “In addition, the properties of this material allow us to run even hotter, leading to safety smoke exhaust at temperatures beyond what tunnel designers anticipated.”\n                        The other solution, Hartlein says, was to make the fan blades out of steel, but this required a specialized motor to turn and reverse the fan. “Steel weighs roughly three times more than aluminum. If it is three times as heavy on the rotating parts, the bearings are heavier, the shaft is heavier, and the motor is heavier—a lot comes with it. The motivation and opportunity for us to use aluminum, where in the past we would have had to use steel, is quite attractive to us. We can lower the cost of the overall product and provide better performance through the use of this alloy. We are just beginning to find applications that will provide value to our industry using this alloy.”\n                        “I am honored to know that my\n                          innovation has moved beyond NASA to\n                          benefit private companies and their customers\n                          in a way that can significantly improve the\n                          quality of our daily lives.”\n                          —Jonathan Lee, Marshall Space Flight Center\n                        While Twin City Fan Company has purchased the tools to produce 3 sizes of the fan, it plans to manufacture 12 different sizes in total. In 2011, Clarage sold the first of its fans made with the NASA alloy to a company testing the fans to certify them to European standards. Hartlein says he has met with a major engineering company in the United States, and the representatives are very interested in the capabilities of new fans. “We are bidding many projects now and should be shipping our first projects by the end of the year,” he says. \n                        According to Hartlein, the tunnel industry is busy and is projected to continue growing. “If you look around major metropolitan areas, there’s no place to put traffic, so it goes underground. This is driving a busy tunnel ventilation market,” he says. There are also opportunities for installing fans in existing tunnels due to stricter air quality standards. \n                        As this innovative application of NASA technology is projected to keep people safer, it is also helping the inventor of the technology answer an important question. “One of the most frequently asked question that I have encountered over the years is, ‘What does the Space Program do for me?’ Unfortunately, few people are aware of the benefits that NASA technology provides to our society,” says Lee. “I am honored to know that my innovation has moved beyond NASA to benefit private companies and their customers in a way that can significantly improve the quality of our daily lives.”\n                        \n                      \n                    \n                      \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            Jonathan Lee is one of the inventors of MSFC-398, a high-strength aluminum alloy.\n                          \n                        \n                        The Partnership for Next Generation Vehicles (PNGV) is not a NASA initiative to develop powerful new rockets and spacecraft, even though it may sound like one. PNGV was a partnership established by the Clinton administration between the Federal government and the U.S. Council for Automotive Research to develop technologies that improve fuel efficiency and reduce emissions from cars and trucks. More than 20 Federal laboratories from the Departments of Commerce, Energy, Transportation, and Defense; the Environmental Protection Agency; the National Science Foundation; and NASA were all involved in PNGV, in addition to more than 350 automotive suppliers, universities, and small businesses.\n                        In support of this tremendous effort, Jonathan Lee, a materials engineer at Marshall Space Flight Center, worked with a major automobile manufacturer in 1995 to develop a strong aluminum alloy for high temperature applications. The aim was to use the alloy for manufacturing parts for an internal combustion engine, as well as for NASA’s propulsion applications. When funding from PNGV ended, Marshall continued to support the alloy’s development with help from NASA’s Innovative Partnerships Program (now the Office of the Chief Technologist). Together with PoShou Chen, a scientist with Morgan Research Corporation, Lee invented a high-strength aluminum alloy called MSFC-398 that, when tested, was three to four times stronger than conventional aluminum alloys at high temperatures. \n                        By the late 1990s, Lee says, NASA’s scientists had successfully developed and patented this technology, which has great potential applications not for just automotive, but also for aerospace, marine, and commercial applications.\n                        Partnership\n                        After Marshall made the technology available for licensing in 2001, Bombardier Recreational Products Inc. licensed the alloy to cast parts for outboard marine engines (Spinoff 2004 and 2008). By 2005, the alloy had won Marshall’s “Invention of the Year” award, and a year later, the National Federal Laboratory Consortium recognized the alloy with an “Excellence in Technology Transfer” award. \n                        The most recent success of this technology, however, was in 2010. Twin City Fan Companies Ltd. in Minneapolis, Minnesota, licensed the alloy to make impellers (blades and hubs) for safety ventilation fans in rail and road tunnels. “We wanted a high temperature alloy that would have the strength and properties needed for safety fan impellers at very high temperatures. We found the NASA alloy, and upon further investigation, we knew that it was the right path for us,” says Dan Hartlein, executive vice president at Twin City Fan Companies Ltd.\n                        The division of Twin City Fan Companies Ltd. that is marketing the first fans made with the NASA aluminum alloy is Clarage, which is based in Pulaski, Tennessee. However, Michael Barry, president and COO of Twin City Fan Companies Ltd., finds there are broad application possibilities for all of the company’s global brands, including Twin City Fan and Blower and Aerovent. “Twin City Fan is a global American company. It gives us great pride to be able to utilize the special technology created by a technology leader like NASA,” says Barry.\n                        Benefits \n                        Twin City Fan licensed the NASA alloy with a specific application in mind: tunnel safety fans for the European market, where fans must be able to operate in 752 ˚F for two hours in order to be certified for use. The reason for the high temperature requirement is the fan must be able to operate successfully when there is a fire in a road or rail tunnel. When spinning in one direction, the fan provides clean air to the people inside; when spinning the other direction, it removes the smoke and gasses from the fire. \n                        \n                          \n                          \n                            \n                          \n                          \n                            Clarage, a division of Twin City Fan Companies Ltd., is using MSFC-398 to make the impellers of tunnel safety fans for road and \\\n                              rail tunnels. \n                          \n                        \n                        Before the NASA alloy, there were two ways to meet these temperature requirements, says Hartlein. One method was to use existing aluminum to make a bigger fan that spins more slowly. The drawback to this approach was that a bigger fan requires more space. “If we use the NASA alloy, the fan is smaller relative to the competition, and the tunnel can be smaller as well. Even if you can take a foot out of the construction of a new tunnel, there are massive potential savings,” says Hartlein. “In addition, the properties of this material allow us to run even hotter, leading to safety smoke exhaust at temperatures beyond what tunnel designers anticipated.”\n                        The other solution, Hartlein says, was to make the fan blades out of steel, but this required a specialized motor to turn and reverse the fan. “Steel weighs roughly three times more than aluminum. If it is three times as heavy on the rotating parts, the bearings are heavier, the shaft is heavier, and the motor is heavier—a lot comes with it. The motivation and opportunity for us to use aluminum, where in the past we would have had to use steel, is quite attractive to us. We can lower the cost of the overall product and provide better performance through the use of this alloy. We are just beginning to find applications that will provide value to our industry using this alloy.”\n                        “I am honored to know that my\n                          innovation has moved beyond NASA to\n                          benefit private companies and their customers\n                          in a way that can significantly improve the\n                          quality of our daily lives.”\n                          —Jonathan Lee, Marshall Space Flight Center\n                        While Twin City Fan Company has purchased the tools to produce 3 sizes of the fan, it plans to manufacture 12 different sizes in total. In 2011, Clarage sold the first of its fans made with the NASA alloy to a company testing the fans to certify them to European standards. Hartlein says he has met with a major engineering company in the United States, and the representatives are very interested in the capabilities of new fans. “We are bidding many projects now and should be shipping our first projects by the end of the year,” he says. \n                        According to Hartlein, the tunnel industry is busy and is projected to continue growing. “If you look around major metropolitan areas, there’s no place to put traffic, so it goes underground. This is driving a busy tunnel ventilation market,” he says. There are also opportunities for installing fans in existing tunnels due to stricter air quality standards. \n                        As this innovative application of NASA technology is projected to keep people safer, it is also helping the inventor of the technology answer an important question. “One of the most frequently asked question that I have encountered over the years is, ‘What does the Space Program do for me?’ Unfortunately, few people are aware of the benefits that NASA technology provides to our society,” says Lee. “I am honored to know that my innovation has moved beyond NASA to benefit private companies and their customers in a way that can significantly improve the quality of our daily lives.”\n                        \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            Jonathan Lee is one of the inventors of MSFC-398, a high-strength aluminum alloy.\n                          \n                        \n                        The Partnership for Next Generation Vehicles (PNGV) is not a NASA initiative to develop powerful new rockets and spacecraft, even though it may sound like one. PNGV was a partnership established by the Clinton administration between the Federal government and the U.S. Council for Automotive Research to develop technologies that improve fuel efficiency and reduce emissions from cars and trucks. More than 20 Federal laboratories from the Departments of Commerce, Energy, Transportation, and Defense; the Environmental Protection Agency; the National Science Foundation; and NASA were all involved in PNGV, in addition to more than 350 automotive suppliers, universities, and small businesses.\n                        In support of this tremendous effort, Jonathan Lee, a materials engineer at Marshall Space Flight Center, worked with a major automobile manufacturer in 1995 to develop a strong aluminum alloy for high temperature applications. The aim was to use the alloy for manufacturing parts for an internal combustion engine, as well as for NASA’s propulsion applications. When funding from PNGV ended, Marshall continued to support the alloy’s development with help from NASA’s Innovative Partnerships Program (now the Office of the Chief Technologist). Together with PoShou Chen, a scientist with Morgan Research Corporation, Lee invented a high-strength aluminum alloy called MSFC-398 that, when tested, was three to four times stronger than conventional aluminum alloys at high temperatures. \n                        By the late 1990s, Lee says, NASA’s scientists had successfully developed and patented this technology, which has great potential applications not for just automotive, but also for aerospace, marine, and commercial applications.\n                        Partnership\n                        After Marshall made the technology available for licensing in 2001, Bombardier Recreational Products Inc. licensed the alloy to cast parts for outboard marine engines (Spinoff 2004 and 2008). By 2005, the alloy had won Marshall’s “Invention of the Year” award, and a year later, the National Federal Laboratory Consortium recognized the alloy with an “Excellence in Technology Transfer” award. \n                        The most recent success of this technology, however, was in 2010. Twin City Fan Companies Ltd. in Minneapolis, Minnesota, licensed the alloy to make impellers (blades and hubs) for safety ventilation fans in rail and road tunnels. “We wanted a high temperature alloy that would have the strength and properties needed for safety fan impellers at very high temperatures. We found the NASA alloy, and upon further investigation, we knew that it was the right path for us,” says Dan Hartlein, executive vice president at Twin City Fan Companies Ltd.\n                        The division of Twin City Fan Companies Ltd. that is marketing the first fans made with the NASA aluminum alloy is Clarage, which is based in Pulaski, Tennessee. However, Michael Barry, president and COO of Twin City Fan Companies Ltd., finds there are broad application possibilities for all of the company’s global brands, including Twin City Fan and Blower and Aerovent. “Twin City Fan is a global American company. It gives us great pride to be able to utilize the special technology created by a technology leader like NASA,” says Barry.\n                        Benefits \n                        Twin City Fan licensed the NASA alloy with a specific application in mind: tunnel safety fans for the European market, where fans must be able to operate in 752 ˚F for two hours in order to be certified for use. The reason for the high temperature requirement is the fan must be able to operate successfully when there is a fire in a road or rail tunnel. When spinning in one direction, the fan provides clean air to the people inside; when spinning the other direction, it removes the smoke and gasses from the fire. \n                        \n                          \n                          \n                            \n                          \n                          \n                            Clarage, a division of Twin City Fan Companies Ltd., is using MSFC-398 to make the impellers of tunnel safety fans for road and \\\n                              rail tunnels. \n                          \n                        \n                        Before the NASA alloy, there were two ways to meet these temperature requirements, says Hartlein. One method was to use existing aluminum to make a bigger fan that spins more slowly. The drawback to this approach was that a bigger fan requires more space. “If we use the NASA alloy, the fan is smaller relative to the competition, and the tunnel can be smaller as well. Even if you can take a foot out of the construction of a new tunnel, there are massive potential savings,” says Hartlein. “In addition, the properties of this material allow us to run even hotter, leading to safety smoke exhaust at temperatures beyond what tunnel designers anticipated.”\n                        The other solution, Hartlein says, was to make the fan blades out of steel, but this required a specialized motor to turn and reverse the fan. “Steel weighs roughly three times more than aluminum. If it is three times as heavy on the rotating parts, the bearings are heavier, the shaft is heavier, and the motor is heavier—a lot comes with it. The motivation and opportunity for us to use aluminum, where in the past we would have had to use steel, is quite attractive to us. We can lower the cost of the overall product and provide better performance through the use of this alloy. We are just beginning to find applications that will provide value to our industry using this alloy.”\n                        “I am honored to know that my\n                          innovation has moved beyond NASA to\n                          benefit private companies and their customers\n                          in a way that can significantly improve the\n                          quality of our daily lives.”\n                          —Jonathan Lee, Marshall Space Flight Center\n                        While Twin City Fan Company has purchased the tools to produce 3 sizes of the fan, it plans to manufacture 12 different sizes in total. In 2011, Clarage sold the first of its fans made with the NASA alloy to a company testing the fans to certify them to European standards. Hartlein says he has met with a major engineering company in the United States, and the representatives are very interested in the capabilities of new fans. “We are bidding many projects now and should be shipping our first projects by the end of the year,” he says. \n                        According to Hartlein, the tunnel industry is busy and is projected to continue growing. “If you look around major metropolitan areas, there’s no place to put traffic, so it goes underground. This is driving a busy tunnel ventilation market,” he says. There are also opportunities for installing fans in existing tunnels due to stricter air quality standards. \n                        As this innovative application of NASA technology is projected to keep people safer, it is also helping the inventor of the technology answer an important question. “One of the most frequently asked question that I have encountered over the years is, ‘What does the Space Program do for me?’ Unfortunately, few people are aware of the benefits that NASA technology provides to our society,” says Lee. “I am honored to know that my innovation has moved beyond NASA to benefit private companies and their customers in a way that can significantly improve the quality of our daily lives.”\n                        "},{"href":"http://spinoff.nasa.gov/Spinoff2011/cg_1.html","text":"Control Algorithms Charge Batteries Faster","image":"http://spinoff.nasa.gov/Spinoff2011/Images/cg_1_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  On March 29, 2011, NASA’s Mercury Surface, Space Environment, Geochemistry and Ranging (MESSENGER) spacecraft beamed a milestone image to Earth: the first photo of Mercury taken from orbit around the solar system’s innermost planet. (MESSENGER is also the first spacecraft to orbit Mercury.) Like most of NASA’s deep space probes, MESSENGER is enabled by a complex power system that allows its science instruments and communications to function continuously as it travels millions of miles from Earth. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Technicians secure guide wires to one of MESSENGER’s two solar panels. The panels combine with a nickel hydrogen battery to power the spacecraft. \n                    \n                  \n                  “Typically, there isn’t one particular power source that can support the entire mission,” says Linda Taylor, electrical engineer in Glenn Research Center’s Power Systems Analysis Branch. “If you have solar arrays and you are in orbit, at some point you’re going to be in eclipse.” Because of this, Taylor explains, spacecraft like MESSENGER feature hybrid power systems. MESSENGER is powered by a two-panel solar array coupled with a nickel hydrogen battery. The solar arrays provide energy to the probe and charge the battery; when the spacecraft’s orbit carries it behind Mercury and out of the Sun’s light, the spacecraft switches to battery power to continue operations.\n                  Typically, hybrid systems with multiple power inputs and a battery acting alternately as storage and a power source require multiple converters to handle the power flow between the devices, Taylor says. (Power converters change the qualities of electrical energy, such as from alternating current to direct current, or between different levels of voltage or frequency.) This contributes to a pair of major concerns for spacecraft design.\n                  “Weight and size are big drivers for any space application,” Taylor says, noting that every pound added to a space vehicle incurs significant costs. For an innovative solution to managing power flows in a lightweight, cost-effective manner, NASA turned to a private industry partner. \n                  Partnership\n                  Through Small Business Innovation Research (SBIR) contracts with Glenn, Advanced Power Electronics Corporation (ApECOR) of Orlando, Florida, devised a three-port power converter for space systems. Much like a traffic cop at an intersection, the converter directs the flow and levels of electricity collected from solar panels, shunting part of that power into storage batteries, and pulling it out of the batteries to provide energy when solar panels are ineffective. \n                  “The control strategy becomes fairly complicated when you have multiple interfaces to the same converter,” says John Elmes, vice president of advanced technology for ApECOR. “The challenge is that you have so many conflicting control parameters, you have to figure out a way to simultaneously operate them.” \n                  “It’s hard for small businesses to pursue work like this that could have a major economic benefit down the road but is currently \n                    risky and difficult. NASA … provides a big benefit.”\n                    —John Elmes, ApECOR \n                  For the NASA project, ApECOR developed complex control algorithms for managing the power flows through a single device that has the potential to directly minimize the size and weight of overall spacecraft power systems. Taylor has used the SBIR-derived device for testing at Glenn and hopes to incorporate it into the Orion Crew Module test bed at the Center. In the meantime, ApECOR has applied the control algorithms it developed for the SBIR project to a new commercial product.\n                  Benefits\n                  \n                    \n                    \n                      \n                    \n                    \n                      ApECOR’s X-90 Solar Charger uses the company’s NASA-derived control algorithms to efficiently charge batteries from solar or \n                        other sources. \n                    \n                  \n                  ApECOR’s X-90 Solar Charger is capable of using a wide range of solar arrays or other DC sources to replenish portable rechargeable batteries. Plugging directly on top of compatible batteries and requiring only the wiring needed to link to the power source, the device makes use of Maximum Power Point Tracking (MPPT) technology to ensure it gathers the most energy possible from a connected solar panel. Solar panel output varies depending on the amount of light and other environmental conditions; MPPT constantly changes the operation of the panel to maximize its efficiency. ApECOR incorporated MPPT into the three-port converter it created for NASA, which in turn provided the company with the capability to add the feature to the X-90.\n                  “We were able to use what we learned from the NASA three-port converter work and use it to help implement our battery charge algorithms on the X-90 while also implementing MPPT on the solar panel,” Elmes says. The result, he says, is ApECOR’s product charges batteries at least 30 percent faster than comparative devices using the same solar panel. This kind of speed is a particular advantage for one of ApECOR’s target customers, the military, providing a means of quickly and efficiently charging the batteries used for radios and other devices in the field. \n                  Elmes says the NASA-derived X-90 is a promising addition to ApECOR’s offerings, and that other potential applications for the technology include providing power through solar or wind sources in rural farming areas in developing countries and allowing for the remote operation of irrigation pumps. The company is also engaged in another SBIR project with Glenn, working to develop high temperature semiconductors for applications in space, where extreme temperatures are the norm. This project could result in numerous terrestrial uses related to eliminating the problem of heat generated by powerful electronics—using temperature-tolerant semiconductors, costly and space-consuming elements like heat sinks and liquid coolant systems could be downsized or eliminated. \n                  “It’s hard for small businesses to pursue work like this that could have a major economic benefit down the road but is currently risky and difficult,” Elmes says. “The combination at NASA, where they have a very strong team of people who understand where the technology is going and can see where there are technological needs, provides a big benefit.\n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  On March 29, 2011, NASA’s Mercury Surface, Space Environment, Geochemistry and Ranging (MESSENGER) spacecraft beamed a milestone image to Earth: the first photo of Mercury taken from orbit around the solar system’s innermost planet. (MESSENGER is also the first spacecraft to orbit Mercury.) Like most of NASA’s deep space probes, MESSENGER is enabled by a complex power system that allows its science instruments and communications to function continuously as it travels millions of miles from Earth. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Technicians secure guide wires to one of MESSENGER’s two solar panels. The panels combine with a nickel hydrogen battery to power the spacecraft. \n                    \n                  \n                  “Typically, there isn’t one particular power source that can support the entire mission,” says Linda Taylor, electrical engineer in Glenn Research Center’s Power Systems Analysis Branch. “If you have solar arrays and you are in orbit, at some point you’re going to be in eclipse.” Because of this, Taylor explains, spacecraft like MESSENGER feature hybrid power systems. MESSENGER is powered by a two-panel solar array coupled with a nickel hydrogen battery. The solar arrays provide energy to the probe and charge the battery; when the spacecraft’s orbit carries it behind Mercury and out of the Sun’s light, the spacecraft switches to battery power to continue operations.\n                  Typically, hybrid systems with multiple power inputs and a battery acting alternately as storage and a power source require multiple converters to handle the power flow between the devices, Taylor says. (Power converters change the qualities of electrical energy, such as from alternating current to direct current, or between different levels of voltage or frequency.) This contributes to a pair of major concerns for spacecraft design.\n                  “Weight and size are big drivers for any space application,” Taylor says, noting that every pound added to a space vehicle incurs significant costs. For an innovative solution to managing power flows in a lightweight, cost-effective manner, NASA turned to a private industry partner. \n                  Partnership\n                  Through Small Business Innovation Research (SBIR) contracts with Glenn, Advanced Power Electronics Corporation (ApECOR) of Orlando, Florida, devised a three-port power converter for space systems. Much like a traffic cop at an intersection, the converter directs the flow and levels of electricity collected from solar panels, shunting part of that power into storage batteries, and pulling it out of the batteries to provide energy when solar panels are ineffective. \n                  “The control strategy becomes fairly complicated when you have multiple interfaces to the same converter,” says John Elmes, vice president of advanced technology for ApECOR. “The challenge is that you have so many conflicting control parameters, you have to figure out a way to simultaneously operate them.” \n                  “It’s hard for small businesses to pursue work like this that could have a major economic benefit down the road but is currently \n                    risky and difficult. NASA … provides a big benefit.”\n                    —John Elmes, ApECOR \n                  For the NASA project, ApECOR developed complex control algorithms for managing the power flows through a single device that has the potential to directly minimize the size and weight of overall spacecraft power systems. Taylor has used the SBIR-derived device for testing at Glenn and hopes to incorporate it into the Orion Crew Module test bed at the Center. In the meantime, ApECOR has applied the control algorithms it developed for the SBIR project to a new commercial product.\n                  Benefits\n                  \n                    \n                    \n                      \n                    \n                    \n                      ApECOR’s X-90 Solar Charger uses the company’s NASA-derived control algorithms to efficiently charge batteries from solar or \n                        other sources. \n                    \n                  \n                  ApECOR’s X-90 Solar Charger is capable of using a wide range of solar arrays or other DC sources to replenish portable rechargeable batteries. Plugging directly on top of compatible batteries and requiring only the wiring needed to link to the power source, the device makes use of Maximum Power Point Tracking (MPPT) technology to ensure it gathers the most energy possible from a connected solar panel. Solar panel output varies depending on the amount of light and other environmental conditions; MPPT constantly changes the operation of the panel to maximize its efficiency. ApECOR incorporated MPPT into the three-port converter it created for NASA, which in turn provided the company with the capability to add the feature to the X-90.\n                  “We were able to use what we learned from the NASA three-port converter work and use it to help implement our battery charge algorithms on the X-90 while also implementing MPPT on the solar panel,” Elmes says. The result, he says, is ApECOR’s product charges batteries at least 30 percent faster than comparative devices using the same solar panel. This kind of speed is a particular advantage for one of ApECOR’s target customers, the military, providing a means of quickly and efficiently charging the batteries used for radios and other devices in the field. \n                  Elmes says the NASA-derived X-90 is a promising addition to ApECOR’s offerings, and that other potential applications for the technology include providing power through solar or wind sources in rural farming areas in developing countries and allowing for the remote operation of irrigation pumps. The company is also engaged in another SBIR project with Glenn, working to develop high temperature semiconductors for applications in space, where extreme temperatures are the norm. This project could result in numerous terrestrial uses related to eliminating the problem of heat generated by powerful electronics—using temperature-tolerant semiconductors, costly and space-consuming elements like heat sinks and liquid coolant systems could be downsized or eliminated. \n                  “It’s hard for small businesses to pursue work like this that could have a major economic benefit down the road but is currently risky and difficult,” Elmes says. “The combination at NASA, where they have a very strong team of people who understand where the technology is going and can see where there are technological needs, provides a big benefit.\n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  On March 29, 2011, NASA’s Mercury Surface, Space Environment, Geochemistry and Ranging (MESSENGER) spacecraft beamed a milestone image to Earth: the first photo of Mercury taken from orbit around the solar system’s innermost planet. (MESSENGER is also the first spacecraft to orbit Mercury.) Like most of NASA’s deep space probes, MESSENGER is enabled by a complex power system that allows its science instruments and communications to function continuously as it travels millions of miles from Earth. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Technicians secure guide wires to one of MESSENGER’s two solar panels. The panels combine with a nickel hydrogen battery to power the spacecraft. \n                    \n                  \n                  “Typically, there isn’t one particular power source that can support the entire mission,” says Linda Taylor, electrical engineer in Glenn Research Center’s Power Systems Analysis Branch. “If you have solar arrays and you are in orbit, at some point you’re going to be in eclipse.” Because of this, Taylor explains, spacecraft like MESSENGER feature hybrid power systems. MESSENGER is powered by a two-panel solar array coupled with a nickel hydrogen battery. The solar arrays provide energy to the probe and charge the battery; when the spacecraft’s orbit carries it behind Mercury and out of the Sun’s light, the spacecraft switches to battery power to continue operations.\n                  Typically, hybrid systems with multiple power inputs and a battery acting alternately as storage and a power source require multiple converters to handle the power flow between the devices, Taylor says. (Power converters change the qualities of electrical energy, such as from alternating current to direct current, or between different levels of voltage or frequency.) This contributes to a pair of major concerns for spacecraft design.\n                  “Weight and size are big drivers for any space application,” Taylor says, noting that every pound added to a space vehicle incurs significant costs. For an innovative solution to managing power flows in a lightweight, cost-effective manner, NASA turned to a private industry partner. \n                  Partnership\n                  Through Small Business Innovation Research (SBIR) contracts with Glenn, Advanced Power Electronics Corporation (ApECOR) of Orlando, Florida, devised a three-port power converter for space systems. Much like a traffic cop at an intersection, the converter directs the flow and levels of electricity collected from solar panels, shunting part of that power into storage batteries, and pulling it out of the batteries to provide energy when solar panels are ineffective. \n                  “The control strategy becomes fairly complicated when you have multiple interfaces to the same converter,” says John Elmes, vice president of advanced technology for ApECOR. “The challenge is that you have so many conflicting control parameters, you have to figure out a way to simultaneously operate them.” \n                  “It’s hard for small businesses to pursue work like this that could have a major economic benefit down the road but is currently \n                    risky and difficult. NASA … provides a big benefit.”\n                    —John Elmes, ApECOR \n                  For the NASA project, ApECOR developed complex control algorithms for managing the power flows through a single device that has the potential to directly minimize the size and weight of overall spacecraft power systems. Taylor has used the SBIR-derived device for testing at Glenn and hopes to incorporate it into the Orion Crew Module test bed at the Center. In the meantime, ApECOR has applied the control algorithms it developed for the SBIR project to a new commercial product.\n                  Benefits\n                  \n                    \n                    \n                      \n                    \n                    \n                      ApECOR’s X-90 Solar Charger uses the company’s NASA-derived control algorithms to efficiently charge batteries from solar or \n                        other sources. \n                    \n                  \n                  ApECOR’s X-90 Solar Charger is capable of using a wide range of solar arrays or other DC sources to replenish portable rechargeable batteries. Plugging directly on top of compatible batteries and requiring only the wiring needed to link to the power source, the device makes use of Maximum Power Point Tracking (MPPT) technology to ensure it gathers the most energy possible from a connected solar panel. Solar panel output varies depending on the amount of light and other environmental conditions; MPPT constantly changes the operation of the panel to maximize its efficiency. ApECOR incorporated MPPT into the three-port converter it created for NASA, which in turn provided the company with the capability to add the feature to the X-90.\n                  “We were able to use what we learned from the NASA three-port converter work and use it to help implement our battery charge algorithms on the X-90 while also implementing MPPT on the solar panel,” Elmes says. The result, he says, is ApECOR’s product charges batteries at least 30 percent faster than comparative devices using the same solar panel. This kind of speed is a particular advantage for one of ApECOR’s target customers, the military, providing a means of quickly and efficiently charging the batteries used for radios and other devices in the field. \n                  Elmes says the NASA-derived X-90 is a promising addition to ApECOR’s offerings, and that other potential applications for the technology include providing power through solar or wind sources in rural farming areas in developing countries and allowing for the remote operation of irrigation pumps. The company is also engaged in another SBIR project with Glenn, working to develop high temperature semiconductors for applications in space, where extreme temperatures are the norm. This project could result in numerous terrestrial uses related to eliminating the problem of heat generated by powerful electronics—using temperature-tolerant semiconductors, costly and space-consuming elements like heat sinks and liquid coolant systems could be downsized or eliminated. \n                  “It’s hard for small businesses to pursue work like this that could have a major economic benefit down the road but is currently risky and difficult,” Elmes says. “The combination at NASA, where they have a very strong team of people who understand where the technology is going and can see where there are technological needs, provides a big benefit.\n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  NASA Technology\n                  On March 29, 2011, NASA’s Mercury Surface, Space Environment, Geochemistry and Ranging (MESSENGER) spacecraft beamed a milestone image to Earth: the first photo of Mercury taken from orbit around the solar system’s innermost planet. (MESSENGER is also the first spacecraft to orbit Mercury.) Like most of NASA’s deep space probes, MESSENGER is enabled by a complex power system that allows its science instruments and communications to function continuously as it travels millions of miles from Earth. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Technicians secure guide wires to one of MESSENGER’s two solar panels. The panels combine with a nickel hydrogen battery to power the spacecraft. \n                    \n                  \n                  “Typically, there isn’t one particular power source that can support the entire mission,” says Linda Taylor, electrical engineer in Glenn Research Center’s Power Systems Analysis Branch. “If you have solar arrays and you are in orbit, at some point you’re going to be in eclipse.” Because of this, Taylor explains, spacecraft like MESSENGER feature hybrid power systems. MESSENGER is powered by a two-panel solar array coupled with a nickel hydrogen battery. The solar arrays provide energy to the probe and charge the battery; when the spacecraft’s orbit carries it behind Mercury and out of the Sun’s light, the spacecraft switches to battery power to continue operations.\n                  Typically, hybrid systems with multiple power inputs and a battery acting alternately as storage and a power source require multiple converters to handle the power flow between the devices, Taylor says. (Power converters change the qualities of electrical energy, such as from alternating current to direct current, or between different levels of voltage or frequency.) This contributes to a pair of major concerns for spacecraft design.\n                  “Weight and size are big drivers for any space application,” Taylor says, noting that every pound added to a space vehicle incurs significant costs. For an innovative solution to managing power flows in a lightweight, cost-effective manner, NASA turned to a private industry partner. \n                  Partnership\n                  Through Small Business Innovation Research (SBIR) contracts with Glenn, Advanced Power Electronics Corporation (ApECOR) of Orlando, Florida, devised a three-port power converter for space systems. Much like a traffic cop at an intersection, the converter directs the flow and levels of electricity collected from solar panels, shunting part of that power into storage batteries, and pulling it out of the batteries to provide energy when solar panels are ineffective. \n                  “The control strategy becomes fairly complicated when you have multiple interfaces to the same converter,” says John Elmes, vice president of advanced technology for ApECOR. “The challenge is that you have so many conflicting control parameters, you have to figure out a way to simultaneously operate them.” \n                  “It’s hard for small businesses to pursue work like this that could have a major economic benefit down the road but is currently \n                    risky and difficult. NASA … provides a big benefit.”\n                    —John Elmes, ApECOR \n                  For the NASA project, ApECOR developed complex control algorithms for managing the power flows through a single device that has the potential to directly minimize the size and weight of overall spacecraft power systems. Taylor has used the SBIR-derived device for testing at Glenn and hopes to incorporate it into the Orion Crew Module test bed at the Center. In the meantime, ApECOR has applied the control algorithms it developed for the SBIR project to a new commercial product.\n                  Benefits\n                  \n                    \n                    \n                      \n                    \n                    \n                      ApECOR’s X-90 Solar Charger uses the company’s NASA-derived control algorithms to efficiently charge batteries from solar or \n                        other sources. \n                    \n                  \n                  ApECOR’s X-90 Solar Charger is capable of using a wide range of solar arrays or other DC sources to replenish portable rechargeable batteries. Plugging directly on top of compatible batteries and requiring only the wiring needed to link to the power source, the device makes use of Maximum Power Point Tracking (MPPT) technology to ensure it gathers the most energy possible from a connected solar panel. Solar panel output varies depending on the amount of light and other environmental conditions; MPPT constantly changes the operation of the panel to maximize its efficiency. ApECOR incorporated MPPT into the three-port converter it created for NASA, which in turn provided the company with the capability to add the feature to the X-90.\n                  “We were able to use what we learned from the NASA three-port converter work and use it to help implement our battery charge algorithms on the X-90 while also implementing MPPT on the solar panel,” Elmes says. The result, he says, is ApECOR’s product charges batteries at least 30 percent faster than comparative devices using the same solar panel. This kind of speed is a particular advantage for one of ApECOR’s target customers, the military, providing a means of quickly and efficiently charging the batteries used for radios and other devices in the field. \n                  Elmes says the NASA-derived X-90 is a promising addition to ApECOR’s offerings, and that other potential applications for the technology include providing power through solar or wind sources in rural farming areas in developing countries and allowing for the remote operation of irrigation pumps. The company is also engaged in another SBIR project with Glenn, working to develop high temperature semiconductors for applications in space, where extreme temperatures are the norm. This project could result in numerous terrestrial uses related to eliminating the problem of heat generated by powerful electronics—using temperature-tolerant semiconductors, costly and space-consuming elements like heat sinks and liquid coolant systems could be downsized or eliminated. \n                  “It’s hard for small businesses to pursue work like this that could have a major economic benefit down the road but is currently risky and difficult,” Elmes says. “The combination at NASA, where they have a very strong team of people who understand where the technology is going and can see where there are technological needs, provides a big benefit.\n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  NASA Technology\n                  On March 29, 2011, NASA’s Mercury Surface, Space Environment, Geochemistry and Ranging (MESSENGER) spacecraft beamed a milestone image to Earth: the first photo of Mercury taken from orbit around the solar system’s innermost planet. (MESSENGER is also the first spacecraft to orbit Mercury.) Like most of NASA’s deep space probes, MESSENGER is enabled by a complex power system that allows its science instruments and communications to function continuously as it travels millions of miles from Earth. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Technicians secure guide wires to one of MESSENGER’s two solar panels. The panels combine with a nickel hydrogen battery to power the spacecraft. \n                    \n                  \n                  “Typically, there isn’t one particular power source that can support the entire mission,” says Linda Taylor, electrical engineer in Glenn Research Center’s Power Systems Analysis Branch. “If you have solar arrays and you are in orbit, at some point you’re going to be in eclipse.” Because of this, Taylor explains, spacecraft like MESSENGER feature hybrid power systems. MESSENGER is powered by a two-panel solar array coupled with a nickel hydrogen battery. The solar arrays provide energy to the probe and charge the battery; when the spacecraft’s orbit carries it behind Mercury and out of the Sun’s light, the spacecraft switches to battery power to continue operations.\n                  Typically, hybrid systems with multiple power inputs and a battery acting alternately as storage and a power source require multiple converters to handle the power flow between the devices, Taylor says. (Power converters change the qualities of electrical energy, such as from alternating current to direct current, or between different levels of voltage or frequency.) This contributes to a pair of major concerns for spacecraft design.\n                  “Weight and size are big drivers for any space application,” Taylor says, noting that every pound added to a space vehicle incurs significant costs. For an innovative solution to managing power flows in a lightweight, cost-effective manner, NASA turned to a private industry partner. \n                  Partnership\n                  Through Small Business Innovation Research (SBIR) contracts with Glenn, Advanced Power Electronics Corporation (ApECOR) of Orlando, Florida, devised a three-port power converter for space systems. Much like a traffic cop at an intersection, the converter directs the flow and levels of electricity collected from solar panels, shunting part of that power into storage batteries, and pulling it out of the batteries to provide energy when solar panels are ineffective. \n                  “The control strategy becomes fairly complicated when you have multiple interfaces to the same converter,” says John Elmes, vice president of advanced technology for ApECOR. “The challenge is that you have so many conflicting control parameters, you have to figure out a way to simultaneously operate them.” \n                  “It’s hard for small businesses to pursue work like this that could have a major economic benefit down the road but is currently \n                    risky and difficult. NASA … provides a big benefit.”\n                    —John Elmes, ApECOR \n                  For the NASA project, ApECOR developed complex control algorithms for managing the power flows through a single device that has the potential to directly minimize the size and weight of overall spacecraft power systems. Taylor has used the SBIR-derived device for testing at Glenn and hopes to incorporate it into the Orion Crew Module test bed at the Center. In the meantime, ApECOR has applied the control algorithms it developed for the SBIR project to a new commercial product.\n                  Benefits\n                  \n                    \n                    \n                      \n                    \n                    \n                      ApECOR’s X-90 Solar Charger uses the company’s NASA-derived control algorithms to efficiently charge batteries from solar or \n                        other sources. \n                    \n                  \n                  ApECOR’s X-90 Solar Charger is capable of using a wide range of solar arrays or other DC sources to replenish portable rechargeable batteries. Plugging directly on top of compatible batteries and requiring only the wiring needed to link to the power source, the device makes use of Maximum Power Point Tracking (MPPT) technology to ensure it gathers the most energy possible from a connected solar panel. Solar panel output varies depending on the amount of light and other environmental conditions; MPPT constantly changes the operation of the panel to maximize its efficiency. ApECOR incorporated MPPT into the three-port converter it created for NASA, which in turn provided the company with the capability to add the feature to the X-90.\n                  “We were able to use what we learned from the NASA three-port converter work and use it to help implement our battery charge algorithms on the X-90 while also implementing MPPT on the solar panel,” Elmes says. The result, he says, is ApECOR’s product charges batteries at least 30 percent faster than comparative devices using the same solar panel. This kind of speed is a particular advantage for one of ApECOR’s target customers, the military, providing a means of quickly and efficiently charging the batteries used for radios and other devices in the field. \n                  Elmes says the NASA-derived X-90 is a promising addition to ApECOR’s offerings, and that other potential applications for the technology include providing power through solar or wind sources in rural farming areas in developing countries and allowing for the remote operation of irrigation pumps. The company is also engaged in another SBIR project with Glenn, working to develop high temperature semiconductors for applications in space, where extreme temperatures are the norm. This project could result in numerous terrestrial uses related to eliminating the problem of heat generated by powerful electronics—using temperature-tolerant semiconductors, costly and space-consuming elements like heat sinks and liquid coolant systems could be downsized or eliminated. \n                  “It’s hard for small businesses to pursue work like this that could have a major economic benefit down the road but is currently risky and difficult,” Elmes says. “The combination at NASA, where they have a very strong team of people who understand where the technology is going and can see where there are technological needs, provides a big benefit.\n                  \n                \n              \n            \n            \n              \n                \n                  NASA Technology\n                  On March 29, 2011, NASA’s Mercury Surface, Space Environment, Geochemistry and Ranging (MESSENGER) spacecraft beamed a milestone image to Earth: the first photo of Mercury taken from orbit around the solar system’s innermost planet. (MESSENGER is also the first spacecraft to orbit Mercury.) Like most of NASA’s deep space probes, MESSENGER is enabled by a complex power system that allows its science instruments and communications to function continuously as it travels millions of miles from Earth. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Technicians secure guide wires to one of MESSENGER’s two solar panels. The panels combine with a nickel hydrogen battery to power the spacecraft. \n                    \n                  \n                  “Typically, there isn’t one particular power source that can support the entire mission,” says Linda Taylor, electrical engineer in Glenn Research Center’s Power Systems Analysis Branch. “If you have solar arrays and you are in orbit, at some point you’re going to be in eclipse.” Because of this, Taylor explains, spacecraft like MESSENGER feature hybrid power systems. MESSENGER is powered by a two-panel solar array coupled with a nickel hydrogen battery. The solar arrays provide energy to the probe and charge the battery; when the spacecraft’s orbit carries it behind Mercury and out of the Sun’s light, the spacecraft switches to battery power to continue operations.\n                  Typically, hybrid systems with multiple power inputs and a battery acting alternately as storage and a power source require multiple converters to handle the power flow between the devices, Taylor says. (Power converters change the qualities of electrical energy, such as from alternating current to direct current, or between different levels of voltage or frequency.) This contributes to a pair of major concerns for spacecraft design.\n                  “Weight and size are big drivers for any space application,” Taylor says, noting that every pound added to a space vehicle incurs significant costs. For an innovative solution to managing power flows in a lightweight, cost-effective manner, NASA turned to a private industry partner. \n                  Partnership\n                  Through Small Business Innovation Research (SBIR) contracts with Glenn, Advanced Power Electronics Corporation (ApECOR) of Orlando, Florida, devised a three-port power converter for space systems. Much like a traffic cop at an intersection, the converter directs the flow and levels of electricity collected from solar panels, shunting part of that power into storage batteries, and pulling it out of the batteries to provide energy when solar panels are ineffective. \n                  “The control strategy becomes fairly complicated when you have multiple interfaces to the same converter,” says John Elmes, vice president of advanced technology for ApECOR. “The challenge is that you have so many conflicting control parameters, you have to figure out a way to simultaneously operate them.” \n                  “It’s hard for small businesses to pursue work like this that could have a major economic benefit down the road but is currently \n                    risky and difficult. NASA … provides a big benefit.”\n                    —John Elmes, ApECOR \n                  For the NASA project, ApECOR developed complex control algorithms for managing the power flows through a single device that has the potential to directly minimize the size and weight of overall spacecraft power systems. Taylor has used the SBIR-derived device for testing at Glenn and hopes to incorporate it into the Orion Crew Module test bed at the Center. In the meantime, ApECOR has applied the control algorithms it developed for the SBIR project to a new commercial product.\n                  Benefits\n                  \n                    \n                    \n                      \n                    \n                    \n                      ApECOR’s X-90 Solar Charger uses the company’s NASA-derived control algorithms to efficiently charge batteries from solar or \n                        other sources. \n                    \n                  \n                  ApECOR’s X-90 Solar Charger is capable of using a wide range of solar arrays or other DC sources to replenish portable rechargeable batteries. Plugging directly on top of compatible batteries and requiring only the wiring needed to link to the power source, the device makes use of Maximum Power Point Tracking (MPPT) technology to ensure it gathers the most energy possible from a connected solar panel. Solar panel output varies depending on the amount of light and other environmental conditions; MPPT constantly changes the operation of the panel to maximize its efficiency. ApECOR incorporated MPPT into the three-port converter it created for NASA, which in turn provided the company with the capability to add the feature to the X-90.\n                  “We were able to use what we learned from the NASA three-port converter work and use it to help implement our battery charge algorithms on the X-90 while also implementing MPPT on the solar panel,” Elmes says. The result, he says, is ApECOR’s product charges batteries at least 30 percent faster than comparative devices using the same solar panel. This kind of speed is a particular advantage for one of ApECOR’s target customers, the military, providing a means of quickly and efficiently charging the batteries used for radios and other devices in the field. \n                  Elmes says the NASA-derived X-90 is a promising addition to ApECOR’s offerings, and that other potential applications for the technology include providing power through solar or wind sources in rural farming areas in developing countries and allowing for the remote operation of irrigation pumps. The company is also engaged in another SBIR project with Glenn, working to develop high temperature semiconductors for applications in space, where extreme temperatures are the norm. This project could result in numerous terrestrial uses related to eliminating the problem of heat generated by powerful electronics—using temperature-tolerant semiconductors, costly and space-consuming elements like heat sinks and liquid coolant systems could be downsized or eliminated. \n                  “It’s hard for small businesses to pursue work like this that could have a major economic benefit down the road but is currently risky and difficult,” Elmes says. “The combination at NASA, where they have a very strong team of people who understand where the technology is going and can see where there are technological needs, provides a big benefit.\n                  \n                \n              \n                  NASA Technology\n                  On March 29, 2011, NASA’s Mercury Surface, Space Environment, Geochemistry and Ranging (MESSENGER) spacecraft beamed a milestone image to Earth: the first photo of Mercury taken from orbit around the solar system’s innermost planet. (MESSENGER is also the first spacecraft to orbit Mercury.) Like most of NASA’s deep space probes, MESSENGER is enabled by a complex power system that allows its science instruments and communications to function continuously as it travels millions of miles from Earth. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Technicians secure guide wires to one of MESSENGER’s two solar panels. The panels combine with a nickel hydrogen battery to power the spacecraft. \n                    \n                  \n                  “Typically, there isn’t one particular power source that can support the entire mission,” says Linda Taylor, electrical engineer in Glenn Research Center’s Power Systems Analysis Branch. “If you have solar arrays and you are in orbit, at some point you’re going to be in eclipse.” Because of this, Taylor explains, spacecraft like MESSENGER feature hybrid power systems. MESSENGER is powered by a two-panel solar array coupled with a nickel hydrogen battery. The solar arrays provide energy to the probe and charge the battery; when the spacecraft’s orbit carries it behind Mercury and out of the Sun’s light, the spacecraft switches to battery power to continue operations.\n                  Typically, hybrid systems with multiple power inputs and a battery acting alternately as storage and a power source require multiple converters to handle the power flow between the devices, Taylor says. (Power converters change the qualities of electrical energy, such as from alternating current to direct current, or between different levels of voltage or frequency.) This contributes to a pair of major concerns for spacecraft design.\n                  “Weight and size are big drivers for any space application,” Taylor says, noting that every pound added to a space vehicle incurs significant costs. For an innovative solution to managing power flows in a lightweight, cost-effective manner, NASA turned to a private industry partner. \n                  Partnership\n                  Through Small Business Innovation Research (SBIR) contracts with Glenn, Advanced Power Electronics Corporation (ApECOR) of Orlando, Florida, devised a three-port power converter for space systems. Much like a traffic cop at an intersection, the converter directs the flow and levels of electricity collected from solar panels, shunting part of that power into storage batteries, and pulling it out of the batteries to provide energy when solar panels are ineffective. \n                  “The control strategy becomes fairly complicated when you have multiple interfaces to the same converter,” says John Elmes, vice president of advanced technology for ApECOR. “The challenge is that you have so many conflicting control parameters, you have to figure out a way to simultaneously operate them.” \n                  “It’s hard for small businesses to pursue work like this that could have a major economic benefit down the road but is currently \n                    risky and difficult. NASA … provides a big benefit.”\n                    —John Elmes, ApECOR \n                  For the NASA project, ApECOR developed complex control algorithms for managing the power flows through a single device that has the potential to directly minimize the size and weight of overall spacecraft power systems. Taylor has used the SBIR-derived device for testing at Glenn and hopes to incorporate it into the Orion Crew Module test bed at the Center. In the meantime, ApECOR has applied the control algorithms it developed for the SBIR project to a new commercial product.\n                  Benefits\n                  \n                    \n                    \n                      \n                    \n                    \n                      ApECOR’s X-90 Solar Charger uses the company’s NASA-derived control algorithms to efficiently charge batteries from solar or \n                        other sources. \n                    \n                  \n                  ApECOR’s X-90 Solar Charger is capable of using a wide range of solar arrays or other DC sources to replenish portable rechargeable batteries. Plugging directly on top of compatible batteries and requiring only the wiring needed to link to the power source, the device makes use of Maximum Power Point Tracking (MPPT) technology to ensure it gathers the most energy possible from a connected solar panel. Solar panel output varies depending on the amount of light and other environmental conditions; MPPT constantly changes the operation of the panel to maximize its efficiency. ApECOR incorporated MPPT into the three-port converter it created for NASA, which in turn provided the company with the capability to add the feature to the X-90.\n                  “We were able to use what we learned from the NASA three-port converter work and use it to help implement our battery charge algorithms on the X-90 while also implementing MPPT on the solar panel,” Elmes says. The result, he says, is ApECOR’s product charges batteries at least 30 percent faster than comparative devices using the same solar panel. This kind of speed is a particular advantage for one of ApECOR’s target customers, the military, providing a means of quickly and efficiently charging the batteries used for radios and other devices in the field. \n                  Elmes says the NASA-derived X-90 is a promising addition to ApECOR’s offerings, and that other potential applications for the technology include providing power through solar or wind sources in rural farming areas in developing countries and allowing for the remote operation of irrigation pumps. The company is also engaged in another SBIR project with Glenn, working to develop high temperature semiconductors for applications in space, where extreme temperatures are the norm. This project could result in numerous terrestrial uses related to eliminating the problem of heat generated by powerful electronics—using temperature-tolerant semiconductors, costly and space-consuming elements like heat sinks and liquid coolant systems could be downsized or eliminated. \n                  “It’s hard for small businesses to pursue work like this that could have a major economic benefit down the road but is currently risky and difficult,” Elmes says. “The combination at NASA, where they have a very strong team of people who understand where the technology is going and can see where there are technological needs, provides a big benefit.\n                  "},{"href":"http://spinoff.nasa.gov/Spinoff2011/cg_2.html","text":"Software Programs Derive Measurements from Photographs","image":"http://spinoff.nasa.gov/Spinoff2011/Images/cg_3_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Even under the most unfortunate circumstances, NASA continues on a path of innovation. After the Space Shuttle Columbia reentered the atmosphere on February 1, 2003, it experienced a catastrophic failure, and the entire crew and vehicle were lost. For the two weeks prior to the accident, Columbia STS-107 was on a mission to perform physical, life, and space sciences research in the unique environment of microgravity. \n                  Following the accident, the remaining shuttles—Endeavor, Atlantis, and Discovery—were grounded, and an intense investigation ensued. The Columbia Accident Investigation Board spent nearly 7 months examining the cause of the accident and determining what would ensure a safe return to flight. To this end, investigators performed an extensive review down five analytic paths: aerodynamic, thermodynamic, sensor data timeline, debris reconstruction, and imaging. \n                  “NASA partnerships are beneficial because they provide access to the \n                    technologies that are being developed at the government level. They’re not in \n                    business to take these technologies to market, but we are.” \n                    —Paul Minor, DigiContractor                  \n                    \n                  \n                  \n                    \n                    \n                      \n                    \n                    \n                      Space Shuttle Discovery launched on July 26, 2005, ending the wait for the historic Return to Flight mission following the Columbia disaster.\n                    \n                  \n                  As part of the evaluation of all the available imagery from Columbia’s ascent, orbit, and entry, investigators needed a new method for analyzing still video images to determine the size of the material that fell from Columbia, as well as the distance that the material traveled. John Lane, a scientist at Kennedy Space Center, devised a software program to calculate the unknown dimension of the material in the images, and soon after the investigation was complete, continued to enhance the technology. Eventually, the program that assisted in the Columbia investigation became available for licensing.\n                  Partnership\n                  In 2008, DigiContractor Corporation of Tarzana, California, learned about the NASA software as well as an additional, related NASA program, and obtained a license for each technology. Paul Minor, founder of DigiContractor, wanted to use the NASA technology to enhance the capabilities of an existing product line called uPhotoMeasure. \n                  Originally developed to measure the dimensions of items in a photograph for construction purposes, uPhotoMeasure can be applied to calculate measurements from a photo for a variety of applications—from landscaping or flooring projects to crime scenes or auto accidents.\n                  “We dissected the NASA version and then we incorporated some of that technology into ours. It’s a benefit to our algorithms and gives an added level of accuracy,” says Minor. “NASA partnerships are beneficial because they provide access to the technologies that are being developed at the Government level. They’re not in business to take these technologies to market, but we are.”\n                  Benefits\n                  With a background in general contracting, Minor had become accustomed to estimating measurements from a photograph, but he wanted to apply a software program that could calculate accurate measurements from a photo. After working with a friend who helped him design the software, Minor tested and refined the technology. By 2004, he formed DigiContractor with funding from family and friends. \n                  \n                    \n                    \n                      \n                    \n                    \n                      DigiContractor licensed NASA technology to incorporate into uPhotoMeasure, a software program that calculates measurements from a photo. After the user defines the measurements for a known reference point, the program can calculate length, width, area, perimeter, or circumference of other items.\n                    \n                  \n                  Over the next several years, the software was modified and updated, and now includes the NASA technology. According to the company, if used correctly, uPhotoMeasure can make measurements with at least 95-percent accuracy. Today, the software has close to 5,000 users who have downloaded the program to their computers or access the software on the Internet. \n                  After taking a digital photo of an area to be measured, a user can access the photo through uPhotoMeasure. Then the user selects and defines a point of reference that can be anything in the image with a known measurement such as a window, tile, or DigiTarget (a square piece of material sold by DigiContractor that can be placed in the area where the picture is taken). After the user defines the measurements for the known reference point, the program can calculate the length, width, area, perimeter, or circumference of other items in the picture. Multiple measurements can be calculated in either conventional or metric units, and after the measurements are displayed on the photo, a user can save, archive, print, or email the image. This is especially convenient for sharing project measurements between individuals and businesses. \n                  “We set out to be able to provide this technology at a certain price point to be able to be used by anybody, including the homeowner,” says Minor. \n                  For outdoor landscaping or roofing projects, a satellite image can be used in uPhotoMeasure to calculate measurements. As in many other applications, the product can potentially save time and expense because there is no need to visit a site and use a measuring tape; users simply obtain a photograph of the project and then analyze it in uPhotoMeasure. A photo can be shared among multiple parties, an estimate can be made, and the proper amount of materials can be obtained. \n                  “You can actually see the measurements in the photo and make a rough decision. You can get a pretty good idea of what a project will cost,” says Minor. \n                   According to Minor, uPhotoMeasure has endless applications for anyone who needs precise measurements. Potential and existing users include, but are not limited to, architects; concrete and asphalt companies; developers; electrical engineers; enterprises and original equipment manufacturers; fencing and flooring companies; garage door and gutter companies; interior and exterior designers; landscaping; law enforcement; painters and plumbers; real estate professionals; sign, label, and decal companies; and swimming pool and spa companies. Even oceanographers have used the software to measure coral growth in a controlled environment. In addition, it has been applied to photos taken underwater to assist with oil rig repair and salvage work. \n                  While there are other products on the market similar to uPhotoMeasure, Minor finds them to be more time consuming and expensive. As an example, he notes one police department that purchased a similar product, but is not using it because it takes too much time to set up to obtain dimensions. Minor says uPhotoMeasure could be used by police to clear the roads faster at an accident scene, using photographs to derive measurements rather than delaying traffic by taking measurements at the site.\n                  “There are other technologies out there, but we are inexpensive,” he says. “Plus, we have better accuracy, thanks to NASA.”\n                  uPhotoMeasure™ is a trademark of DigiContractor Corporation.\n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Even under the most unfortunate circumstances, NASA continues on a path of innovation. After the Space Shuttle Columbia reentered the atmosphere on February 1, 2003, it experienced a catastrophic failure, and the entire crew and vehicle were lost. For the two weeks prior to the accident, Columbia STS-107 was on a mission to perform physical, life, and space sciences research in the unique environment of microgravity. \n                  Following the accident, the remaining shuttles—Endeavor, Atlantis, and Discovery—were grounded, and an intense investigation ensued. The Columbia Accident Investigation Board spent nearly 7 months examining the cause of the accident and determining what would ensure a safe return to flight. To this end, investigators performed an extensive review down five analytic paths: aerodynamic, thermodynamic, sensor data timeline, debris reconstruction, and imaging. \n                  “NASA partnerships are beneficial because they provide access to the \n                    technologies that are being developed at the government level. They’re not in \n                    business to take these technologies to market, but we are.” \n                    —Paul Minor, DigiContractor                  \n                    \n                  \n                  \n                    \n                    \n                      \n                    \n                    \n                      Space Shuttle Discovery launched on July 26, 2005, ending the wait for the historic Return to Flight mission following the Columbia disaster.\n                    \n                  \n                  As part of the evaluation of all the available imagery from Columbia’s ascent, orbit, and entry, investigators needed a new method for analyzing still video images to determine the size of the material that fell from Columbia, as well as the distance that the material traveled. John Lane, a scientist at Kennedy Space Center, devised a software program to calculate the unknown dimension of the material in the images, and soon after the investigation was complete, continued to enhance the technology. Eventually, the program that assisted in the Columbia investigation became available for licensing.\n                  Partnership\n                  In 2008, DigiContractor Corporation of Tarzana, California, learned about the NASA software as well as an additional, related NASA program, and obtained a license for each technology. Paul Minor, founder of DigiContractor, wanted to use the NASA technology to enhance the capabilities of an existing product line called uPhotoMeasure. \n                  Originally developed to measure the dimensions of items in a photograph for construction purposes, uPhotoMeasure can be applied to calculate measurements from a photo for a variety of applications—from landscaping or flooring projects to crime scenes or auto accidents.\n                  “We dissected the NASA version and then we incorporated some of that technology into ours. It’s a benefit to our algorithms and gives an added level of accuracy,” says Minor. “NASA partnerships are beneficial because they provide access to the technologies that are being developed at the Government level. They’re not in business to take these technologies to market, but we are.”\n                  Benefits\n                  With a background in general contracting, Minor had become accustomed to estimating measurements from a photograph, but he wanted to apply a software program that could calculate accurate measurements from a photo. After working with a friend who helped him design the software, Minor tested and refined the technology. By 2004, he formed DigiContractor with funding from family and friends. \n                  \n                    \n                    \n                      \n                    \n                    \n                      DigiContractor licensed NASA technology to incorporate into uPhotoMeasure, a software program that calculates measurements from a photo. After the user defines the measurements for a known reference point, the program can calculate length, width, area, perimeter, or circumference of other items.\n                    \n                  \n                  Over the next several years, the software was modified and updated, and now includes the NASA technology. According to the company, if used correctly, uPhotoMeasure can make measurements with at least 95-percent accuracy. Today, the software has close to 5,000 users who have downloaded the program to their computers or access the software on the Internet. \n                  After taking a digital photo of an area to be measured, a user can access the photo through uPhotoMeasure. Then the user selects and defines a point of reference that can be anything in the image with a known measurement such as a window, tile, or DigiTarget (a square piece of material sold by DigiContractor that can be placed in the area where the picture is taken). After the user defines the measurements for the known reference point, the program can calculate the length, width, area, perimeter, or circumference of other items in the picture. Multiple measurements can be calculated in either conventional or metric units, and after the measurements are displayed on the photo, a user can save, archive, print, or email the image. This is especially convenient for sharing project measurements between individuals and businesses. \n                  “We set out to be able to provide this technology at a certain price point to be able to be used by anybody, including the homeowner,” says Minor. \n                  For outdoor landscaping or roofing projects, a satellite image can be used in uPhotoMeasure to calculate measurements. As in many other applications, the product can potentially save time and expense because there is no need to visit a site and use a measuring tape; users simply obtain a photograph of the project and then analyze it in uPhotoMeasure. A photo can be shared among multiple parties, an estimate can be made, and the proper amount of materials can be obtained. \n                  “You can actually see the measurements in the photo and make a rough decision. You can get a pretty good idea of what a project will cost,” says Minor. \n                   According to Minor, uPhotoMeasure has endless applications for anyone who needs precise measurements. Potential and existing users include, but are not limited to, architects; concrete and asphalt companies; developers; electrical engineers; enterprises and original equipment manufacturers; fencing and flooring companies; garage door and gutter companies; interior and exterior designers; landscaping; law enforcement; painters and plumbers; real estate professionals; sign, label, and decal companies; and swimming pool and spa companies. Even oceanographers have used the software to measure coral growth in a controlled environment. In addition, it has been applied to photos taken underwater to assist with oil rig repair and salvage work. \n                  While there are other products on the market similar to uPhotoMeasure, Minor finds them to be more time consuming and expensive. As an example, he notes one police department that purchased a similar product, but is not using it because it takes too much time to set up to obtain dimensions. Minor says uPhotoMeasure could be used by police to clear the roads faster at an accident scene, using photographs to derive measurements rather than delaying traffic by taking measurements at the site.\n                  “There are other technologies out there, but we are inexpensive,” he says. “Plus, we have better accuracy, thanks to NASA.”\n                  uPhotoMeasure™ is a trademark of DigiContractor Corporation.\n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Even under the most unfortunate circumstances, NASA continues on a path of innovation. After the Space Shuttle Columbia reentered the atmosphere on February 1, 2003, it experienced a catastrophic failure, and the entire crew and vehicle were lost. For the two weeks prior to the accident, Columbia STS-107 was on a mission to perform physical, life, and space sciences research in the unique environment of microgravity. \n                  Following the accident, the remaining shuttles—Endeavor, Atlantis, and Discovery—were grounded, and an intense investigation ensued. The Columbia Accident Investigation Board spent nearly 7 months examining the cause of the accident and determining what would ensure a safe return to flight. To this end, investigators performed an extensive review down five analytic paths: aerodynamic, thermodynamic, sensor data timeline, debris reconstruction, and imaging. \n                  “NASA partnerships are beneficial because they provide access to the \n                    technologies that are being developed at the government level. They’re not in \n                    business to take these technologies to market, but we are.” \n                    —Paul Minor, DigiContractor                  \n                    \n                  \n                  \n                    \n                    \n                      \n                    \n                    \n                      Space Shuttle Discovery launched on July 26, 2005, ending the wait for the historic Return to Flight mission following the Columbia disaster.\n                    \n                  \n                  As part of the evaluation of all the available imagery from Columbia’s ascent, orbit, and entry, investigators needed a new method for analyzing still video images to determine the size of the material that fell from Columbia, as well as the distance that the material traveled. John Lane, a scientist at Kennedy Space Center, devised a software program to calculate the unknown dimension of the material in the images, and soon after the investigation was complete, continued to enhance the technology. Eventually, the program that assisted in the Columbia investigation became available for licensing.\n                  Partnership\n                  In 2008, DigiContractor Corporation of Tarzana, California, learned about the NASA software as well as an additional, related NASA program, and obtained a license for each technology. Paul Minor, founder of DigiContractor, wanted to use the NASA technology to enhance the capabilities of an existing product line called uPhotoMeasure. \n                  Originally developed to measure the dimensions of items in a photograph for construction purposes, uPhotoMeasure can be applied to calculate measurements from a photo for a variety of applications—from landscaping or flooring projects to crime scenes or auto accidents.\n                  “We dissected the NASA version and then we incorporated some of that technology into ours. It’s a benefit to our algorithms and gives an added level of accuracy,” says Minor. “NASA partnerships are beneficial because they provide access to the technologies that are being developed at the Government level. They’re not in business to take these technologies to market, but we are.”\n                  Benefits\n                  With a background in general contracting, Minor had become accustomed to estimating measurements from a photograph, but he wanted to apply a software program that could calculate accurate measurements from a photo. After working with a friend who helped him design the software, Minor tested and refined the technology. By 2004, he formed DigiContractor with funding from family and friends. \n                  \n                    \n                    \n                      \n                    \n                    \n                      DigiContractor licensed NASA technology to incorporate into uPhotoMeasure, a software program that calculates measurements from a photo. After the user defines the measurements for a known reference point, the program can calculate length, width, area, perimeter, or circumference of other items.\n                    \n                  \n                  Over the next several years, the software was modified and updated, and now includes the NASA technology. According to the company, if used correctly, uPhotoMeasure can make measurements with at least 95-percent accuracy. Today, the software has close to 5,000 users who have downloaded the program to their computers or access the software on the Internet. \n                  After taking a digital photo of an area to be measured, a user can access the photo through uPhotoMeasure. Then the user selects and defines a point of reference that can be anything in the image with a known measurement such as a window, tile, or DigiTarget (a square piece of material sold by DigiContractor that can be placed in the area where the picture is taken). After the user defines the measurements for the known reference point, the program can calculate the length, width, area, perimeter, or circumference of other items in the picture. Multiple measurements can be calculated in either conventional or metric units, and after the measurements are displayed on the photo, a user can save, archive, print, or email the image. This is especially convenient for sharing project measurements between individuals and businesses. \n                  “We set out to be able to provide this technology at a certain price point to be able to be used by anybody, including the homeowner,” says Minor. \n                  For outdoor landscaping or roofing projects, a satellite image can be used in uPhotoMeasure to calculate measurements. As in many other applications, the product can potentially save time and expense because there is no need to visit a site and use a measuring tape; users simply obtain a photograph of the project and then analyze it in uPhotoMeasure. A photo can be shared among multiple parties, an estimate can be made, and the proper amount of materials can be obtained. \n                  “You can actually see the measurements in the photo and make a rough decision. You can get a pretty good idea of what a project will cost,” says Minor. \n                   According to Minor, uPhotoMeasure has endless applications for anyone who needs precise measurements. Potential and existing users include, but are not limited to, architects; concrete and asphalt companies; developers; electrical engineers; enterprises and original equipment manufacturers; fencing and flooring companies; garage door and gutter companies; interior and exterior designers; landscaping; law enforcement; painters and plumbers; real estate professionals; sign, label, and decal companies; and swimming pool and spa companies. Even oceanographers have used the software to measure coral growth in a controlled environment. In addition, it has been applied to photos taken underwater to assist with oil rig repair and salvage work. \n                  While there are other products on the market similar to uPhotoMeasure, Minor finds them to be more time consuming and expensive. As an example, he notes one police department that purchased a similar product, but is not using it because it takes too much time to set up to obtain dimensions. Minor says uPhotoMeasure could be used by police to clear the roads faster at an accident scene, using photographs to derive measurements rather than delaying traffic by taking measurements at the site.\n                  “There are other technologies out there, but we are inexpensive,” he says. “Plus, we have better accuracy, thanks to NASA.”\n                  uPhotoMeasure™ is a trademark of DigiContractor Corporation.\n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Even under the most unfortunate circumstances, NASA continues on a path of innovation. After the Space Shuttle Columbia reentered the atmosphere on February 1, 2003, it experienced a catastrophic failure, and the entire crew and vehicle were lost. For the two weeks prior to the accident, Columbia STS-107 was on a mission to perform physical, life, and space sciences research in the unique environment of microgravity. \n                  Following the accident, the remaining shuttles—Endeavor, Atlantis, and Discovery—were grounded, and an intense investigation ensued. The Columbia Accident Investigation Board spent nearly 7 months examining the cause of the accident and determining what would ensure a safe return to flight. To this end, investigators performed an extensive review down five analytic paths: aerodynamic, thermodynamic, sensor data timeline, debris reconstruction, and imaging. \n                  “NASA partnerships are beneficial because they provide access to the \n                    technologies that are being developed at the government level. They’re not in \n                    business to take these technologies to market, but we are.” \n                    —Paul Minor, DigiContractor                  \n                    \n                  \n                  \n                    \n                    \n                      \n                    \n                    \n                      Space Shuttle Discovery launched on July 26, 2005, ending the wait for the historic Return to Flight mission following the Columbia disaster.\n                    \n                  \n                  As part of the evaluation of all the available imagery from Columbia’s ascent, orbit, and entry, investigators needed a new method for analyzing still video images to determine the size of the material that fell from Columbia, as well as the distance that the material traveled. John Lane, a scientist at Kennedy Space Center, devised a software program to calculate the unknown dimension of the material in the images, and soon after the investigation was complete, continued to enhance the technology. Eventually, the program that assisted in the Columbia investigation became available for licensing.\n                  Partnership\n                  In 2008, DigiContractor Corporation of Tarzana, California, learned about the NASA software as well as an additional, related NASA program, and obtained a license for each technology. Paul Minor, founder of DigiContractor, wanted to use the NASA technology to enhance the capabilities of an existing product line called uPhotoMeasure. \n                  Originally developed to measure the dimensions of items in a photograph for construction purposes, uPhotoMeasure can be applied to calculate measurements from a photo for a variety of applications—from landscaping or flooring projects to crime scenes or auto accidents.\n                  “We dissected the NASA version and then we incorporated some of that technology into ours. It’s a benefit to our algorithms and gives an added level of accuracy,” says Minor. “NASA partnerships are beneficial because they provide access to the technologies that are being developed at the Government level. They’re not in business to take these technologies to market, but we are.”\n                  Benefits\n                  With a background in general contracting, Minor had become accustomed to estimating measurements from a photograph, but he wanted to apply a software program that could calculate accurate measurements from a photo. After working with a friend who helped him design the software, Minor tested and refined the technology. By 2004, he formed DigiContractor with funding from family and friends. \n                  \n                    \n                    \n                      \n                    \n                    \n                      DigiContractor licensed NASA technology to incorporate into uPhotoMeasure, a software program that calculates measurements from a photo. After the user defines the measurements for a known reference point, the program can calculate length, width, area, perimeter, or circumference of other items.\n                    \n                  \n                  Over the next several years, the software was modified and updated, and now includes the NASA technology. According to the company, if used correctly, uPhotoMeasure can make measurements with at least 95-percent accuracy. Today, the software has close to 5,000 users who have downloaded the program to their computers or access the software on the Internet. \n                  After taking a digital photo of an area to be measured, a user can access the photo through uPhotoMeasure. Then the user selects and defines a point of reference that can be anything in the image with a known measurement such as a window, tile, or DigiTarget (a square piece of material sold by DigiContractor that can be placed in the area where the picture is taken). After the user defines the measurements for the known reference point, the program can calculate the length, width, area, perimeter, or circumference of other items in the picture. Multiple measurements can be calculated in either conventional or metric units, and after the measurements are displayed on the photo, a user can save, archive, print, or email the image. This is especially convenient for sharing project measurements between individuals and businesses. \n                  “We set out to be able to provide this technology at a certain price point to be able to be used by anybody, including the homeowner,” says Minor. \n                  For outdoor landscaping or roofing projects, a satellite image can be used in uPhotoMeasure to calculate measurements. As in many other applications, the product can potentially save time and expense because there is no need to visit a site and use a measuring tape; users simply obtain a photograph of the project and then analyze it in uPhotoMeasure. A photo can be shared among multiple parties, an estimate can be made, and the proper amount of materials can be obtained. \n                  “You can actually see the measurements in the photo and make a rough decision. You can get a pretty good idea of what a project will cost,” says Minor. \n                   According to Minor, uPhotoMeasure has endless applications for anyone who needs precise measurements. Potential and existing users include, but are not limited to, architects; concrete and asphalt companies; developers; electrical engineers; enterprises and original equipment manufacturers; fencing and flooring companies; garage door and gutter companies; interior and exterior designers; landscaping; law enforcement; painters and plumbers; real estate professionals; sign, label, and decal companies; and swimming pool and spa companies. Even oceanographers have used the software to measure coral growth in a controlled environment. In addition, it has been applied to photos taken underwater to assist with oil rig repair and salvage work. \n                  While there are other products on the market similar to uPhotoMeasure, Minor finds them to be more time consuming and expensive. As an example, he notes one police department that purchased a similar product, but is not using it because it takes too much time to set up to obtain dimensions. Minor says uPhotoMeasure could be used by police to clear the roads faster at an accident scene, using photographs to derive measurements rather than delaying traffic by taking measurements at the site.\n                  “There are other technologies out there, but we are inexpensive,” he says. “Plus, we have better accuracy, thanks to NASA.”\n                  uPhotoMeasure™ is a trademark of DigiContractor Corporation.\n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  NASA Technology\n                  Even under the most unfortunate circumstances, NASA continues on a path of innovation. After the Space Shuttle Columbia reentered the atmosphere on February 1, 2003, it experienced a catastrophic failure, and the entire crew and vehicle were lost. For the two weeks prior to the accident, Columbia STS-107 was on a mission to perform physical, life, and space sciences research in the unique environment of microgravity. \n                  Following the accident, the remaining shuttles—Endeavor, Atlantis, and Discovery—were grounded, and an intense investigation ensued. The Columbia Accident Investigation Board spent nearly 7 months examining the cause of the accident and determining what would ensure a safe return to flight. To this end, investigators performed an extensive review down five analytic paths: aerodynamic, thermodynamic, sensor data timeline, debris reconstruction, and imaging. \n                  “NASA partnerships are beneficial because they provide access to the \n                    technologies that are being developed at the government level. They’re not in \n                    business to take these technologies to market, but we are.” \n                    —Paul Minor, DigiContractor                  \n                    \n                  \n                  \n                    \n                    \n                      \n                    \n                    \n                      Space Shuttle Discovery launched on July 26, 2005, ending the wait for the historic Return to Flight mission following the Columbia disaster.\n                    \n                  \n                  As part of the evaluation of all the available imagery from Columbia’s ascent, orbit, and entry, investigators needed a new method for analyzing still video images to determine the size of the material that fell from Columbia, as well as the distance that the material traveled. John Lane, a scientist at Kennedy Space Center, devised a software program to calculate the unknown dimension of the material in the images, and soon after the investigation was complete, continued to enhance the technology. Eventually, the program that assisted in the Columbia investigation became available for licensing.\n                  Partnership\n                  In 2008, DigiContractor Corporation of Tarzana, California, learned about the NASA software as well as an additional, related NASA program, and obtained a license for each technology. Paul Minor, founder of DigiContractor, wanted to use the NASA technology to enhance the capabilities of an existing product line called uPhotoMeasure. \n                  Originally developed to measure the dimensions of items in a photograph for construction purposes, uPhotoMeasure can be applied to calculate measurements from a photo for a variety of applications—from landscaping or flooring projects to crime scenes or auto accidents.\n                  “We dissected the NASA version and then we incorporated some of that technology into ours. It’s a benefit to our algorithms and gives an added level of accuracy,” says Minor. “NASA partnerships are beneficial because they provide access to the technologies that are being developed at the Government level. They’re not in business to take these technologies to market, but we are.”\n                  Benefits\n                  With a background in general contracting, Minor had become accustomed to estimating measurements from a photograph, but he wanted to apply a software program that could calculate accurate measurements from a photo. After working with a friend who helped him design the software, Minor tested and refined the technology. By 2004, he formed DigiContractor with funding from family and friends. \n                  \n                    \n                    \n                      \n                    \n                    \n                      DigiContractor licensed NASA technology to incorporate into uPhotoMeasure, a software program that calculates measurements from a photo. After the user defines the measurements for a known reference point, the program can calculate length, width, area, perimeter, or circumference of other items.\n                    \n                  \n                  Over the next several years, the software was modified and updated, and now includes the NASA technology. According to the company, if used correctly, uPhotoMeasure can make measurements with at least 95-percent accuracy. Today, the software has close to 5,000 users who have downloaded the program to their computers or access the software on the Internet. \n                  After taking a digital photo of an area to be measured, a user can access the photo through uPhotoMeasure. Then the user selects and defines a point of reference that can be anything in the image with a known measurement such as a window, tile, or DigiTarget (a square piece of material sold by DigiContractor that can be placed in the area where the picture is taken). After the user defines the measurements for the known reference point, the program can calculate the length, width, area, perimeter, or circumference of other items in the picture. Multiple measurements can be calculated in either conventional or metric units, and after the measurements are displayed on the photo, a user can save, archive, print, or email the image. This is especially convenient for sharing project measurements between individuals and businesses. \n                  “We set out to be able to provide this technology at a certain price point to be able to be used by anybody, including the homeowner,” says Minor. \n                  For outdoor landscaping or roofing projects, a satellite image can be used in uPhotoMeasure to calculate measurements. As in many other applications, the product can potentially save time and expense because there is no need to visit a site and use a measuring tape; users simply obtain a photograph of the project and then analyze it in uPhotoMeasure. A photo can be shared among multiple parties, an estimate can be made, and the proper amount of materials can be obtained. \n                  “You can actually see the measurements in the photo and make a rough decision. You can get a pretty good idea of what a project will cost,” says Minor. \n                   According to Minor, uPhotoMeasure has endless applications for anyone who needs precise measurements. Potential and existing users include, but are not limited to, architects; concrete and asphalt companies; developers; electrical engineers; enterprises and original equipment manufacturers; fencing and flooring companies; garage door and gutter companies; interior and exterior designers; landscaping; law enforcement; painters and plumbers; real estate professionals; sign, label, and decal companies; and swimming pool and spa companies. Even oceanographers have used the software to measure coral growth in a controlled environment. In addition, it has been applied to photos taken underwater to assist with oil rig repair and salvage work. \n                  While there are other products on the market similar to uPhotoMeasure, Minor finds them to be more time consuming and expensive. As an example, he notes one police department that purchased a similar product, but is not using it because it takes too much time to set up to obtain dimensions. Minor says uPhotoMeasure could be used by police to clear the roads faster at an accident scene, using photographs to derive measurements rather than delaying traffic by taking measurements at the site.\n                  “There are other technologies out there, but we are inexpensive,” he says. “Plus, we have better accuracy, thanks to NASA.”\n                  uPhotoMeasure™ is a trademark of DigiContractor Corporation.\n                  \n                \n              \n            \n            \n              \n                \n                  NASA Technology\n                  Even under the most unfortunate circumstances, NASA continues on a path of innovation. After the Space Shuttle Columbia reentered the atmosphere on February 1, 2003, it experienced a catastrophic failure, and the entire crew and vehicle were lost. For the two weeks prior to the accident, Columbia STS-107 was on a mission to perform physical, life, and space sciences research in the unique environment of microgravity. \n                  Following the accident, the remaining shuttles—Endeavor, Atlantis, and Discovery—were grounded, and an intense investigation ensued. The Columbia Accident Investigation Board spent nearly 7 months examining the cause of the accident and determining what would ensure a safe return to flight. To this end, investigators performed an extensive review down five analytic paths: aerodynamic, thermodynamic, sensor data timeline, debris reconstruction, and imaging. \n                  “NASA partnerships are beneficial because they provide access to the \n                    technologies that are being developed at the government level. They’re not in \n                    business to take these technologies to market, but we are.” \n                    —Paul Minor, DigiContractor                  \n                    \n                  \n                  \n                    \n                    \n                      \n                    \n                    \n                      Space Shuttle Discovery launched on July 26, 2005, ending the wait for the historic Return to Flight mission following the Columbia disaster.\n                    \n                  \n                  As part of the evaluation of all the available imagery from Columbia’s ascent, orbit, and entry, investigators needed a new method for analyzing still video images to determine the size of the material that fell from Columbia, as well as the distance that the material traveled. John Lane, a scientist at Kennedy Space Center, devised a software program to calculate the unknown dimension of the material in the images, and soon after the investigation was complete, continued to enhance the technology. Eventually, the program that assisted in the Columbia investigation became available for licensing.\n                  Partnership\n                  In 2008, DigiContractor Corporation of Tarzana, California, learned about the NASA software as well as an additional, related NASA program, and obtained a license for each technology. Paul Minor, founder of DigiContractor, wanted to use the NASA technology to enhance the capabilities of an existing product line called uPhotoMeasure. \n                  Originally developed to measure the dimensions of items in a photograph for construction purposes, uPhotoMeasure can be applied to calculate measurements from a photo for a variety of applications—from landscaping or flooring projects to crime scenes or auto accidents.\n                  “We dissected the NASA version and then we incorporated some of that technology into ours. It’s a benefit to our algorithms and gives an added level of accuracy,” says Minor. “NASA partnerships are beneficial because they provide access to the technologies that are being developed at the Government level. They’re not in business to take these technologies to market, but we are.”\n                  Benefits\n                  With a background in general contracting, Minor had become accustomed to estimating measurements from a photograph, but he wanted to apply a software program that could calculate accurate measurements from a photo. After working with a friend who helped him design the software, Minor tested and refined the technology. By 2004, he formed DigiContractor with funding from family and friends. \n                  \n                    \n                    \n                      \n                    \n                    \n                      DigiContractor licensed NASA technology to incorporate into uPhotoMeasure, a software program that calculates measurements from a photo. After the user defines the measurements for a known reference point, the program can calculate length, width, area, perimeter, or circumference of other items.\n                    \n                  \n                  Over the next several years, the software was modified and updated, and now includes the NASA technology. According to the company, if used correctly, uPhotoMeasure can make measurements with at least 95-percent accuracy. Today, the software has close to 5,000 users who have downloaded the program to their computers or access the software on the Internet. \n                  After taking a digital photo of an area to be measured, a user can access the photo through uPhotoMeasure. Then the user selects and defines a point of reference that can be anything in the image with a known measurement such as a window, tile, or DigiTarget (a square piece of material sold by DigiContractor that can be placed in the area where the picture is taken). After the user defines the measurements for the known reference point, the program can calculate the length, width, area, perimeter, or circumference of other items in the picture. Multiple measurements can be calculated in either conventional or metric units, and after the measurements are displayed on the photo, a user can save, archive, print, or email the image. This is especially convenient for sharing project measurements between individuals and businesses. \n                  “We set out to be able to provide this technology at a certain price point to be able to be used by anybody, including the homeowner,” says Minor. \n                  For outdoor landscaping or roofing projects, a satellite image can be used in uPhotoMeasure to calculate measurements. As in many other applications, the product can potentially save time and expense because there is no need to visit a site and use a measuring tape; users simply obtain a photograph of the project and then analyze it in uPhotoMeasure. A photo can be shared among multiple parties, an estimate can be made, and the proper amount of materials can be obtained. \n                  “You can actually see the measurements in the photo and make a rough decision. You can get a pretty good idea of what a project will cost,” says Minor. \n                   According to Minor, uPhotoMeasure has endless applications for anyone who needs precise measurements. Potential and existing users include, but are not limited to, architects; concrete and asphalt companies; developers; electrical engineers; enterprises and original equipment manufacturers; fencing and flooring companies; garage door and gutter companies; interior and exterior designers; landscaping; law enforcement; painters and plumbers; real estate professionals; sign, label, and decal companies; and swimming pool and spa companies. Even oceanographers have used the software to measure coral growth in a controlled environment. In addition, it has been applied to photos taken underwater to assist with oil rig repair and salvage work. \n                  While there are other products on the market similar to uPhotoMeasure, Minor finds them to be more time consuming and expensive. As an example, he notes one police department that purchased a similar product, but is not using it because it takes too much time to set up to obtain dimensions. Minor says uPhotoMeasure could be used by police to clear the roads faster at an accident scene, using photographs to derive measurements rather than delaying traffic by taking measurements at the site.\n                  “There are other technologies out there, but we are inexpensive,” he says. “Plus, we have better accuracy, thanks to NASA.”\n                  uPhotoMeasure™ is a trademark of DigiContractor Corporation.\n                  \n                \n              \n                  NASA Technology\n                  Even under the most unfortunate circumstances, NASA continues on a path of innovation. After the Space Shuttle Columbia reentered the atmosphere on February 1, 2003, it experienced a catastrophic failure, and the entire crew and vehicle were lost. For the two weeks prior to the accident, Columbia STS-107 was on a mission to perform physical, life, and space sciences research in the unique environment of microgravity. \n                  Following the accident, the remaining shuttles—Endeavor, Atlantis, and Discovery—were grounded, and an intense investigation ensued. The Columbia Accident Investigation Board spent nearly 7 months examining the cause of the accident and determining what would ensure a safe return to flight. To this end, investigators performed an extensive review down five analytic paths: aerodynamic, thermodynamic, sensor data timeline, debris reconstruction, and imaging. \n                  “NASA partnerships are beneficial because they provide access to the \n                    technologies that are being developed at the government level. They’re not in \n                    business to take these technologies to market, but we are.” \n                    —Paul Minor, DigiContractor                  \n                    \n                  \n                  \n                    \n                    \n                      \n                    \n                    \n                      Space Shuttle Discovery launched on July 26, 2005, ending the wait for the historic Return to Flight mission following the Columbia disaster.\n                    \n                  \n                  As part of the evaluation of all the available imagery from Columbia’s ascent, orbit, and entry, investigators needed a new method for analyzing still video images to determine the size of the material that fell from Columbia, as well as the distance that the material traveled. John Lane, a scientist at Kennedy Space Center, devised a software program to calculate the unknown dimension of the material in the images, and soon after the investigation was complete, continued to enhance the technology. Eventually, the program that assisted in the Columbia investigation became available for licensing.\n                  Partnership\n                  In 2008, DigiContractor Corporation of Tarzana, California, learned about the NASA software as well as an additional, related NASA program, and obtained a license for each technology. Paul Minor, founder of DigiContractor, wanted to use the NASA technology to enhance the capabilities of an existing product line called uPhotoMeasure. \n                  Originally developed to measure the dimensions of items in a photograph for construction purposes, uPhotoMeasure can be applied to calculate measurements from a photo for a variety of applications—from landscaping or flooring projects to crime scenes or auto accidents.\n                  “We dissected the NASA version and then we incorporated some of that technology into ours. It’s a benefit to our algorithms and gives an added level of accuracy,” says Minor. “NASA partnerships are beneficial because they provide access to the technologies that are being developed at the Government level. They’re not in business to take these technologies to market, but we are.”\n                  Benefits\n                  With a background in general contracting, Minor had become accustomed to estimating measurements from a photograph, but he wanted to apply a software program that could calculate accurate measurements from a photo. After working with a friend who helped him design the software, Minor tested and refined the technology. By 2004, he formed DigiContractor with funding from family and friends. \n                  \n                    \n                    \n                      \n                    \n                    \n                      DigiContractor licensed NASA technology to incorporate into uPhotoMeasure, a software program that calculates measurements from a photo. After the user defines the measurements for a known reference point, the program can calculate length, width, area, perimeter, or circumference of other items.\n                    \n                  \n                  Over the next several years, the software was modified and updated, and now includes the NASA technology. According to the company, if used correctly, uPhotoMeasure can make measurements with at least 95-percent accuracy. Today, the software has close to 5,000 users who have downloaded the program to their computers or access the software on the Internet. \n                  After taking a digital photo of an area to be measured, a user can access the photo through uPhotoMeasure. Then the user selects and defines a point of reference that can be anything in the image with a known measurement such as a window, tile, or DigiTarget (a square piece of material sold by DigiContractor that can be placed in the area where the picture is taken). After the user defines the measurements for the known reference point, the program can calculate the length, width, area, perimeter, or circumference of other items in the picture. Multiple measurements can be calculated in either conventional or metric units, and after the measurements are displayed on the photo, a user can save, archive, print, or email the image. This is especially convenient for sharing project measurements between individuals and businesses. \n                  “We set out to be able to provide this technology at a certain price point to be able to be used by anybody, including the homeowner,” says Minor. \n                  For outdoor landscaping or roofing projects, a satellite image can be used in uPhotoMeasure to calculate measurements. As in many other applications, the product can potentially save time and expense because there is no need to visit a site and use a measuring tape; users simply obtain a photograph of the project and then analyze it in uPhotoMeasure. A photo can be shared among multiple parties, an estimate can be made, and the proper amount of materials can be obtained. \n                  “You can actually see the measurements in the photo and make a rough decision. You can get a pretty good idea of what a project will cost,” says Minor. \n                   According to Minor, uPhotoMeasure has endless applications for anyone who needs precise measurements. Potential and existing users include, but are not limited to, architects; concrete and asphalt companies; developers; electrical engineers; enterprises and original equipment manufacturers; fencing and flooring companies; garage door and gutter companies; interior and exterior designers; landscaping; law enforcement; painters and plumbers; real estate professionals; sign, label, and decal companies; and swimming pool and spa companies. Even oceanographers have used the software to measure coral growth in a controlled environment. In addition, it has been applied to photos taken underwater to assist with oil rig repair and salvage work. \n                  While there are other products on the market similar to uPhotoMeasure, Minor finds them to be more time consuming and expensive. As an example, he notes one police department that purchased a similar product, but is not using it because it takes too much time to set up to obtain dimensions. Minor says uPhotoMeasure could be used by police to clear the roads faster at an accident scene, using photographs to derive measurements rather than delaying traffic by taking measurements at the site.\n                  “There are other technologies out there, but we are inexpensive,” he says. “Plus, we have better accuracy, thanks to NASA.”\n                  uPhotoMeasure™ is a trademark of DigiContractor Corporation.\n                  "},{"href":"http://spinoff.nasa.gov/Spinoff2011/cg_3.html","text":"Retrofits Convert Gas Vehicles into Hybrids","image":"http://spinoff.nasa.gov/Spinoff2011/Images/cg_5_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Successful space missions can rarely be attributed to a single thing. Rather, they are the result of a system of systems: integrated elements functioning effectively in their individual roles and together with related components, then those systems interacting with and supporting other systems to form a collaborative whole—from the spacecraft itself to the engineering and research teams that design and build it.\n                  An example is found in spacecraft power systems. Unlike a gas-powered car or a battery-powered laptop, most spacecraft are powered by multiple energy sources—such as photovoltaic panels, fuel cells, and batteries—working in tandem to ensure the spacecraft functions throughout the course of a mission. As with any system, the appropriate combination of elements and the method of their management are key to high performance and efficiency.\n                  One initiative at Glenn Research Center, the Hybrid Power Management (HPM) program, focused on joining new and mature technologies for optimal power systems applications in space and on Earth, with the goal not only to develop ultra-efficient space power systems, but to advance HPM to address global energy issues. The HPM program emerged from Glenn’s long history of electric vehicle research dating back to the 1970s, including the NASA Hybrid Electric Transit Bus (HETB) project in the 1990s, which was the largest vehicle to use supercapacitor energy storage.\n                  Unlike batteries that store and discharge energy through chemical reactions, supercapacitors store energy electrostatically. In this way, supercapacitors charge and release energy more quickly than a battery, and unlike a battery, can tolerate up to 1 million charge and discharge cycles without wearing out. Though there were certain disadvantages compared to batteries, such as low energy storage, supercapacitors presented an interesting candidate to couple with batteries or other power sources in space applications or in hybrid electric land vehicles. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      The “Bad Amplitude” \n                        dragster.\n                    \n                  \n                  To help test the effectiveness of supercapacitors for power systems, NASA formed a unique partnership—perhaps the only one in the Agency’s history to involve a dragster.\n                  The dragster was named “Bad Amplitude,” and it was battery-powered. Capable of achieving a speed of 127 miles per hour in a quarter mile, the dragster presented an ideal testbed for the supercapacitors NASA was studying. Through the NASA Illinois Commercialization Center (NICC), which at the time provided technology commercialization services for the state’s businesses, Glenn partnered with the dragster’s developer, NetGain Technologies LLC of Lockport, Illinois, in 2003. \n                  The partnership also focused on another advanced concept: the development of a retrofit system for converting rear-wheel drive vehicles into gas/electric hybrids, installing an electric assist motor and using supercapacitors instead of batteries.\n                  While the supercapacitors ultimately did not suit the dragster or the retrofit system, at the conclusion of the NICC grant, NetGain had provided NASA with significant data on supercapacitor use and had proven the viability of a hybrid retrofit system (HRS) using batteries. The company continued developing the HRS, including methods for coordinating the operation of electric motors and internal combustion engines. This NASA-derived work has now led not only to commercial HRS technology, but also, according to NetGain, to the world’s most popular line of motors for electric vehicles.\n                  Benefits\n                  NetGain Technologies’ patent-pending Engine/Motor Interface System (EMIS) employs an electric motor inserted into the drive train of a standard, gas-powered vehicle to supply electrical assist power to the internal combustion engine. Through monitoring multiple engine performance parameters, EMIS strategically establishes the appropriate amounts of assist power to significantly enhance the vehicle’s fuel economy. The system operates in the background, requiring no driver intervention or changes to typical driving habits.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Delivery truck fleets, like those used by the U.S. Post Office, can benefit from the NASA-derived hybrid retrofit systems developed by NetGain Technologies LLC.\n                    \n                  \n                  “This is breakthrough technology,” says NetGain Technologies member Dennis Bieschke. “EMIS allows people to convert the vehicle they have and not buy a new hybrid vehicle.” This makes it economically possible for many people to own a hybrid, Bieschke notes, especially fleet owners who cannot afford to invest in an entirely new fleet to enhance the efficiency and lessen the environmental impact. For fleet or other vehicles with standard, readily available parts, the conversion process can be accomplished in one day, says George Hamstra, also a NetGain member.\n                  “You can drive a vehicle in as a gas vehicle in the morning and drive it out as a hybrid in the afternoon,” Hamstra says.\n                  Not only has NetGain pioneered a commercial HRS based on its work with NASA, but it has also innovated the related electric motor technology. The company learned from the various mechanical failures it encountered during the development of the HRS system with NASA, which led Hamstra to make a series of positive engineering changes to electric motors. NetGain’s sales of these advanced motors quadrupled from 2004 to 2005 and nearly tripled again in 2006. In 2007, Hamstra formed a sister company, NetGain Motors Inc., to focus on manufacturing and marketing the entire line of electric motors.\n                  “We now have well over 150 dealers worldwide that are dependent on these motors,” says Hamstra. The company’s WarP, ImPulse, and TransWarP motor products have rescued an Illinois motor manufacturer, whose business repairing forklift motors had drastically declined; production of NetGain’s motors now supports over 100 jobs at the manufacturing facility.\n                  The combination of the electric motors with the EMIS system has provided an affordable hybrid vehicle option for everyone from celebrities to garage mechanics, says Bieschke. While the benefits to fuel economy change depending on the vehicle, motor and battery size, and driving conditions, NetGain’s results from its delivery truck testbed indicated fuel savings of 15–26 percent. The company believes the short-distance, multiple-stop delivery truck market—trucks used by everyone from the U.S. Postal Service to food distributors, over 8.5 million in the United States alone by NetGain’s estimation—represent an ultimate application for the HRS technology. For these vehicles, the general estimated cost of the conversion is $9,000–$10,000, a cost typically paid back through fuel savings within 30–42 months.\n                  “The system employs impressive technology, tapping into the vehicle’s computer and other sensors to apply the appropriate amount of electrical assist,” says David Hrivnak, a Kingsport, Tennessee-based industrial engineer for Eastman Chemical Company. As a personal project, Hrivnak outfitted his Chevrolet Avalanche with NetGain’s EMIS system and TransWarp motor and realized a more than 15-percent improvement in gas mileage. “I have yet to find any other technology that allows someone to make a significant improvement in efficiency for an existing vehicle,” Hrivnak says. The converted hybrid Avalanche also experienced a performance boost, shaving a full half-second off its quarter-mile elapsed time. \n                  The current success and potential of NetGain Technologies and NetGain Motors originates with the NASA partnership, Hamstra says. “Without the NASA funding, we would not have NetGain Technologies nor NetGain Motors, and we would not have this HRS technology.”\n                  NetGain’s work with NASA may have started with a dragster, but its benefits have gone far beyond advanced engineering. NetGain donated its original HRS prototype delivery truck to the Loaves & Fishes Community Pantry in Naperville, Illinois, providing fuel savings as the organization delivers food to more than 15,000 individuals in need.\n                  EMIS™ is a trademark of NetGain Technologies LLC.\n                  WarP™, ImPulse™, and TransWarP™ are trademarks of NetGain Motors Inc\n                \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Successful space missions can rarely be attributed to a single thing. Rather, they are the result of a system of systems: integrated elements functioning effectively in their individual roles and together with related components, then those systems interacting with and supporting other systems to form a collaborative whole—from the spacecraft itself to the engineering and research teams that design and build it.\n                  An example is found in spacecraft power systems. Unlike a gas-powered car or a battery-powered laptop, most spacecraft are powered by multiple energy sources—such as photovoltaic panels, fuel cells, and batteries—working in tandem to ensure the spacecraft functions throughout the course of a mission. As with any system, the appropriate combination of elements and the method of their management are key to high performance and efficiency.\n                  One initiative at Glenn Research Center, the Hybrid Power Management (HPM) program, focused on joining new and mature technologies for optimal power systems applications in space and on Earth, with the goal not only to develop ultra-efficient space power systems, but to advance HPM to address global energy issues. The HPM program emerged from Glenn’s long history of electric vehicle research dating back to the 1970s, including the NASA Hybrid Electric Transit Bus (HETB) project in the 1990s, which was the largest vehicle to use supercapacitor energy storage.\n                  Unlike batteries that store and discharge energy through chemical reactions, supercapacitors store energy electrostatically. In this way, supercapacitors charge and release energy more quickly than a battery, and unlike a battery, can tolerate up to 1 million charge and discharge cycles without wearing out. Though there were certain disadvantages compared to batteries, such as low energy storage, supercapacitors presented an interesting candidate to couple with batteries or other power sources in space applications or in hybrid electric land vehicles. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      The “Bad Amplitude” \n                        dragster.\n                    \n                  \n                  To help test the effectiveness of supercapacitors for power systems, NASA formed a unique partnership—perhaps the only one in the Agency’s history to involve a dragster.\n                  The dragster was named “Bad Amplitude,” and it was battery-powered. Capable of achieving a speed of 127 miles per hour in a quarter mile, the dragster presented an ideal testbed for the supercapacitors NASA was studying. Through the NASA Illinois Commercialization Center (NICC), which at the time provided technology commercialization services for the state’s businesses, Glenn partnered with the dragster’s developer, NetGain Technologies LLC of Lockport, Illinois, in 2003. \n                  The partnership also focused on another advanced concept: the development of a retrofit system for converting rear-wheel drive vehicles into gas/electric hybrids, installing an electric assist motor and using supercapacitors instead of batteries.\n                  While the supercapacitors ultimately did not suit the dragster or the retrofit system, at the conclusion of the NICC grant, NetGain had provided NASA with significant data on supercapacitor use and had proven the viability of a hybrid retrofit system (HRS) using batteries. The company continued developing the HRS, including methods for coordinating the operation of electric motors and internal combustion engines. This NASA-derived work has now led not only to commercial HRS technology, but also, according to NetGain, to the world’s most popular line of motors for electric vehicles.\n                  Benefits\n                  NetGain Technologies’ patent-pending Engine/Motor Interface System (EMIS) employs an electric motor inserted into the drive train of a standard, gas-powered vehicle to supply electrical assist power to the internal combustion engine. Through monitoring multiple engine performance parameters, EMIS strategically establishes the appropriate amounts of assist power to significantly enhance the vehicle’s fuel economy. The system operates in the background, requiring no driver intervention or changes to typical driving habits.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Delivery truck fleets, like those used by the U.S. Post Office, can benefit from the NASA-derived hybrid retrofit systems developed by NetGain Technologies LLC.\n                    \n                  \n                  “This is breakthrough technology,” says NetGain Technologies member Dennis Bieschke. “EMIS allows people to convert the vehicle they have and not buy a new hybrid vehicle.” This makes it economically possible for many people to own a hybrid, Bieschke notes, especially fleet owners who cannot afford to invest in an entirely new fleet to enhance the efficiency and lessen the environmental impact. For fleet or other vehicles with standard, readily available parts, the conversion process can be accomplished in one day, says George Hamstra, also a NetGain member.\n                  “You can drive a vehicle in as a gas vehicle in the morning and drive it out as a hybrid in the afternoon,” Hamstra says.\n                  Not only has NetGain pioneered a commercial HRS based on its work with NASA, but it has also innovated the related electric motor technology. The company learned from the various mechanical failures it encountered during the development of the HRS system with NASA, which led Hamstra to make a series of positive engineering changes to electric motors. NetGain’s sales of these advanced motors quadrupled from 2004 to 2005 and nearly tripled again in 2006. In 2007, Hamstra formed a sister company, NetGain Motors Inc., to focus on manufacturing and marketing the entire line of electric motors.\n                  “We now have well over 150 dealers worldwide that are dependent on these motors,” says Hamstra. The company’s WarP, ImPulse, and TransWarP motor products have rescued an Illinois motor manufacturer, whose business repairing forklift motors had drastically declined; production of NetGain’s motors now supports over 100 jobs at the manufacturing facility.\n                  The combination of the electric motors with the EMIS system has provided an affordable hybrid vehicle option for everyone from celebrities to garage mechanics, says Bieschke. While the benefits to fuel economy change depending on the vehicle, motor and battery size, and driving conditions, NetGain’s results from its delivery truck testbed indicated fuel savings of 15–26 percent. The company believes the short-distance, multiple-stop delivery truck market—trucks used by everyone from the U.S. Postal Service to food distributors, over 8.5 million in the United States alone by NetGain’s estimation—represent an ultimate application for the HRS technology. For these vehicles, the general estimated cost of the conversion is $9,000–$10,000, a cost typically paid back through fuel savings within 30–42 months.\n                  “The system employs impressive technology, tapping into the vehicle’s computer and other sensors to apply the appropriate amount of electrical assist,” says David Hrivnak, a Kingsport, Tennessee-based industrial engineer for Eastman Chemical Company. As a personal project, Hrivnak outfitted his Chevrolet Avalanche with NetGain’s EMIS system and TransWarp motor and realized a more than 15-percent improvement in gas mileage. “I have yet to find any other technology that allows someone to make a significant improvement in efficiency for an existing vehicle,” Hrivnak says. The converted hybrid Avalanche also experienced a performance boost, shaving a full half-second off its quarter-mile elapsed time. \n                  The current success and potential of NetGain Technologies and NetGain Motors originates with the NASA partnership, Hamstra says. “Without the NASA funding, we would not have NetGain Technologies nor NetGain Motors, and we would not have this HRS technology.”\n                  NetGain’s work with NASA may have started with a dragster, but its benefits have gone far beyond advanced engineering. NetGain donated its original HRS prototype delivery truck to the Loaves & Fishes Community Pantry in Naperville, Illinois, providing fuel savings as the organization delivers food to more than 15,000 individuals in need.\n                  EMIS™ is a trademark of NetGain Technologies LLC.\n                  WarP™, ImPulse™, and TransWarP™ are trademarks of NetGain Motors Inc\n                \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Successful space missions can rarely be attributed to a single thing. Rather, they are the result of a system of systems: integrated elements functioning effectively in their individual roles and together with related components, then those systems interacting with and supporting other systems to form a collaborative whole—from the spacecraft itself to the engineering and research teams that design and build it.\n                  An example is found in spacecraft power systems. Unlike a gas-powered car or a battery-powered laptop, most spacecraft are powered by multiple energy sources—such as photovoltaic panels, fuel cells, and batteries—working in tandem to ensure the spacecraft functions throughout the course of a mission. As with any system, the appropriate combination of elements and the method of their management are key to high performance and efficiency.\n                  One initiative at Glenn Research Center, the Hybrid Power Management (HPM) program, focused on joining new and mature technologies for optimal power systems applications in space and on Earth, with the goal not only to develop ultra-efficient space power systems, but to advance HPM to address global energy issues. The HPM program emerged from Glenn’s long history of electric vehicle research dating back to the 1970s, including the NASA Hybrid Electric Transit Bus (HETB) project in the 1990s, which was the largest vehicle to use supercapacitor energy storage.\n                  Unlike batteries that store and discharge energy through chemical reactions, supercapacitors store energy electrostatically. In this way, supercapacitors charge and release energy more quickly than a battery, and unlike a battery, can tolerate up to 1 million charge and discharge cycles without wearing out. Though there were certain disadvantages compared to batteries, such as low energy storage, supercapacitors presented an interesting candidate to couple with batteries or other power sources in space applications or in hybrid electric land vehicles. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      The “Bad Amplitude” \n                        dragster.\n                    \n                  \n                  To help test the effectiveness of supercapacitors for power systems, NASA formed a unique partnership—perhaps the only one in the Agency’s history to involve a dragster.\n                  The dragster was named “Bad Amplitude,” and it was battery-powered. Capable of achieving a speed of 127 miles per hour in a quarter mile, the dragster presented an ideal testbed for the supercapacitors NASA was studying. Through the NASA Illinois Commercialization Center (NICC), which at the time provided technology commercialization services for the state’s businesses, Glenn partnered with the dragster’s developer, NetGain Technologies LLC of Lockport, Illinois, in 2003. \n                  The partnership also focused on another advanced concept: the development of a retrofit system for converting rear-wheel drive vehicles into gas/electric hybrids, installing an electric assist motor and using supercapacitors instead of batteries.\n                  While the supercapacitors ultimately did not suit the dragster or the retrofit system, at the conclusion of the NICC grant, NetGain had provided NASA with significant data on supercapacitor use and had proven the viability of a hybrid retrofit system (HRS) using batteries. The company continued developing the HRS, including methods for coordinating the operation of electric motors and internal combustion engines. This NASA-derived work has now led not only to commercial HRS technology, but also, according to NetGain, to the world’s most popular line of motors for electric vehicles.\n                  Benefits\n                  NetGain Technologies’ patent-pending Engine/Motor Interface System (EMIS) employs an electric motor inserted into the drive train of a standard, gas-powered vehicle to supply electrical assist power to the internal combustion engine. Through monitoring multiple engine performance parameters, EMIS strategically establishes the appropriate amounts of assist power to significantly enhance the vehicle’s fuel economy. The system operates in the background, requiring no driver intervention or changes to typical driving habits.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Delivery truck fleets, like those used by the U.S. Post Office, can benefit from the NASA-derived hybrid retrofit systems developed by NetGain Technologies LLC.\n                    \n                  \n                  “This is breakthrough technology,” says NetGain Technologies member Dennis Bieschke. “EMIS allows people to convert the vehicle they have and not buy a new hybrid vehicle.” This makes it economically possible for many people to own a hybrid, Bieschke notes, especially fleet owners who cannot afford to invest in an entirely new fleet to enhance the efficiency and lessen the environmental impact. For fleet or other vehicles with standard, readily available parts, the conversion process can be accomplished in one day, says George Hamstra, also a NetGain member.\n                  “You can drive a vehicle in as a gas vehicle in the morning and drive it out as a hybrid in the afternoon,” Hamstra says.\n                  Not only has NetGain pioneered a commercial HRS based on its work with NASA, but it has also innovated the related electric motor technology. The company learned from the various mechanical failures it encountered during the development of the HRS system with NASA, which led Hamstra to make a series of positive engineering changes to electric motors. NetGain’s sales of these advanced motors quadrupled from 2004 to 2005 and nearly tripled again in 2006. In 2007, Hamstra formed a sister company, NetGain Motors Inc., to focus on manufacturing and marketing the entire line of electric motors.\n                  “We now have well over 150 dealers worldwide that are dependent on these motors,” says Hamstra. The company’s WarP, ImPulse, and TransWarP motor products have rescued an Illinois motor manufacturer, whose business repairing forklift motors had drastically declined; production of NetGain’s motors now supports over 100 jobs at the manufacturing facility.\n                  The combination of the electric motors with the EMIS system has provided an affordable hybrid vehicle option for everyone from celebrities to garage mechanics, says Bieschke. While the benefits to fuel economy change depending on the vehicle, motor and battery size, and driving conditions, NetGain’s results from its delivery truck testbed indicated fuel savings of 15–26 percent. The company believes the short-distance, multiple-stop delivery truck market—trucks used by everyone from the U.S. Postal Service to food distributors, over 8.5 million in the United States alone by NetGain’s estimation—represent an ultimate application for the HRS technology. For these vehicles, the general estimated cost of the conversion is $9,000–$10,000, a cost typically paid back through fuel savings within 30–42 months.\n                  “The system employs impressive technology, tapping into the vehicle’s computer and other sensors to apply the appropriate amount of electrical assist,” says David Hrivnak, a Kingsport, Tennessee-based industrial engineer for Eastman Chemical Company. As a personal project, Hrivnak outfitted his Chevrolet Avalanche with NetGain’s EMIS system and TransWarp motor and realized a more than 15-percent improvement in gas mileage. “I have yet to find any other technology that allows someone to make a significant improvement in efficiency for an existing vehicle,” Hrivnak says. The converted hybrid Avalanche also experienced a performance boost, shaving a full half-second off its quarter-mile elapsed time. \n                  The current success and potential of NetGain Technologies and NetGain Motors originates with the NASA partnership, Hamstra says. “Without the NASA funding, we would not have NetGain Technologies nor NetGain Motors, and we would not have this HRS technology.”\n                  NetGain’s work with NASA may have started with a dragster, but its benefits have gone far beyond advanced engineering. NetGain donated its original HRS prototype delivery truck to the Loaves & Fishes Community Pantry in Naperville, Illinois, providing fuel savings as the organization delivers food to more than 15,000 individuals in need.\n                  EMIS™ is a trademark of NetGain Technologies LLC.\n                  WarP™, ImPulse™, and TransWarP™ are trademarks of NetGain Motors Inc\n                \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Successful space missions can rarely be attributed to a single thing. Rather, they are the result of a system of systems: integrated elements functioning effectively in their individual roles and together with related components, then those systems interacting with and supporting other systems to form a collaborative whole—from the spacecraft itself to the engineering and research teams that design and build it.\n                  An example is found in spacecraft power systems. Unlike a gas-powered car or a battery-powered laptop, most spacecraft are powered by multiple energy sources—such as photovoltaic panels, fuel cells, and batteries—working in tandem to ensure the spacecraft functions throughout the course of a mission. As with any system, the appropriate combination of elements and the method of their management are key to high performance and efficiency.\n                  One initiative at Glenn Research Center, the Hybrid Power Management (HPM) program, focused on joining new and mature technologies for optimal power systems applications in space and on Earth, with the goal not only to develop ultra-efficient space power systems, but to advance HPM to address global energy issues. The HPM program emerged from Glenn’s long history of electric vehicle research dating back to the 1970s, including the NASA Hybrid Electric Transit Bus (HETB) project in the 1990s, which was the largest vehicle to use supercapacitor energy storage.\n                  Unlike batteries that store and discharge energy through chemical reactions, supercapacitors store energy electrostatically. In this way, supercapacitors charge and release energy more quickly than a battery, and unlike a battery, can tolerate up to 1 million charge and discharge cycles without wearing out. Though there were certain disadvantages compared to batteries, such as low energy storage, supercapacitors presented an interesting candidate to couple with batteries or other power sources in space applications or in hybrid electric land vehicles. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      The “Bad Amplitude” \n                        dragster.\n                    \n                  \n                  To help test the effectiveness of supercapacitors for power systems, NASA formed a unique partnership—perhaps the only one in the Agency’s history to involve a dragster.\n                  The dragster was named “Bad Amplitude,” and it was battery-powered. Capable of achieving a speed of 127 miles per hour in a quarter mile, the dragster presented an ideal testbed for the supercapacitors NASA was studying. Through the NASA Illinois Commercialization Center (NICC), which at the time provided technology commercialization services for the state’s businesses, Glenn partnered with the dragster’s developer, NetGain Technologies LLC of Lockport, Illinois, in 2003. \n                  The partnership also focused on another advanced concept: the development of a retrofit system for converting rear-wheel drive vehicles into gas/electric hybrids, installing an electric assist motor and using supercapacitors instead of batteries.\n                  While the supercapacitors ultimately did not suit the dragster or the retrofit system, at the conclusion of the NICC grant, NetGain had provided NASA with significant data on supercapacitor use and had proven the viability of a hybrid retrofit system (HRS) using batteries. The company continued developing the HRS, including methods for coordinating the operation of electric motors and internal combustion engines. This NASA-derived work has now led not only to commercial HRS technology, but also, according to NetGain, to the world’s most popular line of motors for electric vehicles.\n                  Benefits\n                  NetGain Technologies’ patent-pending Engine/Motor Interface System (EMIS) employs an electric motor inserted into the drive train of a standard, gas-powered vehicle to supply electrical assist power to the internal combustion engine. Through monitoring multiple engine performance parameters, EMIS strategically establishes the appropriate amounts of assist power to significantly enhance the vehicle’s fuel economy. The system operates in the background, requiring no driver intervention or changes to typical driving habits.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Delivery truck fleets, like those used by the U.S. Post Office, can benefit from the NASA-derived hybrid retrofit systems developed by NetGain Technologies LLC.\n                    \n                  \n                  “This is breakthrough technology,” says NetGain Technologies member Dennis Bieschke. “EMIS allows people to convert the vehicle they have and not buy a new hybrid vehicle.” This makes it economically possible for many people to own a hybrid, Bieschke notes, especially fleet owners who cannot afford to invest in an entirely new fleet to enhance the efficiency and lessen the environmental impact. For fleet or other vehicles with standard, readily available parts, the conversion process can be accomplished in one day, says George Hamstra, also a NetGain member.\n                  “You can drive a vehicle in as a gas vehicle in the morning and drive it out as a hybrid in the afternoon,” Hamstra says.\n                  Not only has NetGain pioneered a commercial HRS based on its work with NASA, but it has also innovated the related electric motor technology. The company learned from the various mechanical failures it encountered during the development of the HRS system with NASA, which led Hamstra to make a series of positive engineering changes to electric motors. NetGain’s sales of these advanced motors quadrupled from 2004 to 2005 and nearly tripled again in 2006. In 2007, Hamstra formed a sister company, NetGain Motors Inc., to focus on manufacturing and marketing the entire line of electric motors.\n                  “We now have well over 150 dealers worldwide that are dependent on these motors,” says Hamstra. The company’s WarP, ImPulse, and TransWarP motor products have rescued an Illinois motor manufacturer, whose business repairing forklift motors had drastically declined; production of NetGain’s motors now supports over 100 jobs at the manufacturing facility.\n                  The combination of the electric motors with the EMIS system has provided an affordable hybrid vehicle option for everyone from celebrities to garage mechanics, says Bieschke. While the benefits to fuel economy change depending on the vehicle, motor and battery size, and driving conditions, NetGain’s results from its delivery truck testbed indicated fuel savings of 15–26 percent. The company believes the short-distance, multiple-stop delivery truck market—trucks used by everyone from the U.S. Postal Service to food distributors, over 8.5 million in the United States alone by NetGain’s estimation—represent an ultimate application for the HRS technology. For these vehicles, the general estimated cost of the conversion is $9,000–$10,000, a cost typically paid back through fuel savings within 30–42 months.\n                  “The system employs impressive technology, tapping into the vehicle’s computer and other sensors to apply the appropriate amount of electrical assist,” says David Hrivnak, a Kingsport, Tennessee-based industrial engineer for Eastman Chemical Company. As a personal project, Hrivnak outfitted his Chevrolet Avalanche with NetGain’s EMIS system and TransWarp motor and realized a more than 15-percent improvement in gas mileage. “I have yet to find any other technology that allows someone to make a significant improvement in efficiency for an existing vehicle,” Hrivnak says. The converted hybrid Avalanche also experienced a performance boost, shaving a full half-second off its quarter-mile elapsed time. \n                  The current success and potential of NetGain Technologies and NetGain Motors originates with the NASA partnership, Hamstra says. “Without the NASA funding, we would not have NetGain Technologies nor NetGain Motors, and we would not have this HRS technology.”\n                  NetGain’s work with NASA may have started with a dragster, but its benefits have gone far beyond advanced engineering. NetGain donated its original HRS prototype delivery truck to the Loaves & Fishes Community Pantry in Naperville, Illinois, providing fuel savings as the organization delivers food to more than 15,000 individuals in need.\n                  EMIS™ is a trademark of NetGain Technologies LLC.\n                  WarP™, ImPulse™, and TransWarP™ are trademarks of NetGain Motors Inc\n                \n                \n              \n            \n            \n          \n            \n              \n                \n                  NASA Technology\n                  Successful space missions can rarely be attributed to a single thing. Rather, they are the result of a system of systems: integrated elements functioning effectively in their individual roles and together with related components, then those systems interacting with and supporting other systems to form a collaborative whole—from the spacecraft itself to the engineering and research teams that design and build it.\n                  An example is found in spacecraft power systems. Unlike a gas-powered car or a battery-powered laptop, most spacecraft are powered by multiple energy sources—such as photovoltaic panels, fuel cells, and batteries—working in tandem to ensure the spacecraft functions throughout the course of a mission. As with any system, the appropriate combination of elements and the method of their management are key to high performance and efficiency.\n                  One initiative at Glenn Research Center, the Hybrid Power Management (HPM) program, focused on joining new and mature technologies for optimal power systems applications in space and on Earth, with the goal not only to develop ultra-efficient space power systems, but to advance HPM to address global energy issues. The HPM program emerged from Glenn’s long history of electric vehicle research dating back to the 1970s, including the NASA Hybrid Electric Transit Bus (HETB) project in the 1990s, which was the largest vehicle to use supercapacitor energy storage.\n                  Unlike batteries that store and discharge energy through chemical reactions, supercapacitors store energy electrostatically. In this way, supercapacitors charge and release energy more quickly than a battery, and unlike a battery, can tolerate up to 1 million charge and discharge cycles without wearing out. Though there were certain disadvantages compared to batteries, such as low energy storage, supercapacitors presented an interesting candidate to couple with batteries or other power sources in space applications or in hybrid electric land vehicles. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      The “Bad Amplitude” \n                        dragster.\n                    \n                  \n                  To help test the effectiveness of supercapacitors for power systems, NASA formed a unique partnership—perhaps the only one in the Agency’s history to involve a dragster.\n                  The dragster was named “Bad Amplitude,” and it was battery-powered. Capable of achieving a speed of 127 miles per hour in a quarter mile, the dragster presented an ideal testbed for the supercapacitors NASA was studying. Through the NASA Illinois Commercialization Center (NICC), which at the time provided technology commercialization services for the state’s businesses, Glenn partnered with the dragster’s developer, NetGain Technologies LLC of Lockport, Illinois, in 2003. \n                  The partnership also focused on another advanced concept: the development of a retrofit system for converting rear-wheel drive vehicles into gas/electric hybrids, installing an electric assist motor and using supercapacitors instead of batteries.\n                  While the supercapacitors ultimately did not suit the dragster or the retrofit system, at the conclusion of the NICC grant, NetGain had provided NASA with significant data on supercapacitor use and had proven the viability of a hybrid retrofit system (HRS) using batteries. The company continued developing the HRS, including methods for coordinating the operation of electric motors and internal combustion engines. This NASA-derived work has now led not only to commercial HRS technology, but also, according to NetGain, to the world’s most popular line of motors for electric vehicles.\n                  Benefits\n                  NetGain Technologies’ patent-pending Engine/Motor Interface System (EMIS) employs an electric motor inserted into the drive train of a standard, gas-powered vehicle to supply electrical assist power to the internal combustion engine. Through monitoring multiple engine performance parameters, EMIS strategically establishes the appropriate amounts of assist power to significantly enhance the vehicle’s fuel economy. The system operates in the background, requiring no driver intervention or changes to typical driving habits.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Delivery truck fleets, like those used by the U.S. Post Office, can benefit from the NASA-derived hybrid retrofit systems developed by NetGain Technologies LLC.\n                    \n                  \n                  “This is breakthrough technology,” says NetGain Technologies member Dennis Bieschke. “EMIS allows people to convert the vehicle they have and not buy a new hybrid vehicle.” This makes it economically possible for many people to own a hybrid, Bieschke notes, especially fleet owners who cannot afford to invest in an entirely new fleet to enhance the efficiency and lessen the environmental impact. For fleet or other vehicles with standard, readily available parts, the conversion process can be accomplished in one day, says George Hamstra, also a NetGain member.\n                  “You can drive a vehicle in as a gas vehicle in the morning and drive it out as a hybrid in the afternoon,” Hamstra says.\n                  Not only has NetGain pioneered a commercial HRS based on its work with NASA, but it has also innovated the related electric motor technology. The company learned from the various mechanical failures it encountered during the development of the HRS system with NASA, which led Hamstra to make a series of positive engineering changes to electric motors. NetGain’s sales of these advanced motors quadrupled from 2004 to 2005 and nearly tripled again in 2006. In 2007, Hamstra formed a sister company, NetGain Motors Inc., to focus on manufacturing and marketing the entire line of electric motors.\n                  “We now have well over 150 dealers worldwide that are dependent on these motors,” says Hamstra. The company’s WarP, ImPulse, and TransWarP motor products have rescued an Illinois motor manufacturer, whose business repairing forklift motors had drastically declined; production of NetGain’s motors now supports over 100 jobs at the manufacturing facility.\n                  The combination of the electric motors with the EMIS system has provided an affordable hybrid vehicle option for everyone from celebrities to garage mechanics, says Bieschke. While the benefits to fuel economy change depending on the vehicle, motor and battery size, and driving conditions, NetGain’s results from its delivery truck testbed indicated fuel savings of 15–26 percent. The company believes the short-distance, multiple-stop delivery truck market—trucks used by everyone from the U.S. Postal Service to food distributors, over 8.5 million in the United States alone by NetGain’s estimation—represent an ultimate application for the HRS technology. For these vehicles, the general estimated cost of the conversion is $9,000–$10,000, a cost typically paid back through fuel savings within 30–42 months.\n                  “The system employs impressive technology, tapping into the vehicle’s computer and other sensors to apply the appropriate amount of electrical assist,” says David Hrivnak, a Kingsport, Tennessee-based industrial engineer for Eastman Chemical Company. As a personal project, Hrivnak outfitted his Chevrolet Avalanche with NetGain’s EMIS system and TransWarp motor and realized a more than 15-percent improvement in gas mileage. “I have yet to find any other technology that allows someone to make a significant improvement in efficiency for an existing vehicle,” Hrivnak says. The converted hybrid Avalanche also experienced a performance boost, shaving a full half-second off its quarter-mile elapsed time. \n                  The current success and potential of NetGain Technologies and NetGain Motors originates with the NASA partnership, Hamstra says. “Without the NASA funding, we would not have NetGain Technologies nor NetGain Motors, and we would not have this HRS technology.”\n                  NetGain’s work with NASA may have started with a dragster, but its benefits have gone far beyond advanced engineering. NetGain donated its original HRS prototype delivery truck to the Loaves & Fishes Community Pantry in Naperville, Illinois, providing fuel savings as the organization delivers food to more than 15,000 individuals in need.\n                  EMIS™ is a trademark of NetGain Technologies LLC.\n                  WarP™, ImPulse™, and TransWarP™ are trademarks of NetGain Motors Inc\n                \n                \n              \n            \n            \n              \n                \n                  NASA Technology\n                  Successful space missions can rarely be attributed to a single thing. Rather, they are the result of a system of systems: integrated elements functioning effectively in their individual roles and together with related components, then those systems interacting with and supporting other systems to form a collaborative whole—from the spacecraft itself to the engineering and research teams that design and build it.\n                  An example is found in spacecraft power systems. Unlike a gas-powered car or a battery-powered laptop, most spacecraft are powered by multiple energy sources—such as photovoltaic panels, fuel cells, and batteries—working in tandem to ensure the spacecraft functions throughout the course of a mission. As with any system, the appropriate combination of elements and the method of their management are key to high performance and efficiency.\n                  One initiative at Glenn Research Center, the Hybrid Power Management (HPM) program, focused on joining new and mature technologies for optimal power systems applications in space and on Earth, with the goal not only to develop ultra-efficient space power systems, but to advance HPM to address global energy issues. The HPM program emerged from Glenn’s long history of electric vehicle research dating back to the 1970s, including the NASA Hybrid Electric Transit Bus (HETB) project in the 1990s, which was the largest vehicle to use supercapacitor energy storage.\n                  Unlike batteries that store and discharge energy through chemical reactions, supercapacitors store energy electrostatically. In this way, supercapacitors charge and release energy more quickly than a battery, and unlike a battery, can tolerate up to 1 million charge and discharge cycles without wearing out. Though there were certain disadvantages compared to batteries, such as low energy storage, supercapacitors presented an interesting candidate to couple with batteries or other power sources in space applications or in hybrid electric land vehicles. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      The “Bad Amplitude” \n                        dragster.\n                    \n                  \n                  To help test the effectiveness of supercapacitors for power systems, NASA formed a unique partnership—perhaps the only one in the Agency’s history to involve a dragster.\n                  The dragster was named “Bad Amplitude,” and it was battery-powered. Capable of achieving a speed of 127 miles per hour in a quarter mile, the dragster presented an ideal testbed for the supercapacitors NASA was studying. Through the NASA Illinois Commercialization Center (NICC), which at the time provided technology commercialization services for the state’s businesses, Glenn partnered with the dragster’s developer, NetGain Technologies LLC of Lockport, Illinois, in 2003. \n                  The partnership also focused on another advanced concept: the development of a retrofit system for converting rear-wheel drive vehicles into gas/electric hybrids, installing an electric assist motor and using supercapacitors instead of batteries.\n                  While the supercapacitors ultimately did not suit the dragster or the retrofit system, at the conclusion of the NICC grant, NetGain had provided NASA with significant data on supercapacitor use and had proven the viability of a hybrid retrofit system (HRS) using batteries. The company continued developing the HRS, including methods for coordinating the operation of electric motors and internal combustion engines. This NASA-derived work has now led not only to commercial HRS technology, but also, according to NetGain, to the world’s most popular line of motors for electric vehicles.\n                  Benefits\n                  NetGain Technologies’ patent-pending Engine/Motor Interface System (EMIS) employs an electric motor inserted into the drive train of a standard, gas-powered vehicle to supply electrical assist power to the internal combustion engine. Through monitoring multiple engine performance parameters, EMIS strategically establishes the appropriate amounts of assist power to significantly enhance the vehicle’s fuel economy. The system operates in the background, requiring no driver intervention or changes to typical driving habits.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Delivery truck fleets, like those used by the U.S. Post Office, can benefit from the NASA-derived hybrid retrofit systems developed by NetGain Technologies LLC.\n                    \n                  \n                  “This is breakthrough technology,” says NetGain Technologies member Dennis Bieschke. “EMIS allows people to convert the vehicle they have and not buy a new hybrid vehicle.” This makes it economically possible for many people to own a hybrid, Bieschke notes, especially fleet owners who cannot afford to invest in an entirely new fleet to enhance the efficiency and lessen the environmental impact. For fleet or other vehicles with standard, readily available parts, the conversion process can be accomplished in one day, says George Hamstra, also a NetGain member.\n                  “You can drive a vehicle in as a gas vehicle in the morning and drive it out as a hybrid in the afternoon,” Hamstra says.\n                  Not only has NetGain pioneered a commercial HRS based on its work with NASA, but it has also innovated the related electric motor technology. The company learned from the various mechanical failures it encountered during the development of the HRS system with NASA, which led Hamstra to make a series of positive engineering changes to electric motors. NetGain’s sales of these advanced motors quadrupled from 2004 to 2005 and nearly tripled again in 2006. In 2007, Hamstra formed a sister company, NetGain Motors Inc., to focus on manufacturing and marketing the entire line of electric motors.\n                  “We now have well over 150 dealers worldwide that are dependent on these motors,” says Hamstra. The company’s WarP, ImPulse, and TransWarP motor products have rescued an Illinois motor manufacturer, whose business repairing forklift motors had drastically declined; production of NetGain’s motors now supports over 100 jobs at the manufacturing facility.\n                  The combination of the electric motors with the EMIS system has provided an affordable hybrid vehicle option for everyone from celebrities to garage mechanics, says Bieschke. While the benefits to fuel economy change depending on the vehicle, motor and battery size, and driving conditions, NetGain’s results from its delivery truck testbed indicated fuel savings of 15–26 percent. The company believes the short-distance, multiple-stop delivery truck market—trucks used by everyone from the U.S. Postal Service to food distributors, over 8.5 million in the United States alone by NetGain’s estimation—represent an ultimate application for the HRS technology. For these vehicles, the general estimated cost of the conversion is $9,000–$10,000, a cost typically paid back through fuel savings within 30–42 months.\n                  “The system employs impressive technology, tapping into the vehicle’s computer and other sensors to apply the appropriate amount of electrical assist,” says David Hrivnak, a Kingsport, Tennessee-based industrial engineer for Eastman Chemical Company. As a personal project, Hrivnak outfitted his Chevrolet Avalanche with NetGain’s EMIS system and TransWarp motor and realized a more than 15-percent improvement in gas mileage. “I have yet to find any other technology that allows someone to make a significant improvement in efficiency for an existing vehicle,” Hrivnak says. The converted hybrid Avalanche also experienced a performance boost, shaving a full half-second off its quarter-mile elapsed time. \n                  The current success and potential of NetGain Technologies and NetGain Motors originates with the NASA partnership, Hamstra says. “Without the NASA funding, we would not have NetGain Technologies nor NetGain Motors, and we would not have this HRS technology.”\n                  NetGain’s work with NASA may have started with a dragster, but its benefits have gone far beyond advanced engineering. NetGain donated its original HRS prototype delivery truck to the Loaves & Fishes Community Pantry in Naperville, Illinois, providing fuel savings as the organization delivers food to more than 15,000 individuals in need.\n                  EMIS™ is a trademark of NetGain Technologies LLC.\n                  WarP™, ImPulse™, and TransWarP™ are trademarks of NetGain Motors Inc\n                \n                \n              \n                  NASA Technology\n                  Successful space missions can rarely be attributed to a single thing. Rather, they are the result of a system of systems: integrated elements functioning effectively in their individual roles and together with related components, then those systems interacting with and supporting other systems to form a collaborative whole—from the spacecraft itself to the engineering and research teams that design and build it.\n                  An example is found in spacecraft power systems. Unlike a gas-powered car or a battery-powered laptop, most spacecraft are powered by multiple energy sources—such as photovoltaic panels, fuel cells, and batteries—working in tandem to ensure the spacecraft functions throughout the course of a mission. As with any system, the appropriate combination of elements and the method of their management are key to high performance and efficiency.\n                  One initiative at Glenn Research Center, the Hybrid Power Management (HPM) program, focused on joining new and mature technologies for optimal power systems applications in space and on Earth, with the goal not only to develop ultra-efficient space power systems, but to advance HPM to address global energy issues. The HPM program emerged from Glenn’s long history of electric vehicle research dating back to the 1970s, including the NASA Hybrid Electric Transit Bus (HETB) project in the 1990s, which was the largest vehicle to use supercapacitor energy storage.\n                  Unlike batteries that store and discharge energy through chemical reactions, supercapacitors store energy electrostatically. In this way, supercapacitors charge and release energy more quickly than a battery, and unlike a battery, can tolerate up to 1 million charge and discharge cycles without wearing out. Though there were certain disadvantages compared to batteries, such as low energy storage, supercapacitors presented an interesting candidate to couple with batteries or other power sources in space applications or in hybrid electric land vehicles. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      The “Bad Amplitude” \n                        dragster.\n                    \n                  \n                  To help test the effectiveness of supercapacitors for power systems, NASA formed a unique partnership—perhaps the only one in the Agency’s history to involve a dragster.\n                  The dragster was named “Bad Amplitude,” and it was battery-powered. Capable of achieving a speed of 127 miles per hour in a quarter mile, the dragster presented an ideal testbed for the supercapacitors NASA was studying. Through the NASA Illinois Commercialization Center (NICC), which at the time provided technology commercialization services for the state’s businesses, Glenn partnered with the dragster’s developer, NetGain Technologies LLC of Lockport, Illinois, in 2003. \n                  The partnership also focused on another advanced concept: the development of a retrofit system for converting rear-wheel drive vehicles into gas/electric hybrids, installing an electric assist motor and using supercapacitors instead of batteries.\n                  While the supercapacitors ultimately did not suit the dragster or the retrofit system, at the conclusion of the NICC grant, NetGain had provided NASA with significant data on supercapacitor use and had proven the viability of a hybrid retrofit system (HRS) using batteries. The company continued developing the HRS, including methods for coordinating the operation of electric motors and internal combustion engines. This NASA-derived work has now led not only to commercial HRS technology, but also, according to NetGain, to the world’s most popular line of motors for electric vehicles.\n                  Benefits\n                  NetGain Technologies’ patent-pending Engine/Motor Interface System (EMIS) employs an electric motor inserted into the drive train of a standard, gas-powered vehicle to supply electrical assist power to the internal combustion engine. Through monitoring multiple engine performance parameters, EMIS strategically establishes the appropriate amounts of assist power to significantly enhance the vehicle’s fuel economy. The system operates in the background, requiring no driver intervention or changes to typical driving habits.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Delivery truck fleets, like those used by the U.S. Post Office, can benefit from the NASA-derived hybrid retrofit systems developed by NetGain Technologies LLC.\n                    \n                  \n                  “This is breakthrough technology,” says NetGain Technologies member Dennis Bieschke. “EMIS allows people to convert the vehicle they have and not buy a new hybrid vehicle.” This makes it economically possible for many people to own a hybrid, Bieschke notes, especially fleet owners who cannot afford to invest in an entirely new fleet to enhance the efficiency and lessen the environmental impact. For fleet or other vehicles with standard, readily available parts, the conversion process can be accomplished in one day, says George Hamstra, also a NetGain member.\n                  “You can drive a vehicle in as a gas vehicle in the morning and drive it out as a hybrid in the afternoon,” Hamstra says.\n                  Not only has NetGain pioneered a commercial HRS based on its work with NASA, but it has also innovated the related electric motor technology. The company learned from the various mechanical failures it encountered during the development of the HRS system with NASA, which led Hamstra to make a series of positive engineering changes to electric motors. NetGain’s sales of these advanced motors quadrupled from 2004 to 2005 and nearly tripled again in 2006. In 2007, Hamstra formed a sister company, NetGain Motors Inc., to focus on manufacturing and marketing the entire line of electric motors.\n                  “We now have well over 150 dealers worldwide that are dependent on these motors,” says Hamstra. The company’s WarP, ImPulse, and TransWarP motor products have rescued an Illinois motor manufacturer, whose business repairing forklift motors had drastically declined; production of NetGain’s motors now supports over 100 jobs at the manufacturing facility.\n                  The combination of the electric motors with the EMIS system has provided an affordable hybrid vehicle option for everyone from celebrities to garage mechanics, says Bieschke. While the benefits to fuel economy change depending on the vehicle, motor and battery size, and driving conditions, NetGain’s results from its delivery truck testbed indicated fuel savings of 15–26 percent. The company believes the short-distance, multiple-stop delivery truck market—trucks used by everyone from the U.S. Postal Service to food distributors, over 8.5 million in the United States alone by NetGain’s estimation—represent an ultimate application for the HRS technology. For these vehicles, the general estimated cost of the conversion is $9,000–$10,000, a cost typically paid back through fuel savings within 30–42 months.\n                  “The system employs impressive technology, tapping into the vehicle’s computer and other sensors to apply the appropriate amount of electrical assist,” says David Hrivnak, a Kingsport, Tennessee-based industrial engineer for Eastman Chemical Company. As a personal project, Hrivnak outfitted his Chevrolet Avalanche with NetGain’s EMIS system and TransWarp motor and realized a more than 15-percent improvement in gas mileage. “I have yet to find any other technology that allows someone to make a significant improvement in efficiency for an existing vehicle,” Hrivnak says. The converted hybrid Avalanche also experienced a performance boost, shaving a full half-second off its quarter-mile elapsed time. \n                  The current success and potential of NetGain Technologies and NetGain Motors originates with the NASA partnership, Hamstra says. “Without the NASA funding, we would not have NetGain Technologies nor NetGain Motors, and we would not have this HRS technology.”\n                  NetGain’s work with NASA may have started with a dragster, but its benefits have gone far beyond advanced engineering. NetGain donated its original HRS prototype delivery truck to the Loaves & Fishes Community Pantry in Naperville, Illinois, providing fuel savings as the organization delivers food to more than 15,000 individuals in need.\n                  EMIS™ is a trademark of NetGain Technologies LLC.\n                  WarP™, ImPulse™, and TransWarP™ are trademarks of NetGain Motors Inc\n                "},{"href":"http://spinoff.nasa.gov/Spinoff2011/cg_4.html","text":"NASA Missions Inspire Online Video Games","image":"http://spinoff.nasa.gov/Spinoff2011/Images/cg_7_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  \n                    \n                    \n                      \n                        \n                    \n                    \n                      An astronaut stands on a lunar rover in Moonbase Alpha, a video game based on NASA lunar architecture plans. Army Game Studio and Virtual Heroes developed the game with NASA funding.\n                    \n                  \n                  Fast forward to 2035. Imagine being part of a community of astronauts living and working on the Moon. Suddenly, in the middle of just another day in space, a meteorite crashes into the surface of the Moon, threatening life as you know it. The support equipment that provides oxygen for the entire community has been compromised. What would you do? \n                  While this situation is one that most people will never encounter, NASA hopes to place students in such situations—virtually—to inspire, engage, and educate about NASA technologies, job opportunities, and the future of space exploration. Specifically, NASA’s Learning Technologies program, part of the Agency’s Office of Education, aims to inspire and motivate students to pursue careers in the science, technology, engineering, and math (STEM) disciplines through interactive technologies. The ultimate goal of these educational programs is to support the growth of a pool of qualified scientific and technical candidates for future careers at places like NASA. STEM education has been an area of concern in the United States; according to the results of the 2009 Program for International Student Assessment, 23 countries had higher average scores in mathematics literacy than the United States. On the science literacy scale, 18 countries had higher average scores.\n                  “This is part of a much bigger picture of trying to grow skilled graduates for places like NASA that will want that technical expertise,” says Daniel Laughlin, the Learning Technologies project manager at Goddard Space Flight Center. “NASA is trying to increase the number of students going into those fields, and so are other government agencies.”\n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      The space station shown here, “The Arthur C. Clarke Astronaut Academy,” is from a new game called Astronaut: Moon, Mars, and Beyond, which is being developed through a Space Act Agreement. \n                    \n                  \n                  In 2004, Laughlin began researching the idea of a Massively Multiplayer Online Game (MMOG) to attract young people and foster their interest in STEM subjects. Used as a formal or informal educational tool, an MMOG could help young people to grasp complex concepts in STEM areas and then transfer their understanding to practice. Because today’s generation of young people spend a large amount of time playing video games, the demographic is already familiar and comfortable with the technology. Laughlin thought an online game could be a successful method of exposure to STEM because virtual environments can provide scientifically-accurate simulations where players can experiment with chemical reactions, practice operating and repairing equipment, and even experience microgravity (virtually). \n                  Laughlin explains, “A virtual space gives a sense of being in a shared space, like a real place. Our brains are geared to process the world in three dimensions and virtual worlds are built in three dimensions, so our brains jump to processing in the same way as in the real world. By creating a real, life-like space, it impacts like real life, and everything done there encodes in memories more firmly.” As an added benefit, MMOGs have been shown to enhance skills like strategic thinking, interpretative analysis, problem solving, plan formulation and execution, team-building and cooperation, and adaptation to rapid change. \n                  In 2009, the Learning Technologies program, along with Goddard, Marshall Space Flight Center, and NASA Headquarters, combined efforts to provide funding \n                    for Army Game Studio, of Redstone Arsenal, Alabama, and Virtual Heroes of Applied Research Associates, in Raleigh, North Carolina, to develop an online 3D video adventure that uses NASA content—specifically, NASA lunar architecture plans—as the basis for an engaging, inspiring, and fun game. The result was Moonbase Alpha.\n                  Benefits\n                  Released in July 2010, Moonbase Alpha was downloaded nearly 300,000 times in its first 8 months, and won the “Best Government Entry” in the Serious Game Showcase and Challenge at the 2010 Interservice/Industry Training, Simulation and Education Conference.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Astronaut: Moon, Mars, and Beyond, will feature game play in the asteroid belt, on Mars (as shown here), and in near-Earth orbit. \n                    \n                  \n                  “We are in the top 10 percent of games as far as popularity goes. Moonbase Alpha has been wildly successful,” says Laughlin. \n                  Available through a commercial network on the Internet, Moonbase Alpha offers 20 minutes of game time during which players can use robots, rovers, and repair tools to help restore the life support system at the lunar base. Because scores are based on the amount of time spent to complete the task as well as proper use of available resources, players are encouraged to form teams and work together. By using voice over communication and an online chat feature, players can communicate and coordinate their efforts with up to six people over a LAN or Internet connection.\n                  On the heels of the success of Moonbase Alpha, Laughlin and others at NASA are pursuing an even larger initiative—an MMOG entitled Astronaut: Moon, Mars, and Beyond. Three companies are working together to develop a fun and inspiring MMOG with 100 hours of game time, focused around a variety of real NASA engineering and science missions. Project Whitecard Inc. of Canada; WisdomTools of Bloomington, Indiana; and Virtual Heroes formed a joint company called Astronaut: Moon, Mars, and Beyond LLC, and then signed a Space Act Agreement with Goddard to allow the developers to consult with NASA to bring real astronauts, scientists, and other people involved with space exploration into the game, as well as incorporate realistic and historical situations. \n                  The plan for the expanded game, says Laughlin, places an emphasis on STEM education, but the fun factor must come first. “There were 800 pages of public input saying this kind of game had to be fun. In the history of educational games, almost all of them have been failures because they were developed under the premise that you want people to learn. If the game play comes second and the goal to teach comes first, it turns out to be a lousy game. The game must be fun,” he says.\n                  The secret to being fun, continues Laughlin, is that a game must have rules, keep track of winning or losing, keep score or another measure, provide some sort of challenge or adversarial condition, and be low stakes. Khal Shariff, the creative director of Astronaut: Moon, Mars, and Beyond LLC, and chief executive officer of Project Whitecard Inc., said the game will include all of that and much, much more.\n                  “Not only will we use the latest technology to drive learning goals, we will also use the best game engine to depict our solar system and a new space station called The Arthur C. Clarke Astronaut Academy. Never before has the ability existed for the public and students to experience the valleys on Mars or the thrill of a launch with such high fidelity,” says Shariff. \n                  Astronaut players will create their own characters, such as an engineer, physicist, or pilot, and as the characters are developed, players working in teams can unlock new activities, tools, and levels. Players learn how to use technology, build structures, and explore their surroundings through their adventures infused with science, technology, engineering, mathematics, and physics. For example, in one of the higher levels of the game, players compete to be the first astronaut team to arrive on planet Mars. Not only do they have to build a manned science vehicle to land on Mars, but they must also plan and maneuver a successful landing, explore their surroundings, and learn to live on the planet, all with inherent realism.\n                  Targeted to students from age 13 to college-age, the game encourages players to form teams of three or four. Shariff says it is designed as a meritocracy where power goes to those with the highest intellect and strategic thinking. “The better you are at science and engineering, putting things together, math, and physics, the more gear you can access and build yourself,” he says. \n                  In its final form, Astronaut: Moon, Mars, and Beyond, with the first chapter entitled “Astronaut Academy,” will feature game play in the asteroid belt, on Mars, and in near-Earth orbit, but it will also be a social game where players can spend time building rovers, customizing space suits, and constructing their own bases. Eventually, the developers plan to release more areas of the solar system as new additions to the game.\n                  In the meantime, curricular support materials are being developed so Moonbase Alpha can be incorporated into formal education, and a number of schools have already signed up to use Astronaut: Moon, Mars, and Beyond for classroom education. With the pilot scheduled for release by late 2011, Shariff says the company expects Astronaut: Moon, Mars, and Beyond to have between 2 and 5 million players within the first year. \n                  “If we can attract people when they are young, using their mediums of video games and social networking,” Shariff says, “it will develop their love for this kind of stuff, just as Buck Rogers, Star Trek, and Carl Sagan did generations beforehand.”\n                  Virtual Heroes® is a registered trademark of Applied Research Associates Inc.\n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  \n                    \n                    \n                      \n                        \n                    \n                    \n                      An astronaut stands on a lunar rover in Moonbase Alpha, a video game based on NASA lunar architecture plans. Army Game Studio and Virtual Heroes developed the game with NASA funding.\n                    \n                  \n                  Fast forward to 2035. Imagine being part of a community of astronauts living and working on the Moon. Suddenly, in the middle of just another day in space, a meteorite crashes into the surface of the Moon, threatening life as you know it. The support equipment that provides oxygen for the entire community has been compromised. What would you do? \n                  While this situation is one that most people will never encounter, NASA hopes to place students in such situations—virtually—to inspire, engage, and educate about NASA technologies, job opportunities, and the future of space exploration. Specifically, NASA’s Learning Technologies program, part of the Agency’s Office of Education, aims to inspire and motivate students to pursue careers in the science, technology, engineering, and math (STEM) disciplines through interactive technologies. The ultimate goal of these educational programs is to support the growth of a pool of qualified scientific and technical candidates for future careers at places like NASA. STEM education has been an area of concern in the United States; according to the results of the 2009 Program for International Student Assessment, 23 countries had higher average scores in mathematics literacy than the United States. On the science literacy scale, 18 countries had higher average scores.\n                  “This is part of a much bigger picture of trying to grow skilled graduates for places like NASA that will want that technical expertise,” says Daniel Laughlin, the Learning Technologies project manager at Goddard Space Flight Center. “NASA is trying to increase the number of students going into those fields, and so are other government agencies.”\n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      The space station shown here, “The Arthur C. Clarke Astronaut Academy,” is from a new game called Astronaut: Moon, Mars, and Beyond, which is being developed through a Space Act Agreement. \n                    \n                  \n                  In 2004, Laughlin began researching the idea of a Massively Multiplayer Online Game (MMOG) to attract young people and foster their interest in STEM subjects. Used as a formal or informal educational tool, an MMOG could help young people to grasp complex concepts in STEM areas and then transfer their understanding to practice. Because today’s generation of young people spend a large amount of time playing video games, the demographic is already familiar and comfortable with the technology. Laughlin thought an online game could be a successful method of exposure to STEM because virtual environments can provide scientifically-accurate simulations where players can experiment with chemical reactions, practice operating and repairing equipment, and even experience microgravity (virtually). \n                  Laughlin explains, “A virtual space gives a sense of being in a shared space, like a real place. Our brains are geared to process the world in three dimensions and virtual worlds are built in three dimensions, so our brains jump to processing in the same way as in the real world. By creating a real, life-like space, it impacts like real life, and everything done there encodes in memories more firmly.” As an added benefit, MMOGs have been shown to enhance skills like strategic thinking, interpretative analysis, problem solving, plan formulation and execution, team-building and cooperation, and adaptation to rapid change. \n                  In 2009, the Learning Technologies program, along with Goddard, Marshall Space Flight Center, and NASA Headquarters, combined efforts to provide funding \n                    for Army Game Studio, of Redstone Arsenal, Alabama, and Virtual Heroes of Applied Research Associates, in Raleigh, North Carolina, to develop an online 3D video adventure that uses NASA content—specifically, NASA lunar architecture plans—as the basis for an engaging, inspiring, and fun game. The result was Moonbase Alpha.\n                  Benefits\n                  Released in July 2010, Moonbase Alpha was downloaded nearly 300,000 times in its first 8 months, and won the “Best Government Entry” in the Serious Game Showcase and Challenge at the 2010 Interservice/Industry Training, Simulation and Education Conference.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Astronaut: Moon, Mars, and Beyond, will feature game play in the asteroid belt, on Mars (as shown here), and in near-Earth orbit. \n                    \n                  \n                  “We are in the top 10 percent of games as far as popularity goes. Moonbase Alpha has been wildly successful,” says Laughlin. \n                  Available through a commercial network on the Internet, Moonbase Alpha offers 20 minutes of game time during which players can use robots, rovers, and repair tools to help restore the life support system at the lunar base. Because scores are based on the amount of time spent to complete the task as well as proper use of available resources, players are encouraged to form teams and work together. By using voice over communication and an online chat feature, players can communicate and coordinate their efforts with up to six people over a LAN or Internet connection.\n                  On the heels of the success of Moonbase Alpha, Laughlin and others at NASA are pursuing an even larger initiative—an MMOG entitled Astronaut: Moon, Mars, and Beyond. Three companies are working together to develop a fun and inspiring MMOG with 100 hours of game time, focused around a variety of real NASA engineering and science missions. Project Whitecard Inc. of Canada; WisdomTools of Bloomington, Indiana; and Virtual Heroes formed a joint company called Astronaut: Moon, Mars, and Beyond LLC, and then signed a Space Act Agreement with Goddard to allow the developers to consult with NASA to bring real astronauts, scientists, and other people involved with space exploration into the game, as well as incorporate realistic and historical situations. \n                  The plan for the expanded game, says Laughlin, places an emphasis on STEM education, but the fun factor must come first. “There were 800 pages of public input saying this kind of game had to be fun. In the history of educational games, almost all of them have been failures because they were developed under the premise that you want people to learn. If the game play comes second and the goal to teach comes first, it turns out to be a lousy game. The game must be fun,” he says.\n                  The secret to being fun, continues Laughlin, is that a game must have rules, keep track of winning or losing, keep score or another measure, provide some sort of challenge or adversarial condition, and be low stakes. Khal Shariff, the creative director of Astronaut: Moon, Mars, and Beyond LLC, and chief executive officer of Project Whitecard Inc., said the game will include all of that and much, much more.\n                  “Not only will we use the latest technology to drive learning goals, we will also use the best game engine to depict our solar system and a new space station called The Arthur C. Clarke Astronaut Academy. Never before has the ability existed for the public and students to experience the valleys on Mars or the thrill of a launch with such high fidelity,” says Shariff. \n                  Astronaut players will create their own characters, such as an engineer, physicist, or pilot, and as the characters are developed, players working in teams can unlock new activities, tools, and levels. Players learn how to use technology, build structures, and explore their surroundings through their adventures infused with science, technology, engineering, mathematics, and physics. For example, in one of the higher levels of the game, players compete to be the first astronaut team to arrive on planet Mars. Not only do they have to build a manned science vehicle to land on Mars, but they must also plan and maneuver a successful landing, explore their surroundings, and learn to live on the planet, all with inherent realism.\n                  Targeted to students from age 13 to college-age, the game encourages players to form teams of three or four. Shariff says it is designed as a meritocracy where power goes to those with the highest intellect and strategic thinking. “The better you are at science and engineering, putting things together, math, and physics, the more gear you can access and build yourself,” he says. \n                  In its final form, Astronaut: Moon, Mars, and Beyond, with the first chapter entitled “Astronaut Academy,” will feature game play in the asteroid belt, on Mars, and in near-Earth orbit, but it will also be a social game where players can spend time building rovers, customizing space suits, and constructing their own bases. Eventually, the developers plan to release more areas of the solar system as new additions to the game.\n                  In the meantime, curricular support materials are being developed so Moonbase Alpha can be incorporated into formal education, and a number of schools have already signed up to use Astronaut: Moon, Mars, and Beyond for classroom education. With the pilot scheduled for release by late 2011, Shariff says the company expects Astronaut: Moon, Mars, and Beyond to have between 2 and 5 million players within the first year. \n                  “If we can attract people when they are young, using their mediums of video games and social networking,” Shariff says, “it will develop their love for this kind of stuff, just as Buck Rogers, Star Trek, and Carl Sagan did generations beforehand.”\n                  Virtual Heroes® is a registered trademark of Applied Research Associates Inc.\n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  \n                    \n                    \n                      \n                        \n                    \n                    \n                      An astronaut stands on a lunar rover in Moonbase Alpha, a video game based on NASA lunar architecture plans. Army Game Studio and Virtual Heroes developed the game with NASA funding.\n                    \n                  \n                  Fast forward to 2035. Imagine being part of a community of astronauts living and working on the Moon. Suddenly, in the middle of just another day in space, a meteorite crashes into the surface of the Moon, threatening life as you know it. The support equipment that provides oxygen for the entire community has been compromised. What would you do? \n                  While this situation is one that most people will never encounter, NASA hopes to place students in such situations—virtually—to inspire, engage, and educate about NASA technologies, job opportunities, and the future of space exploration. Specifically, NASA’s Learning Technologies program, part of the Agency’s Office of Education, aims to inspire and motivate students to pursue careers in the science, technology, engineering, and math (STEM) disciplines through interactive technologies. The ultimate goal of these educational programs is to support the growth of a pool of qualified scientific and technical candidates for future careers at places like NASA. STEM education has been an area of concern in the United States; according to the results of the 2009 Program for International Student Assessment, 23 countries had higher average scores in mathematics literacy than the United States. On the science literacy scale, 18 countries had higher average scores.\n                  “This is part of a much bigger picture of trying to grow skilled graduates for places like NASA that will want that technical expertise,” says Daniel Laughlin, the Learning Technologies project manager at Goddard Space Flight Center. “NASA is trying to increase the number of students going into those fields, and so are other government agencies.”\n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      The space station shown here, “The Arthur C. Clarke Astronaut Academy,” is from a new game called Astronaut: Moon, Mars, and Beyond, which is being developed through a Space Act Agreement. \n                    \n                  \n                  In 2004, Laughlin began researching the idea of a Massively Multiplayer Online Game (MMOG) to attract young people and foster their interest in STEM subjects. Used as a formal or informal educational tool, an MMOG could help young people to grasp complex concepts in STEM areas and then transfer their understanding to practice. Because today’s generation of young people spend a large amount of time playing video games, the demographic is already familiar and comfortable with the technology. Laughlin thought an online game could be a successful method of exposure to STEM because virtual environments can provide scientifically-accurate simulations where players can experiment with chemical reactions, practice operating and repairing equipment, and even experience microgravity (virtually). \n                  Laughlin explains, “A virtual space gives a sense of being in a shared space, like a real place. Our brains are geared to process the world in three dimensions and virtual worlds are built in three dimensions, so our brains jump to processing in the same way as in the real world. By creating a real, life-like space, it impacts like real life, and everything done there encodes in memories more firmly.” As an added benefit, MMOGs have been shown to enhance skills like strategic thinking, interpretative analysis, problem solving, plan formulation and execution, team-building and cooperation, and adaptation to rapid change. \n                  In 2009, the Learning Technologies program, along with Goddard, Marshall Space Flight Center, and NASA Headquarters, combined efforts to provide funding \n                    for Army Game Studio, of Redstone Arsenal, Alabama, and Virtual Heroes of Applied Research Associates, in Raleigh, North Carolina, to develop an online 3D video adventure that uses NASA content—specifically, NASA lunar architecture plans—as the basis for an engaging, inspiring, and fun game. The result was Moonbase Alpha.\n                  Benefits\n                  Released in July 2010, Moonbase Alpha was downloaded nearly 300,000 times in its first 8 months, and won the “Best Government Entry” in the Serious Game Showcase and Challenge at the 2010 Interservice/Industry Training, Simulation and Education Conference.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Astronaut: Moon, Mars, and Beyond, will feature game play in the asteroid belt, on Mars (as shown here), and in near-Earth orbit. \n                    \n                  \n                  “We are in the top 10 percent of games as far as popularity goes. Moonbase Alpha has been wildly successful,” says Laughlin. \n                  Available through a commercial network on the Internet, Moonbase Alpha offers 20 minutes of game time during which players can use robots, rovers, and repair tools to help restore the life support system at the lunar base. Because scores are based on the amount of time spent to complete the task as well as proper use of available resources, players are encouraged to form teams and work together. By using voice over communication and an online chat feature, players can communicate and coordinate their efforts with up to six people over a LAN or Internet connection.\n                  On the heels of the success of Moonbase Alpha, Laughlin and others at NASA are pursuing an even larger initiative—an MMOG entitled Astronaut: Moon, Mars, and Beyond. Three companies are working together to develop a fun and inspiring MMOG with 100 hours of game time, focused around a variety of real NASA engineering and science missions. Project Whitecard Inc. of Canada; WisdomTools of Bloomington, Indiana; and Virtual Heroes formed a joint company called Astronaut: Moon, Mars, and Beyond LLC, and then signed a Space Act Agreement with Goddard to allow the developers to consult with NASA to bring real astronauts, scientists, and other people involved with space exploration into the game, as well as incorporate realistic and historical situations. \n                  The plan for the expanded game, says Laughlin, places an emphasis on STEM education, but the fun factor must come first. “There were 800 pages of public input saying this kind of game had to be fun. In the history of educational games, almost all of them have been failures because they were developed under the premise that you want people to learn. If the game play comes second and the goal to teach comes first, it turns out to be a lousy game. The game must be fun,” he says.\n                  The secret to being fun, continues Laughlin, is that a game must have rules, keep track of winning or losing, keep score or another measure, provide some sort of challenge or adversarial condition, and be low stakes. Khal Shariff, the creative director of Astronaut: Moon, Mars, and Beyond LLC, and chief executive officer of Project Whitecard Inc., said the game will include all of that and much, much more.\n                  “Not only will we use the latest technology to drive learning goals, we will also use the best game engine to depict our solar system and a new space station called The Arthur C. Clarke Astronaut Academy. Never before has the ability existed for the public and students to experience the valleys on Mars or the thrill of a launch with such high fidelity,” says Shariff. \n                  Astronaut players will create their own characters, such as an engineer, physicist, or pilot, and as the characters are developed, players working in teams can unlock new activities, tools, and levels. Players learn how to use technology, build structures, and explore their surroundings through their adventures infused with science, technology, engineering, mathematics, and physics. For example, in one of the higher levels of the game, players compete to be the first astronaut team to arrive on planet Mars. Not only do they have to build a manned science vehicle to land on Mars, but they must also plan and maneuver a successful landing, explore their surroundings, and learn to live on the planet, all with inherent realism.\n                  Targeted to students from age 13 to college-age, the game encourages players to form teams of three or four. Shariff says it is designed as a meritocracy where power goes to those with the highest intellect and strategic thinking. “The better you are at science and engineering, putting things together, math, and physics, the more gear you can access and build yourself,” he says. \n                  In its final form, Astronaut: Moon, Mars, and Beyond, with the first chapter entitled “Astronaut Academy,” will feature game play in the asteroid belt, on Mars, and in near-Earth orbit, but it will also be a social game where players can spend time building rovers, customizing space suits, and constructing their own bases. Eventually, the developers plan to release more areas of the solar system as new additions to the game.\n                  In the meantime, curricular support materials are being developed so Moonbase Alpha can be incorporated into formal education, and a number of schools have already signed up to use Astronaut: Moon, Mars, and Beyond for classroom education. With the pilot scheduled for release by late 2011, Shariff says the company expects Astronaut: Moon, Mars, and Beyond to have between 2 and 5 million players within the first year. \n                  “If we can attract people when they are young, using their mediums of video games and social networking,” Shariff says, “it will develop their love for this kind of stuff, just as Buck Rogers, Star Trek, and Carl Sagan did generations beforehand.”\n                  Virtual Heroes® is a registered trademark of Applied Research Associates Inc.\n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  NASA Technology\n                  \n                    \n                    \n                      \n                        \n                    \n                    \n                      An astronaut stands on a lunar rover in Moonbase Alpha, a video game based on NASA lunar architecture plans. Army Game Studio and Virtual Heroes developed the game with NASA funding.\n                    \n                  \n                  Fast forward to 2035. Imagine being part of a community of astronauts living and working on the Moon. Suddenly, in the middle of just another day in space, a meteorite crashes into the surface of the Moon, threatening life as you know it. The support equipment that provides oxygen for the entire community has been compromised. What would you do? \n                  While this situation is one that most people will never encounter, NASA hopes to place students in such situations—virtually—to inspire, engage, and educate about NASA technologies, job opportunities, and the future of space exploration. Specifically, NASA’s Learning Technologies program, part of the Agency’s Office of Education, aims to inspire and motivate students to pursue careers in the science, technology, engineering, and math (STEM) disciplines through interactive technologies. The ultimate goal of these educational programs is to support the growth of a pool of qualified scientific and technical candidates for future careers at places like NASA. STEM education has been an area of concern in the United States; according to the results of the 2009 Program for International Student Assessment, 23 countries had higher average scores in mathematics literacy than the United States. On the science literacy scale, 18 countries had higher average scores.\n                  “This is part of a much bigger picture of trying to grow skilled graduates for places like NASA that will want that technical expertise,” says Daniel Laughlin, the Learning Technologies project manager at Goddard Space Flight Center. “NASA is trying to increase the number of students going into those fields, and so are other government agencies.”\n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      The space station shown here, “The Arthur C. Clarke Astronaut Academy,” is from a new game called Astronaut: Moon, Mars, and Beyond, which is being developed through a Space Act Agreement. \n                    \n                  \n                  In 2004, Laughlin began researching the idea of a Massively Multiplayer Online Game (MMOG) to attract young people and foster their interest in STEM subjects. Used as a formal or informal educational tool, an MMOG could help young people to grasp complex concepts in STEM areas and then transfer their understanding to practice. Because today’s generation of young people spend a large amount of time playing video games, the demographic is already familiar and comfortable with the technology. Laughlin thought an online game could be a successful method of exposure to STEM because virtual environments can provide scientifically-accurate simulations where players can experiment with chemical reactions, practice operating and repairing equipment, and even experience microgravity (virtually). \n                  Laughlin explains, “A virtual space gives a sense of being in a shared space, like a real place. Our brains are geared to process the world in three dimensions and virtual worlds are built in three dimensions, so our brains jump to processing in the same way as in the real world. By creating a real, life-like space, it impacts like real life, and everything done there encodes in memories more firmly.” As an added benefit, MMOGs have been shown to enhance skills like strategic thinking, interpretative analysis, problem solving, plan formulation and execution, team-building and cooperation, and adaptation to rapid change. \n                  In 2009, the Learning Technologies program, along with Goddard, Marshall Space Flight Center, and NASA Headquarters, combined efforts to provide funding \n                    for Army Game Studio, of Redstone Arsenal, Alabama, and Virtual Heroes of Applied Research Associates, in Raleigh, North Carolina, to develop an online 3D video adventure that uses NASA content—specifically, NASA lunar architecture plans—as the basis for an engaging, inspiring, and fun game. The result was Moonbase Alpha.\n                  Benefits\n                  Released in July 2010, Moonbase Alpha was downloaded nearly 300,000 times in its first 8 months, and won the “Best Government Entry” in the Serious Game Showcase and Challenge at the 2010 Interservice/Industry Training, Simulation and Education Conference.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Astronaut: Moon, Mars, and Beyond, will feature game play in the asteroid belt, on Mars (as shown here), and in near-Earth orbit. \n                    \n                  \n                  “We are in the top 10 percent of games as far as popularity goes. Moonbase Alpha has been wildly successful,” says Laughlin. \n                  Available through a commercial network on the Internet, Moonbase Alpha offers 20 minutes of game time during which players can use robots, rovers, and repair tools to help restore the life support system at the lunar base. Because scores are based on the amount of time spent to complete the task as well as proper use of available resources, players are encouraged to form teams and work together. By using voice over communication and an online chat feature, players can communicate and coordinate their efforts with up to six people over a LAN or Internet connection.\n                  On the heels of the success of Moonbase Alpha, Laughlin and others at NASA are pursuing an even larger initiative—an MMOG entitled Astronaut: Moon, Mars, and Beyond. Three companies are working together to develop a fun and inspiring MMOG with 100 hours of game time, focused around a variety of real NASA engineering and science missions. Project Whitecard Inc. of Canada; WisdomTools of Bloomington, Indiana; and Virtual Heroes formed a joint company called Astronaut: Moon, Mars, and Beyond LLC, and then signed a Space Act Agreement with Goddard to allow the developers to consult with NASA to bring real astronauts, scientists, and other people involved with space exploration into the game, as well as incorporate realistic and historical situations. \n                  The plan for the expanded game, says Laughlin, places an emphasis on STEM education, but the fun factor must come first. “There were 800 pages of public input saying this kind of game had to be fun. In the history of educational games, almost all of them have been failures because they were developed under the premise that you want people to learn. If the game play comes second and the goal to teach comes first, it turns out to be a lousy game. The game must be fun,” he says.\n                  The secret to being fun, continues Laughlin, is that a game must have rules, keep track of winning or losing, keep score or another measure, provide some sort of challenge or adversarial condition, and be low stakes. Khal Shariff, the creative director of Astronaut: Moon, Mars, and Beyond LLC, and chief executive officer of Project Whitecard Inc., said the game will include all of that and much, much more.\n                  “Not only will we use the latest technology to drive learning goals, we will also use the best game engine to depict our solar system and a new space station called The Arthur C. Clarke Astronaut Academy. Never before has the ability existed for the public and students to experience the valleys on Mars or the thrill of a launch with such high fidelity,” says Shariff. \n                  Astronaut players will create their own characters, such as an engineer, physicist, or pilot, and as the characters are developed, players working in teams can unlock new activities, tools, and levels. Players learn how to use technology, build structures, and explore their surroundings through their adventures infused with science, technology, engineering, mathematics, and physics. For example, in one of the higher levels of the game, players compete to be the first astronaut team to arrive on planet Mars. Not only do they have to build a manned science vehicle to land on Mars, but they must also plan and maneuver a successful landing, explore their surroundings, and learn to live on the planet, all with inherent realism.\n                  Targeted to students from age 13 to college-age, the game encourages players to form teams of three or four. Shariff says it is designed as a meritocracy where power goes to those with the highest intellect and strategic thinking. “The better you are at science and engineering, putting things together, math, and physics, the more gear you can access and build yourself,” he says. \n                  In its final form, Astronaut: Moon, Mars, and Beyond, with the first chapter entitled “Astronaut Academy,” will feature game play in the asteroid belt, on Mars, and in near-Earth orbit, but it will also be a social game where players can spend time building rovers, customizing space suits, and constructing their own bases. Eventually, the developers plan to release more areas of the solar system as new additions to the game.\n                  In the meantime, curricular support materials are being developed so Moonbase Alpha can be incorporated into formal education, and a number of schools have already signed up to use Astronaut: Moon, Mars, and Beyond for classroom education. With the pilot scheduled for release by late 2011, Shariff says the company expects Astronaut: Moon, Mars, and Beyond to have between 2 and 5 million players within the first year. \n                  “If we can attract people when they are young, using their mediums of video games and social networking,” Shariff says, “it will develop their love for this kind of stuff, just as Buck Rogers, Star Trek, and Carl Sagan did generations beforehand.”\n                  Virtual Heroes® is a registered trademark of Applied Research Associates Inc.\n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  NASA Technology\n                  \n                    \n                    \n                      \n                        \n                    \n                    \n                      An astronaut stands on a lunar rover in Moonbase Alpha, a video game based on NASA lunar architecture plans. Army Game Studio and Virtual Heroes developed the game with NASA funding.\n                    \n                  \n                  Fast forward to 2035. Imagine being part of a community of astronauts living and working on the Moon. Suddenly, in the middle of just another day in space, a meteorite crashes into the surface of the Moon, threatening life as you know it. The support equipment that provides oxygen for the entire community has been compromised. What would you do? \n                  While this situation is one that most people will never encounter, NASA hopes to place students in such situations—virtually—to inspire, engage, and educate about NASA technologies, job opportunities, and the future of space exploration. Specifically, NASA’s Learning Technologies program, part of the Agency’s Office of Education, aims to inspire and motivate students to pursue careers in the science, technology, engineering, and math (STEM) disciplines through interactive technologies. The ultimate goal of these educational programs is to support the growth of a pool of qualified scientific and technical candidates for future careers at places like NASA. STEM education has been an area of concern in the United States; according to the results of the 2009 Program for International Student Assessment, 23 countries had higher average scores in mathematics literacy than the United States. On the science literacy scale, 18 countries had higher average scores.\n                  “This is part of a much bigger picture of trying to grow skilled graduates for places like NASA that will want that technical expertise,” says Daniel Laughlin, the Learning Technologies project manager at Goddard Space Flight Center. “NASA is trying to increase the number of students going into those fields, and so are other government agencies.”\n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      The space station shown here, “The Arthur C. Clarke Astronaut Academy,” is from a new game called Astronaut: Moon, Mars, and Beyond, which is being developed through a Space Act Agreement. \n                    \n                  \n                  In 2004, Laughlin began researching the idea of a Massively Multiplayer Online Game (MMOG) to attract young people and foster their interest in STEM subjects. Used as a formal or informal educational tool, an MMOG could help young people to grasp complex concepts in STEM areas and then transfer their understanding to practice. Because today’s generation of young people spend a large amount of time playing video games, the demographic is already familiar and comfortable with the technology. Laughlin thought an online game could be a successful method of exposure to STEM because virtual environments can provide scientifically-accurate simulations where players can experiment with chemical reactions, practice operating and repairing equipment, and even experience microgravity (virtually). \n                  Laughlin explains, “A virtual space gives a sense of being in a shared space, like a real place. Our brains are geared to process the world in three dimensions and virtual worlds are built in three dimensions, so our brains jump to processing in the same way as in the real world. By creating a real, life-like space, it impacts like real life, and everything done there encodes in memories more firmly.” As an added benefit, MMOGs have been shown to enhance skills like strategic thinking, interpretative analysis, problem solving, plan formulation and execution, team-building and cooperation, and adaptation to rapid change. \n                  In 2009, the Learning Technologies program, along with Goddard, Marshall Space Flight Center, and NASA Headquarters, combined efforts to provide funding \n                    for Army Game Studio, of Redstone Arsenal, Alabama, and Virtual Heroes of Applied Research Associates, in Raleigh, North Carolina, to develop an online 3D video adventure that uses NASA content—specifically, NASA lunar architecture plans—as the basis for an engaging, inspiring, and fun game. The result was Moonbase Alpha.\n                  Benefits\n                  Released in July 2010, Moonbase Alpha was downloaded nearly 300,000 times in its first 8 months, and won the “Best Government Entry” in the Serious Game Showcase and Challenge at the 2010 Interservice/Industry Training, Simulation and Education Conference.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Astronaut: Moon, Mars, and Beyond, will feature game play in the asteroid belt, on Mars (as shown here), and in near-Earth orbit. \n                    \n                  \n                  “We are in the top 10 percent of games as far as popularity goes. Moonbase Alpha has been wildly successful,” says Laughlin. \n                  Available through a commercial network on the Internet, Moonbase Alpha offers 20 minutes of game time during which players can use robots, rovers, and repair tools to help restore the life support system at the lunar base. Because scores are based on the amount of time spent to complete the task as well as proper use of available resources, players are encouraged to form teams and work together. By using voice over communication and an online chat feature, players can communicate and coordinate their efforts with up to six people over a LAN or Internet connection.\n                  On the heels of the success of Moonbase Alpha, Laughlin and others at NASA are pursuing an even larger initiative—an MMOG entitled Astronaut: Moon, Mars, and Beyond. Three companies are working together to develop a fun and inspiring MMOG with 100 hours of game time, focused around a variety of real NASA engineering and science missions. Project Whitecard Inc. of Canada; WisdomTools of Bloomington, Indiana; and Virtual Heroes formed a joint company called Astronaut: Moon, Mars, and Beyond LLC, and then signed a Space Act Agreement with Goddard to allow the developers to consult with NASA to bring real astronauts, scientists, and other people involved with space exploration into the game, as well as incorporate realistic and historical situations. \n                  The plan for the expanded game, says Laughlin, places an emphasis on STEM education, but the fun factor must come first. “There were 800 pages of public input saying this kind of game had to be fun. In the history of educational games, almost all of them have been failures because they were developed under the premise that you want people to learn. If the game play comes second and the goal to teach comes first, it turns out to be a lousy game. The game must be fun,” he says.\n                  The secret to being fun, continues Laughlin, is that a game must have rules, keep track of winning or losing, keep score or another measure, provide some sort of challenge or adversarial condition, and be low stakes. Khal Shariff, the creative director of Astronaut: Moon, Mars, and Beyond LLC, and chief executive officer of Project Whitecard Inc., said the game will include all of that and much, much more.\n                  “Not only will we use the latest technology to drive learning goals, we will also use the best game engine to depict our solar system and a new space station called The Arthur C. Clarke Astronaut Academy. Never before has the ability existed for the public and students to experience the valleys on Mars or the thrill of a launch with such high fidelity,” says Shariff. \n                  Astronaut players will create their own characters, such as an engineer, physicist, or pilot, and as the characters are developed, players working in teams can unlock new activities, tools, and levels. Players learn how to use technology, build structures, and explore their surroundings through their adventures infused with science, technology, engineering, mathematics, and physics. For example, in one of the higher levels of the game, players compete to be the first astronaut team to arrive on planet Mars. Not only do they have to build a manned science vehicle to land on Mars, but they must also plan and maneuver a successful landing, explore their surroundings, and learn to live on the planet, all with inherent realism.\n                  Targeted to students from age 13 to college-age, the game encourages players to form teams of three or four. Shariff says it is designed as a meritocracy where power goes to those with the highest intellect and strategic thinking. “The better you are at science and engineering, putting things together, math, and physics, the more gear you can access and build yourself,” he says. \n                  In its final form, Astronaut: Moon, Mars, and Beyond, with the first chapter entitled “Astronaut Academy,” will feature game play in the asteroid belt, on Mars, and in near-Earth orbit, but it will also be a social game where players can spend time building rovers, customizing space suits, and constructing their own bases. Eventually, the developers plan to release more areas of the solar system as new additions to the game.\n                  In the meantime, curricular support materials are being developed so Moonbase Alpha can be incorporated into formal education, and a number of schools have already signed up to use Astronaut: Moon, Mars, and Beyond for classroom education. With the pilot scheduled for release by late 2011, Shariff says the company expects Astronaut: Moon, Mars, and Beyond to have between 2 and 5 million players within the first year. \n                  “If we can attract people when they are young, using their mediums of video games and social networking,” Shariff says, “it will develop their love for this kind of stuff, just as Buck Rogers, Star Trek, and Carl Sagan did generations beforehand.”\n                  Virtual Heroes® is a registered trademark of Applied Research Associates Inc.\n                  \n                \n              \n            \n            \n              \n                \n                  NASA Technology\n                  \n                    \n                    \n                      \n                        \n                    \n                    \n                      An astronaut stands on a lunar rover in Moonbase Alpha, a video game based on NASA lunar architecture plans. Army Game Studio and Virtual Heroes developed the game with NASA funding.\n                    \n                  \n                  Fast forward to 2035. Imagine being part of a community of astronauts living and working on the Moon. Suddenly, in the middle of just another day in space, a meteorite crashes into the surface of the Moon, threatening life as you know it. The support equipment that provides oxygen for the entire community has been compromised. What would you do? \n                  While this situation is one that most people will never encounter, NASA hopes to place students in such situations—virtually—to inspire, engage, and educate about NASA technologies, job opportunities, and the future of space exploration. Specifically, NASA’s Learning Technologies program, part of the Agency’s Office of Education, aims to inspire and motivate students to pursue careers in the science, technology, engineering, and math (STEM) disciplines through interactive technologies. The ultimate goal of these educational programs is to support the growth of a pool of qualified scientific and technical candidates for future careers at places like NASA. STEM education has been an area of concern in the United States; according to the results of the 2009 Program for International Student Assessment, 23 countries had higher average scores in mathematics literacy than the United States. On the science literacy scale, 18 countries had higher average scores.\n                  “This is part of a much bigger picture of trying to grow skilled graduates for places like NASA that will want that technical expertise,” says Daniel Laughlin, the Learning Technologies project manager at Goddard Space Flight Center. “NASA is trying to increase the number of students going into those fields, and so are other government agencies.”\n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      The space station shown here, “The Arthur C. Clarke Astronaut Academy,” is from a new game called Astronaut: Moon, Mars, and Beyond, which is being developed through a Space Act Agreement. \n                    \n                  \n                  In 2004, Laughlin began researching the idea of a Massively Multiplayer Online Game (MMOG) to attract young people and foster their interest in STEM subjects. Used as a formal or informal educational tool, an MMOG could help young people to grasp complex concepts in STEM areas and then transfer their understanding to practice. Because today’s generation of young people spend a large amount of time playing video games, the demographic is already familiar and comfortable with the technology. Laughlin thought an online game could be a successful method of exposure to STEM because virtual environments can provide scientifically-accurate simulations where players can experiment with chemical reactions, practice operating and repairing equipment, and even experience microgravity (virtually). \n                  Laughlin explains, “A virtual space gives a sense of being in a shared space, like a real place. Our brains are geared to process the world in three dimensions and virtual worlds are built in three dimensions, so our brains jump to processing in the same way as in the real world. By creating a real, life-like space, it impacts like real life, and everything done there encodes in memories more firmly.” As an added benefit, MMOGs have been shown to enhance skills like strategic thinking, interpretative analysis, problem solving, plan formulation and execution, team-building and cooperation, and adaptation to rapid change. \n                  In 2009, the Learning Technologies program, along with Goddard, Marshall Space Flight Center, and NASA Headquarters, combined efforts to provide funding \n                    for Army Game Studio, of Redstone Arsenal, Alabama, and Virtual Heroes of Applied Research Associates, in Raleigh, North Carolina, to develop an online 3D video adventure that uses NASA content—specifically, NASA lunar architecture plans—as the basis for an engaging, inspiring, and fun game. The result was Moonbase Alpha.\n                  Benefits\n                  Released in July 2010, Moonbase Alpha was downloaded nearly 300,000 times in its first 8 months, and won the “Best Government Entry” in the Serious Game Showcase and Challenge at the 2010 Interservice/Industry Training, Simulation and Education Conference.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Astronaut: Moon, Mars, and Beyond, will feature game play in the asteroid belt, on Mars (as shown here), and in near-Earth orbit. \n                    \n                  \n                  “We are in the top 10 percent of games as far as popularity goes. Moonbase Alpha has been wildly successful,” says Laughlin. \n                  Available through a commercial network on the Internet, Moonbase Alpha offers 20 minutes of game time during which players can use robots, rovers, and repair tools to help restore the life support system at the lunar base. Because scores are based on the amount of time spent to complete the task as well as proper use of available resources, players are encouraged to form teams and work together. By using voice over communication and an online chat feature, players can communicate and coordinate their efforts with up to six people over a LAN or Internet connection.\n                  On the heels of the success of Moonbase Alpha, Laughlin and others at NASA are pursuing an even larger initiative—an MMOG entitled Astronaut: Moon, Mars, and Beyond. Three companies are working together to develop a fun and inspiring MMOG with 100 hours of game time, focused around a variety of real NASA engineering and science missions. Project Whitecard Inc. of Canada; WisdomTools of Bloomington, Indiana; and Virtual Heroes formed a joint company called Astronaut: Moon, Mars, and Beyond LLC, and then signed a Space Act Agreement with Goddard to allow the developers to consult with NASA to bring real astronauts, scientists, and other people involved with space exploration into the game, as well as incorporate realistic and historical situations. \n                  The plan for the expanded game, says Laughlin, places an emphasis on STEM education, but the fun factor must come first. “There were 800 pages of public input saying this kind of game had to be fun. In the history of educational games, almost all of them have been failures because they were developed under the premise that you want people to learn. If the game play comes second and the goal to teach comes first, it turns out to be a lousy game. The game must be fun,” he says.\n                  The secret to being fun, continues Laughlin, is that a game must have rules, keep track of winning or losing, keep score or another measure, provide some sort of challenge or adversarial condition, and be low stakes. Khal Shariff, the creative director of Astronaut: Moon, Mars, and Beyond LLC, and chief executive officer of Project Whitecard Inc., said the game will include all of that and much, much more.\n                  “Not only will we use the latest technology to drive learning goals, we will also use the best game engine to depict our solar system and a new space station called The Arthur C. Clarke Astronaut Academy. Never before has the ability existed for the public and students to experience the valleys on Mars or the thrill of a launch with such high fidelity,” says Shariff. \n                  Astronaut players will create their own characters, such as an engineer, physicist, or pilot, and as the characters are developed, players working in teams can unlock new activities, tools, and levels. Players learn how to use technology, build structures, and explore their surroundings through their adventures infused with science, technology, engineering, mathematics, and physics. For example, in one of the higher levels of the game, players compete to be the first astronaut team to arrive on planet Mars. Not only do they have to build a manned science vehicle to land on Mars, but they must also plan and maneuver a successful landing, explore their surroundings, and learn to live on the planet, all with inherent realism.\n                  Targeted to students from age 13 to college-age, the game encourages players to form teams of three or four. Shariff says it is designed as a meritocracy where power goes to those with the highest intellect and strategic thinking. “The better you are at science and engineering, putting things together, math, and physics, the more gear you can access and build yourself,” he says. \n                  In its final form, Astronaut: Moon, Mars, and Beyond, with the first chapter entitled “Astronaut Academy,” will feature game play in the asteroid belt, on Mars, and in near-Earth orbit, but it will also be a social game where players can spend time building rovers, customizing space suits, and constructing their own bases. Eventually, the developers plan to release more areas of the solar system as new additions to the game.\n                  In the meantime, curricular support materials are being developed so Moonbase Alpha can be incorporated into formal education, and a number of schools have already signed up to use Astronaut: Moon, Mars, and Beyond for classroom education. With the pilot scheduled for release by late 2011, Shariff says the company expects Astronaut: Moon, Mars, and Beyond to have between 2 and 5 million players within the first year. \n                  “If we can attract people when they are young, using their mediums of video games and social networking,” Shariff says, “it will develop their love for this kind of stuff, just as Buck Rogers, Star Trek, and Carl Sagan did generations beforehand.”\n                  Virtual Heroes® is a registered trademark of Applied Research Associates Inc.\n                  \n                \n              \n                  NASA Technology\n                  \n                    \n                    \n                      \n                        \n                    \n                    \n                      An astronaut stands on a lunar rover in Moonbase Alpha, a video game based on NASA lunar architecture plans. Army Game Studio and Virtual Heroes developed the game with NASA funding.\n                    \n                  \n                  Fast forward to 2035. Imagine being part of a community of astronauts living and working on the Moon. Suddenly, in the middle of just another day in space, a meteorite crashes into the surface of the Moon, threatening life as you know it. The support equipment that provides oxygen for the entire community has been compromised. What would you do? \n                  While this situation is one that most people will never encounter, NASA hopes to place students in such situations—virtually—to inspire, engage, and educate about NASA technologies, job opportunities, and the future of space exploration. Specifically, NASA’s Learning Technologies program, part of the Agency’s Office of Education, aims to inspire and motivate students to pursue careers in the science, technology, engineering, and math (STEM) disciplines through interactive technologies. The ultimate goal of these educational programs is to support the growth of a pool of qualified scientific and technical candidates for future careers at places like NASA. STEM education has been an area of concern in the United States; according to the results of the 2009 Program for International Student Assessment, 23 countries had higher average scores in mathematics literacy than the United States. On the science literacy scale, 18 countries had higher average scores.\n                  “This is part of a much bigger picture of trying to grow skilled graduates for places like NASA that will want that technical expertise,” says Daniel Laughlin, the Learning Technologies project manager at Goddard Space Flight Center. “NASA is trying to increase the number of students going into those fields, and so are other government agencies.”\n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      The space station shown here, “The Arthur C. Clarke Astronaut Academy,” is from a new game called Astronaut: Moon, Mars, and Beyond, which is being developed through a Space Act Agreement. \n                    \n                  \n                  In 2004, Laughlin began researching the idea of a Massively Multiplayer Online Game (MMOG) to attract young people and foster their interest in STEM subjects. Used as a formal or informal educational tool, an MMOG could help young people to grasp complex concepts in STEM areas and then transfer their understanding to practice. Because today’s generation of young people spend a large amount of time playing video games, the demographic is already familiar and comfortable with the technology. Laughlin thought an online game could be a successful method of exposure to STEM because virtual environments can provide scientifically-accurate simulations where players can experiment with chemical reactions, practice operating and repairing equipment, and even experience microgravity (virtually). \n                  Laughlin explains, “A virtual space gives a sense of being in a shared space, like a real place. Our brains are geared to process the world in three dimensions and virtual worlds are built in three dimensions, so our brains jump to processing in the same way as in the real world. By creating a real, life-like space, it impacts like real life, and everything done there encodes in memories more firmly.” As an added benefit, MMOGs have been shown to enhance skills like strategic thinking, interpretative analysis, problem solving, plan formulation and execution, team-building and cooperation, and adaptation to rapid change. \n                  In 2009, the Learning Technologies program, along with Goddard, Marshall Space Flight Center, and NASA Headquarters, combined efforts to provide funding \n                    for Army Game Studio, of Redstone Arsenal, Alabama, and Virtual Heroes of Applied Research Associates, in Raleigh, North Carolina, to develop an online 3D video adventure that uses NASA content—specifically, NASA lunar architecture plans—as the basis for an engaging, inspiring, and fun game. The result was Moonbase Alpha.\n                  Benefits\n                  Released in July 2010, Moonbase Alpha was downloaded nearly 300,000 times in its first 8 months, and won the “Best Government Entry” in the Serious Game Showcase and Challenge at the 2010 Interservice/Industry Training, Simulation and Education Conference.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Astronaut: Moon, Mars, and Beyond, will feature game play in the asteroid belt, on Mars (as shown here), and in near-Earth orbit. \n                    \n                  \n                  “We are in the top 10 percent of games as far as popularity goes. Moonbase Alpha has been wildly successful,” says Laughlin. \n                  Available through a commercial network on the Internet, Moonbase Alpha offers 20 minutes of game time during which players can use robots, rovers, and repair tools to help restore the life support system at the lunar base. Because scores are based on the amount of time spent to complete the task as well as proper use of available resources, players are encouraged to form teams and work together. By using voice over communication and an online chat feature, players can communicate and coordinate their efforts with up to six people over a LAN or Internet connection.\n                  On the heels of the success of Moonbase Alpha, Laughlin and others at NASA are pursuing an even larger initiative—an MMOG entitled Astronaut: Moon, Mars, and Beyond. Three companies are working together to develop a fun and inspiring MMOG with 100 hours of game time, focused around a variety of real NASA engineering and science missions. Project Whitecard Inc. of Canada; WisdomTools of Bloomington, Indiana; and Virtual Heroes formed a joint company called Astronaut: Moon, Mars, and Beyond LLC, and then signed a Space Act Agreement with Goddard to allow the developers to consult with NASA to bring real astronauts, scientists, and other people involved with space exploration into the game, as well as incorporate realistic and historical situations. \n                  The plan for the expanded game, says Laughlin, places an emphasis on STEM education, but the fun factor must come first. “There were 800 pages of public input saying this kind of game had to be fun. In the history of educational games, almost all of them have been failures because they were developed under the premise that you want people to learn. If the game play comes second and the goal to teach comes first, it turns out to be a lousy game. The game must be fun,” he says.\n                  The secret to being fun, continues Laughlin, is that a game must have rules, keep track of winning or losing, keep score or another measure, provide some sort of challenge or adversarial condition, and be low stakes. Khal Shariff, the creative director of Astronaut: Moon, Mars, and Beyond LLC, and chief executive officer of Project Whitecard Inc., said the game will include all of that and much, much more.\n                  “Not only will we use the latest technology to drive learning goals, we will also use the best game engine to depict our solar system and a new space station called The Arthur C. Clarke Astronaut Academy. Never before has the ability existed for the public and students to experience the valleys on Mars or the thrill of a launch with such high fidelity,” says Shariff. \n                  Astronaut players will create their own characters, such as an engineer, physicist, or pilot, and as the characters are developed, players working in teams can unlock new activities, tools, and levels. Players learn how to use technology, build structures, and explore their surroundings through their adventures infused with science, technology, engineering, mathematics, and physics. For example, in one of the higher levels of the game, players compete to be the first astronaut team to arrive on planet Mars. Not only do they have to build a manned science vehicle to land on Mars, but they must also plan and maneuver a successful landing, explore their surroundings, and learn to live on the planet, all with inherent realism.\n                  Targeted to students from age 13 to college-age, the game encourages players to form teams of three or four. Shariff says it is designed as a meritocracy where power goes to those with the highest intellect and strategic thinking. “The better you are at science and engineering, putting things together, math, and physics, the more gear you can access and build yourself,” he says. \n                  In its final form, Astronaut: Moon, Mars, and Beyond, with the first chapter entitled “Astronaut Academy,” will feature game play in the asteroid belt, on Mars, and in near-Earth orbit, but it will also be a social game where players can spend time building rovers, customizing space suits, and constructing their own bases. Eventually, the developers plan to release more areas of the solar system as new additions to the game.\n                  In the meantime, curricular support materials are being developed so Moonbase Alpha can be incorporated into formal education, and a number of schools have already signed up to use Astronaut: Moon, Mars, and Beyond for classroom education. With the pilot scheduled for release by late 2011, Shariff says the company expects Astronaut: Moon, Mars, and Beyond to have between 2 and 5 million players within the first year. \n                  “If we can attract people when they are young, using their mediums of video games and social networking,” Shariff says, “it will develop their love for this kind of stuff, just as Buck Rogers, Star Trek, and Carl Sagan did generations beforehand.”\n                  Virtual Heroes® is a registered trademark of Applied Research Associates Inc.\n                  "},{"href":"http://spinoff.nasa.gov/Spinoff2011/cg_5.html","text":"Monitors Track Vital Signs for Fitness \n                    and Safety","image":"http://spinoff.nasa.gov/Spinoff2011/Images/cg_10a_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Have you ever felt nauseous reading a book in the back seat of a car? Or woken from a deep sleep feeling disoriented, unsure which way is up? Momentary mixups like these happen when the sensory systems that track the body’s orientation in space become confused. (In the case of the backseat bookworm, the conflict arises when the reader’s inner ear, part of the body’s vestibular system, senses the car’s motion while her eyes are fixed on the stationary pages of the book.) Conditions like motion sickness are common on Earth, but they also present a significant challenge to astronauts in space. \n                  \n                    \n                    \n                      \n                    \n                    \n                      A subject undergoes preflight motion sickness testing in a rotating chair. NASA researchers developed a technique for overcoming the potentially debilitating condition.\n                    \n                  \n                  Human sensory systems use the pull of gravity to help determine orientation. In the microgravity environment onboard the International Space Station, for example, the body experiences a period of confusion before it adapts to the new circumstances. (In space, even the body’s proprioceptive system, which tells the brain where the arms and legs are oriented without the need for visual confirmation, goes haywire, meaning astronauts sometimes lose track of where their limbs are when they are not moving them.) This Space Adaptation Syndrome affects a majority of astronauts, even experienced ones, causing everything from mild disorientation to nausea to severe vomiting. \n                  “It can be quite debilitating,” says William Toscano, a research scientist in NASA’s Ames Research Center Psychophysiology Laboratory, part of the Center’s Human Systems Integration Division. “When this happens, as you can imagine, work proficiency declines considerably.”\n                  Since astronauts cannot afford to be distracted or incapacitated during critical missions, NASA has explored various means for preventing and countering motion sickness in space, including a range of drug treatments. Many effective motion sickness drugs, however, cause undesirable side effects, such as drowsiness. Toscano and his NASA colleague, Patricia Cowings, have developed a different approach: Utilizing biofeedback training methods, the pair can teach astronauts, military pilots, and others susceptible to motion sickness to self-regulate their own physiological responses and suppress the unpleasant symptoms. This NASA-patented method invented by Cowings is called the Autogenic Feedback Training Exercise (ATFE), and several studies have demonstrated its promise.\n                  “We’re able to get people to significantly increase their motion sickness tolerance,” says Toscano, noting that in laboratory studies conducted over a 20-year period about 85 percent of those who have undergone the 6-hour training experienced benefits, with about 65 percent able to suppress their symptoms entirely. \n                  In order to gather the necessary physiological data for their research and to enable the ATFE biofeedback training, Toscano and Cowings needed a practical solution for monitoring the vital signs of test subjects like astronauts and pilots. \n                  “The biggest consideration with using physiological monitors on astronauts and aircrew is putting sensors on the body,” Toscano says. “You need to have an unobtrusive device.”\n                  A company in Annapolis, Maryland, proved to have the technology the NASA researchers were looking for. Now the resulting partnership has both enabled NASA studies and provided powerful commercial fitness and health monitoring tools for soldiers, first responders, professional athletes, and consumers. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      Ames Research Center and Zephyr Technology collaborated on a motion-sickness study in the microgravity conditions onboard a parabolic-arc flight. A Zephyr BioHarness monitoring device can be seen on the woman’s wrist in the lower left corner. \n                    \n                  \n                  Zephyr Technology launched in 2003 with the goal of providing physiological status monitoring (PSM) for people in any condition or environment. Working with innovative technologies like smart fabrics and solid-state accelerometers, the company developed a unique PSM device—a narrow fabric band worn around the upper torso. Called the BioHarness, the product’s ability to capture, store, and transmit a range of vital sign data, coupled with its comfortable design, made it ideal for Toscano and Cowings’ research. \n                  Under a Space Act Agreement, NASA partnered with Zephyr to use the BioHarness to study motion sickness in test subjects onboard the Zero-G aircraft. Parabolic-arc flights are used to train astronauts and conduct experiments in momentary microgravity. (The plane is also known as the “Vomit Comet” due to its motion sickness-inducing flight maneuvers.) Another study was conducted as part of the Department of Homeland Security’s (DHS) Physiological Health Assessment System for Emergency Responders (PHASER) program. NASA researchers used Zephyr’s technology to monitor the vital signs of firefighters to aid PHASER’s goals of determining the impact of the high-stress jobs on health. According to the DHS, first responders like firefighters experience the highest occupational rate of line-of-duty deaths from events like heart attacks and strokes.\n                  Toscano and Cowings have even employed the BioHarness for training U.S. Navy fighter pilots to overcome the motion sickness some experience in flight; in the study, 5 of the 7 pilots were able to resume their jobs when overwhelming motion sickness had previously made them unfit to fly.\n                  While the Ames researchers benefited from the use of Zephyr’s devices, the company also came away with significant NASA contributions. \n                  “NASA’s depth of experience in physiology and knowledge of what’s been tried before is just massive for a small company like ours,” says Brian Russell, Zephyr’s CEO. \n                  “We’ve been able to give Zephyr good feedback on the types of algorithms to incorporate into their firmware, and on topics like crew comfort issues,” says Toscano. “They have taken that information and redesigned their system over the course of several years.” \n                  Benefits\n                  Zephyr’s BioHarness is now a market-leading technology and the cornerstone of its PSM training system. Through its smart fabric sensors, the BioHarness measures heart rate and heart rate variability, provides a heart electrocardiogram, and monitors breathing, skin temperature, motion (including speed and distance), and posture. The device can either store this data for later retrieval or transmit it using Bluetooth technology to a laptop to be displayed and analyzed by Zephyr’s OmniSense software. Additionally, the data can be sent to a smartphone loaded with any of a range of apps developed by Zephyr partners. A single PSM system can provide real-time monitoring of up to 64 BioHarness users. The applications of the gathered data are many, says Russell, but the common factor to all of them is utility.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Zephyr’s Consumer HxM device monitors heart rate, speed, and distance for everyday fitness training.\n                    \n                  \n                  “If you’re a doctor, a military commander, a medic, or a sports coach, our data needs to tell you something that’s useful,” Russell explains. With the company selling thousands of products a month, the usefulness of the company’s NASA-improved technology seems spoken for.\n                  One key application for the BioHarness is in fitness training. The readings logged by the device provide valuable baseline information on a user’s fitness levels and help the user track improvement over time. Professional sports teams in football, basketball, hockey, and baseball use the BioHarness to support and monitor the effectiveness of training regimens. The data delivered by the system also helps trainers recognize when an athlete might be suffering from dehydration or excessive fatigue or is at risk for heat stroke—a condition that has resulted in the deaths of a number of athletes during training.\n                  Working with the U.S. Special Forces, Zephyr tailored its PSM system for military applications, including determining the fitness of soldiers, and the company also provides PSM systems for first responders. In both cases, the data gathered by the BioHarness is transmitted via Bluetooth over the users’ tactical radios to OmniSense-equipped computers. \n                  The company also offers a system called the Consumer HxM, which provides heart rate, speed, and distance monitoring in a consumer-friendly package, without compromising quality.“It’s very important that a consumer gets the same quality as a fireman or soldier is getting,” Russell says. \n                  Zephyr’s technology has uses that go beyond fitness. On the battlefield, changes in vital signs can indicate if a soldier is injured, alerting medics more quickly than a radio call. The BioHarness continuously transmits data to the rescue vehicle and field hospital so that when the injured soldier arrives, doctors are up-to-date on the patient’s medical status. Similarly, the technology allows doctors to monitor patients in their homes or in nursing facilities. \n                  “Anyone at home who needs medical care can have the BioHarness on and transmit that data over the mobile phone network to the doctor in the hospital,” Russell says. \n                  Zephyr continues to evolve its PSM systems, moving the monitoring technology from straps into shirts and other clothing. In 2012, sports apparel and equipment manufacturer Under Armour plans to release its E39 shirt, which incorporates the Zephyr BioHarness. During the 2011 NFL combine, college football players hoping to be drafted by pro teams wore the shirts during various physical tests. The Zephyr-equipped shirts delivered physiological data not only to NFL scouts, but to fans watching the event on television, who could see immediately how high a prospect jumped, or how fast he ran. \n                  \n                    “NASA’s depth of \n                    experience in physiology \n                    … is just massive for a small \n                    company like ours.”\n                    —Brian Russell, \n                    Zephyr Technology \n                       \n                  \n                  “The athletes loved it,” says Russell. “They thought they were taking part in science fiction.” \n                  Zephyr also continues to work with NASA on research projects, including a study conducted under an International Space Act Agreement to determine indicators of fatigue in commercial airline flight crews. Russell notes that Zephyr’s NASA partnership and U.S.-made technology tells the right kind of story for the Nation’s economic and technological progress.\n                  \n                                        “Having high technology from NASA and innovation from Zephyr resulting in factory jobs here in America, manufacturing products worn by American first responders, soldiers, and athletes—that’s what we need to drive the economy,” he says. “As a taxpayer, I find it heartening that NASA is so open to these partnerships.”                    \n                  \n                  Zephyr™, BioHarness™, and OmniSense™ are trademarks of Zephyr Technology.\n                  Bluetooth® is a registered trademark of Bluetooth SIG Inc.\n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Have you ever felt nauseous reading a book in the back seat of a car? Or woken from a deep sleep feeling disoriented, unsure which way is up? Momentary mixups like these happen when the sensory systems that track the body’s orientation in space become confused. (In the case of the backseat bookworm, the conflict arises when the reader’s inner ear, part of the body’s vestibular system, senses the car’s motion while her eyes are fixed on the stationary pages of the book.) Conditions like motion sickness are common on Earth, but they also present a significant challenge to astronauts in space. \n                  \n                    \n                    \n                      \n                    \n                    \n                      A subject undergoes preflight motion sickness testing in a rotating chair. NASA researchers developed a technique for overcoming the potentially debilitating condition.\n                    \n                  \n                  Human sensory systems use the pull of gravity to help determine orientation. In the microgravity environment onboard the International Space Station, for example, the body experiences a period of confusion before it adapts to the new circumstances. (In space, even the body’s proprioceptive system, which tells the brain where the arms and legs are oriented without the need for visual confirmation, goes haywire, meaning astronauts sometimes lose track of where their limbs are when they are not moving them.) This Space Adaptation Syndrome affects a majority of astronauts, even experienced ones, causing everything from mild disorientation to nausea to severe vomiting. \n                  “It can be quite debilitating,” says William Toscano, a research scientist in NASA’s Ames Research Center Psychophysiology Laboratory, part of the Center’s Human Systems Integration Division. “When this happens, as you can imagine, work proficiency declines considerably.”\n                  Since astronauts cannot afford to be distracted or incapacitated during critical missions, NASA has explored various means for preventing and countering motion sickness in space, including a range of drug treatments. Many effective motion sickness drugs, however, cause undesirable side effects, such as drowsiness. Toscano and his NASA colleague, Patricia Cowings, have developed a different approach: Utilizing biofeedback training methods, the pair can teach astronauts, military pilots, and others susceptible to motion sickness to self-regulate their own physiological responses and suppress the unpleasant symptoms. This NASA-patented method invented by Cowings is called the Autogenic Feedback Training Exercise (ATFE), and several studies have demonstrated its promise.\n                  “We’re able to get people to significantly increase their motion sickness tolerance,” says Toscano, noting that in laboratory studies conducted over a 20-year period about 85 percent of those who have undergone the 6-hour training experienced benefits, with about 65 percent able to suppress their symptoms entirely. \n                  In order to gather the necessary physiological data for their research and to enable the ATFE biofeedback training, Toscano and Cowings needed a practical solution for monitoring the vital signs of test subjects like astronauts and pilots. \n                  “The biggest consideration with using physiological monitors on astronauts and aircrew is putting sensors on the body,” Toscano says. “You need to have an unobtrusive device.”\n                  A company in Annapolis, Maryland, proved to have the technology the NASA researchers were looking for. Now the resulting partnership has both enabled NASA studies and provided powerful commercial fitness and health monitoring tools for soldiers, first responders, professional athletes, and consumers. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      Ames Research Center and Zephyr Technology collaborated on a motion-sickness study in the microgravity conditions onboard a parabolic-arc flight. A Zephyr BioHarness monitoring device can be seen on the woman’s wrist in the lower left corner. \n                    \n                  \n                  Zephyr Technology launched in 2003 with the goal of providing physiological status monitoring (PSM) for people in any condition or environment. Working with innovative technologies like smart fabrics and solid-state accelerometers, the company developed a unique PSM device—a narrow fabric band worn around the upper torso. Called the BioHarness, the product’s ability to capture, store, and transmit a range of vital sign data, coupled with its comfortable design, made it ideal for Toscano and Cowings’ research. \n                  Under a Space Act Agreement, NASA partnered with Zephyr to use the BioHarness to study motion sickness in test subjects onboard the Zero-G aircraft. Parabolic-arc flights are used to train astronauts and conduct experiments in momentary microgravity. (The plane is also known as the “Vomit Comet” due to its motion sickness-inducing flight maneuvers.) Another study was conducted as part of the Department of Homeland Security’s (DHS) Physiological Health Assessment System for Emergency Responders (PHASER) program. NASA researchers used Zephyr’s technology to monitor the vital signs of firefighters to aid PHASER’s goals of determining the impact of the high-stress jobs on health. According to the DHS, first responders like firefighters experience the highest occupational rate of line-of-duty deaths from events like heart attacks and strokes.\n                  Toscano and Cowings have even employed the BioHarness for training U.S. Navy fighter pilots to overcome the motion sickness some experience in flight; in the study, 5 of the 7 pilots were able to resume their jobs when overwhelming motion sickness had previously made them unfit to fly.\n                  While the Ames researchers benefited from the use of Zephyr’s devices, the company also came away with significant NASA contributions. \n                  “NASA’s depth of experience in physiology and knowledge of what’s been tried before is just massive for a small company like ours,” says Brian Russell, Zephyr’s CEO. \n                  “We’ve been able to give Zephyr good feedback on the types of algorithms to incorporate into their firmware, and on topics like crew comfort issues,” says Toscano. “They have taken that information and redesigned their system over the course of several years.” \n                  Benefits\n                  Zephyr’s BioHarness is now a market-leading technology and the cornerstone of its PSM training system. Through its smart fabric sensors, the BioHarness measures heart rate and heart rate variability, provides a heart electrocardiogram, and monitors breathing, skin temperature, motion (including speed and distance), and posture. The device can either store this data for later retrieval or transmit it using Bluetooth technology to a laptop to be displayed and analyzed by Zephyr’s OmniSense software. Additionally, the data can be sent to a smartphone loaded with any of a range of apps developed by Zephyr partners. A single PSM system can provide real-time monitoring of up to 64 BioHarness users. The applications of the gathered data are many, says Russell, but the common factor to all of them is utility.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Zephyr’s Consumer HxM device monitors heart rate, speed, and distance for everyday fitness training.\n                    \n                  \n                  “If you’re a doctor, a military commander, a medic, or a sports coach, our data needs to tell you something that’s useful,” Russell explains. With the company selling thousands of products a month, the usefulness of the company’s NASA-improved technology seems spoken for.\n                  One key application for the BioHarness is in fitness training. The readings logged by the device provide valuable baseline information on a user’s fitness levels and help the user track improvement over time. Professional sports teams in football, basketball, hockey, and baseball use the BioHarness to support and monitor the effectiveness of training regimens. The data delivered by the system also helps trainers recognize when an athlete might be suffering from dehydration or excessive fatigue or is at risk for heat stroke—a condition that has resulted in the deaths of a number of athletes during training.\n                  Working with the U.S. Special Forces, Zephyr tailored its PSM system for military applications, including determining the fitness of soldiers, and the company also provides PSM systems for first responders. In both cases, the data gathered by the BioHarness is transmitted via Bluetooth over the users’ tactical radios to OmniSense-equipped computers. \n                  The company also offers a system called the Consumer HxM, which provides heart rate, speed, and distance monitoring in a consumer-friendly package, without compromising quality.“It’s very important that a consumer gets the same quality as a fireman or soldier is getting,” Russell says. \n                  Zephyr’s technology has uses that go beyond fitness. On the battlefield, changes in vital signs can indicate if a soldier is injured, alerting medics more quickly than a radio call. The BioHarness continuously transmits data to the rescue vehicle and field hospital so that when the injured soldier arrives, doctors are up-to-date on the patient’s medical status. Similarly, the technology allows doctors to monitor patients in their homes or in nursing facilities. \n                  “Anyone at home who needs medical care can have the BioHarness on and transmit that data over the mobile phone network to the doctor in the hospital,” Russell says. \n                  Zephyr continues to evolve its PSM systems, moving the monitoring technology from straps into shirts and other clothing. In 2012, sports apparel and equipment manufacturer Under Armour plans to release its E39 shirt, which incorporates the Zephyr BioHarness. During the 2011 NFL combine, college football players hoping to be drafted by pro teams wore the shirts during various physical tests. The Zephyr-equipped shirts delivered physiological data not only to NFL scouts, but to fans watching the event on television, who could see immediately how high a prospect jumped, or how fast he ran. \n                  \n                    “NASA’s depth of \n                    experience in physiology \n                    … is just massive for a small \n                    company like ours.”\n                    —Brian Russell, \n                    Zephyr Technology \n                       \n                  \n                  “The athletes loved it,” says Russell. “They thought they were taking part in science fiction.” \n                  Zephyr also continues to work with NASA on research projects, including a study conducted under an International Space Act Agreement to determine indicators of fatigue in commercial airline flight crews. Russell notes that Zephyr’s NASA partnership and U.S.-made technology tells the right kind of story for the Nation’s economic and technological progress.\n                  \n                                        “Having high technology from NASA and innovation from Zephyr resulting in factory jobs here in America, manufacturing products worn by American first responders, soldiers, and athletes—that’s what we need to drive the economy,” he says. “As a taxpayer, I find it heartening that NASA is so open to these partnerships.”                    \n                  \n                  Zephyr™, BioHarness™, and OmniSense™ are trademarks of Zephyr Technology.\n                  Bluetooth® is a registered trademark of Bluetooth SIG Inc.\n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Have you ever felt nauseous reading a book in the back seat of a car? Or woken from a deep sleep feeling disoriented, unsure which way is up? Momentary mixups like these happen when the sensory systems that track the body’s orientation in space become confused. (In the case of the backseat bookworm, the conflict arises when the reader’s inner ear, part of the body’s vestibular system, senses the car’s motion while her eyes are fixed on the stationary pages of the book.) Conditions like motion sickness are common on Earth, but they also present a significant challenge to astronauts in space. \n                  \n                    \n                    \n                      \n                    \n                    \n                      A subject undergoes preflight motion sickness testing in a rotating chair. NASA researchers developed a technique for overcoming the potentially debilitating condition.\n                    \n                  \n                  Human sensory systems use the pull of gravity to help determine orientation. In the microgravity environment onboard the International Space Station, for example, the body experiences a period of confusion before it adapts to the new circumstances. (In space, even the body’s proprioceptive system, which tells the brain where the arms and legs are oriented without the need for visual confirmation, goes haywire, meaning astronauts sometimes lose track of where their limbs are when they are not moving them.) This Space Adaptation Syndrome affects a majority of astronauts, even experienced ones, causing everything from mild disorientation to nausea to severe vomiting. \n                  “It can be quite debilitating,” says William Toscano, a research scientist in NASA’s Ames Research Center Psychophysiology Laboratory, part of the Center’s Human Systems Integration Division. “When this happens, as you can imagine, work proficiency declines considerably.”\n                  Since astronauts cannot afford to be distracted or incapacitated during critical missions, NASA has explored various means for preventing and countering motion sickness in space, including a range of drug treatments. Many effective motion sickness drugs, however, cause undesirable side effects, such as drowsiness. Toscano and his NASA colleague, Patricia Cowings, have developed a different approach: Utilizing biofeedback training methods, the pair can teach astronauts, military pilots, and others susceptible to motion sickness to self-regulate their own physiological responses and suppress the unpleasant symptoms. This NASA-patented method invented by Cowings is called the Autogenic Feedback Training Exercise (ATFE), and several studies have demonstrated its promise.\n                  “We’re able to get people to significantly increase their motion sickness tolerance,” says Toscano, noting that in laboratory studies conducted over a 20-year period about 85 percent of those who have undergone the 6-hour training experienced benefits, with about 65 percent able to suppress their symptoms entirely. \n                  In order to gather the necessary physiological data for their research and to enable the ATFE biofeedback training, Toscano and Cowings needed a practical solution for monitoring the vital signs of test subjects like astronauts and pilots. \n                  “The biggest consideration with using physiological monitors on astronauts and aircrew is putting sensors on the body,” Toscano says. “You need to have an unobtrusive device.”\n                  A company in Annapolis, Maryland, proved to have the technology the NASA researchers were looking for. Now the resulting partnership has both enabled NASA studies and provided powerful commercial fitness and health monitoring tools for soldiers, first responders, professional athletes, and consumers. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      Ames Research Center and Zephyr Technology collaborated on a motion-sickness study in the microgravity conditions onboard a parabolic-arc flight. A Zephyr BioHarness monitoring device can be seen on the woman’s wrist in the lower left corner. \n                    \n                  \n                  Zephyr Technology launched in 2003 with the goal of providing physiological status monitoring (PSM) for people in any condition or environment. Working with innovative technologies like smart fabrics and solid-state accelerometers, the company developed a unique PSM device—a narrow fabric band worn around the upper torso. Called the BioHarness, the product’s ability to capture, store, and transmit a range of vital sign data, coupled with its comfortable design, made it ideal for Toscano and Cowings’ research. \n                  Under a Space Act Agreement, NASA partnered with Zephyr to use the BioHarness to study motion sickness in test subjects onboard the Zero-G aircraft. Parabolic-arc flights are used to train astronauts and conduct experiments in momentary microgravity. (The plane is also known as the “Vomit Comet” due to its motion sickness-inducing flight maneuvers.) Another study was conducted as part of the Department of Homeland Security’s (DHS) Physiological Health Assessment System for Emergency Responders (PHASER) program. NASA researchers used Zephyr’s technology to monitor the vital signs of firefighters to aid PHASER’s goals of determining the impact of the high-stress jobs on health. According to the DHS, first responders like firefighters experience the highest occupational rate of line-of-duty deaths from events like heart attacks and strokes.\n                  Toscano and Cowings have even employed the BioHarness for training U.S. Navy fighter pilots to overcome the motion sickness some experience in flight; in the study, 5 of the 7 pilots were able to resume their jobs when overwhelming motion sickness had previously made them unfit to fly.\n                  While the Ames researchers benefited from the use of Zephyr’s devices, the company also came away with significant NASA contributions. \n                  “NASA’s depth of experience in physiology and knowledge of what’s been tried before is just massive for a small company like ours,” says Brian Russell, Zephyr’s CEO. \n                  “We’ve been able to give Zephyr good feedback on the types of algorithms to incorporate into their firmware, and on topics like crew comfort issues,” says Toscano. “They have taken that information and redesigned their system over the course of several years.” \n                  Benefits\n                  Zephyr’s BioHarness is now a market-leading technology and the cornerstone of its PSM training system. Through its smart fabric sensors, the BioHarness measures heart rate and heart rate variability, provides a heart electrocardiogram, and monitors breathing, skin temperature, motion (including speed and distance), and posture. The device can either store this data for later retrieval or transmit it using Bluetooth technology to a laptop to be displayed and analyzed by Zephyr’s OmniSense software. Additionally, the data can be sent to a smartphone loaded with any of a range of apps developed by Zephyr partners. A single PSM system can provide real-time monitoring of up to 64 BioHarness users. The applications of the gathered data are many, says Russell, but the common factor to all of them is utility.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Zephyr’s Consumer HxM device monitors heart rate, speed, and distance for everyday fitness training.\n                    \n                  \n                  “If you’re a doctor, a military commander, a medic, or a sports coach, our data needs to tell you something that’s useful,” Russell explains. With the company selling thousands of products a month, the usefulness of the company’s NASA-improved technology seems spoken for.\n                  One key application for the BioHarness is in fitness training. The readings logged by the device provide valuable baseline information on a user’s fitness levels and help the user track improvement over time. Professional sports teams in football, basketball, hockey, and baseball use the BioHarness to support and monitor the effectiveness of training regimens. The data delivered by the system also helps trainers recognize when an athlete might be suffering from dehydration or excessive fatigue or is at risk for heat stroke—a condition that has resulted in the deaths of a number of athletes during training.\n                  Working with the U.S. Special Forces, Zephyr tailored its PSM system for military applications, including determining the fitness of soldiers, and the company also provides PSM systems for first responders. In both cases, the data gathered by the BioHarness is transmitted via Bluetooth over the users’ tactical radios to OmniSense-equipped computers. \n                  The company also offers a system called the Consumer HxM, which provides heart rate, speed, and distance monitoring in a consumer-friendly package, without compromising quality.“It’s very important that a consumer gets the same quality as a fireman or soldier is getting,” Russell says. \n                  Zephyr’s technology has uses that go beyond fitness. On the battlefield, changes in vital signs can indicate if a soldier is injured, alerting medics more quickly than a radio call. The BioHarness continuously transmits data to the rescue vehicle and field hospital so that when the injured soldier arrives, doctors are up-to-date on the patient’s medical status. Similarly, the technology allows doctors to monitor patients in their homes or in nursing facilities. \n                  “Anyone at home who needs medical care can have the BioHarness on and transmit that data over the mobile phone network to the doctor in the hospital,” Russell says. \n                  Zephyr continues to evolve its PSM systems, moving the monitoring technology from straps into shirts and other clothing. In 2012, sports apparel and equipment manufacturer Under Armour plans to release its E39 shirt, which incorporates the Zephyr BioHarness. During the 2011 NFL combine, college football players hoping to be drafted by pro teams wore the shirts during various physical tests. The Zephyr-equipped shirts delivered physiological data not only to NFL scouts, but to fans watching the event on television, who could see immediately how high a prospect jumped, or how fast he ran. \n                  \n                    “NASA’s depth of \n                    experience in physiology \n                    … is just massive for a small \n                    company like ours.”\n                    —Brian Russell, \n                    Zephyr Technology \n                       \n                  \n                  “The athletes loved it,” says Russell. “They thought they were taking part in science fiction.” \n                  Zephyr also continues to work with NASA on research projects, including a study conducted under an International Space Act Agreement to determine indicators of fatigue in commercial airline flight crews. Russell notes that Zephyr’s NASA partnership and U.S.-made technology tells the right kind of story for the Nation’s economic and technological progress.\n                  \n                                        “Having high technology from NASA and innovation from Zephyr resulting in factory jobs here in America, manufacturing products worn by American first responders, soldiers, and athletes—that’s what we need to drive the economy,” he says. “As a taxpayer, I find it heartening that NASA is so open to these partnerships.”                    \n                  \n                  Zephyr™, BioHarness™, and OmniSense™ are trademarks of Zephyr Technology.\n                  Bluetooth® is a registered trademark of Bluetooth SIG Inc.\n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Have you ever felt nauseous reading a book in the back seat of a car? Or woken from a deep sleep feeling disoriented, unsure which way is up? Momentary mixups like these happen when the sensory systems that track the body’s orientation in space become confused. (In the case of the backseat bookworm, the conflict arises when the reader’s inner ear, part of the body’s vestibular system, senses the car’s motion while her eyes are fixed on the stationary pages of the book.) Conditions like motion sickness are common on Earth, but they also present a significant challenge to astronauts in space. \n                  \n                    \n                    \n                      \n                    \n                    \n                      A subject undergoes preflight motion sickness testing in a rotating chair. NASA researchers developed a technique for overcoming the potentially debilitating condition.\n                    \n                  \n                  Human sensory systems use the pull of gravity to help determine orientation. In the microgravity environment onboard the International Space Station, for example, the body experiences a period of confusion before it adapts to the new circumstances. (In space, even the body’s proprioceptive system, which tells the brain where the arms and legs are oriented without the need for visual confirmation, goes haywire, meaning astronauts sometimes lose track of where their limbs are when they are not moving them.) This Space Adaptation Syndrome affects a majority of astronauts, even experienced ones, causing everything from mild disorientation to nausea to severe vomiting. \n                  “It can be quite debilitating,” says William Toscano, a research scientist in NASA’s Ames Research Center Psychophysiology Laboratory, part of the Center’s Human Systems Integration Division. “When this happens, as you can imagine, work proficiency declines considerably.”\n                  Since astronauts cannot afford to be distracted or incapacitated during critical missions, NASA has explored various means for preventing and countering motion sickness in space, including a range of drug treatments. Many effective motion sickness drugs, however, cause undesirable side effects, such as drowsiness. Toscano and his NASA colleague, Patricia Cowings, have developed a different approach: Utilizing biofeedback training methods, the pair can teach astronauts, military pilots, and others susceptible to motion sickness to self-regulate their own physiological responses and suppress the unpleasant symptoms. This NASA-patented method invented by Cowings is called the Autogenic Feedback Training Exercise (ATFE), and several studies have demonstrated its promise.\n                  “We’re able to get people to significantly increase their motion sickness tolerance,” says Toscano, noting that in laboratory studies conducted over a 20-year period about 85 percent of those who have undergone the 6-hour training experienced benefits, with about 65 percent able to suppress their symptoms entirely. \n                  In order to gather the necessary physiological data for their research and to enable the ATFE biofeedback training, Toscano and Cowings needed a practical solution for monitoring the vital signs of test subjects like astronauts and pilots. \n                  “The biggest consideration with using physiological monitors on astronauts and aircrew is putting sensors on the body,” Toscano says. “You need to have an unobtrusive device.”\n                  A company in Annapolis, Maryland, proved to have the technology the NASA researchers were looking for. Now the resulting partnership has both enabled NASA studies and provided powerful commercial fitness and health monitoring tools for soldiers, first responders, professional athletes, and consumers. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      Ames Research Center and Zephyr Technology collaborated on a motion-sickness study in the microgravity conditions onboard a parabolic-arc flight. A Zephyr BioHarness monitoring device can be seen on the woman’s wrist in the lower left corner. \n                    \n                  \n                  Zephyr Technology launched in 2003 with the goal of providing physiological status monitoring (PSM) for people in any condition or environment. Working with innovative technologies like smart fabrics and solid-state accelerometers, the company developed a unique PSM device—a narrow fabric band worn around the upper torso. Called the BioHarness, the product’s ability to capture, store, and transmit a range of vital sign data, coupled with its comfortable design, made it ideal for Toscano and Cowings’ research. \n                  Under a Space Act Agreement, NASA partnered with Zephyr to use the BioHarness to study motion sickness in test subjects onboard the Zero-G aircraft. Parabolic-arc flights are used to train astronauts and conduct experiments in momentary microgravity. (The plane is also known as the “Vomit Comet” due to its motion sickness-inducing flight maneuvers.) Another study was conducted as part of the Department of Homeland Security’s (DHS) Physiological Health Assessment System for Emergency Responders (PHASER) program. NASA researchers used Zephyr’s technology to monitor the vital signs of firefighters to aid PHASER’s goals of determining the impact of the high-stress jobs on health. According to the DHS, first responders like firefighters experience the highest occupational rate of line-of-duty deaths from events like heart attacks and strokes.\n                  Toscano and Cowings have even employed the BioHarness for training U.S. Navy fighter pilots to overcome the motion sickness some experience in flight; in the study, 5 of the 7 pilots were able to resume their jobs when overwhelming motion sickness had previously made them unfit to fly.\n                  While the Ames researchers benefited from the use of Zephyr’s devices, the company also came away with significant NASA contributions. \n                  “NASA’s depth of experience in physiology and knowledge of what’s been tried before is just massive for a small company like ours,” says Brian Russell, Zephyr’s CEO. \n                  “We’ve been able to give Zephyr good feedback on the types of algorithms to incorporate into their firmware, and on topics like crew comfort issues,” says Toscano. “They have taken that information and redesigned their system over the course of several years.” \n                  Benefits\n                  Zephyr’s BioHarness is now a market-leading technology and the cornerstone of its PSM training system. Through its smart fabric sensors, the BioHarness measures heart rate and heart rate variability, provides a heart electrocardiogram, and monitors breathing, skin temperature, motion (including speed and distance), and posture. The device can either store this data for later retrieval or transmit it using Bluetooth technology to a laptop to be displayed and analyzed by Zephyr’s OmniSense software. Additionally, the data can be sent to a smartphone loaded with any of a range of apps developed by Zephyr partners. A single PSM system can provide real-time monitoring of up to 64 BioHarness users. The applications of the gathered data are many, says Russell, but the common factor to all of them is utility.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Zephyr’s Consumer HxM device monitors heart rate, speed, and distance for everyday fitness training.\n                    \n                  \n                  “If you’re a doctor, a military commander, a medic, or a sports coach, our data needs to tell you something that’s useful,” Russell explains. With the company selling thousands of products a month, the usefulness of the company’s NASA-improved technology seems spoken for.\n                  One key application for the BioHarness is in fitness training. The readings logged by the device provide valuable baseline information on a user’s fitness levels and help the user track improvement over time. Professional sports teams in football, basketball, hockey, and baseball use the BioHarness to support and monitor the effectiveness of training regimens. The data delivered by the system also helps trainers recognize when an athlete might be suffering from dehydration or excessive fatigue or is at risk for heat stroke—a condition that has resulted in the deaths of a number of athletes during training.\n                  Working with the U.S. Special Forces, Zephyr tailored its PSM system for military applications, including determining the fitness of soldiers, and the company also provides PSM systems for first responders. In both cases, the data gathered by the BioHarness is transmitted via Bluetooth over the users’ tactical radios to OmniSense-equipped computers. \n                  The company also offers a system called the Consumer HxM, which provides heart rate, speed, and distance monitoring in a consumer-friendly package, without compromising quality.“It’s very important that a consumer gets the same quality as a fireman or soldier is getting,” Russell says. \n                  Zephyr’s technology has uses that go beyond fitness. On the battlefield, changes in vital signs can indicate if a soldier is injured, alerting medics more quickly than a radio call. The BioHarness continuously transmits data to the rescue vehicle and field hospital so that when the injured soldier arrives, doctors are up-to-date on the patient’s medical status. Similarly, the technology allows doctors to monitor patients in their homes or in nursing facilities. \n                  “Anyone at home who needs medical care can have the BioHarness on and transmit that data over the mobile phone network to the doctor in the hospital,” Russell says. \n                  Zephyr continues to evolve its PSM systems, moving the monitoring technology from straps into shirts and other clothing. In 2012, sports apparel and equipment manufacturer Under Armour plans to release its E39 shirt, which incorporates the Zephyr BioHarness. During the 2011 NFL combine, college football players hoping to be drafted by pro teams wore the shirts during various physical tests. The Zephyr-equipped shirts delivered physiological data not only to NFL scouts, but to fans watching the event on television, who could see immediately how high a prospect jumped, or how fast he ran. \n                  \n                    “NASA’s depth of \n                    experience in physiology \n                    … is just massive for a small \n                    company like ours.”\n                    —Brian Russell, \n                    Zephyr Technology \n                       \n                  \n                  “The athletes loved it,” says Russell. “They thought they were taking part in science fiction.” \n                  Zephyr also continues to work with NASA on research projects, including a study conducted under an International Space Act Agreement to determine indicators of fatigue in commercial airline flight crews. Russell notes that Zephyr’s NASA partnership and U.S.-made technology tells the right kind of story for the Nation’s economic and technological progress.\n                  \n                                        “Having high technology from NASA and innovation from Zephyr resulting in factory jobs here in America, manufacturing products worn by American first responders, soldiers, and athletes—that’s what we need to drive the economy,” he says. “As a taxpayer, I find it heartening that NASA is so open to these partnerships.”                    \n                  \n                  Zephyr™, BioHarness™, and OmniSense™ are trademarks of Zephyr Technology.\n                  Bluetooth® is a registered trademark of Bluetooth SIG Inc.\n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  NASA Technology\n                  Have you ever felt nauseous reading a book in the back seat of a car? Or woken from a deep sleep feeling disoriented, unsure which way is up? Momentary mixups like these happen when the sensory systems that track the body’s orientation in space become confused. (In the case of the backseat bookworm, the conflict arises when the reader’s inner ear, part of the body’s vestibular system, senses the car’s motion while her eyes are fixed on the stationary pages of the book.) Conditions like motion sickness are common on Earth, but they also present a significant challenge to astronauts in space. \n                  \n                    \n                    \n                      \n                    \n                    \n                      A subject undergoes preflight motion sickness testing in a rotating chair. NASA researchers developed a technique for overcoming the potentially debilitating condition.\n                    \n                  \n                  Human sensory systems use the pull of gravity to help determine orientation. In the microgravity environment onboard the International Space Station, for example, the body experiences a period of confusion before it adapts to the new circumstances. (In space, even the body’s proprioceptive system, which tells the brain where the arms and legs are oriented without the need for visual confirmation, goes haywire, meaning astronauts sometimes lose track of where their limbs are when they are not moving them.) This Space Adaptation Syndrome affects a majority of astronauts, even experienced ones, causing everything from mild disorientation to nausea to severe vomiting. \n                  “It can be quite debilitating,” says William Toscano, a research scientist in NASA’s Ames Research Center Psychophysiology Laboratory, part of the Center’s Human Systems Integration Division. “When this happens, as you can imagine, work proficiency declines considerably.”\n                  Since astronauts cannot afford to be distracted or incapacitated during critical missions, NASA has explored various means for preventing and countering motion sickness in space, including a range of drug treatments. Many effective motion sickness drugs, however, cause undesirable side effects, such as drowsiness. Toscano and his NASA colleague, Patricia Cowings, have developed a different approach: Utilizing biofeedback training methods, the pair can teach astronauts, military pilots, and others susceptible to motion sickness to self-regulate their own physiological responses and suppress the unpleasant symptoms. This NASA-patented method invented by Cowings is called the Autogenic Feedback Training Exercise (ATFE), and several studies have demonstrated its promise.\n                  “We’re able to get people to significantly increase their motion sickness tolerance,” says Toscano, noting that in laboratory studies conducted over a 20-year period about 85 percent of those who have undergone the 6-hour training experienced benefits, with about 65 percent able to suppress their symptoms entirely. \n                  In order to gather the necessary physiological data for their research and to enable the ATFE biofeedback training, Toscano and Cowings needed a practical solution for monitoring the vital signs of test subjects like astronauts and pilots. \n                  “The biggest consideration with using physiological monitors on astronauts and aircrew is putting sensors on the body,” Toscano says. “You need to have an unobtrusive device.”\n                  A company in Annapolis, Maryland, proved to have the technology the NASA researchers were looking for. Now the resulting partnership has both enabled NASA studies and provided powerful commercial fitness and health monitoring tools for soldiers, first responders, professional athletes, and consumers. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      Ames Research Center and Zephyr Technology collaborated on a motion-sickness study in the microgravity conditions onboard a parabolic-arc flight. A Zephyr BioHarness monitoring device can be seen on the woman’s wrist in the lower left corner. \n                    \n                  \n                  Zephyr Technology launched in 2003 with the goal of providing physiological status monitoring (PSM) for people in any condition or environment. Working with innovative technologies like smart fabrics and solid-state accelerometers, the company developed a unique PSM device—a narrow fabric band worn around the upper torso. Called the BioHarness, the product’s ability to capture, store, and transmit a range of vital sign data, coupled with its comfortable design, made it ideal for Toscano and Cowings’ research. \n                  Under a Space Act Agreement, NASA partnered with Zephyr to use the BioHarness to study motion sickness in test subjects onboard the Zero-G aircraft. Parabolic-arc flights are used to train astronauts and conduct experiments in momentary microgravity. (The plane is also known as the “Vomit Comet” due to its motion sickness-inducing flight maneuvers.) Another study was conducted as part of the Department of Homeland Security’s (DHS) Physiological Health Assessment System for Emergency Responders (PHASER) program. NASA researchers used Zephyr’s technology to monitor the vital signs of firefighters to aid PHASER’s goals of determining the impact of the high-stress jobs on health. According to the DHS, first responders like firefighters experience the highest occupational rate of line-of-duty deaths from events like heart attacks and strokes.\n                  Toscano and Cowings have even employed the BioHarness for training U.S. Navy fighter pilots to overcome the motion sickness some experience in flight; in the study, 5 of the 7 pilots were able to resume their jobs when overwhelming motion sickness had previously made them unfit to fly.\n                  While the Ames researchers benefited from the use of Zephyr’s devices, the company also came away with significant NASA contributions. \n                  “NASA’s depth of experience in physiology and knowledge of what’s been tried before is just massive for a small company like ours,” says Brian Russell, Zephyr’s CEO. \n                  “We’ve been able to give Zephyr good feedback on the types of algorithms to incorporate into their firmware, and on topics like crew comfort issues,” says Toscano. “They have taken that information and redesigned their system over the course of several years.” \n                  Benefits\n                  Zephyr’s BioHarness is now a market-leading technology and the cornerstone of its PSM training system. Through its smart fabric sensors, the BioHarness measures heart rate and heart rate variability, provides a heart electrocardiogram, and monitors breathing, skin temperature, motion (including speed and distance), and posture. The device can either store this data for later retrieval or transmit it using Bluetooth technology to a laptop to be displayed and analyzed by Zephyr’s OmniSense software. Additionally, the data can be sent to a smartphone loaded with any of a range of apps developed by Zephyr partners. A single PSM system can provide real-time monitoring of up to 64 BioHarness users. The applications of the gathered data are many, says Russell, but the common factor to all of them is utility.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Zephyr’s Consumer HxM device monitors heart rate, speed, and distance for everyday fitness training.\n                    \n                  \n                  “If you’re a doctor, a military commander, a medic, or a sports coach, our data needs to tell you something that’s useful,” Russell explains. With the company selling thousands of products a month, the usefulness of the company’s NASA-improved technology seems spoken for.\n                  One key application for the BioHarness is in fitness training. The readings logged by the device provide valuable baseline information on a user’s fitness levels and help the user track improvement over time. Professional sports teams in football, basketball, hockey, and baseball use the BioHarness to support and monitor the effectiveness of training regimens. The data delivered by the system also helps trainers recognize when an athlete might be suffering from dehydration or excessive fatigue or is at risk for heat stroke—a condition that has resulted in the deaths of a number of athletes during training.\n                  Working with the U.S. Special Forces, Zephyr tailored its PSM system for military applications, including determining the fitness of soldiers, and the company also provides PSM systems for first responders. In both cases, the data gathered by the BioHarness is transmitted via Bluetooth over the users’ tactical radios to OmniSense-equipped computers. \n                  The company also offers a system called the Consumer HxM, which provides heart rate, speed, and distance monitoring in a consumer-friendly package, without compromising quality.“It’s very important that a consumer gets the same quality as a fireman or soldier is getting,” Russell says. \n                  Zephyr’s technology has uses that go beyond fitness. On the battlefield, changes in vital signs can indicate if a soldier is injured, alerting medics more quickly than a radio call. The BioHarness continuously transmits data to the rescue vehicle and field hospital so that when the injured soldier arrives, doctors are up-to-date on the patient’s medical status. Similarly, the technology allows doctors to monitor patients in their homes or in nursing facilities. \n                  “Anyone at home who needs medical care can have the BioHarness on and transmit that data over the mobile phone network to the doctor in the hospital,” Russell says. \n                  Zephyr continues to evolve its PSM systems, moving the monitoring technology from straps into shirts and other clothing. In 2012, sports apparel and equipment manufacturer Under Armour plans to release its E39 shirt, which incorporates the Zephyr BioHarness. During the 2011 NFL combine, college football players hoping to be drafted by pro teams wore the shirts during various physical tests. The Zephyr-equipped shirts delivered physiological data not only to NFL scouts, but to fans watching the event on television, who could see immediately how high a prospect jumped, or how fast he ran. \n                  \n                    “NASA’s depth of \n                    experience in physiology \n                    … is just massive for a small \n                    company like ours.”\n                    —Brian Russell, \n                    Zephyr Technology \n                       \n                  \n                  “The athletes loved it,” says Russell. “They thought they were taking part in science fiction.” \n                  Zephyr also continues to work with NASA on research projects, including a study conducted under an International Space Act Agreement to determine indicators of fatigue in commercial airline flight crews. Russell notes that Zephyr’s NASA partnership and U.S.-made technology tells the right kind of story for the Nation’s economic and technological progress.\n                  \n                                        “Having high technology from NASA and innovation from Zephyr resulting in factory jobs here in America, manufacturing products worn by American first responders, soldiers, and athletes—that’s what we need to drive the economy,” he says. “As a taxpayer, I find it heartening that NASA is so open to these partnerships.”                    \n                  \n                  Zephyr™, BioHarness™, and OmniSense™ are trademarks of Zephyr Technology.\n                  Bluetooth® is a registered trademark of Bluetooth SIG Inc.\n                  \n                \n              \n            \n            \n              \n                \n                  NASA Technology\n                  Have you ever felt nauseous reading a book in the back seat of a car? Or woken from a deep sleep feeling disoriented, unsure which way is up? Momentary mixups like these happen when the sensory systems that track the body’s orientation in space become confused. (In the case of the backseat bookworm, the conflict arises when the reader’s inner ear, part of the body’s vestibular system, senses the car’s motion while her eyes are fixed on the stationary pages of the book.) Conditions like motion sickness are common on Earth, but they also present a significant challenge to astronauts in space. \n                  \n                    \n                    \n                      \n                    \n                    \n                      A subject undergoes preflight motion sickness testing in a rotating chair. NASA researchers developed a technique for overcoming the potentially debilitating condition.\n                    \n                  \n                  Human sensory systems use the pull of gravity to help determine orientation. In the microgravity environment onboard the International Space Station, for example, the body experiences a period of confusion before it adapts to the new circumstances. (In space, even the body’s proprioceptive system, which tells the brain where the arms and legs are oriented without the need for visual confirmation, goes haywire, meaning astronauts sometimes lose track of where their limbs are when they are not moving them.) This Space Adaptation Syndrome affects a majority of astronauts, even experienced ones, causing everything from mild disorientation to nausea to severe vomiting. \n                  “It can be quite debilitating,” says William Toscano, a research scientist in NASA’s Ames Research Center Psychophysiology Laboratory, part of the Center’s Human Systems Integration Division. “When this happens, as you can imagine, work proficiency declines considerably.”\n                  Since astronauts cannot afford to be distracted or incapacitated during critical missions, NASA has explored various means for preventing and countering motion sickness in space, including a range of drug treatments. Many effective motion sickness drugs, however, cause undesirable side effects, such as drowsiness. Toscano and his NASA colleague, Patricia Cowings, have developed a different approach: Utilizing biofeedback training methods, the pair can teach astronauts, military pilots, and others susceptible to motion sickness to self-regulate their own physiological responses and suppress the unpleasant symptoms. This NASA-patented method invented by Cowings is called the Autogenic Feedback Training Exercise (ATFE), and several studies have demonstrated its promise.\n                  “We’re able to get people to significantly increase their motion sickness tolerance,” says Toscano, noting that in laboratory studies conducted over a 20-year period about 85 percent of those who have undergone the 6-hour training experienced benefits, with about 65 percent able to suppress their symptoms entirely. \n                  In order to gather the necessary physiological data for their research and to enable the ATFE biofeedback training, Toscano and Cowings needed a practical solution for monitoring the vital signs of test subjects like astronauts and pilots. \n                  “The biggest consideration with using physiological monitors on astronauts and aircrew is putting sensors on the body,” Toscano says. “You need to have an unobtrusive device.”\n                  A company in Annapolis, Maryland, proved to have the technology the NASA researchers were looking for. Now the resulting partnership has both enabled NASA studies and provided powerful commercial fitness and health monitoring tools for soldiers, first responders, professional athletes, and consumers. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      Ames Research Center and Zephyr Technology collaborated on a motion-sickness study in the microgravity conditions onboard a parabolic-arc flight. A Zephyr BioHarness monitoring device can be seen on the woman’s wrist in the lower left corner. \n                    \n                  \n                  Zephyr Technology launched in 2003 with the goal of providing physiological status monitoring (PSM) for people in any condition or environment. Working with innovative technologies like smart fabrics and solid-state accelerometers, the company developed a unique PSM device—a narrow fabric band worn around the upper torso. Called the BioHarness, the product’s ability to capture, store, and transmit a range of vital sign data, coupled with its comfortable design, made it ideal for Toscano and Cowings’ research. \n                  Under a Space Act Agreement, NASA partnered with Zephyr to use the BioHarness to study motion sickness in test subjects onboard the Zero-G aircraft. Parabolic-arc flights are used to train astronauts and conduct experiments in momentary microgravity. (The plane is also known as the “Vomit Comet” due to its motion sickness-inducing flight maneuvers.) Another study was conducted as part of the Department of Homeland Security’s (DHS) Physiological Health Assessment System for Emergency Responders (PHASER) program. NASA researchers used Zephyr’s technology to monitor the vital signs of firefighters to aid PHASER’s goals of determining the impact of the high-stress jobs on health. According to the DHS, first responders like firefighters experience the highest occupational rate of line-of-duty deaths from events like heart attacks and strokes.\n                  Toscano and Cowings have even employed the BioHarness for training U.S. Navy fighter pilots to overcome the motion sickness some experience in flight; in the study, 5 of the 7 pilots were able to resume their jobs when overwhelming motion sickness had previously made them unfit to fly.\n                  While the Ames researchers benefited from the use of Zephyr’s devices, the company also came away with significant NASA contributions. \n                  “NASA’s depth of experience in physiology and knowledge of what’s been tried before is just massive for a small company like ours,” says Brian Russell, Zephyr’s CEO. \n                  “We’ve been able to give Zephyr good feedback on the types of algorithms to incorporate into their firmware, and on topics like crew comfort issues,” says Toscano. “They have taken that information and redesigned their system over the course of several years.” \n                  Benefits\n                  Zephyr’s BioHarness is now a market-leading technology and the cornerstone of its PSM training system. Through its smart fabric sensors, the BioHarness measures heart rate and heart rate variability, provides a heart electrocardiogram, and monitors breathing, skin temperature, motion (including speed and distance), and posture. The device can either store this data for later retrieval or transmit it using Bluetooth technology to a laptop to be displayed and analyzed by Zephyr’s OmniSense software. Additionally, the data can be sent to a smartphone loaded with any of a range of apps developed by Zephyr partners. A single PSM system can provide real-time monitoring of up to 64 BioHarness users. The applications of the gathered data are many, says Russell, but the common factor to all of them is utility.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Zephyr’s Consumer HxM device monitors heart rate, speed, and distance for everyday fitness training.\n                    \n                  \n                  “If you’re a doctor, a military commander, a medic, or a sports coach, our data needs to tell you something that’s useful,” Russell explains. With the company selling thousands of products a month, the usefulness of the company’s NASA-improved technology seems spoken for.\n                  One key application for the BioHarness is in fitness training. The readings logged by the device provide valuable baseline information on a user’s fitness levels and help the user track improvement over time. Professional sports teams in football, basketball, hockey, and baseball use the BioHarness to support and monitor the effectiveness of training regimens. The data delivered by the system also helps trainers recognize when an athlete might be suffering from dehydration or excessive fatigue or is at risk for heat stroke—a condition that has resulted in the deaths of a number of athletes during training.\n                  Working with the U.S. Special Forces, Zephyr tailored its PSM system for military applications, including determining the fitness of soldiers, and the company also provides PSM systems for first responders. In both cases, the data gathered by the BioHarness is transmitted via Bluetooth over the users’ tactical radios to OmniSense-equipped computers. \n                  The company also offers a system called the Consumer HxM, which provides heart rate, speed, and distance monitoring in a consumer-friendly package, without compromising quality.“It’s very important that a consumer gets the same quality as a fireman or soldier is getting,” Russell says. \n                  Zephyr’s technology has uses that go beyond fitness. On the battlefield, changes in vital signs can indicate if a soldier is injured, alerting medics more quickly than a radio call. The BioHarness continuously transmits data to the rescue vehicle and field hospital so that when the injured soldier arrives, doctors are up-to-date on the patient’s medical status. Similarly, the technology allows doctors to monitor patients in their homes or in nursing facilities. \n                  “Anyone at home who needs medical care can have the BioHarness on and transmit that data over the mobile phone network to the doctor in the hospital,” Russell says. \n                  Zephyr continues to evolve its PSM systems, moving the monitoring technology from straps into shirts and other clothing. In 2012, sports apparel and equipment manufacturer Under Armour plans to release its E39 shirt, which incorporates the Zephyr BioHarness. During the 2011 NFL combine, college football players hoping to be drafted by pro teams wore the shirts during various physical tests. The Zephyr-equipped shirts delivered physiological data not only to NFL scouts, but to fans watching the event on television, who could see immediately how high a prospect jumped, or how fast he ran. \n                  \n                    “NASA’s depth of \n                    experience in physiology \n                    … is just massive for a small \n                    company like ours.”\n                    —Brian Russell, \n                    Zephyr Technology \n                       \n                  \n                  “The athletes loved it,” says Russell. “They thought they were taking part in science fiction.” \n                  Zephyr also continues to work with NASA on research projects, including a study conducted under an International Space Act Agreement to determine indicators of fatigue in commercial airline flight crews. Russell notes that Zephyr’s NASA partnership and U.S.-made technology tells the right kind of story for the Nation’s economic and technological progress.\n                  \n                                        “Having high technology from NASA and innovation from Zephyr resulting in factory jobs here in America, manufacturing products worn by American first responders, soldiers, and athletes—that’s what we need to drive the economy,” he says. “As a taxpayer, I find it heartening that NASA is so open to these partnerships.”                    \n                  \n                  Zephyr™, BioHarness™, and OmniSense™ are trademarks of Zephyr Technology.\n                  Bluetooth® is a registered trademark of Bluetooth SIG Inc.\n                  \n                \n              \n                  NASA Technology\n                  Have you ever felt nauseous reading a book in the back seat of a car? Or woken from a deep sleep feeling disoriented, unsure which way is up? Momentary mixups like these happen when the sensory systems that track the body’s orientation in space become confused. (In the case of the backseat bookworm, the conflict arises when the reader’s inner ear, part of the body’s vestibular system, senses the car’s motion while her eyes are fixed on the stationary pages of the book.) Conditions like motion sickness are common on Earth, but they also present a significant challenge to astronauts in space. \n                  \n                    \n                    \n                      \n                    \n                    \n                      A subject undergoes preflight motion sickness testing in a rotating chair. NASA researchers developed a technique for overcoming the potentially debilitating condition.\n                    \n                  \n                  Human sensory systems use the pull of gravity to help determine orientation. In the microgravity environment onboard the International Space Station, for example, the body experiences a period of confusion before it adapts to the new circumstances. (In space, even the body’s proprioceptive system, which tells the brain where the arms and legs are oriented without the need for visual confirmation, goes haywire, meaning astronauts sometimes lose track of where their limbs are when they are not moving them.) This Space Adaptation Syndrome affects a majority of astronauts, even experienced ones, causing everything from mild disorientation to nausea to severe vomiting. \n                  “It can be quite debilitating,” says William Toscano, a research scientist in NASA’s Ames Research Center Psychophysiology Laboratory, part of the Center’s Human Systems Integration Division. “When this happens, as you can imagine, work proficiency declines considerably.”\n                  Since astronauts cannot afford to be distracted or incapacitated during critical missions, NASA has explored various means for preventing and countering motion sickness in space, including a range of drug treatments. Many effective motion sickness drugs, however, cause undesirable side effects, such as drowsiness. Toscano and his NASA colleague, Patricia Cowings, have developed a different approach: Utilizing biofeedback training methods, the pair can teach astronauts, military pilots, and others susceptible to motion sickness to self-regulate their own physiological responses and suppress the unpleasant symptoms. This NASA-patented method invented by Cowings is called the Autogenic Feedback Training Exercise (ATFE), and several studies have demonstrated its promise.\n                  “We’re able to get people to significantly increase their motion sickness tolerance,” says Toscano, noting that in laboratory studies conducted over a 20-year period about 85 percent of those who have undergone the 6-hour training experienced benefits, with about 65 percent able to suppress their symptoms entirely. \n                  In order to gather the necessary physiological data for their research and to enable the ATFE biofeedback training, Toscano and Cowings needed a practical solution for monitoring the vital signs of test subjects like astronauts and pilots. \n                  “The biggest consideration with using physiological monitors on astronauts and aircrew is putting sensors on the body,” Toscano says. “You need to have an unobtrusive device.”\n                  A company in Annapolis, Maryland, proved to have the technology the NASA researchers were looking for. Now the resulting partnership has both enabled NASA studies and provided powerful commercial fitness and health monitoring tools for soldiers, first responders, professional athletes, and consumers. \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      Ames Research Center and Zephyr Technology collaborated on a motion-sickness study in the microgravity conditions onboard a parabolic-arc flight. A Zephyr BioHarness monitoring device can be seen on the woman’s wrist in the lower left corner. \n                    \n                  \n                  Zephyr Technology launched in 2003 with the goal of providing physiological status monitoring (PSM) for people in any condition or environment. Working with innovative technologies like smart fabrics and solid-state accelerometers, the company developed a unique PSM device—a narrow fabric band worn around the upper torso. Called the BioHarness, the product’s ability to capture, store, and transmit a range of vital sign data, coupled with its comfortable design, made it ideal for Toscano and Cowings’ research. \n                  Under a Space Act Agreement, NASA partnered with Zephyr to use the BioHarness to study motion sickness in test subjects onboard the Zero-G aircraft. Parabolic-arc flights are used to train astronauts and conduct experiments in momentary microgravity. (The plane is also known as the “Vomit Comet” due to its motion sickness-inducing flight maneuvers.) Another study was conducted as part of the Department of Homeland Security’s (DHS) Physiological Health Assessment System for Emergency Responders (PHASER) program. NASA researchers used Zephyr’s technology to monitor the vital signs of firefighters to aid PHASER’s goals of determining the impact of the high-stress jobs on health. According to the DHS, first responders like firefighters experience the highest occupational rate of line-of-duty deaths from events like heart attacks and strokes.\n                  Toscano and Cowings have even employed the BioHarness for training U.S. Navy fighter pilots to overcome the motion sickness some experience in flight; in the study, 5 of the 7 pilots were able to resume their jobs when overwhelming motion sickness had previously made them unfit to fly.\n                  While the Ames researchers benefited from the use of Zephyr’s devices, the company also came away with significant NASA contributions. \n                  “NASA’s depth of experience in physiology and knowledge of what’s been tried before is just massive for a small company like ours,” says Brian Russell, Zephyr’s CEO. \n                  “We’ve been able to give Zephyr good feedback on the types of algorithms to incorporate into their firmware, and on topics like crew comfort issues,” says Toscano. “They have taken that information and redesigned their system over the course of several years.” \n                  Benefits\n                  Zephyr’s BioHarness is now a market-leading technology and the cornerstone of its PSM training system. Through its smart fabric sensors, the BioHarness measures heart rate and heart rate variability, provides a heart electrocardiogram, and monitors breathing, skin temperature, motion (including speed and distance), and posture. The device can either store this data for later retrieval or transmit it using Bluetooth technology to a laptop to be displayed and analyzed by Zephyr’s OmniSense software. Additionally, the data can be sent to a smartphone loaded with any of a range of apps developed by Zephyr partners. A single PSM system can provide real-time monitoring of up to 64 BioHarness users. The applications of the gathered data are many, says Russell, but the common factor to all of them is utility.\n                  \n                    \n                    \n                      \n                    \n                    \n                      Zephyr’s Consumer HxM device monitors heart rate, speed, and distance for everyday fitness training.\n                    \n                  \n                  “If you’re a doctor, a military commander, a medic, or a sports coach, our data needs to tell you something that’s useful,” Russell explains. With the company selling thousands of products a month, the usefulness of the company’s NASA-improved technology seems spoken for.\n                  One key application for the BioHarness is in fitness training. The readings logged by the device provide valuable baseline information on a user’s fitness levels and help the user track improvement over time. Professional sports teams in football, basketball, hockey, and baseball use the BioHarness to support and monitor the effectiveness of training regimens. The data delivered by the system also helps trainers recognize when an athlete might be suffering from dehydration or excessive fatigue or is at risk for heat stroke—a condition that has resulted in the deaths of a number of athletes during training.\n                  Working with the U.S. Special Forces, Zephyr tailored its PSM system for military applications, including determining the fitness of soldiers, and the company also provides PSM systems for first responders. In both cases, the data gathered by the BioHarness is transmitted via Bluetooth over the users’ tactical radios to OmniSense-equipped computers. \n                  The company also offers a system called the Consumer HxM, which provides heart rate, speed, and distance monitoring in a consumer-friendly package, without compromising quality.“It’s very important that a consumer gets the same quality as a fireman or soldier is getting,” Russell says. \n                  Zephyr’s technology has uses that go beyond fitness. On the battlefield, changes in vital signs can indicate if a soldier is injured, alerting medics more quickly than a radio call. The BioHarness continuously transmits data to the rescue vehicle and field hospital so that when the injured soldier arrives, doctors are up-to-date on the patient’s medical status. Similarly, the technology allows doctors to monitor patients in their homes or in nursing facilities. \n                  “Anyone at home who needs medical care can have the BioHarness on and transmit that data over the mobile phone network to the doctor in the hospital,” Russell says. \n                  Zephyr continues to evolve its PSM systems, moving the monitoring technology from straps into shirts and other clothing. In 2012, sports apparel and equipment manufacturer Under Armour plans to release its E39 shirt, which incorporates the Zephyr BioHarness. During the 2011 NFL combine, college football players hoping to be drafted by pro teams wore the shirts during various physical tests. The Zephyr-equipped shirts delivered physiological data not only to NFL scouts, but to fans watching the event on television, who could see immediately how high a prospect jumped, or how fast he ran. \n                  \n                    “NASA’s depth of \n                    experience in physiology \n                    … is just massive for a small \n                    company like ours.”\n                    —Brian Russell, \n                    Zephyr Technology \n                       \n                  \n                  “The athletes loved it,” says Russell. “They thought they were taking part in science fiction.” \n                  Zephyr also continues to work with NASA on research projects, including a study conducted under an International Space Act Agreement to determine indicators of fatigue in commercial airline flight crews. Russell notes that Zephyr’s NASA partnership and U.S.-made technology tells the right kind of story for the Nation’s economic and technological progress.\n                  \n                                        “Having high technology from NASA and innovation from Zephyr resulting in factory jobs here in America, manufacturing products worn by American first responders, soldiers, and athletes—that’s what we need to drive the economy,” he says. “As a taxpayer, I find it heartening that NASA is so open to these partnerships.”                    \n                  \n                  Zephyr™, BioHarness™, and OmniSense™ are trademarks of Zephyr Technology.\n                  Bluetooth® is a registered trademark of Bluetooth SIG Inc.\n                  "},{"href":"http://spinoff.nasa.gov/Spinoff2011/cg_6.html","text":"Thermal Components Boost Performance of HVAC Systems","image":"http://spinoff.nasa.gov/Spinoff2011/Images/cg_12_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  \n                    \n                    \n                      \n                    \n                    \n                      Thanks to the advanced control systems onboard the International Space Station, NASA astronauts Ron Garan (bottom) and Cady Coleman (right), European Space Agency astronaut Paolo Nespoli (left) and Russian cosmonaut Alexander Samokutyaev (top), enjoy a comfortable environment while in orbit.\n                    \n                  \n                  As the International Space Station (ISS) travels 17,500 miles per hour, normal is having a constant sensation of free-falling. Normal is no rain, but an extreme amount of shine—with temperatures reaching 250 ˚F when facing the Sun. Thanks to a number of advanced control systems onboard the ISS, however, the interior of the station remains a cool, comfortable, normal environment where astronauts can live and work for extended periods of time.\n                  There are two main control systems on the ISS that make it possible for humans to survive in space: the Thermal Control System (TCS) and the Environmental Control and Life Support system. These intricate assemblies work together to supply water and oxygen, regulate temperature and pressure, maintain air quality, and manage waste. Through artificial means, these \n                    systems create a habitable environment for the space station’s crew.\n                  The TCS constantly works to regulate the temperature not only for astronauts, but for the critical instruments and machines inside the spacecraft as well. To do its job, the TCS encompasses several components and systems both inside and outside of the ISS. Inside the spacecraft, a liquid heat-exchange process mechanically pumps fluids in closed-loop circuits to collect, transport, and reject heat. Outside the ISS, an external system circulates anhydrous ammonia to transport heat and cool equipment, and radiators release the heat into space.\n                   Over the years, NASA has worked with a variety of partners—public and private, national and international—to develop and refine the most complex thermal control systems ever built for spacecraft, including the one on the ISS. \n                  Partnership\n                  To ensure a normal environment for astronauts and instruments, a Rockledge, Florida-based company, Mainstream Engineering Corporation, has steadily worked with NASA field centers since the 1980s to develop advanced thermal control technology for spacecraft. First featured in Spinoff 1999 for the development of a commercial product called QwikBoost, based on work with NASA on a liquid formulation for a chemical/mechanical heat pump, Mainstream Engineering has since licensed QwikBoost to a company called IDQ Inc. that incorporates the technology into a successful line of products to recharge automotive air conditioning (Spinoff 2010).\n                  Once again, Mainstream has built upon its work with NASA, developing two new products that are offering benefits here on Earth: PuraClean filter spray and QwikShot acid flush. PuraClean grew from work under a Small Business Innovation Research (SBIR) award with Johnson Space Center to research a nontoxic heat transport fluid for the thermal control systems inside a spacecraft. The second product, QwikShot, grew from SBIR work with Johnson to demonstrate high-performance, low-cost thermal control equipment.\n                  Benefits\n                  PuraClean is a liquid spray product that can be applied to any kind of disposable air filter for heating, ventilating, and air conditioning (HVAC) units. By insulating the fibers on the filter with a coating that extends the electrostatic properties of the filter, the spray increases its dirt-attracting and holding capabilities. It is designed to improve the performance of any type of filter, such as reusable metal filters, expensive electrostatic filters, or inexpensive spun glass or foam filters. “Any household, laboratory, hospital, automobile, school, and anywhere an air filter is used can reap the benefits of PuraClean,” says Brandon Scheckel, director of business development at Mainstream Engineering. “After the SBIR, Mainstream engineers worked on the formulation to make it fast evaporating, while still having lasting effects. Also, the goal was to make it allergy and asthma friendly.” \n                  “Mainstream Engineering is working hard \n  at making this NASA-developed technology available to every consumer.” \n                    —Brandon Scheckel, \n                    Mainstream Engineering Corporation \n                  According to results from independent laboratory testing, filters treated by PuraClean provided an improvement in filtration efficiency ranging from 200 percent when exposed to 3 micrometer particles, to more than 1,200 percent when exposed to 7 micrometer particles such as pollen, dust, and dirt. Test results also indicated that PuraClean caused no measurable difference in resistance to airflow. Mainstream says that, unlike other filter sprays, PuraClean can actually make filters more efficient because air conditioner evaporator coils stay cleaner and provide improved energy efficiency.\n                  \n                    \n                    \n                      \n                    \n                    \n                      PuraClean improves the performance of air filters while QwikShot vaporizes acid and moisture when it occurs in air conditioning and refrigeration systems.\n                    \n                  \n                  Available to service technicians from HVAC suppliers, Mainstream has sold between 7,000 and 8,000 bottles of the product since 2007, but expects those numbers to drastically grow in the near future. Currently, the product is being reviewed by the Asthma and \n                    Allergy Friendly Certification Program to become a certified residential allergy- and asthma-reducing HVAC product. “Mainstream Engineering is working hard at making this NASA-developed technology available to every consumer,” says Scheckel. \n                  Much like PuraClean, Scheckel says the development of the QwikShot acid flush product took place after research and development under a NASA SBIR. “We worked on exacting the formulation and wanted to make it as safe and easy to use as possible,” he says. “QwikShot improves the thermal stability of air conditioning and refrigeration systems and extends the life of the system by removing system-destroying acids from the thermal circuit.” \n                  Used for vaporizing acid and moisture when it occurs in air conditioning and refrigeration systems, QwikShot is injected into a system during operation. After it is introduced, the product vaporizes with refrigerant and travels throughout the system to chemically attach to acid and moisture molecules. It then flushes the molecules to the filter or drier. Unlike acid neutralizers that leave a salt-based residue from a chemical reaction, QwikShot leaves no residue in the system.\n                   “Traditional techniques require the technician to open the system and neutralize compressor oil by opening up the compressor, or a line set near the compressor, and add the neutralizing product, says Scheckel. QwikShot is simply introduced into the compressor oil. \n                  According to Mainstream, over 75,000 applications of QwikShot have been sold. “HVAC and refrigeration service technicians who fix residential and commercial air conditioning systems use QwikShot to treat systems with signs of acid prior to system failure, and it improves the thermal stability,” Scheckel says. \n                  Due to the research and development opportunities provided through NASA’s SBIR program, Mainstream has significantly improved the normal operation of HVAC systems on Earth.\n                  PuraClean® and QwikShot® are registered trademarks of Mainstream Engineering Corporation.\n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  \n                    \n                    \n                      \n                    \n                    \n                      Thanks to the advanced control systems onboard the International Space Station, NASA astronauts Ron Garan (bottom) and Cady Coleman (right), European Space Agency astronaut Paolo Nespoli (left) and Russian cosmonaut Alexander Samokutyaev (top), enjoy a comfortable environment while in orbit.\n                    \n                  \n                  As the International Space Station (ISS) travels 17,500 miles per hour, normal is having a constant sensation of free-falling. Normal is no rain, but an extreme amount of shine—with temperatures reaching 250 ˚F when facing the Sun. Thanks to a number of advanced control systems onboard the ISS, however, the interior of the station remains a cool, comfortable, normal environment where astronauts can live and work for extended periods of time.\n                  There are two main control systems on the ISS that make it possible for humans to survive in space: the Thermal Control System (TCS) and the Environmental Control and Life Support system. These intricate assemblies work together to supply water and oxygen, regulate temperature and pressure, maintain air quality, and manage waste. Through artificial means, these \n                    systems create a habitable environment for the space station’s crew.\n                  The TCS constantly works to regulate the temperature not only for astronauts, but for the critical instruments and machines inside the spacecraft as well. To do its job, the TCS encompasses several components and systems both inside and outside of the ISS. Inside the spacecraft, a liquid heat-exchange process mechanically pumps fluids in closed-loop circuits to collect, transport, and reject heat. Outside the ISS, an external system circulates anhydrous ammonia to transport heat and cool equipment, and radiators release the heat into space.\n                   Over the years, NASA has worked with a variety of partners—public and private, national and international—to develop and refine the most complex thermal control systems ever built for spacecraft, including the one on the ISS. \n                  Partnership\n                  To ensure a normal environment for astronauts and instruments, a Rockledge, Florida-based company, Mainstream Engineering Corporation, has steadily worked with NASA field centers since the 1980s to develop advanced thermal control technology for spacecraft. First featured in Spinoff 1999 for the development of a commercial product called QwikBoost, based on work with NASA on a liquid formulation for a chemical/mechanical heat pump, Mainstream Engineering has since licensed QwikBoost to a company called IDQ Inc. that incorporates the technology into a successful line of products to recharge automotive air conditioning (Spinoff 2010).\n                  Once again, Mainstream has built upon its work with NASA, developing two new products that are offering benefits here on Earth: PuraClean filter spray and QwikShot acid flush. PuraClean grew from work under a Small Business Innovation Research (SBIR) award with Johnson Space Center to research a nontoxic heat transport fluid for the thermal control systems inside a spacecraft. The second product, QwikShot, grew from SBIR work with Johnson to demonstrate high-performance, low-cost thermal control equipment.\n                  Benefits\n                  PuraClean is a liquid spray product that can be applied to any kind of disposable air filter for heating, ventilating, and air conditioning (HVAC) units. By insulating the fibers on the filter with a coating that extends the electrostatic properties of the filter, the spray increases its dirt-attracting and holding capabilities. It is designed to improve the performance of any type of filter, such as reusable metal filters, expensive electrostatic filters, or inexpensive spun glass or foam filters. “Any household, laboratory, hospital, automobile, school, and anywhere an air filter is used can reap the benefits of PuraClean,” says Brandon Scheckel, director of business development at Mainstream Engineering. “After the SBIR, Mainstream engineers worked on the formulation to make it fast evaporating, while still having lasting effects. Also, the goal was to make it allergy and asthma friendly.” \n                  “Mainstream Engineering is working hard \n  at making this NASA-developed technology available to every consumer.” \n                    —Brandon Scheckel, \n                    Mainstream Engineering Corporation \n                  According to results from independent laboratory testing, filters treated by PuraClean provided an improvement in filtration efficiency ranging from 200 percent when exposed to 3 micrometer particles, to more than 1,200 percent when exposed to 7 micrometer particles such as pollen, dust, and dirt. Test results also indicated that PuraClean caused no measurable difference in resistance to airflow. Mainstream says that, unlike other filter sprays, PuraClean can actually make filters more efficient because air conditioner evaporator coils stay cleaner and provide improved energy efficiency.\n                  \n                    \n                    \n                      \n                    \n                    \n                      PuraClean improves the performance of air filters while QwikShot vaporizes acid and moisture when it occurs in air conditioning and refrigeration systems.\n                    \n                  \n                  Available to service technicians from HVAC suppliers, Mainstream has sold between 7,000 and 8,000 bottles of the product since 2007, but expects those numbers to drastically grow in the near future. Currently, the product is being reviewed by the Asthma and \n                    Allergy Friendly Certification Program to become a certified residential allergy- and asthma-reducing HVAC product. “Mainstream Engineering is working hard at making this NASA-developed technology available to every consumer,” says Scheckel. \n                  Much like PuraClean, Scheckel says the development of the QwikShot acid flush product took place after research and development under a NASA SBIR. “We worked on exacting the formulation and wanted to make it as safe and easy to use as possible,” he says. “QwikShot improves the thermal stability of air conditioning and refrigeration systems and extends the life of the system by removing system-destroying acids from the thermal circuit.” \n                  Used for vaporizing acid and moisture when it occurs in air conditioning and refrigeration systems, QwikShot is injected into a system during operation. After it is introduced, the product vaporizes with refrigerant and travels throughout the system to chemically attach to acid and moisture molecules. It then flushes the molecules to the filter or drier. Unlike acid neutralizers that leave a salt-based residue from a chemical reaction, QwikShot leaves no residue in the system.\n                   “Traditional techniques require the technician to open the system and neutralize compressor oil by opening up the compressor, or a line set near the compressor, and add the neutralizing product, says Scheckel. QwikShot is simply introduced into the compressor oil. \n                  According to Mainstream, over 75,000 applications of QwikShot have been sold. “HVAC and refrigeration service technicians who fix residential and commercial air conditioning systems use QwikShot to treat systems with signs of acid prior to system failure, and it improves the thermal stability,” Scheckel says. \n                  Due to the research and development opportunities provided through NASA’s SBIR program, Mainstream has significantly improved the normal operation of HVAC systems on Earth.\n                  PuraClean® and QwikShot® are registered trademarks of Mainstream Engineering Corporation.\n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  \n                    \n                    \n                      \n                    \n                    \n                      Thanks to the advanced control systems onboard the International Space Station, NASA astronauts Ron Garan (bottom) and Cady Coleman (right), European Space Agency astronaut Paolo Nespoli (left) and Russian cosmonaut Alexander Samokutyaev (top), enjoy a comfortable environment while in orbit.\n                    \n                  \n                  As the International Space Station (ISS) travels 17,500 miles per hour, normal is having a constant sensation of free-falling. Normal is no rain, but an extreme amount of shine—with temperatures reaching 250 ˚F when facing the Sun. Thanks to a number of advanced control systems onboard the ISS, however, the interior of the station remains a cool, comfortable, normal environment where astronauts can live and work for extended periods of time.\n                  There are two main control systems on the ISS that make it possible for humans to survive in space: the Thermal Control System (TCS) and the Environmental Control and Life Support system. These intricate assemblies work together to supply water and oxygen, regulate temperature and pressure, maintain air quality, and manage waste. Through artificial means, these \n                    systems create a habitable environment for the space station’s crew.\n                  The TCS constantly works to regulate the temperature not only for astronauts, but for the critical instruments and machines inside the spacecraft as well. To do its job, the TCS encompasses several components and systems both inside and outside of the ISS. Inside the spacecraft, a liquid heat-exchange process mechanically pumps fluids in closed-loop circuits to collect, transport, and reject heat. Outside the ISS, an external system circulates anhydrous ammonia to transport heat and cool equipment, and radiators release the heat into space.\n                   Over the years, NASA has worked with a variety of partners—public and private, national and international—to develop and refine the most complex thermal control systems ever built for spacecraft, including the one on the ISS. \n                  Partnership\n                  To ensure a normal environment for astronauts and instruments, a Rockledge, Florida-based company, Mainstream Engineering Corporation, has steadily worked with NASA field centers since the 1980s to develop advanced thermal control technology for spacecraft. First featured in Spinoff 1999 for the development of a commercial product called QwikBoost, based on work with NASA on a liquid formulation for a chemical/mechanical heat pump, Mainstream Engineering has since licensed QwikBoost to a company called IDQ Inc. that incorporates the technology into a successful line of products to recharge automotive air conditioning (Spinoff 2010).\n                  Once again, Mainstream has built upon its work with NASA, developing two new products that are offering benefits here on Earth: PuraClean filter spray and QwikShot acid flush. PuraClean grew from work under a Small Business Innovation Research (SBIR) award with Johnson Space Center to research a nontoxic heat transport fluid for the thermal control systems inside a spacecraft. The second product, QwikShot, grew from SBIR work with Johnson to demonstrate high-performance, low-cost thermal control equipment.\n                  Benefits\n                  PuraClean is a liquid spray product that can be applied to any kind of disposable air filter for heating, ventilating, and air conditioning (HVAC) units. By insulating the fibers on the filter with a coating that extends the electrostatic properties of the filter, the spray increases its dirt-attracting and holding capabilities. It is designed to improve the performance of any type of filter, such as reusable metal filters, expensive electrostatic filters, or inexpensive spun glass or foam filters. “Any household, laboratory, hospital, automobile, school, and anywhere an air filter is used can reap the benefits of PuraClean,” says Brandon Scheckel, director of business development at Mainstream Engineering. “After the SBIR, Mainstream engineers worked on the formulation to make it fast evaporating, while still having lasting effects. Also, the goal was to make it allergy and asthma friendly.” \n                  “Mainstream Engineering is working hard \n  at making this NASA-developed technology available to every consumer.” \n                    —Brandon Scheckel, \n                    Mainstream Engineering Corporation \n                  According to results from independent laboratory testing, filters treated by PuraClean provided an improvement in filtration efficiency ranging from 200 percent when exposed to 3 micrometer particles, to more than 1,200 percent when exposed to 7 micrometer particles such as pollen, dust, and dirt. Test results also indicated that PuraClean caused no measurable difference in resistance to airflow. Mainstream says that, unlike other filter sprays, PuraClean can actually make filters more efficient because air conditioner evaporator coils stay cleaner and provide improved energy efficiency.\n                  \n                    \n                    \n                      \n                    \n                    \n                      PuraClean improves the performance of air filters while QwikShot vaporizes acid and moisture when it occurs in air conditioning and refrigeration systems.\n                    \n                  \n                  Available to service technicians from HVAC suppliers, Mainstream has sold between 7,000 and 8,000 bottles of the product since 2007, but expects those numbers to drastically grow in the near future. Currently, the product is being reviewed by the Asthma and \n                    Allergy Friendly Certification Program to become a certified residential allergy- and asthma-reducing HVAC product. “Mainstream Engineering is working hard at making this NASA-developed technology available to every consumer,” says Scheckel. \n                  Much like PuraClean, Scheckel says the development of the QwikShot acid flush product took place after research and development under a NASA SBIR. “We worked on exacting the formulation and wanted to make it as safe and easy to use as possible,” he says. “QwikShot improves the thermal stability of air conditioning and refrigeration systems and extends the life of the system by removing system-destroying acids from the thermal circuit.” \n                  Used for vaporizing acid and moisture when it occurs in air conditioning and refrigeration systems, QwikShot is injected into a system during operation. After it is introduced, the product vaporizes with refrigerant and travels throughout the system to chemically attach to acid and moisture molecules. It then flushes the molecules to the filter or drier. Unlike acid neutralizers that leave a salt-based residue from a chemical reaction, QwikShot leaves no residue in the system.\n                   “Traditional techniques require the technician to open the system and neutralize compressor oil by opening up the compressor, or a line set near the compressor, and add the neutralizing product, says Scheckel. QwikShot is simply introduced into the compressor oil. \n                  According to Mainstream, over 75,000 applications of QwikShot have been sold. “HVAC and refrigeration service technicians who fix residential and commercial air conditioning systems use QwikShot to treat systems with signs of acid prior to system failure, and it improves the thermal stability,” Scheckel says. \n                  Due to the research and development opportunities provided through NASA’s SBIR program, Mainstream has significantly improved the normal operation of HVAC systems on Earth.\n                  PuraClean® and QwikShot® are registered trademarks of Mainstream Engineering Corporation.\n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  NASA Technology\n                  \n                    \n                    \n                      \n                    \n                    \n                      Thanks to the advanced control systems onboard the International Space Station, NASA astronauts Ron Garan (bottom) and Cady Coleman (right), European Space Agency astronaut Paolo Nespoli (left) and Russian cosmonaut Alexander Samokutyaev (top), enjoy a comfortable environment while in orbit.\n                    \n                  \n                  As the International Space Station (ISS) travels 17,500 miles per hour, normal is having a constant sensation of free-falling. Normal is no rain, but an extreme amount of shine—with temperatures reaching 250 ˚F when facing the Sun. Thanks to a number of advanced control systems onboard the ISS, however, the interior of the station remains a cool, comfortable, normal environment where astronauts can live and work for extended periods of time.\n                  There are two main control systems on the ISS that make it possible for humans to survive in space: the Thermal Control System (TCS) and the Environmental Control and Life Support system. These intricate assemblies work together to supply water and oxygen, regulate temperature and pressure, maintain air quality, and manage waste. Through artificial means, these \n                    systems create a habitable environment for the space station’s crew.\n                  The TCS constantly works to regulate the temperature not only for astronauts, but for the critical instruments and machines inside the spacecraft as well. To do its job, the TCS encompasses several components and systems both inside and outside of the ISS. Inside the spacecraft, a liquid heat-exchange process mechanically pumps fluids in closed-loop circuits to collect, transport, and reject heat. Outside the ISS, an external system circulates anhydrous ammonia to transport heat and cool equipment, and radiators release the heat into space.\n                   Over the years, NASA has worked with a variety of partners—public and private, national and international—to develop and refine the most complex thermal control systems ever built for spacecraft, including the one on the ISS. \n                  Partnership\n                  To ensure a normal environment for astronauts and instruments, a Rockledge, Florida-based company, Mainstream Engineering Corporation, has steadily worked with NASA field centers since the 1980s to develop advanced thermal control technology for spacecraft. First featured in Spinoff 1999 for the development of a commercial product called QwikBoost, based on work with NASA on a liquid formulation for a chemical/mechanical heat pump, Mainstream Engineering has since licensed QwikBoost to a company called IDQ Inc. that incorporates the technology into a successful line of products to recharge automotive air conditioning (Spinoff 2010).\n                  Once again, Mainstream has built upon its work with NASA, developing two new products that are offering benefits here on Earth: PuraClean filter spray and QwikShot acid flush. PuraClean grew from work under a Small Business Innovation Research (SBIR) award with Johnson Space Center to research a nontoxic heat transport fluid for the thermal control systems inside a spacecraft. The second product, QwikShot, grew from SBIR work with Johnson to demonstrate high-performance, low-cost thermal control equipment.\n                  Benefits\n                  PuraClean is a liquid spray product that can be applied to any kind of disposable air filter for heating, ventilating, and air conditioning (HVAC) units. By insulating the fibers on the filter with a coating that extends the electrostatic properties of the filter, the spray increases its dirt-attracting and holding capabilities. It is designed to improve the performance of any type of filter, such as reusable metal filters, expensive electrostatic filters, or inexpensive spun glass or foam filters. “Any household, laboratory, hospital, automobile, school, and anywhere an air filter is used can reap the benefits of PuraClean,” says Brandon Scheckel, director of business development at Mainstream Engineering. “After the SBIR, Mainstream engineers worked on the formulation to make it fast evaporating, while still having lasting effects. Also, the goal was to make it allergy and asthma friendly.” \n                  “Mainstream Engineering is working hard \n  at making this NASA-developed technology available to every consumer.” \n                    —Brandon Scheckel, \n                    Mainstream Engineering Corporation \n                  According to results from independent laboratory testing, filters treated by PuraClean provided an improvement in filtration efficiency ranging from 200 percent when exposed to 3 micrometer particles, to more than 1,200 percent when exposed to 7 micrometer particles such as pollen, dust, and dirt. Test results also indicated that PuraClean caused no measurable difference in resistance to airflow. Mainstream says that, unlike other filter sprays, PuraClean can actually make filters more efficient because air conditioner evaporator coils stay cleaner and provide improved energy efficiency.\n                  \n                    \n                    \n                      \n                    \n                    \n                      PuraClean improves the performance of air filters while QwikShot vaporizes acid and moisture when it occurs in air conditioning and refrigeration systems.\n                    \n                  \n                  Available to service technicians from HVAC suppliers, Mainstream has sold between 7,000 and 8,000 bottles of the product since 2007, but expects those numbers to drastically grow in the near future. Currently, the product is being reviewed by the Asthma and \n                    Allergy Friendly Certification Program to become a certified residential allergy- and asthma-reducing HVAC product. “Mainstream Engineering is working hard at making this NASA-developed technology available to every consumer,” says Scheckel. \n                  Much like PuraClean, Scheckel says the development of the QwikShot acid flush product took place after research and development under a NASA SBIR. “We worked on exacting the formulation and wanted to make it as safe and easy to use as possible,” he says. “QwikShot improves the thermal stability of air conditioning and refrigeration systems and extends the life of the system by removing system-destroying acids from the thermal circuit.” \n                  Used for vaporizing acid and moisture when it occurs in air conditioning and refrigeration systems, QwikShot is injected into a system during operation. After it is introduced, the product vaporizes with refrigerant and travels throughout the system to chemically attach to acid and moisture molecules. It then flushes the molecules to the filter or drier. Unlike acid neutralizers that leave a salt-based residue from a chemical reaction, QwikShot leaves no residue in the system.\n                   “Traditional techniques require the technician to open the system and neutralize compressor oil by opening up the compressor, or a line set near the compressor, and add the neutralizing product, says Scheckel. QwikShot is simply introduced into the compressor oil. \n                  According to Mainstream, over 75,000 applications of QwikShot have been sold. “HVAC and refrigeration service technicians who fix residential and commercial air conditioning systems use QwikShot to treat systems with signs of acid prior to system failure, and it improves the thermal stability,” Scheckel says. \n                  Due to the research and development opportunities provided through NASA’s SBIR program, Mainstream has significantly improved the normal operation of HVAC systems on Earth.\n                  PuraClean® and QwikShot® are registered trademarks of Mainstream Engineering Corporation.\n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  NASA Technology\n                  \n                    \n                    \n                      \n                    \n                    \n                      Thanks to the advanced control systems onboard the International Space Station, NASA astronauts Ron Garan (bottom) and Cady Coleman (right), European Space Agency astronaut Paolo Nespoli (left) and Russian cosmonaut Alexander Samokutyaev (top), enjoy a comfortable environment while in orbit.\n                    \n                  \n                  As the International Space Station (ISS) travels 17,500 miles per hour, normal is having a constant sensation of free-falling. Normal is no rain, but an extreme amount of shine—with temperatures reaching 250 ˚F when facing the Sun. Thanks to a number of advanced control systems onboard the ISS, however, the interior of the station remains a cool, comfortable, normal environment where astronauts can live and work for extended periods of time.\n                  There are two main control systems on the ISS that make it possible for humans to survive in space: the Thermal Control System (TCS) and the Environmental Control and Life Support system. These intricate assemblies work together to supply water and oxygen, regulate temperature and pressure, maintain air quality, and manage waste. Through artificial means, these \n                    systems create a habitable environment for the space station’s crew.\n                  The TCS constantly works to regulate the temperature not only for astronauts, but for the critical instruments and machines inside the spacecraft as well. To do its job, the TCS encompasses several components and systems both inside and outside of the ISS. Inside the spacecraft, a liquid heat-exchange process mechanically pumps fluids in closed-loop circuits to collect, transport, and reject heat. Outside the ISS, an external system circulates anhydrous ammonia to transport heat and cool equipment, and radiators release the heat into space.\n                   Over the years, NASA has worked with a variety of partners—public and private, national and international—to develop and refine the most complex thermal control systems ever built for spacecraft, including the one on the ISS. \n                  Partnership\n                  To ensure a normal environment for astronauts and instruments, a Rockledge, Florida-based company, Mainstream Engineering Corporation, has steadily worked with NASA field centers since the 1980s to develop advanced thermal control technology for spacecraft. First featured in Spinoff 1999 for the development of a commercial product called QwikBoost, based on work with NASA on a liquid formulation for a chemical/mechanical heat pump, Mainstream Engineering has since licensed QwikBoost to a company called IDQ Inc. that incorporates the technology into a successful line of products to recharge automotive air conditioning (Spinoff 2010).\n                  Once again, Mainstream has built upon its work with NASA, developing two new products that are offering benefits here on Earth: PuraClean filter spray and QwikShot acid flush. PuraClean grew from work under a Small Business Innovation Research (SBIR) award with Johnson Space Center to research a nontoxic heat transport fluid for the thermal control systems inside a spacecraft. The second product, QwikShot, grew from SBIR work with Johnson to demonstrate high-performance, low-cost thermal control equipment.\n                  Benefits\n                  PuraClean is a liquid spray product that can be applied to any kind of disposable air filter for heating, ventilating, and air conditioning (HVAC) units. By insulating the fibers on the filter with a coating that extends the electrostatic properties of the filter, the spray increases its dirt-attracting and holding capabilities. It is designed to improve the performance of any type of filter, such as reusable metal filters, expensive electrostatic filters, or inexpensive spun glass or foam filters. “Any household, laboratory, hospital, automobile, school, and anywhere an air filter is used can reap the benefits of PuraClean,” says Brandon Scheckel, director of business development at Mainstream Engineering. “After the SBIR, Mainstream engineers worked on the formulation to make it fast evaporating, while still having lasting effects. Also, the goal was to make it allergy and asthma friendly.” \n                  “Mainstream Engineering is working hard \n  at making this NASA-developed technology available to every consumer.” \n                    —Brandon Scheckel, \n                    Mainstream Engineering Corporation \n                  According to results from independent laboratory testing, filters treated by PuraClean provided an improvement in filtration efficiency ranging from 200 percent when exposed to 3 micrometer particles, to more than 1,200 percent when exposed to 7 micrometer particles such as pollen, dust, and dirt. Test results also indicated that PuraClean caused no measurable difference in resistance to airflow. Mainstream says that, unlike other filter sprays, PuraClean can actually make filters more efficient because air conditioner evaporator coils stay cleaner and provide improved energy efficiency.\n                  \n                    \n                    \n                      \n                    \n                    \n                      PuraClean improves the performance of air filters while QwikShot vaporizes acid and moisture when it occurs in air conditioning and refrigeration systems.\n                    \n                  \n                  Available to service technicians from HVAC suppliers, Mainstream has sold between 7,000 and 8,000 bottles of the product since 2007, but expects those numbers to drastically grow in the near future. Currently, the product is being reviewed by the Asthma and \n                    Allergy Friendly Certification Program to become a certified residential allergy- and asthma-reducing HVAC product. “Mainstream Engineering is working hard at making this NASA-developed technology available to every consumer,” says Scheckel. \n                  Much like PuraClean, Scheckel says the development of the QwikShot acid flush product took place after research and development under a NASA SBIR. “We worked on exacting the formulation and wanted to make it as safe and easy to use as possible,” he says. “QwikShot improves the thermal stability of air conditioning and refrigeration systems and extends the life of the system by removing system-destroying acids from the thermal circuit.” \n                  Used for vaporizing acid and moisture when it occurs in air conditioning and refrigeration systems, QwikShot is injected into a system during operation. After it is introduced, the product vaporizes with refrigerant and travels throughout the system to chemically attach to acid and moisture molecules. It then flushes the molecules to the filter or drier. Unlike acid neutralizers that leave a salt-based residue from a chemical reaction, QwikShot leaves no residue in the system.\n                   “Traditional techniques require the technician to open the system and neutralize compressor oil by opening up the compressor, or a line set near the compressor, and add the neutralizing product, says Scheckel. QwikShot is simply introduced into the compressor oil. \n                  According to Mainstream, over 75,000 applications of QwikShot have been sold. “HVAC and refrigeration service technicians who fix residential and commercial air conditioning systems use QwikShot to treat systems with signs of acid prior to system failure, and it improves the thermal stability,” Scheckel says. \n                  Due to the research and development opportunities provided through NASA’s SBIR program, Mainstream has significantly improved the normal operation of HVAC systems on Earth.\n                  PuraClean® and QwikShot® are registered trademarks of Mainstream Engineering Corporation.\n                  \n                \n              \n            \n            \n              \n                \n                  NASA Technology\n                  \n                    \n                    \n                      \n                    \n                    \n                      Thanks to the advanced control systems onboard the International Space Station, NASA astronauts Ron Garan (bottom) and Cady Coleman (right), European Space Agency astronaut Paolo Nespoli (left) and Russian cosmonaut Alexander Samokutyaev (top), enjoy a comfortable environment while in orbit.\n                    \n                  \n                  As the International Space Station (ISS) travels 17,500 miles per hour, normal is having a constant sensation of free-falling. Normal is no rain, but an extreme amount of shine—with temperatures reaching 250 ˚F when facing the Sun. Thanks to a number of advanced control systems onboard the ISS, however, the interior of the station remains a cool, comfortable, normal environment where astronauts can live and work for extended periods of time.\n                  There are two main control systems on the ISS that make it possible for humans to survive in space: the Thermal Control System (TCS) and the Environmental Control and Life Support system. These intricate assemblies work together to supply water and oxygen, regulate temperature and pressure, maintain air quality, and manage waste. Through artificial means, these \n                    systems create a habitable environment for the space station’s crew.\n                  The TCS constantly works to regulate the temperature not only for astronauts, but for the critical instruments and machines inside the spacecraft as well. To do its job, the TCS encompasses several components and systems both inside and outside of the ISS. Inside the spacecraft, a liquid heat-exchange process mechanically pumps fluids in closed-loop circuits to collect, transport, and reject heat. Outside the ISS, an external system circulates anhydrous ammonia to transport heat and cool equipment, and radiators release the heat into space.\n                   Over the years, NASA has worked with a variety of partners—public and private, national and international—to develop and refine the most complex thermal control systems ever built for spacecraft, including the one on the ISS. \n                  Partnership\n                  To ensure a normal environment for astronauts and instruments, a Rockledge, Florida-based company, Mainstream Engineering Corporation, has steadily worked with NASA field centers since the 1980s to develop advanced thermal control technology for spacecraft. First featured in Spinoff 1999 for the development of a commercial product called QwikBoost, based on work with NASA on a liquid formulation for a chemical/mechanical heat pump, Mainstream Engineering has since licensed QwikBoost to a company called IDQ Inc. that incorporates the technology into a successful line of products to recharge automotive air conditioning (Spinoff 2010).\n                  Once again, Mainstream has built upon its work with NASA, developing two new products that are offering benefits here on Earth: PuraClean filter spray and QwikShot acid flush. PuraClean grew from work under a Small Business Innovation Research (SBIR) award with Johnson Space Center to research a nontoxic heat transport fluid for the thermal control systems inside a spacecraft. The second product, QwikShot, grew from SBIR work with Johnson to demonstrate high-performance, low-cost thermal control equipment.\n                  Benefits\n                  PuraClean is a liquid spray product that can be applied to any kind of disposable air filter for heating, ventilating, and air conditioning (HVAC) units. By insulating the fibers on the filter with a coating that extends the electrostatic properties of the filter, the spray increases its dirt-attracting and holding capabilities. It is designed to improve the performance of any type of filter, such as reusable metal filters, expensive electrostatic filters, or inexpensive spun glass or foam filters. “Any household, laboratory, hospital, automobile, school, and anywhere an air filter is used can reap the benefits of PuraClean,” says Brandon Scheckel, director of business development at Mainstream Engineering. “After the SBIR, Mainstream engineers worked on the formulation to make it fast evaporating, while still having lasting effects. Also, the goal was to make it allergy and asthma friendly.” \n                  “Mainstream Engineering is working hard \n  at making this NASA-developed technology available to every consumer.” \n                    —Brandon Scheckel, \n                    Mainstream Engineering Corporation \n                  According to results from independent laboratory testing, filters treated by PuraClean provided an improvement in filtration efficiency ranging from 200 percent when exposed to 3 micrometer particles, to more than 1,200 percent when exposed to 7 micrometer particles such as pollen, dust, and dirt. Test results also indicated that PuraClean caused no measurable difference in resistance to airflow. Mainstream says that, unlike other filter sprays, PuraClean can actually make filters more efficient because air conditioner evaporator coils stay cleaner and provide improved energy efficiency.\n                  \n                    \n                    \n                      \n                    \n                    \n                      PuraClean improves the performance of air filters while QwikShot vaporizes acid and moisture when it occurs in air conditioning and refrigeration systems.\n                    \n                  \n                  Available to service technicians from HVAC suppliers, Mainstream has sold between 7,000 and 8,000 bottles of the product since 2007, but expects those numbers to drastically grow in the near future. Currently, the product is being reviewed by the Asthma and \n                    Allergy Friendly Certification Program to become a certified residential allergy- and asthma-reducing HVAC product. “Mainstream Engineering is working hard at making this NASA-developed technology available to every consumer,” says Scheckel. \n                  Much like PuraClean, Scheckel says the development of the QwikShot acid flush product took place after research and development under a NASA SBIR. “We worked on exacting the formulation and wanted to make it as safe and easy to use as possible,” he says. “QwikShot improves the thermal stability of air conditioning and refrigeration systems and extends the life of the system by removing system-destroying acids from the thermal circuit.” \n                  Used for vaporizing acid and moisture when it occurs in air conditioning and refrigeration systems, QwikShot is injected into a system during operation. After it is introduced, the product vaporizes with refrigerant and travels throughout the system to chemically attach to acid and moisture molecules. It then flushes the molecules to the filter or drier. Unlike acid neutralizers that leave a salt-based residue from a chemical reaction, QwikShot leaves no residue in the system.\n                   “Traditional techniques require the technician to open the system and neutralize compressor oil by opening up the compressor, or a line set near the compressor, and add the neutralizing product, says Scheckel. QwikShot is simply introduced into the compressor oil. \n                  According to Mainstream, over 75,000 applications of QwikShot have been sold. “HVAC and refrigeration service technicians who fix residential and commercial air conditioning systems use QwikShot to treat systems with signs of acid prior to system failure, and it improves the thermal stability,” Scheckel says. \n                  Due to the research and development opportunities provided through NASA’s SBIR program, Mainstream has significantly improved the normal operation of HVAC systems on Earth.\n                  PuraClean® and QwikShot® are registered trademarks of Mainstream Engineering Corporation.\n                  \n                \n              \n                  NASA Technology\n                  \n                    \n                    \n                      \n                    \n                    \n                      Thanks to the advanced control systems onboard the International Space Station, NASA astronauts Ron Garan (bottom) and Cady Coleman (right), European Space Agency astronaut Paolo Nespoli (left) and Russian cosmonaut Alexander Samokutyaev (top), enjoy a comfortable environment while in orbit.\n                    \n                  \n                  As the International Space Station (ISS) travels 17,500 miles per hour, normal is having a constant sensation of free-falling. Normal is no rain, but an extreme amount of shine—with temperatures reaching 250 ˚F when facing the Sun. Thanks to a number of advanced control systems onboard the ISS, however, the interior of the station remains a cool, comfortable, normal environment where astronauts can live and work for extended periods of time.\n                  There are two main control systems on the ISS that make it possible for humans to survive in space: the Thermal Control System (TCS) and the Environmental Control and Life Support system. These intricate assemblies work together to supply water and oxygen, regulate temperature and pressure, maintain air quality, and manage waste. Through artificial means, these \n                    systems create a habitable environment for the space station’s crew.\n                  The TCS constantly works to regulate the temperature not only for astronauts, but for the critical instruments and machines inside the spacecraft as well. To do its job, the TCS encompasses several components and systems both inside and outside of the ISS. Inside the spacecraft, a liquid heat-exchange process mechanically pumps fluids in closed-loop circuits to collect, transport, and reject heat. Outside the ISS, an external system circulates anhydrous ammonia to transport heat and cool equipment, and radiators release the heat into space.\n                   Over the years, NASA has worked with a variety of partners—public and private, national and international—to develop and refine the most complex thermal control systems ever built for spacecraft, including the one on the ISS. \n                  Partnership\n                  To ensure a normal environment for astronauts and instruments, a Rockledge, Florida-based company, Mainstream Engineering Corporation, has steadily worked with NASA field centers since the 1980s to develop advanced thermal control technology for spacecraft. First featured in Spinoff 1999 for the development of a commercial product called QwikBoost, based on work with NASA on a liquid formulation for a chemical/mechanical heat pump, Mainstream Engineering has since licensed QwikBoost to a company called IDQ Inc. that incorporates the technology into a successful line of products to recharge automotive air conditioning (Spinoff 2010).\n                  Once again, Mainstream has built upon its work with NASA, developing two new products that are offering benefits here on Earth: PuraClean filter spray and QwikShot acid flush. PuraClean grew from work under a Small Business Innovation Research (SBIR) award with Johnson Space Center to research a nontoxic heat transport fluid for the thermal control systems inside a spacecraft. The second product, QwikShot, grew from SBIR work with Johnson to demonstrate high-performance, low-cost thermal control equipment.\n                  Benefits\n                  PuraClean is a liquid spray product that can be applied to any kind of disposable air filter for heating, ventilating, and air conditioning (HVAC) units. By insulating the fibers on the filter with a coating that extends the electrostatic properties of the filter, the spray increases its dirt-attracting and holding capabilities. It is designed to improve the performance of any type of filter, such as reusable metal filters, expensive electrostatic filters, or inexpensive spun glass or foam filters. “Any household, laboratory, hospital, automobile, school, and anywhere an air filter is used can reap the benefits of PuraClean,” says Brandon Scheckel, director of business development at Mainstream Engineering. “After the SBIR, Mainstream engineers worked on the formulation to make it fast evaporating, while still having lasting effects. Also, the goal was to make it allergy and asthma friendly.” \n                  “Mainstream Engineering is working hard \n  at making this NASA-developed technology available to every consumer.” \n                    —Brandon Scheckel, \n                    Mainstream Engineering Corporation \n                  According to results from independent laboratory testing, filters treated by PuraClean provided an improvement in filtration efficiency ranging from 200 percent when exposed to 3 micrometer particles, to more than 1,200 percent when exposed to 7 micrometer particles such as pollen, dust, and dirt. Test results also indicated that PuraClean caused no measurable difference in resistance to airflow. Mainstream says that, unlike other filter sprays, PuraClean can actually make filters more efficient because air conditioner evaporator coils stay cleaner and provide improved energy efficiency.\n                  \n                    \n                    \n                      \n                    \n                    \n                      PuraClean improves the performance of air filters while QwikShot vaporizes acid and moisture when it occurs in air conditioning and refrigeration systems.\n                    \n                  \n                  Available to service technicians from HVAC suppliers, Mainstream has sold between 7,000 and 8,000 bottles of the product since 2007, but expects those numbers to drastically grow in the near future. Currently, the product is being reviewed by the Asthma and \n                    Allergy Friendly Certification Program to become a certified residential allergy- and asthma-reducing HVAC product. “Mainstream Engineering is working hard at making this NASA-developed technology available to every consumer,” says Scheckel. \n                  Much like PuraClean, Scheckel says the development of the QwikShot acid flush product took place after research and development under a NASA SBIR. “We worked on exacting the formulation and wanted to make it as safe and easy to use as possible,” he says. “QwikShot improves the thermal stability of air conditioning and refrigeration systems and extends the life of the system by removing system-destroying acids from the thermal circuit.” \n                  Used for vaporizing acid and moisture when it occurs in air conditioning and refrigeration systems, QwikShot is injected into a system during operation. After it is introduced, the product vaporizes with refrigerant and travels throughout the system to chemically attach to acid and moisture molecules. It then flushes the molecules to the filter or drier. Unlike acid neutralizers that leave a salt-based residue from a chemical reaction, QwikShot leaves no residue in the system.\n                   “Traditional techniques require the technician to open the system and neutralize compressor oil by opening up the compressor, or a line set near the compressor, and add the neutralizing product, says Scheckel. QwikShot is simply introduced into the compressor oil. \n                  According to Mainstream, over 75,000 applications of QwikShot have been sold. “HVAC and refrigeration service technicians who fix residential and commercial air conditioning systems use QwikShot to treat systems with signs of acid prior to system failure, and it improves the thermal stability,” Scheckel says. \n                  Due to the research and development opportunities provided through NASA’s SBIR program, Mainstream has significantly improved the normal operation of HVAC systems on Earth.\n                  PuraClean® and QwikShot® are registered trademarks of Mainstream Engineering Corporation.\n                  "},{"href":"http://spinoff.nasa.gov/Spinoff2011/er_1.html","text":"World Wind Tools Reveal Environmental  Change","image":"http://spinoff.nasa.gov/Spinoff2011/Images/er_1_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    NASA Technology\n                    “Who has more satellite data than NASA?” asks Patrick Hogan.\n                    \n                      \n                      \n                        \n                      \n                      \n                        NASA’s World Wind geospatial visualization technology allows users to zoom from satellite altitude to any place on Earth. World Wind includes the cloud-free, true-color images of Earth called “Blue Marble: Next Generation,” one of which is pictured here.\n                      \n                    \n                    The question is a rhetorical one. After dozens of Earth-observing satellite launches and missions to other planets, NASA has accumulated an unmatched amount of planetary science information, including satellite imagery, terrain information, and climate data. To visualize this data and make it accessible, in 2002 Hogan and his colleagues at Ames Research Center started building a software program called World Wind. \n                    Originally developed under NASA’s Learning Technologies program as a tool to engage and inspire students, World Wind aspired to help NASA move 3D visualization of NASA data into the classroom, using videogame-like virtual globes of Earth, Moon, Venus, Mars, and Jupiter.\n                    In 2005, shortly after the release of World Wind, the U.S. Department of Energy (DOE) was impressed by the technology at a geographic information systems (GIS) conference. “At the time, World Wind was an Internet application, specific to the Windows platform. DOE wanted something cross-platform,” says Hogan, World Wind project manager at Ames. \n                    With support from DOE, Hogan and his team designed World Wind to be a technology that others could simply plug into their application, rather than an application that required others to plug into it. This redesign is the World Wind Java Software Development Kit (SDK) and the Web Mapping Services (WMS) Server. Currently, there are over a million requests for World Wind data each day.\n                    Partnership\n                    Released under the NASA Open Source Agreement (NOSA) license, anyone is permitted to use World Wind for their purposes, with one caveat: According to the license, if a user changes the SDK or WMS Server, the code changes fall under the NOSA and need to be made open and available. \n                    Hogan describes World Wind as enabling government, commercial enterprise, and individual developers to focus on their needs, without having to “recreate the wheel” for 3D visualization. “We’re providing the essential infrastructure for spatial data so others can make their data come alive in a virtual world. This allows those people to concentrate on information intelligence and data analysis. We make it possible to see the information in its native concept of the real world.” As a testament to the software’s success, World Wind was awarded the prestigious NASA “Software of the Year” for 2009.\n                    By not having to develop a \n                      technology like NASA’s World Wind, \n                      Intelesense has saved approximately \n                      $1 million in costs. \n                    One of the companies currently making use of the NASA technology is Honolulu, Hawaii-based Intelesense Technologies (Spinoff 2007). Started by Stanford University and former NASA engineers to provide global monitoring services, today the company uses the technology for environmental, public health, and other monitoring applications for nonprofit organizations and government agencies. \n                    Benefits\n                    \n                      \n                      \n                        \n                      \n                      \n                        Intelesense Technologies is working with The Nature Conservancy to develop and deploy a remote monitoring system in Hawaii’s Wainiha preserve and Alakai plateau to assist in conservation efforts. The monitoring system includes visualization technology that incorporates NASA’s World Wind software.\n                      \n                    \n                    Intelesense develops wireless sensor networks that support its three integrated global monitoring products and services: InteleCell, a dedicated data acquisition platform that communicates data from the sensors through the Internet; InteleNet, a real-time distributed mesh network that integrates data from different sources; and InteleView, a secure GIS-based 3D visualizer based on NASA’s World Wind. \n                    According to Kevin Montgomery, the chief executive officer of Intelesense, by not having to develop a technology like NASA’s World Wind, the company has saved approximately $1 million in costs. After adopting World Wind 4 years ago, the company significantly enhanced the technology. “We’ve added security features like authentication, advanced visualization features, and linked it to our server cluster that has hundreds of thousands of layers and other capabilities,” says Montgomery.\n                    Some of the applications for Intelesense’s system include monitoring climate change, air quality, security, and public health. \n                    In 2010, Intelesense started working with The Nature Conservancy to deploy a remote monitoring system on 6,500 acres of intact native-dominated lowland and wet forest in the Hawaiian island of Kauai. The project involves the trapping of feral pigs to assist in conservation efforts across the area. “Our sensor devices allow us to transmit the state of the traps, images from the traps, and even allow personnel to remotely arm or trigger the traps, despite the traps being located deep in the rainforest,” says Montgomery.\n                    In another environmental project, Intelesense is working with the Planetary Skin Institute to use information technology to help decision-makers manage scarce resources and risks. With 170 different layers, the visualization technology can show disturbances in land patterns; create views like global heat maps to identify hot spots; and zoom in to reveal roads, settlements, or other human factors.\n                    As part of the Center for Island, Maritime, and Extreme Environment Security (CIMES) project, supported by the Department of Homeland Security, Intelesense is developing advanced sensors and data fusion and visualization for maritime domain awareness. “We’re integrating live feeds of satellite data, ship transponders, and advanced sensors and other maritime data into a visualizer that Coast Guard or others could use,” says Montgomery. \n                    The company is also involved with the University of Hawaii and the University of Alaska Fairbanks to work on the Pacific Area Climate Modeling and Analysis Network (PACMAN) project. The goal of PACMAN is to help community groups work together and better understand the impacts of climate change locally, especially on the freshwater resources in Alaska and Hawaii. \n                    Lastly, under the President’s Emergency Program for AIDS Relief, Intelesense is using its NASA spinoff technology to monitor public health in Ethiopia. As part of a large antiretroviral (ARV) therapy study, which uses ARV drugs to suppress and stop the progression of HIV, the project aims to provide a wireless infrastructure for transmitting patient and drug information from 126 clinics to five main hospitals.\n                    By providing the infrastructure for spatial data, Hogan says World Wind exemplifies the NASA motto: For the benefit of all. “We’re providing the foundation for others to compete, innovate, and deliver solutions that result in higher quality and lower cost. World Wind provides a stimulus for companies like Intelesense to innovate.”\n                    Windows® is a registered trademark of Microsoft Corporation.\n                    InteleCell™, InteleNet™, and InteleView™ are trademarks of Intelesense Technologies. \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    NASA Technology\n                    “Who has more satellite data than NASA?” asks Patrick Hogan.\n                    \n                      \n                      \n                        \n                      \n                      \n                        NASA’s World Wind geospatial visualization technology allows users to zoom from satellite altitude to any place on Earth. World Wind includes the cloud-free, true-color images of Earth called “Blue Marble: Next Generation,” one of which is pictured here.\n                      \n                    \n                    The question is a rhetorical one. After dozens of Earth-observing satellite launches and missions to other planets, NASA has accumulated an unmatched amount of planetary science information, including satellite imagery, terrain information, and climate data. To visualize this data and make it accessible, in 2002 Hogan and his colleagues at Ames Research Center started building a software program called World Wind. \n                    Originally developed under NASA’s Learning Technologies program as a tool to engage and inspire students, World Wind aspired to help NASA move 3D visualization of NASA data into the classroom, using videogame-like virtual globes of Earth, Moon, Venus, Mars, and Jupiter.\n                    In 2005, shortly after the release of World Wind, the U.S. Department of Energy (DOE) was impressed by the technology at a geographic information systems (GIS) conference. “At the time, World Wind was an Internet application, specific to the Windows platform. DOE wanted something cross-platform,” says Hogan, World Wind project manager at Ames. \n                    With support from DOE, Hogan and his team designed World Wind to be a technology that others could simply plug into their application, rather than an application that required others to plug into it. This redesign is the World Wind Java Software Development Kit (SDK) and the Web Mapping Services (WMS) Server. Currently, there are over a million requests for World Wind data each day.\n                    Partnership\n                    Released under the NASA Open Source Agreement (NOSA) license, anyone is permitted to use World Wind for their purposes, with one caveat: According to the license, if a user changes the SDK or WMS Server, the code changes fall under the NOSA and need to be made open and available. \n                    Hogan describes World Wind as enabling government, commercial enterprise, and individual developers to focus on their needs, without having to “recreate the wheel” for 3D visualization. “We’re providing the essential infrastructure for spatial data so others can make their data come alive in a virtual world. This allows those people to concentrate on information intelligence and data analysis. We make it possible to see the information in its native concept of the real world.” As a testament to the software’s success, World Wind was awarded the prestigious NASA “Software of the Year” for 2009.\n                    By not having to develop a \n                      technology like NASA’s World Wind, \n                      Intelesense has saved approximately \n                      $1 million in costs. \n                    One of the companies currently making use of the NASA technology is Honolulu, Hawaii-based Intelesense Technologies (Spinoff 2007). Started by Stanford University and former NASA engineers to provide global monitoring services, today the company uses the technology for environmental, public health, and other monitoring applications for nonprofit organizations and government agencies. \n                    Benefits\n                    \n                      \n                      \n                        \n                      \n                      \n                        Intelesense Technologies is working with The Nature Conservancy to develop and deploy a remote monitoring system in Hawaii’s Wainiha preserve and Alakai plateau to assist in conservation efforts. The monitoring system includes visualization technology that incorporates NASA’s World Wind software.\n                      \n                    \n                    Intelesense develops wireless sensor networks that support its three integrated global monitoring products and services: InteleCell, a dedicated data acquisition platform that communicates data from the sensors through the Internet; InteleNet, a real-time distributed mesh network that integrates data from different sources; and InteleView, a secure GIS-based 3D visualizer based on NASA’s World Wind. \n                    According to Kevin Montgomery, the chief executive officer of Intelesense, by not having to develop a technology like NASA’s World Wind, the company has saved approximately $1 million in costs. After adopting World Wind 4 years ago, the company significantly enhanced the technology. “We’ve added security features like authentication, advanced visualization features, and linked it to our server cluster that has hundreds of thousands of layers and other capabilities,” says Montgomery.\n                    Some of the applications for Intelesense’s system include monitoring climate change, air quality, security, and public health. \n                    In 2010, Intelesense started working with The Nature Conservancy to deploy a remote monitoring system on 6,500 acres of intact native-dominated lowland and wet forest in the Hawaiian island of Kauai. The project involves the trapping of feral pigs to assist in conservation efforts across the area. “Our sensor devices allow us to transmit the state of the traps, images from the traps, and even allow personnel to remotely arm or trigger the traps, despite the traps being located deep in the rainforest,” says Montgomery.\n                    In another environmental project, Intelesense is working with the Planetary Skin Institute to use information technology to help decision-makers manage scarce resources and risks. With 170 different layers, the visualization technology can show disturbances in land patterns; create views like global heat maps to identify hot spots; and zoom in to reveal roads, settlements, or other human factors.\n                    As part of the Center for Island, Maritime, and Extreme Environment Security (CIMES) project, supported by the Department of Homeland Security, Intelesense is developing advanced sensors and data fusion and visualization for maritime domain awareness. “We’re integrating live feeds of satellite data, ship transponders, and advanced sensors and other maritime data into a visualizer that Coast Guard or others could use,” says Montgomery. \n                    The company is also involved with the University of Hawaii and the University of Alaska Fairbanks to work on the Pacific Area Climate Modeling and Analysis Network (PACMAN) project. The goal of PACMAN is to help community groups work together and better understand the impacts of climate change locally, especially on the freshwater resources in Alaska and Hawaii. \n                    Lastly, under the President’s Emergency Program for AIDS Relief, Intelesense is using its NASA spinoff technology to monitor public health in Ethiopia. As part of a large antiretroviral (ARV) therapy study, which uses ARV drugs to suppress and stop the progression of HIV, the project aims to provide a wireless infrastructure for transmitting patient and drug information from 126 clinics to five main hospitals.\n                    By providing the infrastructure for spatial data, Hogan says World Wind exemplifies the NASA motto: For the benefit of all. “We’re providing the foundation for others to compete, innovate, and deliver solutions that result in higher quality and lower cost. World Wind provides a stimulus for companies like Intelesense to innovate.”\n                    Windows® is a registered trademark of Microsoft Corporation.\n                    InteleCell™, InteleNet™, and InteleView™ are trademarks of Intelesense Technologies. \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  \n                    NASA Technology\n                    “Who has more satellite data than NASA?” asks Patrick Hogan.\n                    \n                      \n                      \n                        \n                      \n                      \n                        NASA’s World Wind geospatial visualization technology allows users to zoom from satellite altitude to any place on Earth. World Wind includes the cloud-free, true-color images of Earth called “Blue Marble: Next Generation,” one of which is pictured here.\n                      \n                    \n                    The question is a rhetorical one. After dozens of Earth-observing satellite launches and missions to other planets, NASA has accumulated an unmatched amount of planetary science information, including satellite imagery, terrain information, and climate data. To visualize this data and make it accessible, in 2002 Hogan and his colleagues at Ames Research Center started building a software program called World Wind. \n                    Originally developed under NASA’s Learning Technologies program as a tool to engage and inspire students, World Wind aspired to help NASA move 3D visualization of NASA data into the classroom, using videogame-like virtual globes of Earth, Moon, Venus, Mars, and Jupiter.\n                    In 2005, shortly after the release of World Wind, the U.S. Department of Energy (DOE) was impressed by the technology at a geographic information systems (GIS) conference. “At the time, World Wind was an Internet application, specific to the Windows platform. DOE wanted something cross-platform,” says Hogan, World Wind project manager at Ames. \n                    With support from DOE, Hogan and his team designed World Wind to be a technology that others could simply plug into their application, rather than an application that required others to plug into it. This redesign is the World Wind Java Software Development Kit (SDK) and the Web Mapping Services (WMS) Server. Currently, there are over a million requests for World Wind data each day.\n                    Partnership\n                    Released under the NASA Open Source Agreement (NOSA) license, anyone is permitted to use World Wind for their purposes, with one caveat: According to the license, if a user changes the SDK or WMS Server, the code changes fall under the NOSA and need to be made open and available. \n                    Hogan describes World Wind as enabling government, commercial enterprise, and individual developers to focus on their needs, without having to “recreate the wheel” for 3D visualization. “We’re providing the essential infrastructure for spatial data so others can make their data come alive in a virtual world. This allows those people to concentrate on information intelligence and data analysis. We make it possible to see the information in its native concept of the real world.” As a testament to the software’s success, World Wind was awarded the prestigious NASA “Software of the Year” for 2009.\n                    By not having to develop a \n                      technology like NASA’s World Wind, \n                      Intelesense has saved approximately \n                      $1 million in costs. \n                    One of the companies currently making use of the NASA technology is Honolulu, Hawaii-based Intelesense Technologies (Spinoff 2007). Started by Stanford University and former NASA engineers to provide global monitoring services, today the company uses the technology for environmental, public health, and other monitoring applications for nonprofit organizations and government agencies. \n                    Benefits\n                    \n                      \n                      \n                        \n                      \n                      \n                        Intelesense Technologies is working with The Nature Conservancy to develop and deploy a remote monitoring system in Hawaii’s Wainiha preserve and Alakai plateau to assist in conservation efforts. The monitoring system includes visualization technology that incorporates NASA’s World Wind software.\n                      \n                    \n                    Intelesense develops wireless sensor networks that support its three integrated global monitoring products and services: InteleCell, a dedicated data acquisition platform that communicates data from the sensors through the Internet; InteleNet, a real-time distributed mesh network that integrates data from different sources; and InteleView, a secure GIS-based 3D visualizer based on NASA’s World Wind. \n                    According to Kevin Montgomery, the chief executive officer of Intelesense, by not having to develop a technology like NASA’s World Wind, the company has saved approximately $1 million in costs. After adopting World Wind 4 years ago, the company significantly enhanced the technology. “We’ve added security features like authentication, advanced visualization features, and linked it to our server cluster that has hundreds of thousands of layers and other capabilities,” says Montgomery.\n                    Some of the applications for Intelesense’s system include monitoring climate change, air quality, security, and public health. \n                    In 2010, Intelesense started working with The Nature Conservancy to deploy a remote monitoring system on 6,500 acres of intact native-dominated lowland and wet forest in the Hawaiian island of Kauai. The project involves the trapping of feral pigs to assist in conservation efforts across the area. “Our sensor devices allow us to transmit the state of the traps, images from the traps, and even allow personnel to remotely arm or trigger the traps, despite the traps being located deep in the rainforest,” says Montgomery.\n                    In another environmental project, Intelesense is working with the Planetary Skin Institute to use information technology to help decision-makers manage scarce resources and risks. With 170 different layers, the visualization technology can show disturbances in land patterns; create views like global heat maps to identify hot spots; and zoom in to reveal roads, settlements, or other human factors.\n                    As part of the Center for Island, Maritime, and Extreme Environment Security (CIMES) project, supported by the Department of Homeland Security, Intelesense is developing advanced sensors and data fusion and visualization for maritime domain awareness. “We’re integrating live feeds of satellite data, ship transponders, and advanced sensors and other maritime data into a visualizer that Coast Guard or others could use,” says Montgomery. \n                    The company is also involved with the University of Hawaii and the University of Alaska Fairbanks to work on the Pacific Area Climate Modeling and Analysis Network (PACMAN) project. The goal of PACMAN is to help community groups work together and better understand the impacts of climate change locally, especially on the freshwater resources in Alaska and Hawaii. \n                    Lastly, under the President’s Emergency Program for AIDS Relief, Intelesense is using its NASA spinoff technology to monitor public health in Ethiopia. As part of a large antiretroviral (ARV) therapy study, which uses ARV drugs to suppress and stop the progression of HIV, the project aims to provide a wireless infrastructure for transmitting patient and drug information from 126 clinics to five main hospitals.\n                    By providing the infrastructure for spatial data, Hogan says World Wind exemplifies the NASA motto: For the benefit of all. “We’re providing the foundation for others to compete, innovate, and deliver solutions that result in higher quality and lower cost. World Wind provides a stimulus for companies like Intelesense to innovate.”\n                    Windows® is a registered trademark of Microsoft Corporation.\n                    InteleCell™, InteleNet™, and InteleView™ are trademarks of Intelesense Technologies. \n                    \n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  \n                    NASA Technology\n                    “Who has more satellite data than NASA?” asks Patrick Hogan.\n                    \n                      \n                      \n                        \n                      \n                      \n                        NASA’s World Wind geospatial visualization technology allows users to zoom from satellite altitude to any place on Earth. World Wind includes the cloud-free, true-color images of Earth called “Blue Marble: Next Generation,” one of which is pictured here.\n                      \n                    \n                    The question is a rhetorical one. After dozens of Earth-observing satellite launches and missions to other planets, NASA has accumulated an unmatched amount of planetary science information, including satellite imagery, terrain information, and climate data. To visualize this data and make it accessible, in 2002 Hogan and his colleagues at Ames Research Center started building a software program called World Wind. \n                    Originally developed under NASA’s Learning Technologies program as a tool to engage and inspire students, World Wind aspired to help NASA move 3D visualization of NASA data into the classroom, using videogame-like virtual globes of Earth, Moon, Venus, Mars, and Jupiter.\n                    In 2005, shortly after the release of World Wind, the U.S. Department of Energy (DOE) was impressed by the technology at a geographic information systems (GIS) conference. “At the time, World Wind was an Internet application, specific to the Windows platform. DOE wanted something cross-platform,” says Hogan, World Wind project manager at Ames. \n                    With support from DOE, Hogan and his team designed World Wind to be a technology that others could simply plug into their application, rather than an application that required others to plug into it. This redesign is the World Wind Java Software Development Kit (SDK) and the Web Mapping Services (WMS) Server. Currently, there are over a million requests for World Wind data each day.\n                    Partnership\n                    Released under the NASA Open Source Agreement (NOSA) license, anyone is permitted to use World Wind for their purposes, with one caveat: According to the license, if a user changes the SDK or WMS Server, the code changes fall under the NOSA and need to be made open and available. \n                    Hogan describes World Wind as enabling government, commercial enterprise, and individual developers to focus on their needs, without having to “recreate the wheel” for 3D visualization. “We’re providing the essential infrastructure for spatial data so others can make their data come alive in a virtual world. This allows those people to concentrate on information intelligence and data analysis. We make it possible to see the information in its native concept of the real world.” As a testament to the software’s success, World Wind was awarded the prestigious NASA “Software of the Year” for 2009.\n                    By not having to develop a \n                      technology like NASA’s World Wind, \n                      Intelesense has saved approximately \n                      $1 million in costs. \n                    One of the companies currently making use of the NASA technology is Honolulu, Hawaii-based Intelesense Technologies (Spinoff 2007). Started by Stanford University and former NASA engineers to provide global monitoring services, today the company uses the technology for environmental, public health, and other monitoring applications for nonprofit organizations and government agencies. \n                    Benefits\n                    \n                      \n                      \n                        \n                      \n                      \n                        Intelesense Technologies is working with The Nature Conservancy to develop and deploy a remote monitoring system in Hawaii’s Wainiha preserve and Alakai plateau to assist in conservation efforts. The monitoring system includes visualization technology that incorporates NASA’s World Wind software.\n                      \n                    \n                    Intelesense develops wireless sensor networks that support its three integrated global monitoring products and services: InteleCell, a dedicated data acquisition platform that communicates data from the sensors through the Internet; InteleNet, a real-time distributed mesh network that integrates data from different sources; and InteleView, a secure GIS-based 3D visualizer based on NASA’s World Wind. \n                    According to Kevin Montgomery, the chief executive officer of Intelesense, by not having to develop a technology like NASA’s World Wind, the company has saved approximately $1 million in costs. After adopting World Wind 4 years ago, the company significantly enhanced the technology. “We’ve added security features like authentication, advanced visualization features, and linked it to our server cluster that has hundreds of thousands of layers and other capabilities,” says Montgomery.\n                    Some of the applications for Intelesense’s system include monitoring climate change, air quality, security, and public health. \n                    In 2010, Intelesense started working with The Nature Conservancy to deploy a remote monitoring system on 6,500 acres of intact native-dominated lowland and wet forest in the Hawaiian island of Kauai. The project involves the trapping of feral pigs to assist in conservation efforts across the area. “Our sensor devices allow us to transmit the state of the traps, images from the traps, and even allow personnel to remotely arm or trigger the traps, despite the traps being located deep in the rainforest,” says Montgomery.\n                    In another environmental project, Intelesense is working with the Planetary Skin Institute to use information technology to help decision-makers manage scarce resources and risks. With 170 different layers, the visualization technology can show disturbances in land patterns; create views like global heat maps to identify hot spots; and zoom in to reveal roads, settlements, or other human factors.\n                    As part of the Center for Island, Maritime, and Extreme Environment Security (CIMES) project, supported by the Department of Homeland Security, Intelesense is developing advanced sensors and data fusion and visualization for maritime domain awareness. “We’re integrating live feeds of satellite data, ship transponders, and advanced sensors and other maritime data into a visualizer that Coast Guard or others could use,” says Montgomery. \n                    The company is also involved with the University of Hawaii and the University of Alaska Fairbanks to work on the Pacific Area Climate Modeling and Analysis Network (PACMAN) project. The goal of PACMAN is to help community groups work together and better understand the impacts of climate change locally, especially on the freshwater resources in Alaska and Hawaii. \n                    Lastly, under the President’s Emergency Program for AIDS Relief, Intelesense is using its NASA spinoff technology to monitor public health in Ethiopia. As part of a large antiretroviral (ARV) therapy study, which uses ARV drugs to suppress and stop the progression of HIV, the project aims to provide a wireless infrastructure for transmitting patient and drug information from 126 clinics to five main hospitals.\n                    By providing the infrastructure for spatial data, Hogan says World Wind exemplifies the NASA motto: For the benefit of all. “We’re providing the foundation for others to compete, innovate, and deliver solutions that result in higher quality and lower cost. World Wind provides a stimulus for companies like Intelesense to innovate.”\n                    Windows® is a registered trademark of Microsoft Corporation.\n                    InteleCell™, InteleNet™, and InteleView™ are trademarks of Intelesense Technologies. \n                    \n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  \n                    NASA Technology\n                    “Who has more satellite data than NASA?” asks Patrick Hogan.\n                    \n                      \n                      \n                        \n                      \n                      \n                        NASA’s World Wind geospatial visualization technology allows users to zoom from satellite altitude to any place on Earth. World Wind includes the cloud-free, true-color images of Earth called “Blue Marble: Next Generation,” one of which is pictured here.\n                      \n                    \n                    The question is a rhetorical one. After dozens of Earth-observing satellite launches and missions to other planets, NASA has accumulated an unmatched amount of planetary science information, including satellite imagery, terrain information, and climate data. To visualize this data and make it accessible, in 2002 Hogan and his colleagues at Ames Research Center started building a software program called World Wind. \n                    Originally developed under NASA’s Learning Technologies program as a tool to engage and inspire students, World Wind aspired to help NASA move 3D visualization of NASA data into the classroom, using videogame-like virtual globes of Earth, Moon, Venus, Mars, and Jupiter.\n                    In 2005, shortly after the release of World Wind, the U.S. Department of Energy (DOE) was impressed by the technology at a geographic information systems (GIS) conference. “At the time, World Wind was an Internet application, specific to the Windows platform. DOE wanted something cross-platform,” says Hogan, World Wind project manager at Ames. \n                    With support from DOE, Hogan and his team designed World Wind to be a technology that others could simply plug into their application, rather than an application that required others to plug into it. This redesign is the World Wind Java Software Development Kit (SDK) and the Web Mapping Services (WMS) Server. Currently, there are over a million requests for World Wind data each day.\n                    Partnership\n                    Released under the NASA Open Source Agreement (NOSA) license, anyone is permitted to use World Wind for their purposes, with one caveat: According to the license, if a user changes the SDK or WMS Server, the code changes fall under the NOSA and need to be made open and available. \n                    Hogan describes World Wind as enabling government, commercial enterprise, and individual developers to focus on their needs, without having to “recreate the wheel” for 3D visualization. “We’re providing the essential infrastructure for spatial data so others can make their data come alive in a virtual world. This allows those people to concentrate on information intelligence and data analysis. We make it possible to see the information in its native concept of the real world.” As a testament to the software’s success, World Wind was awarded the prestigious NASA “Software of the Year” for 2009.\n                    By not having to develop a \n                      technology like NASA’s World Wind, \n                      Intelesense has saved approximately \n                      $1 million in costs. \n                    One of the companies currently making use of the NASA technology is Honolulu, Hawaii-based Intelesense Technologies (Spinoff 2007). Started by Stanford University and former NASA engineers to provide global monitoring services, today the company uses the technology for environmental, public health, and other monitoring applications for nonprofit organizations and government agencies. \n                    Benefits\n                    \n                      \n                      \n                        \n                      \n                      \n                        Intelesense Technologies is working with The Nature Conservancy to develop and deploy a remote monitoring system in Hawaii’s Wainiha preserve and Alakai plateau to assist in conservation efforts. The monitoring system includes visualization technology that incorporates NASA’s World Wind software.\n                      \n                    \n                    Intelesense develops wireless sensor networks that support its three integrated global monitoring products and services: InteleCell, a dedicated data acquisition platform that communicates data from the sensors through the Internet; InteleNet, a real-time distributed mesh network that integrates data from different sources; and InteleView, a secure GIS-based 3D visualizer based on NASA’s World Wind. \n                    According to Kevin Montgomery, the chief executive officer of Intelesense, by not having to develop a technology like NASA’s World Wind, the company has saved approximately $1 million in costs. After adopting World Wind 4 years ago, the company significantly enhanced the technology. “We’ve added security features like authentication, advanced visualization features, and linked it to our server cluster that has hundreds of thousands of layers and other capabilities,” says Montgomery.\n                    Some of the applications for Intelesense’s system include monitoring climate change, air quality, security, and public health. \n                    In 2010, Intelesense started working with The Nature Conservancy to deploy a remote monitoring system on 6,500 acres of intact native-dominated lowland and wet forest in the Hawaiian island of Kauai. The project involves the trapping of feral pigs to assist in conservation efforts across the area. “Our sensor devices allow us to transmit the state of the traps, images from the traps, and even allow personnel to remotely arm or trigger the traps, despite the traps being located deep in the rainforest,” says Montgomery.\n                    In another environmental project, Intelesense is working with the Planetary Skin Institute to use information technology to help decision-makers manage scarce resources and risks. With 170 different layers, the visualization technology can show disturbances in land patterns; create views like global heat maps to identify hot spots; and zoom in to reveal roads, settlements, or other human factors.\n                    As part of the Center for Island, Maritime, and Extreme Environment Security (CIMES) project, supported by the Department of Homeland Security, Intelesense is developing advanced sensors and data fusion and visualization for maritime domain awareness. “We’re integrating live feeds of satellite data, ship transponders, and advanced sensors and other maritime data into a visualizer that Coast Guard or others could use,” says Montgomery. \n                    The company is also involved with the University of Hawaii and the University of Alaska Fairbanks to work on the Pacific Area Climate Modeling and Analysis Network (PACMAN) project. The goal of PACMAN is to help community groups work together and better understand the impacts of climate change locally, especially on the freshwater resources in Alaska and Hawaii. \n                    Lastly, under the President’s Emergency Program for AIDS Relief, Intelesense is using its NASA spinoff technology to monitor public health in Ethiopia. As part of a large antiretroviral (ARV) therapy study, which uses ARV drugs to suppress and stop the progression of HIV, the project aims to provide a wireless infrastructure for transmitting patient and drug information from 126 clinics to five main hospitals.\n                    By providing the infrastructure for spatial data, Hogan says World Wind exemplifies the NASA motto: For the benefit of all. “We’re providing the foundation for others to compete, innovate, and deliver solutions that result in higher quality and lower cost. World Wind provides a stimulus for companies like Intelesense to innovate.”\n                    Windows® is a registered trademark of Microsoft Corporation.\n                    InteleCell™, InteleNet™, and InteleView™ are trademarks of Intelesense Technologies. \n                    \n                  \n                \n              \n            \n            \n              \n                \n                  \n                    NASA Technology\n                    “Who has more satellite data than NASA?” asks Patrick Hogan.\n                    \n                      \n                      \n                        \n                      \n                      \n                        NASA’s World Wind geospatial visualization technology allows users to zoom from satellite altitude to any place on Earth. World Wind includes the cloud-free, true-color images of Earth called “Blue Marble: Next Generation,” one of which is pictured here.\n                      \n                    \n                    The question is a rhetorical one. After dozens of Earth-observing satellite launches and missions to other planets, NASA has accumulated an unmatched amount of planetary science information, including satellite imagery, terrain information, and climate data. To visualize this data and make it accessible, in 2002 Hogan and his colleagues at Ames Research Center started building a software program called World Wind. \n                    Originally developed under NASA’s Learning Technologies program as a tool to engage and inspire students, World Wind aspired to help NASA move 3D visualization of NASA data into the classroom, using videogame-like virtual globes of Earth, Moon, Venus, Mars, and Jupiter.\n                    In 2005, shortly after the release of World Wind, the U.S. Department of Energy (DOE) was impressed by the technology at a geographic information systems (GIS) conference. “At the time, World Wind was an Internet application, specific to the Windows platform. DOE wanted something cross-platform,” says Hogan, World Wind project manager at Ames. \n                    With support from DOE, Hogan and his team designed World Wind to be a technology that others could simply plug into their application, rather than an application that required others to plug into it. This redesign is the World Wind Java Software Development Kit (SDK) and the Web Mapping Services (WMS) Server. Currently, there are over a million requests for World Wind data each day.\n                    Partnership\n                    Released under the NASA Open Source Agreement (NOSA) license, anyone is permitted to use World Wind for their purposes, with one caveat: According to the license, if a user changes the SDK or WMS Server, the code changes fall under the NOSA and need to be made open and available. \n                    Hogan describes World Wind as enabling government, commercial enterprise, and individual developers to focus on their needs, without having to “recreate the wheel” for 3D visualization. “We’re providing the essential infrastructure for spatial data so others can make their data come alive in a virtual world. This allows those people to concentrate on information intelligence and data analysis. We make it possible to see the information in its native concept of the real world.” As a testament to the software’s success, World Wind was awarded the prestigious NASA “Software of the Year” for 2009.\n                    By not having to develop a \n                      technology like NASA’s World Wind, \n                      Intelesense has saved approximately \n                      $1 million in costs. \n                    One of the companies currently making use of the NASA technology is Honolulu, Hawaii-based Intelesense Technologies (Spinoff 2007). Started by Stanford University and former NASA engineers to provide global monitoring services, today the company uses the technology for environmental, public health, and other monitoring applications for nonprofit organizations and government agencies. \n                    Benefits\n                    \n                      \n                      \n                        \n                      \n                      \n                        Intelesense Technologies is working with The Nature Conservancy to develop and deploy a remote monitoring system in Hawaii’s Wainiha preserve and Alakai plateau to assist in conservation efforts. The monitoring system includes visualization technology that incorporates NASA’s World Wind software.\n                      \n                    \n                    Intelesense develops wireless sensor networks that support its three integrated global monitoring products and services: InteleCell, a dedicated data acquisition platform that communicates data from the sensors through the Internet; InteleNet, a real-time distributed mesh network that integrates data from different sources; and InteleView, a secure GIS-based 3D visualizer based on NASA’s World Wind. \n                    According to Kevin Montgomery, the chief executive officer of Intelesense, by not having to develop a technology like NASA’s World Wind, the company has saved approximately $1 million in costs. After adopting World Wind 4 years ago, the company significantly enhanced the technology. “We’ve added security features like authentication, advanced visualization features, and linked it to our server cluster that has hundreds of thousands of layers and other capabilities,” says Montgomery.\n                    Some of the applications for Intelesense’s system include monitoring climate change, air quality, security, and public health. \n                    In 2010, Intelesense started working with The Nature Conservancy to deploy a remote monitoring system on 6,500 acres of intact native-dominated lowland and wet forest in the Hawaiian island of Kauai. The project involves the trapping of feral pigs to assist in conservation efforts across the area. “Our sensor devices allow us to transmit the state of the traps, images from the traps, and even allow personnel to remotely arm or trigger the traps, despite the traps being located deep in the rainforest,” says Montgomery.\n                    In another environmental project, Intelesense is working with the Planetary Skin Institute to use information technology to help decision-makers manage scarce resources and risks. With 170 different layers, the visualization technology can show disturbances in land patterns; create views like global heat maps to identify hot spots; and zoom in to reveal roads, settlements, or other human factors.\n                    As part of the Center for Island, Maritime, and Extreme Environment Security (CIMES) project, supported by the Department of Homeland Security, Intelesense is developing advanced sensors and data fusion and visualization for maritime domain awareness. “We’re integrating live feeds of satellite data, ship transponders, and advanced sensors and other maritime data into a visualizer that Coast Guard or others could use,” says Montgomery. \n                    The company is also involved with the University of Hawaii and the University of Alaska Fairbanks to work on the Pacific Area Climate Modeling and Analysis Network (PACMAN) project. The goal of PACMAN is to help community groups work together and better understand the impacts of climate change locally, especially on the freshwater resources in Alaska and Hawaii. \n                    Lastly, under the President’s Emergency Program for AIDS Relief, Intelesense is using its NASA spinoff technology to monitor public health in Ethiopia. As part of a large antiretroviral (ARV) therapy study, which uses ARV drugs to suppress and stop the progression of HIV, the project aims to provide a wireless infrastructure for transmitting patient and drug information from 126 clinics to five main hospitals.\n                    By providing the infrastructure for spatial data, Hogan says World Wind exemplifies the NASA motto: For the benefit of all. “We’re providing the foundation for others to compete, innovate, and deliver solutions that result in higher quality and lower cost. World Wind provides a stimulus for companies like Intelesense to innovate.”\n                    Windows® is a registered trademark of Microsoft Corporation.\n                    InteleCell™, InteleNet™, and InteleView™ are trademarks of Intelesense Technologies. \n                    \n                  \n                \n              \n                  \n                    NASA Technology\n                    “Who has more satellite data than NASA?” asks Patrick Hogan.\n                    \n                      \n                      \n                        \n                      \n                      \n                        NASA’s World Wind geospatial visualization technology allows users to zoom from satellite altitude to any place on Earth. World Wind includes the cloud-free, true-color images of Earth called “Blue Marble: Next Generation,” one of which is pictured here.\n                      \n                    \n                    The question is a rhetorical one. After dozens of Earth-observing satellite launches and missions to other planets, NASA has accumulated an unmatched amount of planetary science information, including satellite imagery, terrain information, and climate data. To visualize this data and make it accessible, in 2002 Hogan and his colleagues at Ames Research Center started building a software program called World Wind. \n                    Originally developed under NASA’s Learning Technologies program as a tool to engage and inspire students, World Wind aspired to help NASA move 3D visualization of NASA data into the classroom, using videogame-like virtual globes of Earth, Moon, Venus, Mars, and Jupiter.\n                    In 2005, shortly after the release of World Wind, the U.S. Department of Energy (DOE) was impressed by the technology at a geographic information systems (GIS) conference. “At the time, World Wind was an Internet application, specific to the Windows platform. DOE wanted something cross-platform,” says Hogan, World Wind project manager at Ames. \n                    With support from DOE, Hogan and his team designed World Wind to be a technology that others could simply plug into their application, rather than an application that required others to plug into it. This redesign is the World Wind Java Software Development Kit (SDK) and the Web Mapping Services (WMS) Server. Currently, there are over a million requests for World Wind data each day.\n                    Partnership\n                    Released under the NASA Open Source Agreement (NOSA) license, anyone is permitted to use World Wind for their purposes, with one caveat: According to the license, if a user changes the SDK or WMS Server, the code changes fall under the NOSA and need to be made open and available. \n                    Hogan describes World Wind as enabling government, commercial enterprise, and individual developers to focus on their needs, without having to “recreate the wheel” for 3D visualization. “We’re providing the essential infrastructure for spatial data so others can make their data come alive in a virtual world. This allows those people to concentrate on information intelligence and data analysis. We make it possible to see the information in its native concept of the real world.” As a testament to the software’s success, World Wind was awarded the prestigious NASA “Software of the Year” for 2009.\n                    By not having to develop a \n                      technology like NASA’s World Wind, \n                      Intelesense has saved approximately \n                      $1 million in costs. \n                    One of the companies currently making use of the NASA technology is Honolulu, Hawaii-based Intelesense Technologies (Spinoff 2007). Started by Stanford University and former NASA engineers to provide global monitoring services, today the company uses the technology for environmental, public health, and other monitoring applications for nonprofit organizations and government agencies. \n                    Benefits\n                    \n                      \n                      \n                        \n                      \n                      \n                        Intelesense Technologies is working with The Nature Conservancy to develop and deploy a remote monitoring system in Hawaii’s Wainiha preserve and Alakai plateau to assist in conservation efforts. The monitoring system includes visualization technology that incorporates NASA’s World Wind software.\n                      \n                    \n                    Intelesense develops wireless sensor networks that support its three integrated global monitoring products and services: InteleCell, a dedicated data acquisition platform that communicates data from the sensors through the Internet; InteleNet, a real-time distributed mesh network that integrates data from different sources; and InteleView, a secure GIS-based 3D visualizer based on NASA’s World Wind. \n                    According to Kevin Montgomery, the chief executive officer of Intelesense, by not having to develop a technology like NASA’s World Wind, the company has saved approximately $1 million in costs. After adopting World Wind 4 years ago, the company significantly enhanced the technology. “We’ve added security features like authentication, advanced visualization features, and linked it to our server cluster that has hundreds of thousands of layers and other capabilities,” says Montgomery.\n                    Some of the applications for Intelesense’s system include monitoring climate change, air quality, security, and public health. \n                    In 2010, Intelesense started working with The Nature Conservancy to deploy a remote monitoring system on 6,500 acres of intact native-dominated lowland and wet forest in the Hawaiian island of Kauai. The project involves the trapping of feral pigs to assist in conservation efforts across the area. “Our sensor devices allow us to transmit the state of the traps, images from the traps, and even allow personnel to remotely arm or trigger the traps, despite the traps being located deep in the rainforest,” says Montgomery.\n                    In another environmental project, Intelesense is working with the Planetary Skin Institute to use information technology to help decision-makers manage scarce resources and risks. With 170 different layers, the visualization technology can show disturbances in land patterns; create views like global heat maps to identify hot spots; and zoom in to reveal roads, settlements, or other human factors.\n                    As part of the Center for Island, Maritime, and Extreme Environment Security (CIMES) project, supported by the Department of Homeland Security, Intelesense is developing advanced sensors and data fusion and visualization for maritime domain awareness. “We’re integrating live feeds of satellite data, ship transponders, and advanced sensors and other maritime data into a visualizer that Coast Guard or others could use,” says Montgomery. \n                    The company is also involved with the University of Hawaii and the University of Alaska Fairbanks to work on the Pacific Area Climate Modeling and Analysis Network (PACMAN) project. The goal of PACMAN is to help community groups work together and better understand the impacts of climate change locally, especially on the freshwater resources in Alaska and Hawaii. \n                    Lastly, under the President’s Emergency Program for AIDS Relief, Intelesense is using its NASA spinoff technology to monitor public health in Ethiopia. As part of a large antiretroviral (ARV) therapy study, which uses ARV drugs to suppress and stop the progression of HIV, the project aims to provide a wireless infrastructure for transmitting patient and drug information from 126 clinics to five main hospitals.\n                    By providing the infrastructure for spatial data, Hogan says World Wind exemplifies the NASA motto: For the benefit of all. “We’re providing the foundation for others to compete, innovate, and deliver solutions that result in higher quality and lower cost. World Wind provides a stimulus for companies like Intelesense to innovate.”\n                    Windows® is a registered trademark of Microsoft Corporation.\n                    InteleCell™, InteleNet™, and InteleView™ are trademarks of Intelesense Technologies. \n                    \n                  \n                    NASA Technology\n                    “Who has more satellite data than NASA?” asks Patrick Hogan.\n                    \n                      \n                      \n                        \n                      \n                      \n                        NASA’s World Wind geospatial visualization technology allows users to zoom from satellite altitude to any place on Earth. World Wind includes the cloud-free, true-color images of Earth called “Blue Marble: Next Generation,” one of which is pictured here.\n                      \n                    \n                    The question is a rhetorical one. After dozens of Earth-observing satellite launches and missions to other planets, NASA has accumulated an unmatched amount of planetary science information, including satellite imagery, terrain information, and climate data. To visualize this data and make it accessible, in 2002 Hogan and his colleagues at Ames Research Center started building a software program called World Wind. \n                    Originally developed under NASA’s Learning Technologies program as a tool to engage and inspire students, World Wind aspired to help NASA move 3D visualization of NASA data into the classroom, using videogame-like virtual globes of Earth, Moon, Venus, Mars, and Jupiter.\n                    In 2005, shortly after the release of World Wind, the U.S. Department of Energy (DOE) was impressed by the technology at a geographic information systems (GIS) conference. “At the time, World Wind was an Internet application, specific to the Windows platform. DOE wanted something cross-platform,” says Hogan, World Wind project manager at Ames. \n                    With support from DOE, Hogan and his team designed World Wind to be a technology that others could simply plug into their application, rather than an application that required others to plug into it. This redesign is the World Wind Java Software Development Kit (SDK) and the Web Mapping Services (WMS) Server. Currently, there are over a million requests for World Wind data each day.\n                    Partnership\n                    Released under the NASA Open Source Agreement (NOSA) license, anyone is permitted to use World Wind for their purposes, with one caveat: According to the license, if a user changes the SDK or WMS Server, the code changes fall under the NOSA and need to be made open and available. \n                    Hogan describes World Wind as enabling government, commercial enterprise, and individual developers to focus on their needs, without having to “recreate the wheel” for 3D visualization. “We’re providing the essential infrastructure for spatial data so others can make their data come alive in a virtual world. This allows those people to concentrate on information intelligence and data analysis. We make it possible to see the information in its native concept of the real world.” As a testament to the software’s success, World Wind was awarded the prestigious NASA “Software of the Year” for 2009.\n                    By not having to develop a \n                      technology like NASA’s World Wind, \n                      Intelesense has saved approximately \n                      $1 million in costs. \n                    One of the companies currently making use of the NASA technology is Honolulu, Hawaii-based Intelesense Technologies (Spinoff 2007). Started by Stanford University and former NASA engineers to provide global monitoring services, today the company uses the technology for environmental, public health, and other monitoring applications for nonprofit organizations and government agencies. \n                    Benefits\n                    \n                      \n                      \n                        \n                      \n                      \n                        Intelesense Technologies is working with The Nature Conservancy to develop and deploy a remote monitoring system in Hawaii’s Wainiha preserve and Alakai plateau to assist in conservation efforts. The monitoring system includes visualization technology that incorporates NASA’s World Wind software.\n                      \n                    \n                    Intelesense develops wireless sensor networks that support its three integrated global monitoring products and services: InteleCell, a dedicated data acquisition platform that communicates data from the sensors through the Internet; InteleNet, a real-time distributed mesh network that integrates data from different sources; and InteleView, a secure GIS-based 3D visualizer based on NASA’s World Wind. \n                    According to Kevin Montgomery, the chief executive officer of Intelesense, by not having to develop a technology like NASA’s World Wind, the company has saved approximately $1 million in costs. After adopting World Wind 4 years ago, the company significantly enhanced the technology. “We’ve added security features like authentication, advanced visualization features, and linked it to our server cluster that has hundreds of thousands of layers and other capabilities,” says Montgomery.\n                    Some of the applications for Intelesense’s system include monitoring climate change, air quality, security, and public health. \n                    In 2010, Intelesense started working with The Nature Conservancy to deploy a remote monitoring system on 6,500 acres of intact native-dominated lowland and wet forest in the Hawaiian island of Kauai. The project involves the trapping of feral pigs to assist in conservation efforts across the area. “Our sensor devices allow us to transmit the state of the traps, images from the traps, and even allow personnel to remotely arm or trigger the traps, despite the traps being located deep in the rainforest,” says Montgomery.\n                    In another environmental project, Intelesense is working with the Planetary Skin Institute to use information technology to help decision-makers manage scarce resources and risks. With 170 different layers, the visualization technology can show disturbances in land patterns; create views like global heat maps to identify hot spots; and zoom in to reveal roads, settlements, or other human factors.\n                    As part of the Center for Island, Maritime, and Extreme Environment Security (CIMES) project, supported by the Department of Homeland Security, Intelesense is developing advanced sensors and data fusion and visualization for maritime domain awareness. “We’re integrating live feeds of satellite data, ship transponders, and advanced sensors and other maritime data into a visualizer that Coast Guard or others could use,” says Montgomery. \n                    The company is also involved with the University of Hawaii and the University of Alaska Fairbanks to work on the Pacific Area Climate Modeling and Analysis Network (PACMAN) project. The goal of PACMAN is to help community groups work together and better understand the impacts of climate change locally, especially on the freshwater resources in Alaska and Hawaii. \n                    Lastly, under the President’s Emergency Program for AIDS Relief, Intelesense is using its NASA spinoff technology to monitor public health in Ethiopia. As part of a large antiretroviral (ARV) therapy study, which uses ARV drugs to suppress and stop the progression of HIV, the project aims to provide a wireless infrastructure for transmitting patient and drug information from 126 clinics to five main hospitals.\n                    By providing the infrastructure for spatial data, Hogan says World Wind exemplifies the NASA motto: For the benefit of all. “We’re providing the foundation for others to compete, innovate, and deliver solutions that result in higher quality and lower cost. World Wind provides a stimulus for companies like Intelesense to innovate.”\n                    Windows® is a registered trademark of Microsoft Corporation.\n                    InteleCell™, InteleNet™, and InteleView™ are trademarks of Intelesense Technologies. \n                    "},{"href":"http://spinoff.nasa.gov/Spinoff2011/er_2.html","text":"Analyzers Measure Greenhouse Gasses, Airborne Pollutants","image":"http://spinoff.nasa.gov/Spinoff2011/Images/er_3a_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      In complete darkness, a NASA observatory waits. When an eruption of boiling water billows from a nearby crack in the ground, the observatory’s sensors seek particles in the fluid, measure shifts in carbon isotopes, and analyze samples for biological signatures. NASA has landed the observatory in this remote location, far removed from air and sunlight, to find life unlike any that scientists have ever seen. \n                      It might sound like a scene from a distant planet, but this NASA mission is actually exploring an ocean floor right here on Earth. \n                      NASA established a formal exobiology program in 1960, which expanded into the present-day Astrobiology Program. The program, which celebrated its 50th anniversary in 2010, not only explores the possibility of life elsewhere in the universe, but also examines how life begins and evolves, and what the future may hold for life on Earth and other planets.\n                      \n                        \n                        \n                          \n                        \n                        \n                          NASA’s Astrobiology Program looks for life in places beyond Earth, such as Europa, one of Jupiter’s moons.\n                        \n                      \n                      Answers to these questions may be found not only by launching rockets skyward, but by sending probes in the opposite direction. Research here on Earth can revise prevailing concepts of life and biochemistry and point to the possibilities for life on other planets, as was demonstrated in December 2010, when NASA researchers discovered microbes in Mono Lake in California that subsist and reproduce using arsenic, a toxic chemical. \n                      The Mono Lake discovery may be the first of many that could reveal possible models for extraterrestrial life. One primary area of interest for NASA astrobiologists lies with the hydrothermal vents on the ocean floor. These vents expel jets of water heated and enriched with chemicals from off-gassing magma below the Earth’s crust. Also potentially within the vents: microbes that, like the Mono Lake microorganisms, defy the common characteristics of life on Earth. \n                      Basically all organisms on our planet generate energy through the Krebs Cycle, explains Mike Flynn, research scientist at NASA’s Ames Research Center. This metabolic process breaks down sugars for energy to fuel cellular functions. “We think this chemical process did not exist when life first formed on Earth,” he says, “because it is based on oxygen being available, and there was little oxygen available on the early Earth.” It is possible that there are anaerobic regions beneath the sea floor in which life forms like those early non-Krebs Cycle microbes may yet exist. \n                      To detect and potentially collect samples of life emerging from hydrothermal vents, Flynn and his colleagues created Medusa, a multi-sensor instrument designed for long-term observation of diked vents on the ocean floor. When the vents erupt, Medusa assesses indicators of life within the expelled water. If the results are positive, the observatory collects samples and detaches from the ocean floor, making the long journey to the surface for retrieval by scientists. \n                      One of the indicators Medusa measures is the ratio of carbon isotopes in the water, namely carbon-12 and carbon-13. Living organisms preferentially take up carbon-12, Flynn says, so examining the ratio of these isotopes can help to determine the source of carbon in an environment as either biological or non-biological. \n                      “On Mars, there is evidence of localized methane in the atmosphere, and that methane could come from biological sources or from geochemical ones,” Flynn says. “Determining the background planetary carbon isotope ratios and then evaluating the specific carbon ratios in this methane would help to determine how it was formed.” A long-duration observatory similar to Medusa could one day provide essential evidence for or against the presence of life on the Red Planet or beneath the ice-crusted oceans of Europa.\n                      Partnership\n                      To develop instrumentation capable of precisely measuring carbon isotopes in deep sea and deep space environments, Ames partnered with Los Gatos Research (LGR) Inc., of Mountain View, California, through the Small Business Innovation Research (SBIR) program. The company had already pioneered cavity-enhanced absorption techniques for spectroscopy and, with the help of the NASA funding, developed the latest generation of this cavity ringdown technology, called Off-Axis Integrated Cavity Output Spectroscopy (ICOS). \n                      LGR’s Off-Axis ICOS technology uses an optical cavity—a tube bound on both ends by two high-reflectivity mirrors—as an absorption cell, explains company president Doug Baer. A laser beam is directed through the first mirror and then trapped inside the cell containing the sample of air. The beam reflects between the mirrors, propagating thousands of meters and interacting extensively with the molecules in the cell, revealing their makeup and concentration. \n                      “The longer path length means that we don’t need to have as many molecules in the cell to detect, so the instrument’s sensitivity is greatly enhanced,” Baer says. \n                      This innovation enabled a deep-sea carbon isotope analyzer for NASA’s Medusa project and currently forms the basis of all of the company’s commercial products—including devices that are providing significant information for environmental researchers around the globe. \n                      “The SBIR program has been critical to the creation of these technologies, which would otherwise have taken a much longer time to develop,” says Baer.\n                       Benefits\n                      LGR’s SBIR-derived technology has been incorporated into a variety of analyzer devices deployed for use on all seven continents for the measurement of a range of greenhouse gasses, pollutants, and isotopes. Employing lasers ranging in wavelength from visible light to mid-infrared, these Off-Axis ICOS-based instruments can measure precise amounts of practically any molecule with an absorption spectrum. And because the system is easy to build, Baer says, it can be made rugged at a low cost.\n                      “This allows us to streamline our manufacturing and create products at inexpensive cost to government agencies and researchers around the globe,” he says. \n                      LGR analyzers are designed for the measurement of target molecules such as carbon dioxide, methane, nitrous oxide, water, water vapor, liquid water, and isotopes of all of those molecules down to parts-per-billion sensitivity. This allows researchers to gather detailed information about the sources and sinks of greenhouse gasses that are affecting the planet’s climate. (Sinks absorb and store particular molecules; a forest, for example, can act as a carbon sink, absorbing carbon dioxide from the air until burning or decomposition releases the stored carbon back into the environment.) \n                      \n                        \n                        \n                          \n                        \n                        \n                          Los Gatos Research Inc.’s analyzers measure a range of target molecules, providing researchers with a cost-effective means of attaining valuable environmental data.\n                        \n                      \n                      NASA has flown LGR analyzers on the Agency’s DC-8 research aircraft for studies of greenhouse gasses and pollutants in the atmosphere, and other scientists have employed the company’s devices to study Earth’s hydrological cycle. LGR also recently collaborated with Texas A&M University to deploy a methane analyzer to the Gulf of Mexico to record the distribution of methane and methane isotopes resulting from the Deepwater Horizon oil spill, helping scientists understand the environmental impact of the disaster. \n                      In part due to the support of NASA’s SBIR program, LGR has experienced significant growth since first commercializing its products in 2005. Baer expects the company’s workforce to grow from 30 to nearly 50 full-time employees by the end of 2011, and the company employs a large number of contractors as well. \n                      Even as LGR’s SBIR-derived technology helps NASA search for unusual life on the ocean floor, Flynn notes a fiberoptic spectrometer the company also developed through NASA SBIR funding. Small and inexpensive to fabricate, “you can put it on any mission going to Mars and build up a global understanding of the planet’s carbon distributions,” an understanding that may lead to the first discovery of life beyond Earth. \n                      “That’s the ultimate objective,” Flynn say\n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      In complete darkness, a NASA observatory waits. When an eruption of boiling water billows from a nearby crack in the ground, the observatory’s sensors seek particles in the fluid, measure shifts in carbon isotopes, and analyze samples for biological signatures. NASA has landed the observatory in this remote location, far removed from air and sunlight, to find life unlike any that scientists have ever seen. \n                      It might sound like a scene from a distant planet, but this NASA mission is actually exploring an ocean floor right here on Earth. \n                      NASA established a formal exobiology program in 1960, which expanded into the present-day Astrobiology Program. The program, which celebrated its 50th anniversary in 2010, not only explores the possibility of life elsewhere in the universe, but also examines how life begins and evolves, and what the future may hold for life on Earth and other planets.\n                      \n                        \n                        \n                          \n                        \n                        \n                          NASA’s Astrobiology Program looks for life in places beyond Earth, such as Europa, one of Jupiter’s moons.\n                        \n                      \n                      Answers to these questions may be found not only by launching rockets skyward, but by sending probes in the opposite direction. Research here on Earth can revise prevailing concepts of life and biochemistry and point to the possibilities for life on other planets, as was demonstrated in December 2010, when NASA researchers discovered microbes in Mono Lake in California that subsist and reproduce using arsenic, a toxic chemical. \n                      The Mono Lake discovery may be the first of many that could reveal possible models for extraterrestrial life. One primary area of interest for NASA astrobiologists lies with the hydrothermal vents on the ocean floor. These vents expel jets of water heated and enriched with chemicals from off-gassing magma below the Earth’s crust. Also potentially within the vents: microbes that, like the Mono Lake microorganisms, defy the common characteristics of life on Earth. \n                      Basically all organisms on our planet generate energy through the Krebs Cycle, explains Mike Flynn, research scientist at NASA’s Ames Research Center. This metabolic process breaks down sugars for energy to fuel cellular functions. “We think this chemical process did not exist when life first formed on Earth,” he says, “because it is based on oxygen being available, and there was little oxygen available on the early Earth.” It is possible that there are anaerobic regions beneath the sea floor in which life forms like those early non-Krebs Cycle microbes may yet exist. \n                      To detect and potentially collect samples of life emerging from hydrothermal vents, Flynn and his colleagues created Medusa, a multi-sensor instrument designed for long-term observation of diked vents on the ocean floor. When the vents erupt, Medusa assesses indicators of life within the expelled water. If the results are positive, the observatory collects samples and detaches from the ocean floor, making the long journey to the surface for retrieval by scientists. \n                      One of the indicators Medusa measures is the ratio of carbon isotopes in the water, namely carbon-12 and carbon-13. Living organisms preferentially take up carbon-12, Flynn says, so examining the ratio of these isotopes can help to determine the source of carbon in an environment as either biological or non-biological. \n                      “On Mars, there is evidence of localized methane in the atmosphere, and that methane could come from biological sources or from geochemical ones,” Flynn says. “Determining the background planetary carbon isotope ratios and then evaluating the specific carbon ratios in this methane would help to determine how it was formed.” A long-duration observatory similar to Medusa could one day provide essential evidence for or against the presence of life on the Red Planet or beneath the ice-crusted oceans of Europa.\n                      Partnership\n                      To develop instrumentation capable of precisely measuring carbon isotopes in deep sea and deep space environments, Ames partnered with Los Gatos Research (LGR) Inc., of Mountain View, California, through the Small Business Innovation Research (SBIR) program. The company had already pioneered cavity-enhanced absorption techniques for spectroscopy and, with the help of the NASA funding, developed the latest generation of this cavity ringdown technology, called Off-Axis Integrated Cavity Output Spectroscopy (ICOS). \n                      LGR’s Off-Axis ICOS technology uses an optical cavity—a tube bound on both ends by two high-reflectivity mirrors—as an absorption cell, explains company president Doug Baer. A laser beam is directed through the first mirror and then trapped inside the cell containing the sample of air. The beam reflects between the mirrors, propagating thousands of meters and interacting extensively with the molecules in the cell, revealing their makeup and concentration. \n                      “The longer path length means that we don’t need to have as many molecules in the cell to detect, so the instrument’s sensitivity is greatly enhanced,” Baer says. \n                      This innovation enabled a deep-sea carbon isotope analyzer for NASA’s Medusa project and currently forms the basis of all of the company’s commercial products—including devices that are providing significant information for environmental researchers around the globe. \n                      “The SBIR program has been critical to the creation of these technologies, which would otherwise have taken a much longer time to develop,” says Baer.\n                       Benefits\n                      LGR’s SBIR-derived technology has been incorporated into a variety of analyzer devices deployed for use on all seven continents for the measurement of a range of greenhouse gasses, pollutants, and isotopes. Employing lasers ranging in wavelength from visible light to mid-infrared, these Off-Axis ICOS-based instruments can measure precise amounts of practically any molecule with an absorption spectrum. And because the system is easy to build, Baer says, it can be made rugged at a low cost.\n                      “This allows us to streamline our manufacturing and create products at inexpensive cost to government agencies and researchers around the globe,” he says. \n                      LGR analyzers are designed for the measurement of target molecules such as carbon dioxide, methane, nitrous oxide, water, water vapor, liquid water, and isotopes of all of those molecules down to parts-per-billion sensitivity. This allows researchers to gather detailed information about the sources and sinks of greenhouse gasses that are affecting the planet’s climate. (Sinks absorb and store particular molecules; a forest, for example, can act as a carbon sink, absorbing carbon dioxide from the air until burning or decomposition releases the stored carbon back into the environment.) \n                      \n                        \n                        \n                          \n                        \n                        \n                          Los Gatos Research Inc.’s analyzers measure a range of target molecules, providing researchers with a cost-effective means of attaining valuable environmental data.\n                        \n                      \n                      NASA has flown LGR analyzers on the Agency’s DC-8 research aircraft for studies of greenhouse gasses and pollutants in the atmosphere, and other scientists have employed the company’s devices to study Earth’s hydrological cycle. LGR also recently collaborated with Texas A&M University to deploy a methane analyzer to the Gulf of Mexico to record the distribution of methane and methane isotopes resulting from the Deepwater Horizon oil spill, helping scientists understand the environmental impact of the disaster. \n                      In part due to the support of NASA’s SBIR program, LGR has experienced significant growth since first commercializing its products in 2005. Baer expects the company’s workforce to grow from 30 to nearly 50 full-time employees by the end of 2011, and the company employs a large number of contractors as well. \n                      Even as LGR’s SBIR-derived technology helps NASA search for unusual life on the ocean floor, Flynn notes a fiberoptic spectrometer the company also developed through NASA SBIR funding. Small and inexpensive to fabricate, “you can put it on any mission going to Mars and build up a global understanding of the planet’s carbon distributions,” an understanding that may lead to the first discovery of life beyond Earth. \n                      “That’s the ultimate objective,” Flynn say\n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      In complete darkness, a NASA observatory waits. When an eruption of boiling water billows from a nearby crack in the ground, the observatory’s sensors seek particles in the fluid, measure shifts in carbon isotopes, and analyze samples for biological signatures. NASA has landed the observatory in this remote location, far removed from air and sunlight, to find life unlike any that scientists have ever seen. \n                      It might sound like a scene from a distant planet, but this NASA mission is actually exploring an ocean floor right here on Earth. \n                      NASA established a formal exobiology program in 1960, which expanded into the present-day Astrobiology Program. The program, which celebrated its 50th anniversary in 2010, not only explores the possibility of life elsewhere in the universe, but also examines how life begins and evolves, and what the future may hold for life on Earth and other planets.\n                      \n                        \n                        \n                          \n                        \n                        \n                          NASA’s Astrobiology Program looks for life in places beyond Earth, such as Europa, one of Jupiter’s moons.\n                        \n                      \n                      Answers to these questions may be found not only by launching rockets skyward, but by sending probes in the opposite direction. Research here on Earth can revise prevailing concepts of life and biochemistry and point to the possibilities for life on other planets, as was demonstrated in December 2010, when NASA researchers discovered microbes in Mono Lake in California that subsist and reproduce using arsenic, a toxic chemical. \n                      The Mono Lake discovery may be the first of many that could reveal possible models for extraterrestrial life. One primary area of interest for NASA astrobiologists lies with the hydrothermal vents on the ocean floor. These vents expel jets of water heated and enriched with chemicals from off-gassing magma below the Earth’s crust. Also potentially within the vents: microbes that, like the Mono Lake microorganisms, defy the common characteristics of life on Earth. \n                      Basically all organisms on our planet generate energy through the Krebs Cycle, explains Mike Flynn, research scientist at NASA’s Ames Research Center. This metabolic process breaks down sugars for energy to fuel cellular functions. “We think this chemical process did not exist when life first formed on Earth,” he says, “because it is based on oxygen being available, and there was little oxygen available on the early Earth.” It is possible that there are anaerobic regions beneath the sea floor in which life forms like those early non-Krebs Cycle microbes may yet exist. \n                      To detect and potentially collect samples of life emerging from hydrothermal vents, Flynn and his colleagues created Medusa, a multi-sensor instrument designed for long-term observation of diked vents on the ocean floor. When the vents erupt, Medusa assesses indicators of life within the expelled water. If the results are positive, the observatory collects samples and detaches from the ocean floor, making the long journey to the surface for retrieval by scientists. \n                      One of the indicators Medusa measures is the ratio of carbon isotopes in the water, namely carbon-12 and carbon-13. Living organisms preferentially take up carbon-12, Flynn says, so examining the ratio of these isotopes can help to determine the source of carbon in an environment as either biological or non-biological. \n                      “On Mars, there is evidence of localized methane in the atmosphere, and that methane could come from biological sources or from geochemical ones,” Flynn says. “Determining the background planetary carbon isotope ratios and then evaluating the specific carbon ratios in this methane would help to determine how it was formed.” A long-duration observatory similar to Medusa could one day provide essential evidence for or against the presence of life on the Red Planet or beneath the ice-crusted oceans of Europa.\n                      Partnership\n                      To develop instrumentation capable of precisely measuring carbon isotopes in deep sea and deep space environments, Ames partnered with Los Gatos Research (LGR) Inc., of Mountain View, California, through the Small Business Innovation Research (SBIR) program. The company had already pioneered cavity-enhanced absorption techniques for spectroscopy and, with the help of the NASA funding, developed the latest generation of this cavity ringdown technology, called Off-Axis Integrated Cavity Output Spectroscopy (ICOS). \n                      LGR’s Off-Axis ICOS technology uses an optical cavity—a tube bound on both ends by two high-reflectivity mirrors—as an absorption cell, explains company president Doug Baer. A laser beam is directed through the first mirror and then trapped inside the cell containing the sample of air. The beam reflects between the mirrors, propagating thousands of meters and interacting extensively with the molecules in the cell, revealing their makeup and concentration. \n                      “The longer path length means that we don’t need to have as many molecules in the cell to detect, so the instrument’s sensitivity is greatly enhanced,” Baer says. \n                      This innovation enabled a deep-sea carbon isotope analyzer for NASA’s Medusa project and currently forms the basis of all of the company’s commercial products—including devices that are providing significant information for environmental researchers around the globe. \n                      “The SBIR program has been critical to the creation of these technologies, which would otherwise have taken a much longer time to develop,” says Baer.\n                       Benefits\n                      LGR’s SBIR-derived technology has been incorporated into a variety of analyzer devices deployed for use on all seven continents for the measurement of a range of greenhouse gasses, pollutants, and isotopes. Employing lasers ranging in wavelength from visible light to mid-infrared, these Off-Axis ICOS-based instruments can measure precise amounts of practically any molecule with an absorption spectrum. And because the system is easy to build, Baer says, it can be made rugged at a low cost.\n                      “This allows us to streamline our manufacturing and create products at inexpensive cost to government agencies and researchers around the globe,” he says. \n                      LGR analyzers are designed for the measurement of target molecules such as carbon dioxide, methane, nitrous oxide, water, water vapor, liquid water, and isotopes of all of those molecules down to parts-per-billion sensitivity. This allows researchers to gather detailed information about the sources and sinks of greenhouse gasses that are affecting the planet’s climate. (Sinks absorb and store particular molecules; a forest, for example, can act as a carbon sink, absorbing carbon dioxide from the air until burning or decomposition releases the stored carbon back into the environment.) \n                      \n                        \n                        \n                          \n                        \n                        \n                          Los Gatos Research Inc.’s analyzers measure a range of target molecules, providing researchers with a cost-effective means of attaining valuable environmental data.\n                        \n                      \n                      NASA has flown LGR analyzers on the Agency’s DC-8 research aircraft for studies of greenhouse gasses and pollutants in the atmosphere, and other scientists have employed the company’s devices to study Earth’s hydrological cycle. LGR also recently collaborated with Texas A&M University to deploy a methane analyzer to the Gulf of Mexico to record the distribution of methane and methane isotopes resulting from the Deepwater Horizon oil spill, helping scientists understand the environmental impact of the disaster. \n                      In part due to the support of NASA’s SBIR program, LGR has experienced significant growth since first commercializing its products in 2005. Baer expects the company’s workforce to grow from 30 to nearly 50 full-time employees by the end of 2011, and the company employs a large number of contractors as well. \n                      Even as LGR’s SBIR-derived technology helps NASA search for unusual life on the ocean floor, Flynn notes a fiberoptic spectrometer the company also developed through NASA SBIR funding. Small and inexpensive to fabricate, “you can put it on any mission going to Mars and build up a global understanding of the planet’s carbon distributions,” an understanding that may lead to the first discovery of life beyond Earth. \n                      “That’s the ultimate objective,” Flynn say\n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      In complete darkness, a NASA observatory waits. When an eruption of boiling water billows from a nearby crack in the ground, the observatory’s sensors seek particles in the fluid, measure shifts in carbon isotopes, and analyze samples for biological signatures. NASA has landed the observatory in this remote location, far removed from air and sunlight, to find life unlike any that scientists have ever seen. \n                      It might sound like a scene from a distant planet, but this NASA mission is actually exploring an ocean floor right here on Earth. \n                      NASA established a formal exobiology program in 1960, which expanded into the present-day Astrobiology Program. The program, which celebrated its 50th anniversary in 2010, not only explores the possibility of life elsewhere in the universe, but also examines how life begins and evolves, and what the future may hold for life on Earth and other planets.\n                      \n                        \n                        \n                          \n                        \n                        \n                          NASA’s Astrobiology Program looks for life in places beyond Earth, such as Europa, one of Jupiter’s moons.\n                        \n                      \n                      Answers to these questions may be found not only by launching rockets skyward, but by sending probes in the opposite direction. Research here on Earth can revise prevailing concepts of life and biochemistry and point to the possibilities for life on other planets, as was demonstrated in December 2010, when NASA researchers discovered microbes in Mono Lake in California that subsist and reproduce using arsenic, a toxic chemical. \n                      The Mono Lake discovery may be the first of many that could reveal possible models for extraterrestrial life. One primary area of interest for NASA astrobiologists lies with the hydrothermal vents on the ocean floor. These vents expel jets of water heated and enriched with chemicals from off-gassing magma below the Earth’s crust. Also potentially within the vents: microbes that, like the Mono Lake microorganisms, defy the common characteristics of life on Earth. \n                      Basically all organisms on our planet generate energy through the Krebs Cycle, explains Mike Flynn, research scientist at NASA’s Ames Research Center. This metabolic process breaks down sugars for energy to fuel cellular functions. “We think this chemical process did not exist when life first formed on Earth,” he says, “because it is based on oxygen being available, and there was little oxygen available on the early Earth.” It is possible that there are anaerobic regions beneath the sea floor in which life forms like those early non-Krebs Cycle microbes may yet exist. \n                      To detect and potentially collect samples of life emerging from hydrothermal vents, Flynn and his colleagues created Medusa, a multi-sensor instrument designed for long-term observation of diked vents on the ocean floor. When the vents erupt, Medusa assesses indicators of life within the expelled water. If the results are positive, the observatory collects samples and detaches from the ocean floor, making the long journey to the surface for retrieval by scientists. \n                      One of the indicators Medusa measures is the ratio of carbon isotopes in the water, namely carbon-12 and carbon-13. Living organisms preferentially take up carbon-12, Flynn says, so examining the ratio of these isotopes can help to determine the source of carbon in an environment as either biological or non-biological. \n                      “On Mars, there is evidence of localized methane in the atmosphere, and that methane could come from biological sources or from geochemical ones,” Flynn says. “Determining the background planetary carbon isotope ratios and then evaluating the specific carbon ratios in this methane would help to determine how it was formed.” A long-duration observatory similar to Medusa could one day provide essential evidence for or against the presence of life on the Red Planet or beneath the ice-crusted oceans of Europa.\n                      Partnership\n                      To develop instrumentation capable of precisely measuring carbon isotopes in deep sea and deep space environments, Ames partnered with Los Gatos Research (LGR) Inc., of Mountain View, California, through the Small Business Innovation Research (SBIR) program. The company had already pioneered cavity-enhanced absorption techniques for spectroscopy and, with the help of the NASA funding, developed the latest generation of this cavity ringdown technology, called Off-Axis Integrated Cavity Output Spectroscopy (ICOS). \n                      LGR’s Off-Axis ICOS technology uses an optical cavity—a tube bound on both ends by two high-reflectivity mirrors—as an absorption cell, explains company president Doug Baer. A laser beam is directed through the first mirror and then trapped inside the cell containing the sample of air. The beam reflects between the mirrors, propagating thousands of meters and interacting extensively with the molecules in the cell, revealing their makeup and concentration. \n                      “The longer path length means that we don’t need to have as many molecules in the cell to detect, so the instrument’s sensitivity is greatly enhanced,” Baer says. \n                      This innovation enabled a deep-sea carbon isotope analyzer for NASA’s Medusa project and currently forms the basis of all of the company’s commercial products—including devices that are providing significant information for environmental researchers around the globe. \n                      “The SBIR program has been critical to the creation of these technologies, which would otherwise have taken a much longer time to develop,” says Baer.\n                       Benefits\n                      LGR’s SBIR-derived technology has been incorporated into a variety of analyzer devices deployed for use on all seven continents for the measurement of a range of greenhouse gasses, pollutants, and isotopes. Employing lasers ranging in wavelength from visible light to mid-infrared, these Off-Axis ICOS-based instruments can measure precise amounts of practically any molecule with an absorption spectrum. And because the system is easy to build, Baer says, it can be made rugged at a low cost.\n                      “This allows us to streamline our manufacturing and create products at inexpensive cost to government agencies and researchers around the globe,” he says. \n                      LGR analyzers are designed for the measurement of target molecules such as carbon dioxide, methane, nitrous oxide, water, water vapor, liquid water, and isotopes of all of those molecules down to parts-per-billion sensitivity. This allows researchers to gather detailed information about the sources and sinks of greenhouse gasses that are affecting the planet’s climate. (Sinks absorb and store particular molecules; a forest, for example, can act as a carbon sink, absorbing carbon dioxide from the air until burning or decomposition releases the stored carbon back into the environment.) \n                      \n                        \n                        \n                          \n                        \n                        \n                          Los Gatos Research Inc.’s analyzers measure a range of target molecules, providing researchers with a cost-effective means of attaining valuable environmental data.\n                        \n                      \n                      NASA has flown LGR analyzers on the Agency’s DC-8 research aircraft for studies of greenhouse gasses and pollutants in the atmosphere, and other scientists have employed the company’s devices to study Earth’s hydrological cycle. LGR also recently collaborated with Texas A&M University to deploy a methane analyzer to the Gulf of Mexico to record the distribution of methane and methane isotopes resulting from the Deepwater Horizon oil spill, helping scientists understand the environmental impact of the disaster. \n                      In part due to the support of NASA’s SBIR program, LGR has experienced significant growth since first commercializing its products in 2005. Baer expects the company’s workforce to grow from 30 to nearly 50 full-time employees by the end of 2011, and the company employs a large number of contractors as well. \n                      Even as LGR’s SBIR-derived technology helps NASA search for unusual life on the ocean floor, Flynn notes a fiberoptic spectrometer the company also developed through NASA SBIR funding. Small and inexpensive to fabricate, “you can put it on any mission going to Mars and build up a global understanding of the planet’s carbon distributions,” an understanding that may lead to the first discovery of life beyond Earth. \n                      “That’s the ultimate objective,” Flynn say\n                      \n                    \n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      In complete darkness, a NASA observatory waits. When an eruption of boiling water billows from a nearby crack in the ground, the observatory’s sensors seek particles in the fluid, measure shifts in carbon isotopes, and analyze samples for biological signatures. NASA has landed the observatory in this remote location, far removed from air and sunlight, to find life unlike any that scientists have ever seen. \n                      It might sound like a scene from a distant planet, but this NASA mission is actually exploring an ocean floor right here on Earth. \n                      NASA established a formal exobiology program in 1960, which expanded into the present-day Astrobiology Program. The program, which celebrated its 50th anniversary in 2010, not only explores the possibility of life elsewhere in the universe, but also examines how life begins and evolves, and what the future may hold for life on Earth and other planets.\n                      \n                        \n                        \n                          \n                        \n                        \n                          NASA’s Astrobiology Program looks for life in places beyond Earth, such as Europa, one of Jupiter’s moons.\n                        \n                      \n                      Answers to these questions may be found not only by launching rockets skyward, but by sending probes in the opposite direction. Research here on Earth can revise prevailing concepts of life and biochemistry and point to the possibilities for life on other planets, as was demonstrated in December 2010, when NASA researchers discovered microbes in Mono Lake in California that subsist and reproduce using arsenic, a toxic chemical. \n                      The Mono Lake discovery may be the first of many that could reveal possible models for extraterrestrial life. One primary area of interest for NASA astrobiologists lies with the hydrothermal vents on the ocean floor. These vents expel jets of water heated and enriched with chemicals from off-gassing magma below the Earth’s crust. Also potentially within the vents: microbes that, like the Mono Lake microorganisms, defy the common characteristics of life on Earth. \n                      Basically all organisms on our planet generate energy through the Krebs Cycle, explains Mike Flynn, research scientist at NASA’s Ames Research Center. This metabolic process breaks down sugars for energy to fuel cellular functions. “We think this chemical process did not exist when life first formed on Earth,” he says, “because it is based on oxygen being available, and there was little oxygen available on the early Earth.” It is possible that there are anaerobic regions beneath the sea floor in which life forms like those early non-Krebs Cycle microbes may yet exist. \n                      To detect and potentially collect samples of life emerging from hydrothermal vents, Flynn and his colleagues created Medusa, a multi-sensor instrument designed for long-term observation of diked vents on the ocean floor. When the vents erupt, Medusa assesses indicators of life within the expelled water. If the results are positive, the observatory collects samples and detaches from the ocean floor, making the long journey to the surface for retrieval by scientists. \n                      One of the indicators Medusa measures is the ratio of carbon isotopes in the water, namely carbon-12 and carbon-13. Living organisms preferentially take up carbon-12, Flynn says, so examining the ratio of these isotopes can help to determine the source of carbon in an environment as either biological or non-biological. \n                      “On Mars, there is evidence of localized methane in the atmosphere, and that methane could come from biological sources or from geochemical ones,” Flynn says. “Determining the background planetary carbon isotope ratios and then evaluating the specific carbon ratios in this methane would help to determine how it was formed.” A long-duration observatory similar to Medusa could one day provide essential evidence for or against the presence of life on the Red Planet or beneath the ice-crusted oceans of Europa.\n                      Partnership\n                      To develop instrumentation capable of precisely measuring carbon isotopes in deep sea and deep space environments, Ames partnered with Los Gatos Research (LGR) Inc., of Mountain View, California, through the Small Business Innovation Research (SBIR) program. The company had already pioneered cavity-enhanced absorption techniques for spectroscopy and, with the help of the NASA funding, developed the latest generation of this cavity ringdown technology, called Off-Axis Integrated Cavity Output Spectroscopy (ICOS). \n                      LGR’s Off-Axis ICOS technology uses an optical cavity—a tube bound on both ends by two high-reflectivity mirrors—as an absorption cell, explains company president Doug Baer. A laser beam is directed through the first mirror and then trapped inside the cell containing the sample of air. The beam reflects between the mirrors, propagating thousands of meters and interacting extensively with the molecules in the cell, revealing their makeup and concentration. \n                      “The longer path length means that we don’t need to have as many molecules in the cell to detect, so the instrument’s sensitivity is greatly enhanced,” Baer says. \n                      This innovation enabled a deep-sea carbon isotope analyzer for NASA’s Medusa project and currently forms the basis of all of the company’s commercial products—including devices that are providing significant information for environmental researchers around the globe. \n                      “The SBIR program has been critical to the creation of these technologies, which would otherwise have taken a much longer time to develop,” says Baer.\n                       Benefits\n                      LGR’s SBIR-derived technology has been incorporated into a variety of analyzer devices deployed for use on all seven continents for the measurement of a range of greenhouse gasses, pollutants, and isotopes. Employing lasers ranging in wavelength from visible light to mid-infrared, these Off-Axis ICOS-based instruments can measure precise amounts of practically any molecule with an absorption spectrum. And because the system is easy to build, Baer says, it can be made rugged at a low cost.\n                      “This allows us to streamline our manufacturing and create products at inexpensive cost to government agencies and researchers around the globe,” he says. \n                      LGR analyzers are designed for the measurement of target molecules such as carbon dioxide, methane, nitrous oxide, water, water vapor, liquid water, and isotopes of all of those molecules down to parts-per-billion sensitivity. This allows researchers to gather detailed information about the sources and sinks of greenhouse gasses that are affecting the planet’s climate. (Sinks absorb and store particular molecules; a forest, for example, can act as a carbon sink, absorbing carbon dioxide from the air until burning or decomposition releases the stored carbon back into the environment.) \n                      \n                        \n                        \n                          \n                        \n                        \n                          Los Gatos Research Inc.’s analyzers measure a range of target molecules, providing researchers with a cost-effective means of attaining valuable environmental data.\n                        \n                      \n                      NASA has flown LGR analyzers on the Agency’s DC-8 research aircraft for studies of greenhouse gasses and pollutants in the atmosphere, and other scientists have employed the company’s devices to study Earth’s hydrological cycle. LGR also recently collaborated with Texas A&M University to deploy a methane analyzer to the Gulf of Mexico to record the distribution of methane and methane isotopes resulting from the Deepwater Horizon oil spill, helping scientists understand the environmental impact of the disaster. \n                      In part due to the support of NASA’s SBIR program, LGR has experienced significant growth since first commercializing its products in 2005. Baer expects the company’s workforce to grow from 30 to nearly 50 full-time employees by the end of 2011, and the company employs a large number of contractors as well. \n                      Even as LGR’s SBIR-derived technology helps NASA search for unusual life on the ocean floor, Flynn notes a fiberoptic spectrometer the company also developed through NASA SBIR funding. Small and inexpensive to fabricate, “you can put it on any mission going to Mars and build up a global understanding of the planet’s carbon distributions,” an understanding that may lead to the first discovery of life beyond Earth. \n                      “That’s the ultimate objective,” Flynn say\n                      \n                    \n                  \n                \n              \n            \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      In complete darkness, a NASA observatory waits. When an eruption of boiling water billows from a nearby crack in the ground, the observatory’s sensors seek particles in the fluid, measure shifts in carbon isotopes, and analyze samples for biological signatures. NASA has landed the observatory in this remote location, far removed from air and sunlight, to find life unlike any that scientists have ever seen. \n                      It might sound like a scene from a distant planet, but this NASA mission is actually exploring an ocean floor right here on Earth. \n                      NASA established a formal exobiology program in 1960, which expanded into the present-day Astrobiology Program. The program, which celebrated its 50th anniversary in 2010, not only explores the possibility of life elsewhere in the universe, but also examines how life begins and evolves, and what the future may hold for life on Earth and other planets.\n                      \n                        \n                        \n                          \n                        \n                        \n                          NASA’s Astrobiology Program looks for life in places beyond Earth, such as Europa, one of Jupiter’s moons.\n                        \n                      \n                      Answers to these questions may be found not only by launching rockets skyward, but by sending probes in the opposite direction. Research here on Earth can revise prevailing concepts of life and biochemistry and point to the possibilities for life on other planets, as was demonstrated in December 2010, when NASA researchers discovered microbes in Mono Lake in California that subsist and reproduce using arsenic, a toxic chemical. \n                      The Mono Lake discovery may be the first of many that could reveal possible models for extraterrestrial life. One primary area of interest for NASA astrobiologists lies with the hydrothermal vents on the ocean floor. These vents expel jets of water heated and enriched with chemicals from off-gassing magma below the Earth’s crust. Also potentially within the vents: microbes that, like the Mono Lake microorganisms, defy the common characteristics of life on Earth. \n                      Basically all organisms on our planet generate energy through the Krebs Cycle, explains Mike Flynn, research scientist at NASA’s Ames Research Center. This metabolic process breaks down sugars for energy to fuel cellular functions. “We think this chemical process did not exist when life first formed on Earth,” he says, “because it is based on oxygen being available, and there was little oxygen available on the early Earth.” It is possible that there are anaerobic regions beneath the sea floor in which life forms like those early non-Krebs Cycle microbes may yet exist. \n                      To detect and potentially collect samples of life emerging from hydrothermal vents, Flynn and his colleagues created Medusa, a multi-sensor instrument designed for long-term observation of diked vents on the ocean floor. When the vents erupt, Medusa assesses indicators of life within the expelled water. If the results are positive, the observatory collects samples and detaches from the ocean floor, making the long journey to the surface for retrieval by scientists. \n                      One of the indicators Medusa measures is the ratio of carbon isotopes in the water, namely carbon-12 and carbon-13. Living organisms preferentially take up carbon-12, Flynn says, so examining the ratio of these isotopes can help to determine the source of carbon in an environment as either biological or non-biological. \n                      “On Mars, there is evidence of localized methane in the atmosphere, and that methane could come from biological sources or from geochemical ones,” Flynn says. “Determining the background planetary carbon isotope ratios and then evaluating the specific carbon ratios in this methane would help to determine how it was formed.” A long-duration observatory similar to Medusa could one day provide essential evidence for or against the presence of life on the Red Planet or beneath the ice-crusted oceans of Europa.\n                      Partnership\n                      To develop instrumentation capable of precisely measuring carbon isotopes in deep sea and deep space environments, Ames partnered with Los Gatos Research (LGR) Inc., of Mountain View, California, through the Small Business Innovation Research (SBIR) program. The company had already pioneered cavity-enhanced absorption techniques for spectroscopy and, with the help of the NASA funding, developed the latest generation of this cavity ringdown technology, called Off-Axis Integrated Cavity Output Spectroscopy (ICOS). \n                      LGR’s Off-Axis ICOS technology uses an optical cavity—a tube bound on both ends by two high-reflectivity mirrors—as an absorption cell, explains company president Doug Baer. A laser beam is directed through the first mirror and then trapped inside the cell containing the sample of air. The beam reflects between the mirrors, propagating thousands of meters and interacting extensively with the molecules in the cell, revealing their makeup and concentration. \n                      “The longer path length means that we don’t need to have as many molecules in the cell to detect, so the instrument’s sensitivity is greatly enhanced,” Baer says. \n                      This innovation enabled a deep-sea carbon isotope analyzer for NASA’s Medusa project and currently forms the basis of all of the company’s commercial products—including devices that are providing significant information for environmental researchers around the globe. \n                      “The SBIR program has been critical to the creation of these technologies, which would otherwise have taken a much longer time to develop,” says Baer.\n                       Benefits\n                      LGR’s SBIR-derived technology has been incorporated into a variety of analyzer devices deployed for use on all seven continents for the measurement of a range of greenhouse gasses, pollutants, and isotopes. Employing lasers ranging in wavelength from visible light to mid-infrared, these Off-Axis ICOS-based instruments can measure precise amounts of practically any molecule with an absorption spectrum. And because the system is easy to build, Baer says, it can be made rugged at a low cost.\n                      “This allows us to streamline our manufacturing and create products at inexpensive cost to government agencies and researchers around the globe,” he says. \n                      LGR analyzers are designed for the measurement of target molecules such as carbon dioxide, methane, nitrous oxide, water, water vapor, liquid water, and isotopes of all of those molecules down to parts-per-billion sensitivity. This allows researchers to gather detailed information about the sources and sinks of greenhouse gasses that are affecting the planet’s climate. (Sinks absorb and store particular molecules; a forest, for example, can act as a carbon sink, absorbing carbon dioxide from the air until burning or decomposition releases the stored carbon back into the environment.) \n                      \n                        \n                        \n                          \n                        \n                        \n                          Los Gatos Research Inc.’s analyzers measure a range of target molecules, providing researchers with a cost-effective means of attaining valuable environmental data.\n                        \n                      \n                      NASA has flown LGR analyzers on the Agency’s DC-8 research aircraft for studies of greenhouse gasses and pollutants in the atmosphere, and other scientists have employed the company’s devices to study Earth’s hydrological cycle. LGR also recently collaborated with Texas A&M University to deploy a methane analyzer to the Gulf of Mexico to record the distribution of methane and methane isotopes resulting from the Deepwater Horizon oil spill, helping scientists understand the environmental impact of the disaster. \n                      In part due to the support of NASA’s SBIR program, LGR has experienced significant growth since first commercializing its products in 2005. Baer expects the company’s workforce to grow from 30 to nearly 50 full-time employees by the end of 2011, and the company employs a large number of contractors as well. \n                      Even as LGR’s SBIR-derived technology helps NASA search for unusual life on the ocean floor, Flynn notes a fiberoptic spectrometer the company also developed through NASA SBIR funding. Small and inexpensive to fabricate, “you can put it on any mission going to Mars and build up a global understanding of the planet’s carbon distributions,” an understanding that may lead to the first discovery of life beyond Earth. \n                      “That’s the ultimate objective,” Flynn say\n                      \n                    \n                  \n                \n              \n                  \n                    \n                      NASA Technology\n                      In complete darkness, a NASA observatory waits. When an eruption of boiling water billows from a nearby crack in the ground, the observatory’s sensors seek particles in the fluid, measure shifts in carbon isotopes, and analyze samples for biological signatures. NASA has landed the observatory in this remote location, far removed from air and sunlight, to find life unlike any that scientists have ever seen. \n                      It might sound like a scene from a distant planet, but this NASA mission is actually exploring an ocean floor right here on Earth. \n                      NASA established a formal exobiology program in 1960, which expanded into the present-day Astrobiology Program. The program, which celebrated its 50th anniversary in 2010, not only explores the possibility of life elsewhere in the universe, but also examines how life begins and evolves, and what the future may hold for life on Earth and other planets.\n                      \n                        \n                        \n                          \n                        \n                        \n                          NASA’s Astrobiology Program looks for life in places beyond Earth, such as Europa, one of Jupiter’s moons.\n                        \n                      \n                      Answers to these questions may be found not only by launching rockets skyward, but by sending probes in the opposite direction. Research here on Earth can revise prevailing concepts of life and biochemistry and point to the possibilities for life on other planets, as was demonstrated in December 2010, when NASA researchers discovered microbes in Mono Lake in California that subsist and reproduce using arsenic, a toxic chemical. \n                      The Mono Lake discovery may be the first of many that could reveal possible models for extraterrestrial life. One primary area of interest for NASA astrobiologists lies with the hydrothermal vents on the ocean floor. These vents expel jets of water heated and enriched with chemicals from off-gassing magma below the Earth’s crust. Also potentially within the vents: microbes that, like the Mono Lake microorganisms, defy the common characteristics of life on Earth. \n                      Basically all organisms on our planet generate energy through the Krebs Cycle, explains Mike Flynn, research scientist at NASA’s Ames Research Center. This metabolic process breaks down sugars for energy to fuel cellular functions. “We think this chemical process did not exist when life first formed on Earth,” he says, “because it is based on oxygen being available, and there was little oxygen available on the early Earth.” It is possible that there are anaerobic regions beneath the sea floor in which life forms like those early non-Krebs Cycle microbes may yet exist. \n                      To detect and potentially collect samples of life emerging from hydrothermal vents, Flynn and his colleagues created Medusa, a multi-sensor instrument designed for long-term observation of diked vents on the ocean floor. When the vents erupt, Medusa assesses indicators of life within the expelled water. If the results are positive, the observatory collects samples and detaches from the ocean floor, making the long journey to the surface for retrieval by scientists. \n                      One of the indicators Medusa measures is the ratio of carbon isotopes in the water, namely carbon-12 and carbon-13. Living organisms preferentially take up carbon-12, Flynn says, so examining the ratio of these isotopes can help to determine the source of carbon in an environment as either biological or non-biological. \n                      “On Mars, there is evidence of localized methane in the atmosphere, and that methane could come from biological sources or from geochemical ones,” Flynn says. “Determining the background planetary carbon isotope ratios and then evaluating the specific carbon ratios in this methane would help to determine how it was formed.” A long-duration observatory similar to Medusa could one day provide essential evidence for or against the presence of life on the Red Planet or beneath the ice-crusted oceans of Europa.\n                      Partnership\n                      To develop instrumentation capable of precisely measuring carbon isotopes in deep sea and deep space environments, Ames partnered with Los Gatos Research (LGR) Inc., of Mountain View, California, through the Small Business Innovation Research (SBIR) program. The company had already pioneered cavity-enhanced absorption techniques for spectroscopy and, with the help of the NASA funding, developed the latest generation of this cavity ringdown technology, called Off-Axis Integrated Cavity Output Spectroscopy (ICOS). \n                      LGR’s Off-Axis ICOS technology uses an optical cavity—a tube bound on both ends by two high-reflectivity mirrors—as an absorption cell, explains company president Doug Baer. A laser beam is directed through the first mirror and then trapped inside the cell containing the sample of air. The beam reflects between the mirrors, propagating thousands of meters and interacting extensively with the molecules in the cell, revealing their makeup and concentration. \n                      “The longer path length means that we don’t need to have as many molecules in the cell to detect, so the instrument’s sensitivity is greatly enhanced,” Baer says. \n                      This innovation enabled a deep-sea carbon isotope analyzer for NASA’s Medusa project and currently forms the basis of all of the company’s commercial products—including devices that are providing significant information for environmental researchers around the globe. \n                      “The SBIR program has been critical to the creation of these technologies, which would otherwise have taken a much longer time to develop,” says Baer.\n                       Benefits\n                      LGR’s SBIR-derived technology has been incorporated into a variety of analyzer devices deployed for use on all seven continents for the measurement of a range of greenhouse gasses, pollutants, and isotopes. Employing lasers ranging in wavelength from visible light to mid-infrared, these Off-Axis ICOS-based instruments can measure precise amounts of practically any molecule with an absorption spectrum. And because the system is easy to build, Baer says, it can be made rugged at a low cost.\n                      “This allows us to streamline our manufacturing and create products at inexpensive cost to government agencies and researchers around the globe,” he says. \n                      LGR analyzers are designed for the measurement of target molecules such as carbon dioxide, methane, nitrous oxide, water, water vapor, liquid water, and isotopes of all of those molecules down to parts-per-billion sensitivity. This allows researchers to gather detailed information about the sources and sinks of greenhouse gasses that are affecting the planet’s climate. (Sinks absorb and store particular molecules; a forest, for example, can act as a carbon sink, absorbing carbon dioxide from the air until burning or decomposition releases the stored carbon back into the environment.) \n                      \n                        \n                        \n                          \n                        \n                        \n                          Los Gatos Research Inc.’s analyzers measure a range of target molecules, providing researchers with a cost-effective means of attaining valuable environmental data.\n                        \n                      \n                      NASA has flown LGR analyzers on the Agency’s DC-8 research aircraft for studies of greenhouse gasses and pollutants in the atmosphere, and other scientists have employed the company’s devices to study Earth’s hydrological cycle. LGR also recently collaborated with Texas A&M University to deploy a methane analyzer to the Gulf of Mexico to record the distribution of methane and methane isotopes resulting from the Deepwater Horizon oil spill, helping scientists understand the environmental impact of the disaster. \n                      In part due to the support of NASA’s SBIR program, LGR has experienced significant growth since first commercializing its products in 2005. Baer expects the company’s workforce to grow from 30 to nearly 50 full-time employees by the end of 2011, and the company employs a large number of contractors as well. \n                      Even as LGR’s SBIR-derived technology helps NASA search for unusual life on the ocean floor, Flynn notes a fiberoptic spectrometer the company also developed through NASA SBIR funding. Small and inexpensive to fabricate, “you can put it on any mission going to Mars and build up a global understanding of the planet’s carbon distributions,” an understanding that may lead to the first discovery of life beyond Earth. \n                      “That’s the ultimate objective,” Flynn say\n                      \n                    \n                  \n                    \n                      NASA Technology\n                      In complete darkness, a NASA observatory waits. When an eruption of boiling water billows from a nearby crack in the ground, the observatory’s sensors seek particles in the fluid, measure shifts in carbon isotopes, and analyze samples for biological signatures. NASA has landed the observatory in this remote location, far removed from air and sunlight, to find life unlike any that scientists have ever seen. \n                      It might sound like a scene from a distant planet, but this NASA mission is actually exploring an ocean floor right here on Earth. \n                      NASA established a formal exobiology program in 1960, which expanded into the present-day Astrobiology Program. The program, which celebrated its 50th anniversary in 2010, not only explores the possibility of life elsewhere in the universe, but also examines how life begins and evolves, and what the future may hold for life on Earth and other planets.\n                      \n                        \n                        \n                          \n                        \n                        \n                          NASA’s Astrobiology Program looks for life in places beyond Earth, such as Europa, one of Jupiter’s moons.\n                        \n                      \n                      Answers to these questions may be found not only by launching rockets skyward, but by sending probes in the opposite direction. Research here on Earth can revise prevailing concepts of life and biochemistry and point to the possibilities for life on other planets, as was demonstrated in December 2010, when NASA researchers discovered microbes in Mono Lake in California that subsist and reproduce using arsenic, a toxic chemical. \n                      The Mono Lake discovery may be the first of many that could reveal possible models for extraterrestrial life. One primary area of interest for NASA astrobiologists lies with the hydrothermal vents on the ocean floor. These vents expel jets of water heated and enriched with chemicals from off-gassing magma below the Earth’s crust. Also potentially within the vents: microbes that, like the Mono Lake microorganisms, defy the common characteristics of life on Earth. \n                      Basically all organisms on our planet generate energy through the Krebs Cycle, explains Mike Flynn, research scientist at NASA’s Ames Research Center. This metabolic process breaks down sugars for energy to fuel cellular functions. “We think this chemical process did not exist when life first formed on Earth,” he says, “because it is based on oxygen being available, and there was little oxygen available on the early Earth.” It is possible that there are anaerobic regions beneath the sea floor in which life forms like those early non-Krebs Cycle microbes may yet exist. \n                      To detect and potentially collect samples of life emerging from hydrothermal vents, Flynn and his colleagues created Medusa, a multi-sensor instrument designed for long-term observation of diked vents on the ocean floor. When the vents erupt, Medusa assesses indicators of life within the expelled water. If the results are positive, the observatory collects samples and detaches from the ocean floor, making the long journey to the surface for retrieval by scientists. \n                      One of the indicators Medusa measures is the ratio of carbon isotopes in the water, namely carbon-12 and carbon-13. Living organisms preferentially take up carbon-12, Flynn says, so examining the ratio of these isotopes can help to determine the source of carbon in an environment as either biological or non-biological. \n                      “On Mars, there is evidence of localized methane in the atmosphere, and that methane could come from biological sources or from geochemical ones,” Flynn says. “Determining the background planetary carbon isotope ratios and then evaluating the specific carbon ratios in this methane would help to determine how it was formed.” A long-duration observatory similar to Medusa could one day provide essential evidence for or against the presence of life on the Red Planet or beneath the ice-crusted oceans of Europa.\n                      Partnership\n                      To develop instrumentation capable of precisely measuring carbon isotopes in deep sea and deep space environments, Ames partnered with Los Gatos Research (LGR) Inc., of Mountain View, California, through the Small Business Innovation Research (SBIR) program. The company had already pioneered cavity-enhanced absorption techniques for spectroscopy and, with the help of the NASA funding, developed the latest generation of this cavity ringdown technology, called Off-Axis Integrated Cavity Output Spectroscopy (ICOS). \n                      LGR’s Off-Axis ICOS technology uses an optical cavity—a tube bound on both ends by two high-reflectivity mirrors—as an absorption cell, explains company president Doug Baer. A laser beam is directed through the first mirror and then trapped inside the cell containing the sample of air. The beam reflects between the mirrors, propagating thousands of meters and interacting extensively with the molecules in the cell, revealing their makeup and concentration. \n                      “The longer path length means that we don’t need to have as many molecules in the cell to detect, so the instrument’s sensitivity is greatly enhanced,” Baer says. \n                      This innovation enabled a deep-sea carbon isotope analyzer for NASA’s Medusa project and currently forms the basis of all of the company’s commercial products—including devices that are providing significant information for environmental researchers around the globe. \n                      “The SBIR program has been critical to the creation of these technologies, which would otherwise have taken a much longer time to develop,” says Baer.\n                       Benefits\n                      LGR’s SBIR-derived technology has been incorporated into a variety of analyzer devices deployed for use on all seven continents for the measurement of a range of greenhouse gasses, pollutants, and isotopes. Employing lasers ranging in wavelength from visible light to mid-infrared, these Off-Axis ICOS-based instruments can measure precise amounts of practically any molecule with an absorption spectrum. And because the system is easy to build, Baer says, it can be made rugged at a low cost.\n                      “This allows us to streamline our manufacturing and create products at inexpensive cost to government agencies and researchers around the globe,” he says. \n                      LGR analyzers are designed for the measurement of target molecules such as carbon dioxide, methane, nitrous oxide, water, water vapor, liquid water, and isotopes of all of those molecules down to parts-per-billion sensitivity. This allows researchers to gather detailed information about the sources and sinks of greenhouse gasses that are affecting the planet’s climate. (Sinks absorb and store particular molecules; a forest, for example, can act as a carbon sink, absorbing carbon dioxide from the air until burning or decomposition releases the stored carbon back into the environment.) \n                      \n                        \n                        \n                          \n                        \n                        \n                          Los Gatos Research Inc.’s analyzers measure a range of target molecules, providing researchers with a cost-effective means of attaining valuable environmental data.\n                        \n                      \n                      NASA has flown LGR analyzers on the Agency’s DC-8 research aircraft for studies of greenhouse gasses and pollutants in the atmosphere, and other scientists have employed the company’s devices to study Earth’s hydrological cycle. LGR also recently collaborated with Texas A&M University to deploy a methane analyzer to the Gulf of Mexico to record the distribution of methane and methane isotopes resulting from the Deepwater Horizon oil spill, helping scientists understand the environmental impact of the disaster. \n                      In part due to the support of NASA’s SBIR program, LGR has experienced significant growth since first commercializing its products in 2005. Baer expects the company’s workforce to grow from 30 to nearly 50 full-time employees by the end of 2011, and the company employs a large number of contractors as well. \n                      Even as LGR’s SBIR-derived technology helps NASA search for unusual life on the ocean floor, Flynn notes a fiberoptic spectrometer the company also developed through NASA SBIR funding. Small and inexpensive to fabricate, “you can put it on any mission going to Mars and build up a global understanding of the planet’s carbon distributions,” an understanding that may lead to the first discovery of life beyond Earth. \n                      “That’s the ultimate objective,” Flynn say\n                      \n                    \n                      NASA Technology\n                      In complete darkness, a NASA observatory waits. When an eruption of boiling water billows from a nearby crack in the ground, the observatory’s sensors seek particles in the fluid, measure shifts in carbon isotopes, and analyze samples for biological signatures. NASA has landed the observatory in this remote location, far removed from air and sunlight, to find life unlike any that scientists have ever seen. \n                      It might sound like a scene from a distant planet, but this NASA mission is actually exploring an ocean floor right here on Earth. \n                      NASA established a formal exobiology program in 1960, which expanded into the present-day Astrobiology Program. The program, which celebrated its 50th anniversary in 2010, not only explores the possibility of life elsewhere in the universe, but also examines how life begins and evolves, and what the future may hold for life on Earth and other planets.\n                      \n                        \n                        \n                          \n                        \n                        \n                          NASA’s Astrobiology Program looks for life in places beyond Earth, such as Europa, one of Jupiter’s moons.\n                        \n                      \n                      Answers to these questions may be found not only by launching rockets skyward, but by sending probes in the opposite direction. Research here on Earth can revise prevailing concepts of life and biochemistry and point to the possibilities for life on other planets, as was demonstrated in December 2010, when NASA researchers discovered microbes in Mono Lake in California that subsist and reproduce using arsenic, a toxic chemical. \n                      The Mono Lake discovery may be the first of many that could reveal possible models for extraterrestrial life. One primary area of interest for NASA astrobiologists lies with the hydrothermal vents on the ocean floor. These vents expel jets of water heated and enriched with chemicals from off-gassing magma below the Earth’s crust. Also potentially within the vents: microbes that, like the Mono Lake microorganisms, defy the common characteristics of life on Earth. \n                      Basically all organisms on our planet generate energy through the Krebs Cycle, explains Mike Flynn, research scientist at NASA’s Ames Research Center. This metabolic process breaks down sugars for energy to fuel cellular functions. “We think this chemical process did not exist when life first formed on Earth,” he says, “because it is based on oxygen being available, and there was little oxygen available on the early Earth.” It is possible that there are anaerobic regions beneath the sea floor in which life forms like those early non-Krebs Cycle microbes may yet exist. \n                      To detect and potentially collect samples of life emerging from hydrothermal vents, Flynn and his colleagues created Medusa, a multi-sensor instrument designed for long-term observation of diked vents on the ocean floor. When the vents erupt, Medusa assesses indicators of life within the expelled water. If the results are positive, the observatory collects samples and detaches from the ocean floor, making the long journey to the surface for retrieval by scientists. \n                      One of the indicators Medusa measures is the ratio of carbon isotopes in the water, namely carbon-12 and carbon-13. Living organisms preferentially take up carbon-12, Flynn says, so examining the ratio of these isotopes can help to determine the source of carbon in an environment as either biological or non-biological. \n                      “On Mars, there is evidence of localized methane in the atmosphere, and that methane could come from biological sources or from geochemical ones,” Flynn says. “Determining the background planetary carbon isotope ratios and then evaluating the specific carbon ratios in this methane would help to determine how it was formed.” A long-duration observatory similar to Medusa could one day provide essential evidence for or against the presence of life on the Red Planet or beneath the ice-crusted oceans of Europa.\n                      Partnership\n                      To develop instrumentation capable of precisely measuring carbon isotopes in deep sea and deep space environments, Ames partnered with Los Gatos Research (LGR) Inc., of Mountain View, California, through the Small Business Innovation Research (SBIR) program. The company had already pioneered cavity-enhanced absorption techniques for spectroscopy and, with the help of the NASA funding, developed the latest generation of this cavity ringdown technology, called Off-Axis Integrated Cavity Output Spectroscopy (ICOS). \n                      LGR’s Off-Axis ICOS technology uses an optical cavity—a tube bound on both ends by two high-reflectivity mirrors—as an absorption cell, explains company president Doug Baer. A laser beam is directed through the first mirror and then trapped inside the cell containing the sample of air. The beam reflects between the mirrors, propagating thousands of meters and interacting extensively with the molecules in the cell, revealing their makeup and concentration. \n                      “The longer path length means that we don’t need to have as many molecules in the cell to detect, so the instrument’s sensitivity is greatly enhanced,” Baer says. \n                      This innovation enabled a deep-sea carbon isotope analyzer for NASA’s Medusa project and currently forms the basis of all of the company’s commercial products—including devices that are providing significant information for environmental researchers around the globe. \n                      “The SBIR program has been critical to the creation of these technologies, which would otherwise have taken a much longer time to develop,” says Baer.\n                       Benefits\n                      LGR’s SBIR-derived technology has been incorporated into a variety of analyzer devices deployed for use on all seven continents for the measurement of a range of greenhouse gasses, pollutants, and isotopes. Employing lasers ranging in wavelength from visible light to mid-infrared, these Off-Axis ICOS-based instruments can measure precise amounts of practically any molecule with an absorption spectrum. And because the system is easy to build, Baer says, it can be made rugged at a low cost.\n                      “This allows us to streamline our manufacturing and create products at inexpensive cost to government agencies and researchers around the globe,” he says. \n                      LGR analyzers are designed for the measurement of target molecules such as carbon dioxide, methane, nitrous oxide, water, water vapor, liquid water, and isotopes of all of those molecules down to parts-per-billion sensitivity. This allows researchers to gather detailed information about the sources and sinks of greenhouse gasses that are affecting the planet’s climate. (Sinks absorb and store particular molecules; a forest, for example, can act as a carbon sink, absorbing carbon dioxide from the air until burning or decomposition releases the stored carbon back into the environment.) \n                      \n                        \n                        \n                          \n                        \n                        \n                          Los Gatos Research Inc.’s analyzers measure a range of target molecules, providing researchers with a cost-effective means of attaining valuable environmental data.\n                        \n                      \n                      NASA has flown LGR analyzers on the Agency’s DC-8 research aircraft for studies of greenhouse gasses and pollutants in the atmosphere, and other scientists have employed the company’s devices to study Earth’s hydrological cycle. LGR also recently collaborated with Texas A&M University to deploy a methane analyzer to the Gulf of Mexico to record the distribution of methane and methane isotopes resulting from the Deepwater Horizon oil spill, helping scientists understand the environmental impact of the disaster. \n                      In part due to the support of NASA’s SBIR program, LGR has experienced significant growth since first commercializing its products in 2005. Baer expects the company’s workforce to grow from 30 to nearly 50 full-time employees by the end of 2011, and the company employs a large number of contractors as well. \n                      Even as LGR’s SBIR-derived technology helps NASA search for unusual life on the ocean floor, Flynn notes a fiberoptic spectrometer the company also developed through NASA SBIR funding. Small and inexpensive to fabricate, “you can put it on any mission going to Mars and build up a global understanding of the planet’s carbon distributions,” an understanding that may lead to the first discovery of life beyond Earth. \n                      “That’s the ultimate objective,” Flynn say\n                      "},{"href":"http://spinoff.nasa.gov/Spinoff2011/er_3.html","text":"Remediation Technologies Eliminate Contaminants","image":"http://spinoff.nasa.gov/Spinoff2011/Images/er_5a_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Saturn 1B rocket carrying Skylab astronauts lifts off from Kennedy Space Center. Years later, after the launch stand was dismantled, its paint was found to contain toxic chemicals. \n                        \n                      \n                      All research and development has a story behind it, says Jacqueline Quinn, environmental engineer at Kennedy Space Center. For Quinn, one such story begins with the Saturn 1B launch stand at Kennedy and ends with a unique solution to a challenging environmental problem.\n                      Used in a number of Apollo missions and during the Skylab program, the Saturn 1B launch stand was dismantled following the transition to the Space Shuttle Program and stored in an open field at Kennedy. Decades later, the Center’s Environmental Program Office discovered evidence of chemicals called polychlorinated biphenyls (PCBs) in the field’s soil. The findings were puzzling since PCBs—a toxin classified as a probable carcinogen by the Environmental Protection Agency (EPA)—have been banned in the United States since 1979. Before the ban, PCBs were commonly used in transformer oils that leached into the ground when the oils were changed out and dumped near transformer sites, but there were no electrical transformers near the dismantled stand. It soon became apparent that the source of the PCBs was the launch stand itself. Prior to the ban, PCBs were used extensively in paints to add elasticity and other desirable characteristics. The PCB-laden paint on the Saturn 1B launch stand was flaking off into the field’s soil.\n                      “Nobody knew there were PCBs in the paint,” says Quinn, noting that the ingredient was not monitored carefully when it was in use in 1960s. In fact, she says, the U.S. EPA was not even established until 1970, a year after Neil Armstrong first set foot on the Moon. Nobody knew any better at the time, Quinn says, but today, “we have the responsibility to return any natural environmental media to as close to pristine a condition as possible.”\n                      Quinn, fellow engineer Kathleen Loftin, and other Kennedy colleagues already had experience developing unprecedented solutions for environmental contamination; the team invented the emulsified zero-valent iron (EZVI) technology to safely treat groundwater tainted by chlorinated solvents once used to clean rocket engine components. The award-winning innovation (Spinoff 2010) is now NASA’s most licensed technology to date.\n                      PCBs in paint presented a new challenge. Removing the launch stand for recycling proved a difficult operation; the toxic paint had to be fully stripped from the steel structure, a lengthy and costly process that required the stripped paint to be treated before disposal. Noting the lack of efficient, environmentally friendly options for dealing with PCBs, Quinn and her colleagues developed the Activated Metal Treatment System (AMTS).\n                      AMTS is a paste consisting of a solvent solution containing microscale particles of activated zero-valent metal. When applied to a painted surface, the paste extracts and degrades the PCBs into benign byproducts while leaving the paint on the structure. This provides a superior alternative to other methods for PCB remediation, such as stripping the paint or incinerating the structure, which prevents reuse and can release volatized PCBs into the air.\n                      Since its development, AMTS has proven to be a valuable solution for removing PCBs from paint, caulking, and various insulation and filler materials in older buildings, naval ships, and former munitions facilities where the presence of PCBs interferes with methods for removing trace explosive materials. Miles of potentially toxic caulking join sections of runways at airports. Any of these materials installed before 1979 potentially contain PCBs, Quinn says.\n                      “This is not just a NASA problem,” she says. “It’s a global problem.”\n                      Partnership\n                      To provide the benefits of the AMTS solution on a national scale, Kennedy made the technology available for licensing. It quickly caught the eye of a company already familiar with the Center’s environmental innovations. Cantonment, Florida-based Bio Blend Technologies, the remedial arm of U.S. O’Neill Industries, had previously licensed the NASA-developed EZVI technology and saw AMTS as an innovation with significant potential.\n                      “The future for AMTS is untapped,” says Bio Blend COO Roger Kubala. The company licensed the technology, and now, Kubala says, “Bio Blend is capable of cleaning any kind of hydrocarbon contamination, pesticides, PCBs—we’re a one-stop shop for treating all organic chlorides and contaminants.”\n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Bio Blend’s specialized onsite remediation equipment employs the company’s NASA-developed solutions to treat virtually any environmental contaminant. The inset, magnified image shows one of those solutions, the emulsified zero-valent iron or EZVI technology, which consists of tiny iron particles in a water and biodegradable oil emulsification. \n                        \n                      \n                      AMTS joins Bio Blend’s extensive range of remediation tools, including EZVI and the company’s proprietary remediation blends. Employing these products using a mobile system that allows the company to treat and destroy nearly any contaminant onsite, Bio Blend has solved environmental challenges resistant to other treatment methods. \n                      At one site—a Florida gas station where years of leaks from single-skin, underground gas tanks had contaminated the surrounding soil and groundwater—nine years and over $1 million worth of remediation had yielded little effect. Utilizing its NASA and proprietary solutions, Bio Blend cleared 98.9 percent of the contaminants in 77 days at a fraction of the cost. At a similar site, the company reduced the pollutants to nondetect status in 52 days. Owners of contaminated land are often unable to sell their property or even secure loans; Bio Blend’s intervention allows these property owners to regain the value of their land and does not interfere with ongoing business. The gas stations maintained full operations during the remediation.\n                      “It provides a great sense of fulfillment that \n                        the technologies we are developing through NASA \n                        can impact the everyday lives of everyday people.”\n                        —Jacqueline Quinn, \n                        Kennedy Space Center \n                      Bio Blend’s success in these cases results from its pairing of NASA technology with its own innovations, says David O’Neill, president of U.S. O’Neill Industries and Bio Blend. “There was nothing prior to EZVI that would get far enough down into the groundwater. Coupling EZVI with our blends allows you to dig down as deep as you want and eradicate whatever the contaminant is. It is revolutionary.” The AMTS technology takes the company’s capabilities even further, he says. “PCBs are the asbestos of the future. Because there has not been a lot of dialogue about it, there was not a good remediation technique for it until now.”\n                        Quinn finds significant satisfaction in the impact these technologies have outside of NASA. “It provides a great sense of fulfillment that the technologies we are developing through NASA can impact the everyday lives of everyday people,” she says.\n                        Bio Blend is also working closely with the University of West Florida, where it has a dedicated lab for the testing, creation, and production of new products. “This is a perfect collaborative fit with some of the best academic minds, a talented student pool, and a university president focused on being a think tank for cutting edge technologies,” says O’Neill. In addition, the company will soon open a new blending plant for manufacturing its proprietary and NASA-derived products, and it is exploring ways of using AMTS to remove PCBs from soil.\n                        “We feel very strongly that, from a societal standpoint, we’re in a unique place and time,” says O’Neill. “We are going to have to clean up to continue our quality of life for future generations.” According to Bio Blend, its NASA-developed solutions help enable that goal.\n                        “We have the tools now,” says Kubala. “It’s time to get the word out to the world that there is an answer.”\n                        \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Saturn 1B rocket carrying Skylab astronauts lifts off from Kennedy Space Center. Years later, after the launch stand was dismantled, its paint was found to contain toxic chemicals. \n                        \n                      \n                      All research and development has a story behind it, says Jacqueline Quinn, environmental engineer at Kennedy Space Center. For Quinn, one such story begins with the Saturn 1B launch stand at Kennedy and ends with a unique solution to a challenging environmental problem.\n                      Used in a number of Apollo missions and during the Skylab program, the Saturn 1B launch stand was dismantled following the transition to the Space Shuttle Program and stored in an open field at Kennedy. Decades later, the Center’s Environmental Program Office discovered evidence of chemicals called polychlorinated biphenyls (PCBs) in the field’s soil. The findings were puzzling since PCBs—a toxin classified as a probable carcinogen by the Environmental Protection Agency (EPA)—have been banned in the United States since 1979. Before the ban, PCBs were commonly used in transformer oils that leached into the ground when the oils were changed out and dumped near transformer sites, but there were no electrical transformers near the dismantled stand. It soon became apparent that the source of the PCBs was the launch stand itself. Prior to the ban, PCBs were used extensively in paints to add elasticity and other desirable characteristics. The PCB-laden paint on the Saturn 1B launch stand was flaking off into the field’s soil.\n                      “Nobody knew there were PCBs in the paint,” says Quinn, noting that the ingredient was not monitored carefully when it was in use in 1960s. In fact, she says, the U.S. EPA was not even established until 1970, a year after Neil Armstrong first set foot on the Moon. Nobody knew any better at the time, Quinn says, but today, “we have the responsibility to return any natural environmental media to as close to pristine a condition as possible.”\n                      Quinn, fellow engineer Kathleen Loftin, and other Kennedy colleagues already had experience developing unprecedented solutions for environmental contamination; the team invented the emulsified zero-valent iron (EZVI) technology to safely treat groundwater tainted by chlorinated solvents once used to clean rocket engine components. The award-winning innovation (Spinoff 2010) is now NASA’s most licensed technology to date.\n                      PCBs in paint presented a new challenge. Removing the launch stand for recycling proved a difficult operation; the toxic paint had to be fully stripped from the steel structure, a lengthy and costly process that required the stripped paint to be treated before disposal. Noting the lack of efficient, environmentally friendly options for dealing with PCBs, Quinn and her colleagues developed the Activated Metal Treatment System (AMTS).\n                      AMTS is a paste consisting of a solvent solution containing microscale particles of activated zero-valent metal. When applied to a painted surface, the paste extracts and degrades the PCBs into benign byproducts while leaving the paint on the structure. This provides a superior alternative to other methods for PCB remediation, such as stripping the paint or incinerating the structure, which prevents reuse and can release volatized PCBs into the air.\n                      Since its development, AMTS has proven to be a valuable solution for removing PCBs from paint, caulking, and various insulation and filler materials in older buildings, naval ships, and former munitions facilities where the presence of PCBs interferes with methods for removing trace explosive materials. Miles of potentially toxic caulking join sections of runways at airports. Any of these materials installed before 1979 potentially contain PCBs, Quinn says.\n                      “This is not just a NASA problem,” she says. “It’s a global problem.”\n                      Partnership\n                      To provide the benefits of the AMTS solution on a national scale, Kennedy made the technology available for licensing. It quickly caught the eye of a company already familiar with the Center’s environmental innovations. Cantonment, Florida-based Bio Blend Technologies, the remedial arm of U.S. O’Neill Industries, had previously licensed the NASA-developed EZVI technology and saw AMTS as an innovation with significant potential.\n                      “The future for AMTS is untapped,” says Bio Blend COO Roger Kubala. The company licensed the technology, and now, Kubala says, “Bio Blend is capable of cleaning any kind of hydrocarbon contamination, pesticides, PCBs—we’re a one-stop shop for treating all organic chlorides and contaminants.”\n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Bio Blend’s specialized onsite remediation equipment employs the company’s NASA-developed solutions to treat virtually any environmental contaminant. The inset, magnified image shows one of those solutions, the emulsified zero-valent iron or EZVI technology, which consists of tiny iron particles in a water and biodegradable oil emulsification. \n                        \n                      \n                      AMTS joins Bio Blend’s extensive range of remediation tools, including EZVI and the company’s proprietary remediation blends. Employing these products using a mobile system that allows the company to treat and destroy nearly any contaminant onsite, Bio Blend has solved environmental challenges resistant to other treatment methods. \n                      At one site—a Florida gas station where years of leaks from single-skin, underground gas tanks had contaminated the surrounding soil and groundwater—nine years and over $1 million worth of remediation had yielded little effect. Utilizing its NASA and proprietary solutions, Bio Blend cleared 98.9 percent of the contaminants in 77 days at a fraction of the cost. At a similar site, the company reduced the pollutants to nondetect status in 52 days. Owners of contaminated land are often unable to sell their property or even secure loans; Bio Blend’s intervention allows these property owners to regain the value of their land and does not interfere with ongoing business. The gas stations maintained full operations during the remediation.\n                      “It provides a great sense of fulfillment that \n                        the technologies we are developing through NASA \n                        can impact the everyday lives of everyday people.”\n                        —Jacqueline Quinn, \n                        Kennedy Space Center \n                      Bio Blend’s success in these cases results from its pairing of NASA technology with its own innovations, says David O’Neill, president of U.S. O’Neill Industries and Bio Blend. “There was nothing prior to EZVI that would get far enough down into the groundwater. Coupling EZVI with our blends allows you to dig down as deep as you want and eradicate whatever the contaminant is. It is revolutionary.” The AMTS technology takes the company’s capabilities even further, he says. “PCBs are the asbestos of the future. Because there has not been a lot of dialogue about it, there was not a good remediation technique for it until now.”\n                        Quinn finds significant satisfaction in the impact these technologies have outside of NASA. “It provides a great sense of fulfillment that the technologies we are developing through NASA can impact the everyday lives of everyday people,” she says.\n                        Bio Blend is also working closely with the University of West Florida, where it has a dedicated lab for the testing, creation, and production of new products. “This is a perfect collaborative fit with some of the best academic minds, a talented student pool, and a university president focused on being a think tank for cutting edge technologies,” says O’Neill. In addition, the company will soon open a new blending plant for manufacturing its proprietary and NASA-derived products, and it is exploring ways of using AMTS to remove PCBs from soil.\n                        “We feel very strongly that, from a societal standpoint, we’re in a unique place and time,” says O’Neill. “We are going to have to clean up to continue our quality of life for future generations.” According to Bio Blend, its NASA-developed solutions help enable that goal.\n                        “We have the tools now,” says Kubala. “It’s time to get the word out to the world that there is an answer.”\n                        \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Saturn 1B rocket carrying Skylab astronauts lifts off from Kennedy Space Center. Years later, after the launch stand was dismantled, its paint was found to contain toxic chemicals. \n                        \n                      \n                      All research and development has a story behind it, says Jacqueline Quinn, environmental engineer at Kennedy Space Center. For Quinn, one such story begins with the Saturn 1B launch stand at Kennedy and ends with a unique solution to a challenging environmental problem.\n                      Used in a number of Apollo missions and during the Skylab program, the Saturn 1B launch stand was dismantled following the transition to the Space Shuttle Program and stored in an open field at Kennedy. Decades later, the Center’s Environmental Program Office discovered evidence of chemicals called polychlorinated biphenyls (PCBs) in the field’s soil. The findings were puzzling since PCBs—a toxin classified as a probable carcinogen by the Environmental Protection Agency (EPA)—have been banned in the United States since 1979. Before the ban, PCBs were commonly used in transformer oils that leached into the ground when the oils were changed out and dumped near transformer sites, but there were no electrical transformers near the dismantled stand. It soon became apparent that the source of the PCBs was the launch stand itself. Prior to the ban, PCBs were used extensively in paints to add elasticity and other desirable characteristics. The PCB-laden paint on the Saturn 1B launch stand was flaking off into the field’s soil.\n                      “Nobody knew there were PCBs in the paint,” says Quinn, noting that the ingredient was not monitored carefully when it was in use in 1960s. In fact, she says, the U.S. EPA was not even established until 1970, a year after Neil Armstrong first set foot on the Moon. Nobody knew any better at the time, Quinn says, but today, “we have the responsibility to return any natural environmental media to as close to pristine a condition as possible.”\n                      Quinn, fellow engineer Kathleen Loftin, and other Kennedy colleagues already had experience developing unprecedented solutions for environmental contamination; the team invented the emulsified zero-valent iron (EZVI) technology to safely treat groundwater tainted by chlorinated solvents once used to clean rocket engine components. The award-winning innovation (Spinoff 2010) is now NASA’s most licensed technology to date.\n                      PCBs in paint presented a new challenge. Removing the launch stand for recycling proved a difficult operation; the toxic paint had to be fully stripped from the steel structure, a lengthy and costly process that required the stripped paint to be treated before disposal. Noting the lack of efficient, environmentally friendly options for dealing with PCBs, Quinn and her colleagues developed the Activated Metal Treatment System (AMTS).\n                      AMTS is a paste consisting of a solvent solution containing microscale particles of activated zero-valent metal. When applied to a painted surface, the paste extracts and degrades the PCBs into benign byproducts while leaving the paint on the structure. This provides a superior alternative to other methods for PCB remediation, such as stripping the paint or incinerating the structure, which prevents reuse and can release volatized PCBs into the air.\n                      Since its development, AMTS has proven to be a valuable solution for removing PCBs from paint, caulking, and various insulation and filler materials in older buildings, naval ships, and former munitions facilities where the presence of PCBs interferes with methods for removing trace explosive materials. Miles of potentially toxic caulking join sections of runways at airports. Any of these materials installed before 1979 potentially contain PCBs, Quinn says.\n                      “This is not just a NASA problem,” she says. “It’s a global problem.”\n                      Partnership\n                      To provide the benefits of the AMTS solution on a national scale, Kennedy made the technology available for licensing. It quickly caught the eye of a company already familiar with the Center’s environmental innovations. Cantonment, Florida-based Bio Blend Technologies, the remedial arm of U.S. O’Neill Industries, had previously licensed the NASA-developed EZVI technology and saw AMTS as an innovation with significant potential.\n                      “The future for AMTS is untapped,” says Bio Blend COO Roger Kubala. The company licensed the technology, and now, Kubala says, “Bio Blend is capable of cleaning any kind of hydrocarbon contamination, pesticides, PCBs—we’re a one-stop shop for treating all organic chlorides and contaminants.”\n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Bio Blend’s specialized onsite remediation equipment employs the company’s NASA-developed solutions to treat virtually any environmental contaminant. The inset, magnified image shows one of those solutions, the emulsified zero-valent iron or EZVI technology, which consists of tiny iron particles in a water and biodegradable oil emulsification. \n                        \n                      \n                      AMTS joins Bio Blend’s extensive range of remediation tools, including EZVI and the company’s proprietary remediation blends. Employing these products using a mobile system that allows the company to treat and destroy nearly any contaminant onsite, Bio Blend has solved environmental challenges resistant to other treatment methods. \n                      At one site—a Florida gas station where years of leaks from single-skin, underground gas tanks had contaminated the surrounding soil and groundwater—nine years and over $1 million worth of remediation had yielded little effect. Utilizing its NASA and proprietary solutions, Bio Blend cleared 98.9 percent of the contaminants in 77 days at a fraction of the cost. At a similar site, the company reduced the pollutants to nondetect status in 52 days. Owners of contaminated land are often unable to sell their property or even secure loans; Bio Blend’s intervention allows these property owners to regain the value of their land and does not interfere with ongoing business. The gas stations maintained full operations during the remediation.\n                      “It provides a great sense of fulfillment that \n                        the technologies we are developing through NASA \n                        can impact the everyday lives of everyday people.”\n                        —Jacqueline Quinn, \n                        Kennedy Space Center \n                      Bio Blend’s success in these cases results from its pairing of NASA technology with its own innovations, says David O’Neill, president of U.S. O’Neill Industries and Bio Blend. “There was nothing prior to EZVI that would get far enough down into the groundwater. Coupling EZVI with our blends allows you to dig down as deep as you want and eradicate whatever the contaminant is. It is revolutionary.” The AMTS technology takes the company’s capabilities even further, he says. “PCBs are the asbestos of the future. Because there has not been a lot of dialogue about it, there was not a good remediation technique for it until now.”\n                        Quinn finds significant satisfaction in the impact these technologies have outside of NASA. “It provides a great sense of fulfillment that the technologies we are developing through NASA can impact the everyday lives of everyday people,” she says.\n                        Bio Blend is also working closely with the University of West Florida, where it has a dedicated lab for the testing, creation, and production of new products. “This is a perfect collaborative fit with some of the best academic minds, a talented student pool, and a university president focused on being a think tank for cutting edge technologies,” says O’Neill. In addition, the company will soon open a new blending plant for manufacturing its proprietary and NASA-derived products, and it is exploring ways of using AMTS to remove PCBs from soil.\n                        “We feel very strongly that, from a societal standpoint, we’re in a unique place and time,” says O’Neill. “We are going to have to clean up to continue our quality of life for future generations.” According to Bio Blend, its NASA-developed solutions help enable that goal.\n                        “We have the tools now,” says Kubala. “It’s time to get the word out to the world that there is an answer.”\n                        \n                    \n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Saturn 1B rocket carrying Skylab astronauts lifts off from Kennedy Space Center. Years later, after the launch stand was dismantled, its paint was found to contain toxic chemicals. \n                        \n                      \n                      All research and development has a story behind it, says Jacqueline Quinn, environmental engineer at Kennedy Space Center. For Quinn, one such story begins with the Saturn 1B launch stand at Kennedy and ends with a unique solution to a challenging environmental problem.\n                      Used in a number of Apollo missions and during the Skylab program, the Saturn 1B launch stand was dismantled following the transition to the Space Shuttle Program and stored in an open field at Kennedy. Decades later, the Center’s Environmental Program Office discovered evidence of chemicals called polychlorinated biphenyls (PCBs) in the field’s soil. The findings were puzzling since PCBs—a toxin classified as a probable carcinogen by the Environmental Protection Agency (EPA)—have been banned in the United States since 1979. Before the ban, PCBs were commonly used in transformer oils that leached into the ground when the oils were changed out and dumped near transformer sites, but there were no electrical transformers near the dismantled stand. It soon became apparent that the source of the PCBs was the launch stand itself. Prior to the ban, PCBs were used extensively in paints to add elasticity and other desirable characteristics. The PCB-laden paint on the Saturn 1B launch stand was flaking off into the field’s soil.\n                      “Nobody knew there were PCBs in the paint,” says Quinn, noting that the ingredient was not monitored carefully when it was in use in 1960s. In fact, she says, the U.S. EPA was not even established until 1970, a year after Neil Armstrong first set foot on the Moon. Nobody knew any better at the time, Quinn says, but today, “we have the responsibility to return any natural environmental media to as close to pristine a condition as possible.”\n                      Quinn, fellow engineer Kathleen Loftin, and other Kennedy colleagues already had experience developing unprecedented solutions for environmental contamination; the team invented the emulsified zero-valent iron (EZVI) technology to safely treat groundwater tainted by chlorinated solvents once used to clean rocket engine components. The award-winning innovation (Spinoff 2010) is now NASA’s most licensed technology to date.\n                      PCBs in paint presented a new challenge. Removing the launch stand for recycling proved a difficult operation; the toxic paint had to be fully stripped from the steel structure, a lengthy and costly process that required the stripped paint to be treated before disposal. Noting the lack of efficient, environmentally friendly options for dealing with PCBs, Quinn and her colleagues developed the Activated Metal Treatment System (AMTS).\n                      AMTS is a paste consisting of a solvent solution containing microscale particles of activated zero-valent metal. When applied to a painted surface, the paste extracts and degrades the PCBs into benign byproducts while leaving the paint on the structure. This provides a superior alternative to other methods for PCB remediation, such as stripping the paint or incinerating the structure, which prevents reuse and can release volatized PCBs into the air.\n                      Since its development, AMTS has proven to be a valuable solution for removing PCBs from paint, caulking, and various insulation and filler materials in older buildings, naval ships, and former munitions facilities where the presence of PCBs interferes with methods for removing trace explosive materials. Miles of potentially toxic caulking join sections of runways at airports. Any of these materials installed before 1979 potentially contain PCBs, Quinn says.\n                      “This is not just a NASA problem,” she says. “It’s a global problem.”\n                      Partnership\n                      To provide the benefits of the AMTS solution on a national scale, Kennedy made the technology available for licensing. It quickly caught the eye of a company already familiar with the Center’s environmental innovations. Cantonment, Florida-based Bio Blend Technologies, the remedial arm of U.S. O’Neill Industries, had previously licensed the NASA-developed EZVI technology and saw AMTS as an innovation with significant potential.\n                      “The future for AMTS is untapped,” says Bio Blend COO Roger Kubala. The company licensed the technology, and now, Kubala says, “Bio Blend is capable of cleaning any kind of hydrocarbon contamination, pesticides, PCBs—we’re a one-stop shop for treating all organic chlorides and contaminants.”\n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Bio Blend’s specialized onsite remediation equipment employs the company’s NASA-developed solutions to treat virtually any environmental contaminant. The inset, magnified image shows one of those solutions, the emulsified zero-valent iron or EZVI technology, which consists of tiny iron particles in a water and biodegradable oil emulsification. \n                        \n                      \n                      AMTS joins Bio Blend’s extensive range of remediation tools, including EZVI and the company’s proprietary remediation blends. Employing these products using a mobile system that allows the company to treat and destroy nearly any contaminant onsite, Bio Blend has solved environmental challenges resistant to other treatment methods. \n                      At one site—a Florida gas station where years of leaks from single-skin, underground gas tanks had contaminated the surrounding soil and groundwater—nine years and over $1 million worth of remediation had yielded little effect. Utilizing its NASA and proprietary solutions, Bio Blend cleared 98.9 percent of the contaminants in 77 days at a fraction of the cost. At a similar site, the company reduced the pollutants to nondetect status in 52 days. Owners of contaminated land are often unable to sell their property or even secure loans; Bio Blend’s intervention allows these property owners to regain the value of their land and does not interfere with ongoing business. The gas stations maintained full operations during the remediation.\n                      “It provides a great sense of fulfillment that \n                        the technologies we are developing through NASA \n                        can impact the everyday lives of everyday people.”\n                        —Jacqueline Quinn, \n                        Kennedy Space Center \n                      Bio Blend’s success in these cases results from its pairing of NASA technology with its own innovations, says David O’Neill, president of U.S. O’Neill Industries and Bio Blend. “There was nothing prior to EZVI that would get far enough down into the groundwater. Coupling EZVI with our blends allows you to dig down as deep as you want and eradicate whatever the contaminant is. It is revolutionary.” The AMTS technology takes the company’s capabilities even further, he says. “PCBs are the asbestos of the future. Because there has not been a lot of dialogue about it, there was not a good remediation technique for it until now.”\n                        Quinn finds significant satisfaction in the impact these technologies have outside of NASA. “It provides a great sense of fulfillment that the technologies we are developing through NASA can impact the everyday lives of everyday people,” she says.\n                        Bio Blend is also working closely with the University of West Florida, where it has a dedicated lab for the testing, creation, and production of new products. “This is a perfect collaborative fit with some of the best academic minds, a talented student pool, and a university president focused on being a think tank for cutting edge technologies,” says O’Neill. In addition, the company will soon open a new blending plant for manufacturing its proprietary and NASA-derived products, and it is exploring ways of using AMTS to remove PCBs from soil.\n                        “We feel very strongly that, from a societal standpoint, we’re in a unique place and time,” says O’Neill. “We are going to have to clean up to continue our quality of life for future generations.” According to Bio Blend, its NASA-developed solutions help enable that goal.\n                        “We have the tools now,” says Kubala. “It’s time to get the word out to the world that there is an answer.”\n                        \n                    \n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Saturn 1B rocket carrying Skylab astronauts lifts off from Kennedy Space Center. Years later, after the launch stand was dismantled, its paint was found to contain toxic chemicals. \n                        \n                      \n                      All research and development has a story behind it, says Jacqueline Quinn, environmental engineer at Kennedy Space Center. For Quinn, one such story begins with the Saturn 1B launch stand at Kennedy and ends with a unique solution to a challenging environmental problem.\n                      Used in a number of Apollo missions and during the Skylab program, the Saturn 1B launch stand was dismantled following the transition to the Space Shuttle Program and stored in an open field at Kennedy. Decades later, the Center’s Environmental Program Office discovered evidence of chemicals called polychlorinated biphenyls (PCBs) in the field’s soil. The findings were puzzling since PCBs—a toxin classified as a probable carcinogen by the Environmental Protection Agency (EPA)—have been banned in the United States since 1979. Before the ban, PCBs were commonly used in transformer oils that leached into the ground when the oils were changed out and dumped near transformer sites, but there were no electrical transformers near the dismantled stand. It soon became apparent that the source of the PCBs was the launch stand itself. Prior to the ban, PCBs were used extensively in paints to add elasticity and other desirable characteristics. The PCB-laden paint on the Saturn 1B launch stand was flaking off into the field’s soil.\n                      “Nobody knew there were PCBs in the paint,” says Quinn, noting that the ingredient was not monitored carefully when it was in use in 1960s. In fact, she says, the U.S. EPA was not even established until 1970, a year after Neil Armstrong first set foot on the Moon. Nobody knew any better at the time, Quinn says, but today, “we have the responsibility to return any natural environmental media to as close to pristine a condition as possible.”\n                      Quinn, fellow engineer Kathleen Loftin, and other Kennedy colleagues already had experience developing unprecedented solutions for environmental contamination; the team invented the emulsified zero-valent iron (EZVI) technology to safely treat groundwater tainted by chlorinated solvents once used to clean rocket engine components. The award-winning innovation (Spinoff 2010) is now NASA’s most licensed technology to date.\n                      PCBs in paint presented a new challenge. Removing the launch stand for recycling proved a difficult operation; the toxic paint had to be fully stripped from the steel structure, a lengthy and costly process that required the stripped paint to be treated before disposal. Noting the lack of efficient, environmentally friendly options for dealing with PCBs, Quinn and her colleagues developed the Activated Metal Treatment System (AMTS).\n                      AMTS is a paste consisting of a solvent solution containing microscale particles of activated zero-valent metal. When applied to a painted surface, the paste extracts and degrades the PCBs into benign byproducts while leaving the paint on the structure. This provides a superior alternative to other methods for PCB remediation, such as stripping the paint or incinerating the structure, which prevents reuse and can release volatized PCBs into the air.\n                      Since its development, AMTS has proven to be a valuable solution for removing PCBs from paint, caulking, and various insulation and filler materials in older buildings, naval ships, and former munitions facilities where the presence of PCBs interferes with methods for removing trace explosive materials. Miles of potentially toxic caulking join sections of runways at airports. Any of these materials installed before 1979 potentially contain PCBs, Quinn says.\n                      “This is not just a NASA problem,” she says. “It’s a global problem.”\n                      Partnership\n                      To provide the benefits of the AMTS solution on a national scale, Kennedy made the technology available for licensing. It quickly caught the eye of a company already familiar with the Center’s environmental innovations. Cantonment, Florida-based Bio Blend Technologies, the remedial arm of U.S. O’Neill Industries, had previously licensed the NASA-developed EZVI technology and saw AMTS as an innovation with significant potential.\n                      “The future for AMTS is untapped,” says Bio Blend COO Roger Kubala. The company licensed the technology, and now, Kubala says, “Bio Blend is capable of cleaning any kind of hydrocarbon contamination, pesticides, PCBs—we’re a one-stop shop for treating all organic chlorides and contaminants.”\n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Bio Blend’s specialized onsite remediation equipment employs the company’s NASA-developed solutions to treat virtually any environmental contaminant. The inset, magnified image shows one of those solutions, the emulsified zero-valent iron or EZVI technology, which consists of tiny iron particles in a water and biodegradable oil emulsification. \n                        \n                      \n                      AMTS joins Bio Blend’s extensive range of remediation tools, including EZVI and the company’s proprietary remediation blends. Employing these products using a mobile system that allows the company to treat and destroy nearly any contaminant onsite, Bio Blend has solved environmental challenges resistant to other treatment methods. \n                      At one site—a Florida gas station where years of leaks from single-skin, underground gas tanks had contaminated the surrounding soil and groundwater—nine years and over $1 million worth of remediation had yielded little effect. Utilizing its NASA and proprietary solutions, Bio Blend cleared 98.9 percent of the contaminants in 77 days at a fraction of the cost. At a similar site, the company reduced the pollutants to nondetect status in 52 days. Owners of contaminated land are often unable to sell their property or even secure loans; Bio Blend’s intervention allows these property owners to regain the value of their land and does not interfere with ongoing business. The gas stations maintained full operations during the remediation.\n                      “It provides a great sense of fulfillment that \n                        the technologies we are developing through NASA \n                        can impact the everyday lives of everyday people.”\n                        —Jacqueline Quinn, \n                        Kennedy Space Center \n                      Bio Blend’s success in these cases results from its pairing of NASA technology with its own innovations, says David O’Neill, president of U.S. O’Neill Industries and Bio Blend. “There was nothing prior to EZVI that would get far enough down into the groundwater. Coupling EZVI with our blends allows you to dig down as deep as you want and eradicate whatever the contaminant is. It is revolutionary.” The AMTS technology takes the company’s capabilities even further, he says. “PCBs are the asbestos of the future. Because there has not been a lot of dialogue about it, there was not a good remediation technique for it until now.”\n                        Quinn finds significant satisfaction in the impact these technologies have outside of NASA. “It provides a great sense of fulfillment that the technologies we are developing through NASA can impact the everyday lives of everyday people,” she says.\n                        Bio Blend is also working closely with the University of West Florida, where it has a dedicated lab for the testing, creation, and production of new products. “This is a perfect collaborative fit with some of the best academic minds, a talented student pool, and a university president focused on being a think tank for cutting edge technologies,” says O’Neill. In addition, the company will soon open a new blending plant for manufacturing its proprietary and NASA-derived products, and it is exploring ways of using AMTS to remove PCBs from soil.\n                        “We feel very strongly that, from a societal standpoint, we’re in a unique place and time,” says O’Neill. “We are going to have to clean up to continue our quality of life for future generations.” According to Bio Blend, its NASA-developed solutions help enable that goal.\n                        “We have the tools now,” says Kubala. “It’s time to get the word out to the world that there is an answer.”\n                        \n                    \n                  \n                \n              \n            \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Saturn 1B rocket carrying Skylab astronauts lifts off from Kennedy Space Center. Years later, after the launch stand was dismantled, its paint was found to contain toxic chemicals. \n                        \n                      \n                      All research and development has a story behind it, says Jacqueline Quinn, environmental engineer at Kennedy Space Center. For Quinn, one such story begins with the Saturn 1B launch stand at Kennedy and ends with a unique solution to a challenging environmental problem.\n                      Used in a number of Apollo missions and during the Skylab program, the Saturn 1B launch stand was dismantled following the transition to the Space Shuttle Program and stored in an open field at Kennedy. Decades later, the Center’s Environmental Program Office discovered evidence of chemicals called polychlorinated biphenyls (PCBs) in the field’s soil. The findings were puzzling since PCBs—a toxin classified as a probable carcinogen by the Environmental Protection Agency (EPA)—have been banned in the United States since 1979. Before the ban, PCBs were commonly used in transformer oils that leached into the ground when the oils were changed out and dumped near transformer sites, but there were no electrical transformers near the dismantled stand. It soon became apparent that the source of the PCBs was the launch stand itself. Prior to the ban, PCBs were used extensively in paints to add elasticity and other desirable characteristics. The PCB-laden paint on the Saturn 1B launch stand was flaking off into the field’s soil.\n                      “Nobody knew there were PCBs in the paint,” says Quinn, noting that the ingredient was not monitored carefully when it was in use in 1960s. In fact, she says, the U.S. EPA was not even established until 1970, a year after Neil Armstrong first set foot on the Moon. Nobody knew any better at the time, Quinn says, but today, “we have the responsibility to return any natural environmental media to as close to pristine a condition as possible.”\n                      Quinn, fellow engineer Kathleen Loftin, and other Kennedy colleagues already had experience developing unprecedented solutions for environmental contamination; the team invented the emulsified zero-valent iron (EZVI) technology to safely treat groundwater tainted by chlorinated solvents once used to clean rocket engine components. The award-winning innovation (Spinoff 2010) is now NASA’s most licensed technology to date.\n                      PCBs in paint presented a new challenge. Removing the launch stand for recycling proved a difficult operation; the toxic paint had to be fully stripped from the steel structure, a lengthy and costly process that required the stripped paint to be treated before disposal. Noting the lack of efficient, environmentally friendly options for dealing with PCBs, Quinn and her colleagues developed the Activated Metal Treatment System (AMTS).\n                      AMTS is a paste consisting of a solvent solution containing microscale particles of activated zero-valent metal. When applied to a painted surface, the paste extracts and degrades the PCBs into benign byproducts while leaving the paint on the structure. This provides a superior alternative to other methods for PCB remediation, such as stripping the paint or incinerating the structure, which prevents reuse and can release volatized PCBs into the air.\n                      Since its development, AMTS has proven to be a valuable solution for removing PCBs from paint, caulking, and various insulation and filler materials in older buildings, naval ships, and former munitions facilities where the presence of PCBs interferes with methods for removing trace explosive materials. Miles of potentially toxic caulking join sections of runways at airports. Any of these materials installed before 1979 potentially contain PCBs, Quinn says.\n                      “This is not just a NASA problem,” she says. “It’s a global problem.”\n                      Partnership\n                      To provide the benefits of the AMTS solution on a national scale, Kennedy made the technology available for licensing. It quickly caught the eye of a company already familiar with the Center’s environmental innovations. Cantonment, Florida-based Bio Blend Technologies, the remedial arm of U.S. O’Neill Industries, had previously licensed the NASA-developed EZVI technology and saw AMTS as an innovation with significant potential.\n                      “The future for AMTS is untapped,” says Bio Blend COO Roger Kubala. The company licensed the technology, and now, Kubala says, “Bio Blend is capable of cleaning any kind of hydrocarbon contamination, pesticides, PCBs—we’re a one-stop shop for treating all organic chlorides and contaminants.”\n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Bio Blend’s specialized onsite remediation equipment employs the company’s NASA-developed solutions to treat virtually any environmental contaminant. The inset, magnified image shows one of those solutions, the emulsified zero-valent iron or EZVI technology, which consists of tiny iron particles in a water and biodegradable oil emulsification. \n                        \n                      \n                      AMTS joins Bio Blend’s extensive range of remediation tools, including EZVI and the company’s proprietary remediation blends. Employing these products using a mobile system that allows the company to treat and destroy nearly any contaminant onsite, Bio Blend has solved environmental challenges resistant to other treatment methods. \n                      At one site—a Florida gas station where years of leaks from single-skin, underground gas tanks had contaminated the surrounding soil and groundwater—nine years and over $1 million worth of remediation had yielded little effect. Utilizing its NASA and proprietary solutions, Bio Blend cleared 98.9 percent of the contaminants in 77 days at a fraction of the cost. At a similar site, the company reduced the pollutants to nondetect status in 52 days. Owners of contaminated land are often unable to sell their property or even secure loans; Bio Blend’s intervention allows these property owners to regain the value of their land and does not interfere with ongoing business. The gas stations maintained full operations during the remediation.\n                      “It provides a great sense of fulfillment that \n                        the technologies we are developing through NASA \n                        can impact the everyday lives of everyday people.”\n                        —Jacqueline Quinn, \n                        Kennedy Space Center \n                      Bio Blend’s success in these cases results from its pairing of NASA technology with its own innovations, says David O’Neill, president of U.S. O’Neill Industries and Bio Blend. “There was nothing prior to EZVI that would get far enough down into the groundwater. Coupling EZVI with our blends allows you to dig down as deep as you want and eradicate whatever the contaminant is. It is revolutionary.” The AMTS technology takes the company’s capabilities even further, he says. “PCBs are the asbestos of the future. Because there has not been a lot of dialogue about it, there was not a good remediation technique for it until now.”\n                        Quinn finds significant satisfaction in the impact these technologies have outside of NASA. “It provides a great sense of fulfillment that the technologies we are developing through NASA can impact the everyday lives of everyday people,” she says.\n                        Bio Blend is also working closely with the University of West Florida, where it has a dedicated lab for the testing, creation, and production of new products. “This is a perfect collaborative fit with some of the best academic minds, a talented student pool, and a university president focused on being a think tank for cutting edge technologies,” says O’Neill. In addition, the company will soon open a new blending plant for manufacturing its proprietary and NASA-derived products, and it is exploring ways of using AMTS to remove PCBs from soil.\n                        “We feel very strongly that, from a societal standpoint, we’re in a unique place and time,” says O’Neill. “We are going to have to clean up to continue our quality of life for future generations.” According to Bio Blend, its NASA-developed solutions help enable that goal.\n                        “We have the tools now,” says Kubala. “It’s time to get the word out to the world that there is an answer.”\n                        \n                    \n                  \n                \n              \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Saturn 1B rocket carrying Skylab astronauts lifts off from Kennedy Space Center. Years later, after the launch stand was dismantled, its paint was found to contain toxic chemicals. \n                        \n                      \n                      All research and development has a story behind it, says Jacqueline Quinn, environmental engineer at Kennedy Space Center. For Quinn, one such story begins with the Saturn 1B launch stand at Kennedy and ends with a unique solution to a challenging environmental problem.\n                      Used in a number of Apollo missions and during the Skylab program, the Saturn 1B launch stand was dismantled following the transition to the Space Shuttle Program and stored in an open field at Kennedy. Decades later, the Center’s Environmental Program Office discovered evidence of chemicals called polychlorinated biphenyls (PCBs) in the field’s soil. The findings were puzzling since PCBs—a toxin classified as a probable carcinogen by the Environmental Protection Agency (EPA)—have been banned in the United States since 1979. Before the ban, PCBs were commonly used in transformer oils that leached into the ground when the oils were changed out and dumped near transformer sites, but there were no electrical transformers near the dismantled stand. It soon became apparent that the source of the PCBs was the launch stand itself. Prior to the ban, PCBs were used extensively in paints to add elasticity and other desirable characteristics. The PCB-laden paint on the Saturn 1B launch stand was flaking off into the field’s soil.\n                      “Nobody knew there were PCBs in the paint,” says Quinn, noting that the ingredient was not monitored carefully when it was in use in 1960s. In fact, she says, the U.S. EPA was not even established until 1970, a year after Neil Armstrong first set foot on the Moon. Nobody knew any better at the time, Quinn says, but today, “we have the responsibility to return any natural environmental media to as close to pristine a condition as possible.”\n                      Quinn, fellow engineer Kathleen Loftin, and other Kennedy colleagues already had experience developing unprecedented solutions for environmental contamination; the team invented the emulsified zero-valent iron (EZVI) technology to safely treat groundwater tainted by chlorinated solvents once used to clean rocket engine components. The award-winning innovation (Spinoff 2010) is now NASA’s most licensed technology to date.\n                      PCBs in paint presented a new challenge. Removing the launch stand for recycling proved a difficult operation; the toxic paint had to be fully stripped from the steel structure, a lengthy and costly process that required the stripped paint to be treated before disposal. Noting the lack of efficient, environmentally friendly options for dealing with PCBs, Quinn and her colleagues developed the Activated Metal Treatment System (AMTS).\n                      AMTS is a paste consisting of a solvent solution containing microscale particles of activated zero-valent metal. When applied to a painted surface, the paste extracts and degrades the PCBs into benign byproducts while leaving the paint on the structure. This provides a superior alternative to other methods for PCB remediation, such as stripping the paint or incinerating the structure, which prevents reuse and can release volatized PCBs into the air.\n                      Since its development, AMTS has proven to be a valuable solution for removing PCBs from paint, caulking, and various insulation and filler materials in older buildings, naval ships, and former munitions facilities where the presence of PCBs interferes with methods for removing trace explosive materials. Miles of potentially toxic caulking join sections of runways at airports. Any of these materials installed before 1979 potentially contain PCBs, Quinn says.\n                      “This is not just a NASA problem,” she says. “It’s a global problem.”\n                      Partnership\n                      To provide the benefits of the AMTS solution on a national scale, Kennedy made the technology available for licensing. It quickly caught the eye of a company already familiar with the Center’s environmental innovations. Cantonment, Florida-based Bio Blend Technologies, the remedial arm of U.S. O’Neill Industries, had previously licensed the NASA-developed EZVI technology and saw AMTS as an innovation with significant potential.\n                      “The future for AMTS is untapped,” says Bio Blend COO Roger Kubala. The company licensed the technology, and now, Kubala says, “Bio Blend is capable of cleaning any kind of hydrocarbon contamination, pesticides, PCBs—we’re a one-stop shop for treating all organic chlorides and contaminants.”\n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Bio Blend’s specialized onsite remediation equipment employs the company’s NASA-developed solutions to treat virtually any environmental contaminant. The inset, magnified image shows one of those solutions, the emulsified zero-valent iron or EZVI technology, which consists of tiny iron particles in a water and biodegradable oil emulsification. \n                        \n                      \n                      AMTS joins Bio Blend’s extensive range of remediation tools, including EZVI and the company’s proprietary remediation blends. Employing these products using a mobile system that allows the company to treat and destroy nearly any contaminant onsite, Bio Blend has solved environmental challenges resistant to other treatment methods. \n                      At one site—a Florida gas station where years of leaks from single-skin, underground gas tanks had contaminated the surrounding soil and groundwater—nine years and over $1 million worth of remediation had yielded little effect. Utilizing its NASA and proprietary solutions, Bio Blend cleared 98.9 percent of the contaminants in 77 days at a fraction of the cost. At a similar site, the company reduced the pollutants to nondetect status in 52 days. Owners of contaminated land are often unable to sell their property or even secure loans; Bio Blend’s intervention allows these property owners to regain the value of their land and does not interfere with ongoing business. The gas stations maintained full operations during the remediation.\n                      “It provides a great sense of fulfillment that \n                        the technologies we are developing through NASA \n                        can impact the everyday lives of everyday people.”\n                        —Jacqueline Quinn, \n                        Kennedy Space Center \n                      Bio Blend’s success in these cases results from its pairing of NASA technology with its own innovations, says David O’Neill, president of U.S. O’Neill Industries and Bio Blend. “There was nothing prior to EZVI that would get far enough down into the groundwater. Coupling EZVI with our blends allows you to dig down as deep as you want and eradicate whatever the contaminant is. It is revolutionary.” The AMTS technology takes the company’s capabilities even further, he says. “PCBs are the asbestos of the future. Because there has not been a lot of dialogue about it, there was not a good remediation technique for it until now.”\n                        Quinn finds significant satisfaction in the impact these technologies have outside of NASA. “It provides a great sense of fulfillment that the technologies we are developing through NASA can impact the everyday lives of everyday people,” she says.\n                        Bio Blend is also working closely with the University of West Florida, where it has a dedicated lab for the testing, creation, and production of new products. “This is a perfect collaborative fit with some of the best academic minds, a talented student pool, and a university president focused on being a think tank for cutting edge technologies,” says O’Neill. In addition, the company will soon open a new blending plant for manufacturing its proprietary and NASA-derived products, and it is exploring ways of using AMTS to remove PCBs from soil.\n                        “We feel very strongly that, from a societal standpoint, we’re in a unique place and time,” says O’Neill. “We are going to have to clean up to continue our quality of life for future generations.” According to Bio Blend, its NASA-developed solutions help enable that goal.\n                        “We have the tools now,” says Kubala. “It’s time to get the word out to the world that there is an answer.”\n                        \n                    \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Saturn 1B rocket carrying Skylab astronauts lifts off from Kennedy Space Center. Years later, after the launch stand was dismantled, its paint was found to contain toxic chemicals. \n                        \n                      \n                      All research and development has a story behind it, says Jacqueline Quinn, environmental engineer at Kennedy Space Center. For Quinn, one such story begins with the Saturn 1B launch stand at Kennedy and ends with a unique solution to a challenging environmental problem.\n                      Used in a number of Apollo missions and during the Skylab program, the Saturn 1B launch stand was dismantled following the transition to the Space Shuttle Program and stored in an open field at Kennedy. Decades later, the Center’s Environmental Program Office discovered evidence of chemicals called polychlorinated biphenyls (PCBs) in the field’s soil. The findings were puzzling since PCBs—a toxin classified as a probable carcinogen by the Environmental Protection Agency (EPA)—have been banned in the United States since 1979. Before the ban, PCBs were commonly used in transformer oils that leached into the ground when the oils were changed out and dumped near transformer sites, but there were no electrical transformers near the dismantled stand. It soon became apparent that the source of the PCBs was the launch stand itself. Prior to the ban, PCBs were used extensively in paints to add elasticity and other desirable characteristics. The PCB-laden paint on the Saturn 1B launch stand was flaking off into the field’s soil.\n                      “Nobody knew there were PCBs in the paint,” says Quinn, noting that the ingredient was not monitored carefully when it was in use in 1960s. In fact, she says, the U.S. EPA was not even established until 1970, a year after Neil Armstrong first set foot on the Moon. Nobody knew any better at the time, Quinn says, but today, “we have the responsibility to return any natural environmental media to as close to pristine a condition as possible.”\n                      Quinn, fellow engineer Kathleen Loftin, and other Kennedy colleagues already had experience developing unprecedented solutions for environmental contamination; the team invented the emulsified zero-valent iron (EZVI) technology to safely treat groundwater tainted by chlorinated solvents once used to clean rocket engine components. The award-winning innovation (Spinoff 2010) is now NASA’s most licensed technology to date.\n                      PCBs in paint presented a new challenge. Removing the launch stand for recycling proved a difficult operation; the toxic paint had to be fully stripped from the steel structure, a lengthy and costly process that required the stripped paint to be treated before disposal. Noting the lack of efficient, environmentally friendly options for dealing with PCBs, Quinn and her colleagues developed the Activated Metal Treatment System (AMTS).\n                      AMTS is a paste consisting of a solvent solution containing microscale particles of activated zero-valent metal. When applied to a painted surface, the paste extracts and degrades the PCBs into benign byproducts while leaving the paint on the structure. This provides a superior alternative to other methods for PCB remediation, such as stripping the paint or incinerating the structure, which prevents reuse and can release volatized PCBs into the air.\n                      Since its development, AMTS has proven to be a valuable solution for removing PCBs from paint, caulking, and various insulation and filler materials in older buildings, naval ships, and former munitions facilities where the presence of PCBs interferes with methods for removing trace explosive materials. Miles of potentially toxic caulking join sections of runways at airports. Any of these materials installed before 1979 potentially contain PCBs, Quinn says.\n                      “This is not just a NASA problem,” she says. “It’s a global problem.”\n                      Partnership\n                      To provide the benefits of the AMTS solution on a national scale, Kennedy made the technology available for licensing. It quickly caught the eye of a company already familiar with the Center’s environmental innovations. Cantonment, Florida-based Bio Blend Technologies, the remedial arm of U.S. O’Neill Industries, had previously licensed the NASA-developed EZVI technology and saw AMTS as an innovation with significant potential.\n                      “The future for AMTS is untapped,” says Bio Blend COO Roger Kubala. The company licensed the technology, and now, Kubala says, “Bio Blend is capable of cleaning any kind of hydrocarbon contamination, pesticides, PCBs—we’re a one-stop shop for treating all organic chlorides and contaminants.”\n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Bio Blend’s specialized onsite remediation equipment employs the company’s NASA-developed solutions to treat virtually any environmental contaminant. The inset, magnified image shows one of those solutions, the emulsified zero-valent iron or EZVI technology, which consists of tiny iron particles in a water and biodegradable oil emulsification. \n                        \n                      \n                      AMTS joins Bio Blend’s extensive range of remediation tools, including EZVI and the company’s proprietary remediation blends. Employing these products using a mobile system that allows the company to treat and destroy nearly any contaminant onsite, Bio Blend has solved environmental challenges resistant to other treatment methods. \n                      At one site—a Florida gas station where years of leaks from single-skin, underground gas tanks had contaminated the surrounding soil and groundwater—nine years and over $1 million worth of remediation had yielded little effect. Utilizing its NASA and proprietary solutions, Bio Blend cleared 98.9 percent of the contaminants in 77 days at a fraction of the cost. At a similar site, the company reduced the pollutants to nondetect status in 52 days. Owners of contaminated land are often unable to sell their property or even secure loans; Bio Blend’s intervention allows these property owners to regain the value of their land and does not interfere with ongoing business. The gas stations maintained full operations during the remediation.\n                      “It provides a great sense of fulfillment that \n                        the technologies we are developing through NASA \n                        can impact the everyday lives of everyday people.”\n                        —Jacqueline Quinn, \n                        Kennedy Space Center \n                      Bio Blend’s success in these cases results from its pairing of NASA technology with its own innovations, says David O’Neill, president of U.S. O’Neill Industries and Bio Blend. “There was nothing prior to EZVI that would get far enough down into the groundwater. Coupling EZVI with our blends allows you to dig down as deep as you want and eradicate whatever the contaminant is. It is revolutionary.” The AMTS technology takes the company’s capabilities even further, he says. “PCBs are the asbestos of the future. Because there has not been a lot of dialogue about it, there was not a good remediation technique for it until now.”\n                        Quinn finds significant satisfaction in the impact these technologies have outside of NASA. “It provides a great sense of fulfillment that the technologies we are developing through NASA can impact the everyday lives of everyday people,” she says.\n                        Bio Blend is also working closely with the University of West Florida, where it has a dedicated lab for the testing, creation, and production of new products. “This is a perfect collaborative fit with some of the best academic minds, a talented student pool, and a university president focused on being a think tank for cutting edge technologies,” says O’Neill. In addition, the company will soon open a new blending plant for manufacturing its proprietary and NASA-derived products, and it is exploring ways of using AMTS to remove PCBs from soil.\n                        “We feel very strongly that, from a societal standpoint, we’re in a unique place and time,” says O’Neill. “We are going to have to clean up to continue our quality of life for future generations.” According to Bio Blend, its NASA-developed solutions help enable that goal.\n                        “We have the tools now,” says Kubala. “It’s time to get the word out to the world that there is an answer.”\n                        \n                    NASA TechnologyAll research and development has a story behind it, says Jacqueline Quinn, environmental engineer at Kennedy Space Center. For Quinn, one such story begins with the Saturn 1B launch stand at Kennedy and ends with a unique solution to a challenging environmental problem.Used in a number of Apollo missions and during the Skylab program, the Saturn 1B launch stand was dismantled following the transition to the Space Shuttle Program and stored in an open field at Kennedy. Decades later, the Center’s Environmental Program Office discovered evidence of chemicals called polychlorinated biphenyls (PCBs) in the field’s soil. The findings were puzzling since PCBs—a toxin classified as a probable carcinogen by the Environmental Protection Agency (EPA)—have been banned in the United States since 1979. Before the ban, PCBs were commonly used in transformer oils that leached into the ground when the oils were changed out and dumped near transformer sites, but there were no electrical transformers near the dismantled stand. It soon became apparent that the source of the PCBs was the launch stand itself. Prior to the ban, PCBs were used extensively in paints to add elasticity and other desirable characteristics. The PCB-laden paint on the Saturn 1B launch stand was flaking off into the field’s soil.“Nobody knew there were PCBs in the paint,” says Quinn, noting that the ingredient was not monitored carefully when it was in use in 1960s. In fact, she says, the U.S. EPA was not even established until 1970, a year after Neil Armstrong first set foot on the Moon. Nobody knew any better at the time, Quinn says, but today, “we have the responsibility to return any natural environmental media to as close to pristine a condition as possible.”Quinn, fellow engineer Kathleen Loftin, and other Kennedy colleagues already had experience developing unprecedented solutions for environmental contamination; the team invented the emulsified zero-valent iron (EZVI) technology to safely treat groundwater tainted by chlorinated solvents once used to clean rocket engine components. The award-winning innovation (Spinoff 2010) is now NASA’s most licensed technology to date.PCBs in paint presented a new challenge. Removing the launch stand for recycling proved a difficult operation; the toxic paint had to be fully stripped from the steel structure, a lengthy and costly process that required the stripped paint to be treated before disposal. Noting the lack of efficient, environmentally friendly options for dealing with PCBs, Quinn and her colleagues developed the Activated Metal Treatment System (AMTS).AMTS is a paste consisting of a solvent solution containing microscale particles of activated zero-valent metal. When applied to a painted surface, the paste extracts and degrades the PCBs into benign byproducts while leaving the paint on the structure. This provides a superior alternative to other methods for PCB remediation, such as stripping the paint or incinerating the structure, which prevents reuse and can release volatized PCBs into the air.Since its development, AMTS has proven to be a valuable solution for removing PCBs from paint, caulking, and various insulation and filler materials in older buildings, naval ships, and former munitions facilities where the presence of PCBs interferes with methods for removing trace explosive materials. Miles of potentially toxic caulking join sections of runways at airports. Any of these materials installed before 1979 potentially contain PCBs, Quinn says.“This is not just a NASA problem,” she says. “It’s a global problem.”PartnershipTo provide the benefits of the AMTS solution on a national scale, Kennedy made the technology available for licensing. It quickly caught the eye of a company already familiar with the Center’s environmental innovations. Cantonment, Florida-based Bio Blend Technologies, the remedial arm of U.S. O’Neill Industries, had previously licensed the NASA-developed EZVI technology and saw AMTS as an innovation with significant potential.“The future for AMTS is untapped,” says Bio Blend COO Roger Kubala. The company licensed the technology, and now, Kubala says, “Bio Blend is capable of cleaning any kind of hydrocarbon contamination, pesticides, PCBs—we’re a one-stop shop for treating all organic chlorides and contaminants.”BenefitsAMTS joins Bio Blend’s extensive range of remediation tools, including EZVI and the company’s proprietary remediation blends. Employing these products using a mobile system that allows the company to treat and destroy nearly any contaminant onsite, Bio Blend has solved environmental challenges resistant to other treatment methods. At one site—a Florida gas station where years of leaks from single-skin, underground gas tanks had contaminated the surrounding soil and groundwater—nine years and over $1 million worth of remediation had yielded little effect. Utilizing its NASA and proprietary solutions, Bio Blend cleared 98.9 percent of the contaminants in 77 days at a fraction of the cost. At a similar site, the company reduced the pollutants to nondetect status in 52 days. Owners of contaminated land are often unable to sell their property or even secure loans; Bio Blend’s intervention allows these property owners to regain the value of their land and does not interfere with ongoing business. The gas stations maintained full operations during the remediation.Bio Blend’s success in these cases results from its pairing of NASA technology with its own innovations, says David O’Neill, president of U.S. O’Neill Industries and Bio Blend. “There was nothing prior to EZVI that would get far enough down into the groundwater. Coupling EZVI with our blends allows you to dig down as deep as you want and eradicate whatever the contaminant is. It is revolutionary.” The AMTS technology takes the company’s capabilities even further, he says. “PCBs are the asbestos of the future. Because there has not been a lot of dialogue about it, there was not a good remediation technique for it until now.”\n                        Quinn finds significant satisfaction in the impact these technologies have outside of NASA. “It provides a great sense of fulfillment that the technologies we are developing through NASA can impact the everyday lives of everyday people,” she says.\n                        Bio Blend is also working closely with the University of West Florida, where it has a dedicated lab for the testing, creation, and production of new products. “This is a perfect collaborative fit with some of the best academic minds, a talented student pool, and a university president focused on being a think tank for cutting edge technologies,” says O’Neill. In addition, the company will soon open a new blending plant for manufacturing its proprietary and NASA-derived products, and it is exploring ways of using AMTS to remove PCBs from soil.\n                        “We feel very strongly that, from a societal standpoint, we’re in a unique place and time,” says O’Neill. “We are going to have to clean up to continue our quality of life for future generations.” According to Bio Blend, its NASA-developed solutions help enable that goal.\n                        “We have the tools now,” says Kubala. “It’s time to get the word out to the world that there is an answer.”\n                        "},{"href":"http://spinoff.nasa.gov/Spinoff2011/er_4.html","text":"Receivers Gather Data for Climate Research, Weather Prediction","image":"http://spinoff.nasa.gov/Spinoff2011/Images/er_7a_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      Signals from global positioning system (GPS) satellites are now being used for more than just location and navigation information. By looking at the radio waves from GPS satellites, a technology developed at NASA’s Jet Propulsion Laboratory (JPL) not only precisely calculates its position, but can also use a technique known as radio occultation to help scientists study the Earth’s atmosphere and gravity field to improve weather forecasts, monitor climate change, and enhance space weather research.\n                      \n                        \n                        \n                          \n                        \n                        \n                          This artist’s illustration shows six microsatellites entering low-Earth orbit to form the Constellation Observing System for Meteorology, Ionosphere, and Climate.\n                        \n                      \n                      The University Corporation for Atmospheric Research (UCAR), a nonprofit group of universities in Boulder, Colorado, compares radio occultation to the appearance of a pencil when viewed though a glass of water. The water molecules change the path of visible light waves so that the pencil appears bent, just like molecules in the air bend GPS radio signals as they pass through (or are occulted by) the atmosphere. Through measurements of the amount of bending in the signals, scientists can construct detailed images of the ionosphere (the energetic upper part of the atmosphere) and also gather information about atmospheric density, pressure, temperature, and moisture. Once collected, this data can be input into weather forecasting and climate models for weather prediction and climate studies. Traditionally, such information is obtained through the use of weather balloons.\n                      In 1998, JPL started developing a new class of GPS space science receivers, called Black Jack, that could take precise measurements of how GPS signals are distorted or delayed along their way to the receiver. By 2006, the first demonstration of a GPS radio occultation constellation was launched through a collaboration among Taiwan’s National Science Council and National Space Organization, the U.S. National Science Foundation, NASA, the National Oceanic and Atmospheric Administration (NOAA), and other Federal entities. Called the Constellation Observing System for Meteorology, Ionosphere, and Climate (COSMIC), JPL was responsible for designing COSMIC’s primary instrument—based on its revolutionary Black Jack receiver.\n                      Partnership\n                      To produce the Black Jack GPS radio occultation receivers required for COSMIC, JPL turned to Tempe, Arizona-based Broad Reach Engineering Company (BRE). BRE made enhancements to JPL’s existing technology, including the addition of an internal redundancy feature and internal mass memory. BRE built the new receivers, and while delivering the flight hardware for the COSMIC program, entered into a license agreement for the technology that extends to 2017. \n                      As a result of the license agreement, BRE commercialized a new product called the Integrated GPS Occultation Receiver (IGOR) based on NASA’s Black Jack device. “After the successful transfer of commercial technology to BRE, the company further improved it—allowing for increased parts reliability and the ability to modify the digital signal processing algorithms while on orbit,” says Garth Franklin, supervisor of the advanced radiometric and gravity sensing instruments group at JPL.\n                      Benefits\n                      With one of the company’s main products being an integrated avionics unit (IAU) that provides all satellite command and data handling, electrical power system, and payload interface capability from a single box, BRE now offers an additional option, based on the NASA receiver, as a standalone GPS receiver or as part of the IAU. “We can handle power inputs, switching and distribution, uplink and downlink, and payload interfaces—it’s a tightly integrated solution for satellites. The Black Jack technology provides us with another product line of avionics to offer to our customers,” says Dan Smith, a project manager at Broad Reach Engineering.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Broad Reach Engineering Company licensed NASA technology, which is now provided through the company’s Integrated GPS Occultation Receiver.\n                        \n                      \n                      As a dual-frequency (frequencies L1 and L2) receiver, IGOR is available in two versions for low-Earth orbit: as a receiver for precision orbit determination (POD) only, or as a receiver for both POD and radio occultation. “IGOR provides orbit determination, which is similar to other GPS receivers on the market. However, the unique feature is that IGOR has the radio occultation science capability,” says Smith.\n                      IGOR also features a solid state recorder that allows the recording of extra data in case there are problems with the downlink at ground stations, and a payload controller that can control additional instruments on the satellite. “We repackaged it a little bit, but we didn’t touch any of the JPL items such as the signal acquisition and tracking algorithms. We focused on the hardware,” says Smith.\n                      Designed to meet all of the requirements of occultation science experiments, IGOR is currently being used by NASA, as well as by German, Korean, and Brazilian organizations. To date, nine IGOR receivers have been deployed on orbit: six flight units for COSMIC, one flight unit for the German TerraSAR-X, one flight unit for the German Tandem-X, and one flight unit for the U.S. Air Force Research Laboratory’s TACSAT-2 (which is no longer operational). Two additional flight units have been delivered, including one to Korea for KOMPSAT-5, and one to Brazil for LATTES. While BRE is currently working on a flight build for the Spanish PAZ, company personnel are also in discussions with Japanese customers. \n                      “Some of the international agencies collaborate with NOAA or UCAR, and they are basically building the global dataset for radio occultation,” says Smith. “As they input the radio occultation data into the operational NOAA weather models, the severe weather forecasting has improved significantly. The data is indicating that hurricane tracking predictions are improving.” \n                      According to UCAR, data from COSMIC has proven valuable for weather forecasting, hurricane forecasting, and investigation of the atmospheric boundary layer (the lowest part of the atmosphere). The data has also proven useful for testing ionospheric models, is being used for space weather models, and can potentially benefit climate studies, due to its high precision and global and daily sampling coverage. As Franklin describes, “Temperature, pressure, water vapor, and electron content can be retrieved in a widely distributed way as each of the 31 GPS spacecraft signals are observed by the six COSMIC spacecraft, cutting though Earth’s atmosphere on average of 1,500 times per day.” This is the first time such large amounts of data have been obtained on a global scale.\n                      After introducing the benefits of IGOR to the satellite industry, BRE licensed additional technology from Goddard Space Flight Center in 2011. Called Navigator, the NASA-derived GPS receiver can acquire and track the weaker signals broadcast by GPS satellites to enable navigation in geosynchronous orbits (GEO) and highly elliptical orbits (HEO), where typical GPS receivers fail to pick up a signal. “Goddard provided the software, algorithms, and Kalman filtering. Again, we repackaged the hardware and coordinated initial bench-top performance testing with Goddard. This effort allowed us to make it part of our IAU, creating another hardware option for satellites considering these type of missions,” says Smith. \n                      The first use of BRE’s version of Navigator will fly on the Air Force Research Laboratory’s Nanosatellite Guardian for Evaluating Local Space (ANGELS) mission, planned for 2012.\n                      While Smith looks forward to continued collaborations with NASA to make the next generation of GPS receivers for tracking additional frequencies, in the meantime, he says, “As we continually look for options in the best interest of flight hardware, we have a good product line based on NASA technology.\n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      Signals from global positioning system (GPS) satellites are now being used for more than just location and navigation information. By looking at the radio waves from GPS satellites, a technology developed at NASA’s Jet Propulsion Laboratory (JPL) not only precisely calculates its position, but can also use a technique known as radio occultation to help scientists study the Earth’s atmosphere and gravity field to improve weather forecasts, monitor climate change, and enhance space weather research.\n                      \n                        \n                        \n                          \n                        \n                        \n                          This artist’s illustration shows six microsatellites entering low-Earth orbit to form the Constellation Observing System for Meteorology, Ionosphere, and Climate.\n                        \n                      \n                      The University Corporation for Atmospheric Research (UCAR), a nonprofit group of universities in Boulder, Colorado, compares radio occultation to the appearance of a pencil when viewed though a glass of water. The water molecules change the path of visible light waves so that the pencil appears bent, just like molecules in the air bend GPS radio signals as they pass through (or are occulted by) the atmosphere. Through measurements of the amount of bending in the signals, scientists can construct detailed images of the ionosphere (the energetic upper part of the atmosphere) and also gather information about atmospheric density, pressure, temperature, and moisture. Once collected, this data can be input into weather forecasting and climate models for weather prediction and climate studies. Traditionally, such information is obtained through the use of weather balloons.\n                      In 1998, JPL started developing a new class of GPS space science receivers, called Black Jack, that could take precise measurements of how GPS signals are distorted or delayed along their way to the receiver. By 2006, the first demonstration of a GPS radio occultation constellation was launched through a collaboration among Taiwan’s National Science Council and National Space Organization, the U.S. National Science Foundation, NASA, the National Oceanic and Atmospheric Administration (NOAA), and other Federal entities. Called the Constellation Observing System for Meteorology, Ionosphere, and Climate (COSMIC), JPL was responsible for designing COSMIC’s primary instrument—based on its revolutionary Black Jack receiver.\n                      Partnership\n                      To produce the Black Jack GPS radio occultation receivers required for COSMIC, JPL turned to Tempe, Arizona-based Broad Reach Engineering Company (BRE). BRE made enhancements to JPL’s existing technology, including the addition of an internal redundancy feature and internal mass memory. BRE built the new receivers, and while delivering the flight hardware for the COSMIC program, entered into a license agreement for the technology that extends to 2017. \n                      As a result of the license agreement, BRE commercialized a new product called the Integrated GPS Occultation Receiver (IGOR) based on NASA’s Black Jack device. “After the successful transfer of commercial technology to BRE, the company further improved it—allowing for increased parts reliability and the ability to modify the digital signal processing algorithms while on orbit,” says Garth Franklin, supervisor of the advanced radiometric and gravity sensing instruments group at JPL.\n                      Benefits\n                      With one of the company’s main products being an integrated avionics unit (IAU) that provides all satellite command and data handling, electrical power system, and payload interface capability from a single box, BRE now offers an additional option, based on the NASA receiver, as a standalone GPS receiver or as part of the IAU. “We can handle power inputs, switching and distribution, uplink and downlink, and payload interfaces—it’s a tightly integrated solution for satellites. The Black Jack technology provides us with another product line of avionics to offer to our customers,” says Dan Smith, a project manager at Broad Reach Engineering.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Broad Reach Engineering Company licensed NASA technology, which is now provided through the company’s Integrated GPS Occultation Receiver.\n                        \n                      \n                      As a dual-frequency (frequencies L1 and L2) receiver, IGOR is available in two versions for low-Earth orbit: as a receiver for precision orbit determination (POD) only, or as a receiver for both POD and radio occultation. “IGOR provides orbit determination, which is similar to other GPS receivers on the market. However, the unique feature is that IGOR has the radio occultation science capability,” says Smith.\n                      IGOR also features a solid state recorder that allows the recording of extra data in case there are problems with the downlink at ground stations, and a payload controller that can control additional instruments on the satellite. “We repackaged it a little bit, but we didn’t touch any of the JPL items such as the signal acquisition and tracking algorithms. We focused on the hardware,” says Smith.\n                      Designed to meet all of the requirements of occultation science experiments, IGOR is currently being used by NASA, as well as by German, Korean, and Brazilian organizations. To date, nine IGOR receivers have been deployed on orbit: six flight units for COSMIC, one flight unit for the German TerraSAR-X, one flight unit for the German Tandem-X, and one flight unit for the U.S. Air Force Research Laboratory’s TACSAT-2 (which is no longer operational). Two additional flight units have been delivered, including one to Korea for KOMPSAT-5, and one to Brazil for LATTES. While BRE is currently working on a flight build for the Spanish PAZ, company personnel are also in discussions with Japanese customers. \n                      “Some of the international agencies collaborate with NOAA or UCAR, and they are basically building the global dataset for radio occultation,” says Smith. “As they input the radio occultation data into the operational NOAA weather models, the severe weather forecasting has improved significantly. The data is indicating that hurricane tracking predictions are improving.” \n                      According to UCAR, data from COSMIC has proven valuable for weather forecasting, hurricane forecasting, and investigation of the atmospheric boundary layer (the lowest part of the atmosphere). The data has also proven useful for testing ionospheric models, is being used for space weather models, and can potentially benefit climate studies, due to its high precision and global and daily sampling coverage. As Franklin describes, “Temperature, pressure, water vapor, and electron content can be retrieved in a widely distributed way as each of the 31 GPS spacecraft signals are observed by the six COSMIC spacecraft, cutting though Earth’s atmosphere on average of 1,500 times per day.” This is the first time such large amounts of data have been obtained on a global scale.\n                      After introducing the benefits of IGOR to the satellite industry, BRE licensed additional technology from Goddard Space Flight Center in 2011. Called Navigator, the NASA-derived GPS receiver can acquire and track the weaker signals broadcast by GPS satellites to enable navigation in geosynchronous orbits (GEO) and highly elliptical orbits (HEO), where typical GPS receivers fail to pick up a signal. “Goddard provided the software, algorithms, and Kalman filtering. Again, we repackaged the hardware and coordinated initial bench-top performance testing with Goddard. This effort allowed us to make it part of our IAU, creating another hardware option for satellites considering these type of missions,” says Smith. \n                      The first use of BRE’s version of Navigator will fly on the Air Force Research Laboratory’s Nanosatellite Guardian for Evaluating Local Space (ANGELS) mission, planned for 2012.\n                      While Smith looks forward to continued collaborations with NASA to make the next generation of GPS receivers for tracking additional frequencies, in the meantime, he says, “As we continually look for options in the best interest of flight hardware, we have a good product line based on NASA technology.\n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      Signals from global positioning system (GPS) satellites are now being used for more than just location and navigation information. By looking at the radio waves from GPS satellites, a technology developed at NASA’s Jet Propulsion Laboratory (JPL) not only precisely calculates its position, but can also use a technique known as radio occultation to help scientists study the Earth’s atmosphere and gravity field to improve weather forecasts, monitor climate change, and enhance space weather research.\n                      \n                        \n                        \n                          \n                        \n                        \n                          This artist’s illustration shows six microsatellites entering low-Earth orbit to form the Constellation Observing System for Meteorology, Ionosphere, and Climate.\n                        \n                      \n                      The University Corporation for Atmospheric Research (UCAR), a nonprofit group of universities in Boulder, Colorado, compares radio occultation to the appearance of a pencil when viewed though a glass of water. The water molecules change the path of visible light waves so that the pencil appears bent, just like molecules in the air bend GPS radio signals as they pass through (or are occulted by) the atmosphere. Through measurements of the amount of bending in the signals, scientists can construct detailed images of the ionosphere (the energetic upper part of the atmosphere) and also gather information about atmospheric density, pressure, temperature, and moisture. Once collected, this data can be input into weather forecasting and climate models for weather prediction and climate studies. Traditionally, such information is obtained through the use of weather balloons.\n                      In 1998, JPL started developing a new class of GPS space science receivers, called Black Jack, that could take precise measurements of how GPS signals are distorted or delayed along their way to the receiver. By 2006, the first demonstration of a GPS radio occultation constellation was launched through a collaboration among Taiwan’s National Science Council and National Space Organization, the U.S. National Science Foundation, NASA, the National Oceanic and Atmospheric Administration (NOAA), and other Federal entities. Called the Constellation Observing System for Meteorology, Ionosphere, and Climate (COSMIC), JPL was responsible for designing COSMIC’s primary instrument—based on its revolutionary Black Jack receiver.\n                      Partnership\n                      To produce the Black Jack GPS radio occultation receivers required for COSMIC, JPL turned to Tempe, Arizona-based Broad Reach Engineering Company (BRE). BRE made enhancements to JPL’s existing technology, including the addition of an internal redundancy feature and internal mass memory. BRE built the new receivers, and while delivering the flight hardware for the COSMIC program, entered into a license agreement for the technology that extends to 2017. \n                      As a result of the license agreement, BRE commercialized a new product called the Integrated GPS Occultation Receiver (IGOR) based on NASA’s Black Jack device. “After the successful transfer of commercial technology to BRE, the company further improved it—allowing for increased parts reliability and the ability to modify the digital signal processing algorithms while on orbit,” says Garth Franklin, supervisor of the advanced radiometric and gravity sensing instruments group at JPL.\n                      Benefits\n                      With one of the company’s main products being an integrated avionics unit (IAU) that provides all satellite command and data handling, electrical power system, and payload interface capability from a single box, BRE now offers an additional option, based on the NASA receiver, as a standalone GPS receiver or as part of the IAU. “We can handle power inputs, switching and distribution, uplink and downlink, and payload interfaces—it’s a tightly integrated solution for satellites. The Black Jack technology provides us with another product line of avionics to offer to our customers,” says Dan Smith, a project manager at Broad Reach Engineering.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Broad Reach Engineering Company licensed NASA technology, which is now provided through the company’s Integrated GPS Occultation Receiver.\n                        \n                      \n                      As a dual-frequency (frequencies L1 and L2) receiver, IGOR is available in two versions for low-Earth orbit: as a receiver for precision orbit determination (POD) only, or as a receiver for both POD and radio occultation. “IGOR provides orbit determination, which is similar to other GPS receivers on the market. However, the unique feature is that IGOR has the radio occultation science capability,” says Smith.\n                      IGOR also features a solid state recorder that allows the recording of extra data in case there are problems with the downlink at ground stations, and a payload controller that can control additional instruments on the satellite. “We repackaged it a little bit, but we didn’t touch any of the JPL items such as the signal acquisition and tracking algorithms. We focused on the hardware,” says Smith.\n                      Designed to meet all of the requirements of occultation science experiments, IGOR is currently being used by NASA, as well as by German, Korean, and Brazilian organizations. To date, nine IGOR receivers have been deployed on orbit: six flight units for COSMIC, one flight unit for the German TerraSAR-X, one flight unit for the German Tandem-X, and one flight unit for the U.S. Air Force Research Laboratory’s TACSAT-2 (which is no longer operational). Two additional flight units have been delivered, including one to Korea for KOMPSAT-5, and one to Brazil for LATTES. While BRE is currently working on a flight build for the Spanish PAZ, company personnel are also in discussions with Japanese customers. \n                      “Some of the international agencies collaborate with NOAA or UCAR, and they are basically building the global dataset for radio occultation,” says Smith. “As they input the radio occultation data into the operational NOAA weather models, the severe weather forecasting has improved significantly. The data is indicating that hurricane tracking predictions are improving.” \n                      According to UCAR, data from COSMIC has proven valuable for weather forecasting, hurricane forecasting, and investigation of the atmospheric boundary layer (the lowest part of the atmosphere). The data has also proven useful for testing ionospheric models, is being used for space weather models, and can potentially benefit climate studies, due to its high precision and global and daily sampling coverage. As Franklin describes, “Temperature, pressure, water vapor, and electron content can be retrieved in a widely distributed way as each of the 31 GPS spacecraft signals are observed by the six COSMIC spacecraft, cutting though Earth’s atmosphere on average of 1,500 times per day.” This is the first time such large amounts of data have been obtained on a global scale.\n                      After introducing the benefits of IGOR to the satellite industry, BRE licensed additional technology from Goddard Space Flight Center in 2011. Called Navigator, the NASA-derived GPS receiver can acquire and track the weaker signals broadcast by GPS satellites to enable navigation in geosynchronous orbits (GEO) and highly elliptical orbits (HEO), where typical GPS receivers fail to pick up a signal. “Goddard provided the software, algorithms, and Kalman filtering. Again, we repackaged the hardware and coordinated initial bench-top performance testing with Goddard. This effort allowed us to make it part of our IAU, creating another hardware option for satellites considering these type of missions,” says Smith. \n                      The first use of BRE’s version of Navigator will fly on the Air Force Research Laboratory’s Nanosatellite Guardian for Evaluating Local Space (ANGELS) mission, planned for 2012.\n                      While Smith looks forward to continued collaborations with NASA to make the next generation of GPS receivers for tracking additional frequencies, in the meantime, he says, “As we continually look for options in the best interest of flight hardware, we have a good product line based on NASA technology.\n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      Signals from global positioning system (GPS) satellites are now being used for more than just location and navigation information. By looking at the radio waves from GPS satellites, a technology developed at NASA’s Jet Propulsion Laboratory (JPL) not only precisely calculates its position, but can also use a technique known as radio occultation to help scientists study the Earth’s atmosphere and gravity field to improve weather forecasts, monitor climate change, and enhance space weather research.\n                      \n                        \n                        \n                          \n                        \n                        \n                          This artist’s illustration shows six microsatellites entering low-Earth orbit to form the Constellation Observing System for Meteorology, Ionosphere, and Climate.\n                        \n                      \n                      The University Corporation for Atmospheric Research (UCAR), a nonprofit group of universities in Boulder, Colorado, compares radio occultation to the appearance of a pencil when viewed though a glass of water. The water molecules change the path of visible light waves so that the pencil appears bent, just like molecules in the air bend GPS radio signals as they pass through (or are occulted by) the atmosphere. Through measurements of the amount of bending in the signals, scientists can construct detailed images of the ionosphere (the energetic upper part of the atmosphere) and also gather information about atmospheric density, pressure, temperature, and moisture. Once collected, this data can be input into weather forecasting and climate models for weather prediction and climate studies. Traditionally, such information is obtained through the use of weather balloons.\n                      In 1998, JPL started developing a new class of GPS space science receivers, called Black Jack, that could take precise measurements of how GPS signals are distorted or delayed along their way to the receiver. By 2006, the first demonstration of a GPS radio occultation constellation was launched through a collaboration among Taiwan’s National Science Council and National Space Organization, the U.S. National Science Foundation, NASA, the National Oceanic and Atmospheric Administration (NOAA), and other Federal entities. Called the Constellation Observing System for Meteorology, Ionosphere, and Climate (COSMIC), JPL was responsible for designing COSMIC’s primary instrument—based on its revolutionary Black Jack receiver.\n                      Partnership\n                      To produce the Black Jack GPS radio occultation receivers required for COSMIC, JPL turned to Tempe, Arizona-based Broad Reach Engineering Company (BRE). BRE made enhancements to JPL’s existing technology, including the addition of an internal redundancy feature and internal mass memory. BRE built the new receivers, and while delivering the flight hardware for the COSMIC program, entered into a license agreement for the technology that extends to 2017. \n                      As a result of the license agreement, BRE commercialized a new product called the Integrated GPS Occultation Receiver (IGOR) based on NASA’s Black Jack device. “After the successful transfer of commercial technology to BRE, the company further improved it—allowing for increased parts reliability and the ability to modify the digital signal processing algorithms while on orbit,” says Garth Franklin, supervisor of the advanced radiometric and gravity sensing instruments group at JPL.\n                      Benefits\n                      With one of the company’s main products being an integrated avionics unit (IAU) that provides all satellite command and data handling, electrical power system, and payload interface capability from a single box, BRE now offers an additional option, based on the NASA receiver, as a standalone GPS receiver or as part of the IAU. “We can handle power inputs, switching and distribution, uplink and downlink, and payload interfaces—it’s a tightly integrated solution for satellites. The Black Jack technology provides us with another product line of avionics to offer to our customers,” says Dan Smith, a project manager at Broad Reach Engineering.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Broad Reach Engineering Company licensed NASA technology, which is now provided through the company’s Integrated GPS Occultation Receiver.\n                        \n                      \n                      As a dual-frequency (frequencies L1 and L2) receiver, IGOR is available in two versions for low-Earth orbit: as a receiver for precision orbit determination (POD) only, or as a receiver for both POD and radio occultation. “IGOR provides orbit determination, which is similar to other GPS receivers on the market. However, the unique feature is that IGOR has the radio occultation science capability,” says Smith.\n                      IGOR also features a solid state recorder that allows the recording of extra data in case there are problems with the downlink at ground stations, and a payload controller that can control additional instruments on the satellite. “We repackaged it a little bit, but we didn’t touch any of the JPL items such as the signal acquisition and tracking algorithms. We focused on the hardware,” says Smith.\n                      Designed to meet all of the requirements of occultation science experiments, IGOR is currently being used by NASA, as well as by German, Korean, and Brazilian organizations. To date, nine IGOR receivers have been deployed on orbit: six flight units for COSMIC, one flight unit for the German TerraSAR-X, one flight unit for the German Tandem-X, and one flight unit for the U.S. Air Force Research Laboratory’s TACSAT-2 (which is no longer operational). Two additional flight units have been delivered, including one to Korea for KOMPSAT-5, and one to Brazil for LATTES. While BRE is currently working on a flight build for the Spanish PAZ, company personnel are also in discussions with Japanese customers. \n                      “Some of the international agencies collaborate with NOAA or UCAR, and they are basically building the global dataset for radio occultation,” says Smith. “As they input the radio occultation data into the operational NOAA weather models, the severe weather forecasting has improved significantly. The data is indicating that hurricane tracking predictions are improving.” \n                      According to UCAR, data from COSMIC has proven valuable for weather forecasting, hurricane forecasting, and investigation of the atmospheric boundary layer (the lowest part of the atmosphere). The data has also proven useful for testing ionospheric models, is being used for space weather models, and can potentially benefit climate studies, due to its high precision and global and daily sampling coverage. As Franklin describes, “Temperature, pressure, water vapor, and electron content can be retrieved in a widely distributed way as each of the 31 GPS spacecraft signals are observed by the six COSMIC spacecraft, cutting though Earth’s atmosphere on average of 1,500 times per day.” This is the first time such large amounts of data have been obtained on a global scale.\n                      After introducing the benefits of IGOR to the satellite industry, BRE licensed additional technology from Goddard Space Flight Center in 2011. Called Navigator, the NASA-derived GPS receiver can acquire and track the weaker signals broadcast by GPS satellites to enable navigation in geosynchronous orbits (GEO) and highly elliptical orbits (HEO), where typical GPS receivers fail to pick up a signal. “Goddard provided the software, algorithms, and Kalman filtering. Again, we repackaged the hardware and coordinated initial bench-top performance testing with Goddard. This effort allowed us to make it part of our IAU, creating another hardware option for satellites considering these type of missions,” says Smith. \n                      The first use of BRE’s version of Navigator will fly on the Air Force Research Laboratory’s Nanosatellite Guardian for Evaluating Local Space (ANGELS) mission, planned for 2012.\n                      While Smith looks forward to continued collaborations with NASA to make the next generation of GPS receivers for tracking additional frequencies, in the meantime, he says, “As we continually look for options in the best interest of flight hardware, we have a good product line based on NASA technology.\n                      \n                    \n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      Signals from global positioning system (GPS) satellites are now being used for more than just location and navigation information. By looking at the radio waves from GPS satellites, a technology developed at NASA’s Jet Propulsion Laboratory (JPL) not only precisely calculates its position, but can also use a technique known as radio occultation to help scientists study the Earth’s atmosphere and gravity field to improve weather forecasts, monitor climate change, and enhance space weather research.\n                      \n                        \n                        \n                          \n                        \n                        \n                          This artist’s illustration shows six microsatellites entering low-Earth orbit to form the Constellation Observing System for Meteorology, Ionosphere, and Climate.\n                        \n                      \n                      The University Corporation for Atmospheric Research (UCAR), a nonprofit group of universities in Boulder, Colorado, compares radio occultation to the appearance of a pencil when viewed though a glass of water. The water molecules change the path of visible light waves so that the pencil appears bent, just like molecules in the air bend GPS radio signals as they pass through (or are occulted by) the atmosphere. Through measurements of the amount of bending in the signals, scientists can construct detailed images of the ionosphere (the energetic upper part of the atmosphere) and also gather information about atmospheric density, pressure, temperature, and moisture. Once collected, this data can be input into weather forecasting and climate models for weather prediction and climate studies. Traditionally, such information is obtained through the use of weather balloons.\n                      In 1998, JPL started developing a new class of GPS space science receivers, called Black Jack, that could take precise measurements of how GPS signals are distorted or delayed along their way to the receiver. By 2006, the first demonstration of a GPS radio occultation constellation was launched through a collaboration among Taiwan’s National Science Council and National Space Organization, the U.S. National Science Foundation, NASA, the National Oceanic and Atmospheric Administration (NOAA), and other Federal entities. Called the Constellation Observing System for Meteorology, Ionosphere, and Climate (COSMIC), JPL was responsible for designing COSMIC’s primary instrument—based on its revolutionary Black Jack receiver.\n                      Partnership\n                      To produce the Black Jack GPS radio occultation receivers required for COSMIC, JPL turned to Tempe, Arizona-based Broad Reach Engineering Company (BRE). BRE made enhancements to JPL’s existing technology, including the addition of an internal redundancy feature and internal mass memory. BRE built the new receivers, and while delivering the flight hardware for the COSMIC program, entered into a license agreement for the technology that extends to 2017. \n                      As a result of the license agreement, BRE commercialized a new product called the Integrated GPS Occultation Receiver (IGOR) based on NASA’s Black Jack device. “After the successful transfer of commercial technology to BRE, the company further improved it—allowing for increased parts reliability and the ability to modify the digital signal processing algorithms while on orbit,” says Garth Franklin, supervisor of the advanced radiometric and gravity sensing instruments group at JPL.\n                      Benefits\n                      With one of the company’s main products being an integrated avionics unit (IAU) that provides all satellite command and data handling, electrical power system, and payload interface capability from a single box, BRE now offers an additional option, based on the NASA receiver, as a standalone GPS receiver or as part of the IAU. “We can handle power inputs, switching and distribution, uplink and downlink, and payload interfaces—it’s a tightly integrated solution for satellites. The Black Jack technology provides us with another product line of avionics to offer to our customers,” says Dan Smith, a project manager at Broad Reach Engineering.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Broad Reach Engineering Company licensed NASA technology, which is now provided through the company’s Integrated GPS Occultation Receiver.\n                        \n                      \n                      As a dual-frequency (frequencies L1 and L2) receiver, IGOR is available in two versions for low-Earth orbit: as a receiver for precision orbit determination (POD) only, or as a receiver for both POD and radio occultation. “IGOR provides orbit determination, which is similar to other GPS receivers on the market. However, the unique feature is that IGOR has the radio occultation science capability,” says Smith.\n                      IGOR also features a solid state recorder that allows the recording of extra data in case there are problems with the downlink at ground stations, and a payload controller that can control additional instruments on the satellite. “We repackaged it a little bit, but we didn’t touch any of the JPL items such as the signal acquisition and tracking algorithms. We focused on the hardware,” says Smith.\n                      Designed to meet all of the requirements of occultation science experiments, IGOR is currently being used by NASA, as well as by German, Korean, and Brazilian organizations. To date, nine IGOR receivers have been deployed on orbit: six flight units for COSMIC, one flight unit for the German TerraSAR-X, one flight unit for the German Tandem-X, and one flight unit for the U.S. Air Force Research Laboratory’s TACSAT-2 (which is no longer operational). Two additional flight units have been delivered, including one to Korea for KOMPSAT-5, and one to Brazil for LATTES. While BRE is currently working on a flight build for the Spanish PAZ, company personnel are also in discussions with Japanese customers. \n                      “Some of the international agencies collaborate with NOAA or UCAR, and they are basically building the global dataset for radio occultation,” says Smith. “As they input the radio occultation data into the operational NOAA weather models, the severe weather forecasting has improved significantly. The data is indicating that hurricane tracking predictions are improving.” \n                      According to UCAR, data from COSMIC has proven valuable for weather forecasting, hurricane forecasting, and investigation of the atmospheric boundary layer (the lowest part of the atmosphere). The data has also proven useful for testing ionospheric models, is being used for space weather models, and can potentially benefit climate studies, due to its high precision and global and daily sampling coverage. As Franklin describes, “Temperature, pressure, water vapor, and electron content can be retrieved in a widely distributed way as each of the 31 GPS spacecraft signals are observed by the six COSMIC spacecraft, cutting though Earth’s atmosphere on average of 1,500 times per day.” This is the first time such large amounts of data have been obtained on a global scale.\n                      After introducing the benefits of IGOR to the satellite industry, BRE licensed additional technology from Goddard Space Flight Center in 2011. Called Navigator, the NASA-derived GPS receiver can acquire and track the weaker signals broadcast by GPS satellites to enable navigation in geosynchronous orbits (GEO) and highly elliptical orbits (HEO), where typical GPS receivers fail to pick up a signal. “Goddard provided the software, algorithms, and Kalman filtering. Again, we repackaged the hardware and coordinated initial bench-top performance testing with Goddard. This effort allowed us to make it part of our IAU, creating another hardware option for satellites considering these type of missions,” says Smith. \n                      The first use of BRE’s version of Navigator will fly on the Air Force Research Laboratory’s Nanosatellite Guardian for Evaluating Local Space (ANGELS) mission, planned for 2012.\n                      While Smith looks forward to continued collaborations with NASA to make the next generation of GPS receivers for tracking additional frequencies, in the meantime, he says, “As we continually look for options in the best interest of flight hardware, we have a good product line based on NASA technology.\n                      \n                    \n                  \n                \n              \n            \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      Signals from global positioning system (GPS) satellites are now being used for more than just location and navigation information. By looking at the radio waves from GPS satellites, a technology developed at NASA’s Jet Propulsion Laboratory (JPL) not only precisely calculates its position, but can also use a technique known as radio occultation to help scientists study the Earth’s atmosphere and gravity field to improve weather forecasts, monitor climate change, and enhance space weather research.\n                      \n                        \n                        \n                          \n                        \n                        \n                          This artist’s illustration shows six microsatellites entering low-Earth orbit to form the Constellation Observing System for Meteorology, Ionosphere, and Climate.\n                        \n                      \n                      The University Corporation for Atmospheric Research (UCAR), a nonprofit group of universities in Boulder, Colorado, compares radio occultation to the appearance of a pencil when viewed though a glass of water. The water molecules change the path of visible light waves so that the pencil appears bent, just like molecules in the air bend GPS radio signals as they pass through (or are occulted by) the atmosphere. Through measurements of the amount of bending in the signals, scientists can construct detailed images of the ionosphere (the energetic upper part of the atmosphere) and also gather information about atmospheric density, pressure, temperature, and moisture. Once collected, this data can be input into weather forecasting and climate models for weather prediction and climate studies. Traditionally, such information is obtained through the use of weather balloons.\n                      In 1998, JPL started developing a new class of GPS space science receivers, called Black Jack, that could take precise measurements of how GPS signals are distorted or delayed along their way to the receiver. By 2006, the first demonstration of a GPS radio occultation constellation was launched through a collaboration among Taiwan’s National Science Council and National Space Organization, the U.S. National Science Foundation, NASA, the National Oceanic and Atmospheric Administration (NOAA), and other Federal entities. Called the Constellation Observing System for Meteorology, Ionosphere, and Climate (COSMIC), JPL was responsible for designing COSMIC’s primary instrument—based on its revolutionary Black Jack receiver.\n                      Partnership\n                      To produce the Black Jack GPS radio occultation receivers required for COSMIC, JPL turned to Tempe, Arizona-based Broad Reach Engineering Company (BRE). BRE made enhancements to JPL’s existing technology, including the addition of an internal redundancy feature and internal mass memory. BRE built the new receivers, and while delivering the flight hardware for the COSMIC program, entered into a license agreement for the technology that extends to 2017. \n                      As a result of the license agreement, BRE commercialized a new product called the Integrated GPS Occultation Receiver (IGOR) based on NASA’s Black Jack device. “After the successful transfer of commercial technology to BRE, the company further improved it—allowing for increased parts reliability and the ability to modify the digital signal processing algorithms while on orbit,” says Garth Franklin, supervisor of the advanced radiometric and gravity sensing instruments group at JPL.\n                      Benefits\n                      With one of the company’s main products being an integrated avionics unit (IAU) that provides all satellite command and data handling, electrical power system, and payload interface capability from a single box, BRE now offers an additional option, based on the NASA receiver, as a standalone GPS receiver or as part of the IAU. “We can handle power inputs, switching and distribution, uplink and downlink, and payload interfaces—it’s a tightly integrated solution for satellites. The Black Jack technology provides us with another product line of avionics to offer to our customers,” says Dan Smith, a project manager at Broad Reach Engineering.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Broad Reach Engineering Company licensed NASA technology, which is now provided through the company’s Integrated GPS Occultation Receiver.\n                        \n                      \n                      As a dual-frequency (frequencies L1 and L2) receiver, IGOR is available in two versions for low-Earth orbit: as a receiver for precision orbit determination (POD) only, or as a receiver for both POD and radio occultation. “IGOR provides orbit determination, which is similar to other GPS receivers on the market. However, the unique feature is that IGOR has the radio occultation science capability,” says Smith.\n                      IGOR also features a solid state recorder that allows the recording of extra data in case there are problems with the downlink at ground stations, and a payload controller that can control additional instruments on the satellite. “We repackaged it a little bit, but we didn’t touch any of the JPL items such as the signal acquisition and tracking algorithms. We focused on the hardware,” says Smith.\n                      Designed to meet all of the requirements of occultation science experiments, IGOR is currently being used by NASA, as well as by German, Korean, and Brazilian organizations. To date, nine IGOR receivers have been deployed on orbit: six flight units for COSMIC, one flight unit for the German TerraSAR-X, one flight unit for the German Tandem-X, and one flight unit for the U.S. Air Force Research Laboratory’s TACSAT-2 (which is no longer operational). Two additional flight units have been delivered, including one to Korea for KOMPSAT-5, and one to Brazil for LATTES. While BRE is currently working on a flight build for the Spanish PAZ, company personnel are also in discussions with Japanese customers. \n                      “Some of the international agencies collaborate with NOAA or UCAR, and they are basically building the global dataset for radio occultation,” says Smith. “As they input the radio occultation data into the operational NOAA weather models, the severe weather forecasting has improved significantly. The data is indicating that hurricane tracking predictions are improving.” \n                      According to UCAR, data from COSMIC has proven valuable for weather forecasting, hurricane forecasting, and investigation of the atmospheric boundary layer (the lowest part of the atmosphere). The data has also proven useful for testing ionospheric models, is being used for space weather models, and can potentially benefit climate studies, due to its high precision and global and daily sampling coverage. As Franklin describes, “Temperature, pressure, water vapor, and electron content can be retrieved in a widely distributed way as each of the 31 GPS spacecraft signals are observed by the six COSMIC spacecraft, cutting though Earth’s atmosphere on average of 1,500 times per day.” This is the first time such large amounts of data have been obtained on a global scale.\n                      After introducing the benefits of IGOR to the satellite industry, BRE licensed additional technology from Goddard Space Flight Center in 2011. Called Navigator, the NASA-derived GPS receiver can acquire and track the weaker signals broadcast by GPS satellites to enable navigation in geosynchronous orbits (GEO) and highly elliptical orbits (HEO), where typical GPS receivers fail to pick up a signal. “Goddard provided the software, algorithms, and Kalman filtering. Again, we repackaged the hardware and coordinated initial bench-top performance testing with Goddard. This effort allowed us to make it part of our IAU, creating another hardware option for satellites considering these type of missions,” says Smith. \n                      The first use of BRE’s version of Navigator will fly on the Air Force Research Laboratory’s Nanosatellite Guardian for Evaluating Local Space (ANGELS) mission, planned for 2012.\n                      While Smith looks forward to continued collaborations with NASA to make the next generation of GPS receivers for tracking additional frequencies, in the meantime, he says, “As we continually look for options in the best interest of flight hardware, we have a good product line based on NASA technology.\n                      \n                    \n                  \n                \n              \n                  \n                    \n                      NASA Technology\n                      Signals from global positioning system (GPS) satellites are now being used for more than just location and navigation information. By looking at the radio waves from GPS satellites, a technology developed at NASA’s Jet Propulsion Laboratory (JPL) not only precisely calculates its position, but can also use a technique known as radio occultation to help scientists study the Earth’s atmosphere and gravity field to improve weather forecasts, monitor climate change, and enhance space weather research.\n                      \n                        \n                        \n                          \n                        \n                        \n                          This artist’s illustration shows six microsatellites entering low-Earth orbit to form the Constellation Observing System for Meteorology, Ionosphere, and Climate.\n                        \n                      \n                      The University Corporation for Atmospheric Research (UCAR), a nonprofit group of universities in Boulder, Colorado, compares radio occultation to the appearance of a pencil when viewed though a glass of water. The water molecules change the path of visible light waves so that the pencil appears bent, just like molecules in the air bend GPS radio signals as they pass through (or are occulted by) the atmosphere. Through measurements of the amount of bending in the signals, scientists can construct detailed images of the ionosphere (the energetic upper part of the atmosphere) and also gather information about atmospheric density, pressure, temperature, and moisture. Once collected, this data can be input into weather forecasting and climate models for weather prediction and climate studies. Traditionally, such information is obtained through the use of weather balloons.\n                      In 1998, JPL started developing a new class of GPS space science receivers, called Black Jack, that could take precise measurements of how GPS signals are distorted or delayed along their way to the receiver. By 2006, the first demonstration of a GPS radio occultation constellation was launched through a collaboration among Taiwan’s National Science Council and National Space Organization, the U.S. National Science Foundation, NASA, the National Oceanic and Atmospheric Administration (NOAA), and other Federal entities. Called the Constellation Observing System for Meteorology, Ionosphere, and Climate (COSMIC), JPL was responsible for designing COSMIC’s primary instrument—based on its revolutionary Black Jack receiver.\n                      Partnership\n                      To produce the Black Jack GPS radio occultation receivers required for COSMIC, JPL turned to Tempe, Arizona-based Broad Reach Engineering Company (BRE). BRE made enhancements to JPL’s existing technology, including the addition of an internal redundancy feature and internal mass memory. BRE built the new receivers, and while delivering the flight hardware for the COSMIC program, entered into a license agreement for the technology that extends to 2017. \n                      As a result of the license agreement, BRE commercialized a new product called the Integrated GPS Occultation Receiver (IGOR) based on NASA’s Black Jack device. “After the successful transfer of commercial technology to BRE, the company further improved it—allowing for increased parts reliability and the ability to modify the digital signal processing algorithms while on orbit,” says Garth Franklin, supervisor of the advanced radiometric and gravity sensing instruments group at JPL.\n                      Benefits\n                      With one of the company’s main products being an integrated avionics unit (IAU) that provides all satellite command and data handling, electrical power system, and payload interface capability from a single box, BRE now offers an additional option, based on the NASA receiver, as a standalone GPS receiver or as part of the IAU. “We can handle power inputs, switching and distribution, uplink and downlink, and payload interfaces—it’s a tightly integrated solution for satellites. The Black Jack technology provides us with another product line of avionics to offer to our customers,” says Dan Smith, a project manager at Broad Reach Engineering.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Broad Reach Engineering Company licensed NASA technology, which is now provided through the company’s Integrated GPS Occultation Receiver.\n                        \n                      \n                      As a dual-frequency (frequencies L1 and L2) receiver, IGOR is available in two versions for low-Earth orbit: as a receiver for precision orbit determination (POD) only, or as a receiver for both POD and radio occultation. “IGOR provides orbit determination, which is similar to other GPS receivers on the market. However, the unique feature is that IGOR has the radio occultation science capability,” says Smith.\n                      IGOR also features a solid state recorder that allows the recording of extra data in case there are problems with the downlink at ground stations, and a payload controller that can control additional instruments on the satellite. “We repackaged it a little bit, but we didn’t touch any of the JPL items such as the signal acquisition and tracking algorithms. We focused on the hardware,” says Smith.\n                      Designed to meet all of the requirements of occultation science experiments, IGOR is currently being used by NASA, as well as by German, Korean, and Brazilian organizations. To date, nine IGOR receivers have been deployed on orbit: six flight units for COSMIC, one flight unit for the German TerraSAR-X, one flight unit for the German Tandem-X, and one flight unit for the U.S. Air Force Research Laboratory’s TACSAT-2 (which is no longer operational). Two additional flight units have been delivered, including one to Korea for KOMPSAT-5, and one to Brazil for LATTES. While BRE is currently working on a flight build for the Spanish PAZ, company personnel are also in discussions with Japanese customers. \n                      “Some of the international agencies collaborate with NOAA or UCAR, and they are basically building the global dataset for radio occultation,” says Smith. “As they input the radio occultation data into the operational NOAA weather models, the severe weather forecasting has improved significantly. The data is indicating that hurricane tracking predictions are improving.” \n                      According to UCAR, data from COSMIC has proven valuable for weather forecasting, hurricane forecasting, and investigation of the atmospheric boundary layer (the lowest part of the atmosphere). The data has also proven useful for testing ionospheric models, is being used for space weather models, and can potentially benefit climate studies, due to its high precision and global and daily sampling coverage. As Franklin describes, “Temperature, pressure, water vapor, and electron content can be retrieved in a widely distributed way as each of the 31 GPS spacecraft signals are observed by the six COSMIC spacecraft, cutting though Earth’s atmosphere on average of 1,500 times per day.” This is the first time such large amounts of data have been obtained on a global scale.\n                      After introducing the benefits of IGOR to the satellite industry, BRE licensed additional technology from Goddard Space Flight Center in 2011. Called Navigator, the NASA-derived GPS receiver can acquire and track the weaker signals broadcast by GPS satellites to enable navigation in geosynchronous orbits (GEO) and highly elliptical orbits (HEO), where typical GPS receivers fail to pick up a signal. “Goddard provided the software, algorithms, and Kalman filtering. Again, we repackaged the hardware and coordinated initial bench-top performance testing with Goddard. This effort allowed us to make it part of our IAU, creating another hardware option for satellites considering these type of missions,” says Smith. \n                      The first use of BRE’s version of Navigator will fly on the Air Force Research Laboratory’s Nanosatellite Guardian for Evaluating Local Space (ANGELS) mission, planned for 2012.\n                      While Smith looks forward to continued collaborations with NASA to make the next generation of GPS receivers for tracking additional frequencies, in the meantime, he says, “As we continually look for options in the best interest of flight hardware, we have a good product line based on NASA technology.\n                      \n                    \n                  \n                    \n                      NASA Technology\n                      Signals from global positioning system (GPS) satellites are now being used for more than just location and navigation information. By looking at the radio waves from GPS satellites, a technology developed at NASA’s Jet Propulsion Laboratory (JPL) not only precisely calculates its position, but can also use a technique known as radio occultation to help scientists study the Earth’s atmosphere and gravity field to improve weather forecasts, monitor climate change, and enhance space weather research.\n                      \n                        \n                        \n                          \n                        \n                        \n                          This artist’s illustration shows six microsatellites entering low-Earth orbit to form the Constellation Observing System for Meteorology, Ionosphere, and Climate.\n                        \n                      \n                      The University Corporation for Atmospheric Research (UCAR), a nonprofit group of universities in Boulder, Colorado, compares radio occultation to the appearance of a pencil when viewed though a glass of water. The water molecules change the path of visible light waves so that the pencil appears bent, just like molecules in the air bend GPS radio signals as they pass through (or are occulted by) the atmosphere. Through measurements of the amount of bending in the signals, scientists can construct detailed images of the ionosphere (the energetic upper part of the atmosphere) and also gather information about atmospheric density, pressure, temperature, and moisture. Once collected, this data can be input into weather forecasting and climate models for weather prediction and climate studies. Traditionally, such information is obtained through the use of weather balloons.\n                      In 1998, JPL started developing a new class of GPS space science receivers, called Black Jack, that could take precise measurements of how GPS signals are distorted or delayed along their way to the receiver. By 2006, the first demonstration of a GPS radio occultation constellation was launched through a collaboration among Taiwan’s National Science Council and National Space Organization, the U.S. National Science Foundation, NASA, the National Oceanic and Atmospheric Administration (NOAA), and other Federal entities. Called the Constellation Observing System for Meteorology, Ionosphere, and Climate (COSMIC), JPL was responsible for designing COSMIC’s primary instrument—based on its revolutionary Black Jack receiver.\n                      Partnership\n                      To produce the Black Jack GPS radio occultation receivers required for COSMIC, JPL turned to Tempe, Arizona-based Broad Reach Engineering Company (BRE). BRE made enhancements to JPL’s existing technology, including the addition of an internal redundancy feature and internal mass memory. BRE built the new receivers, and while delivering the flight hardware for the COSMIC program, entered into a license agreement for the technology that extends to 2017. \n                      As a result of the license agreement, BRE commercialized a new product called the Integrated GPS Occultation Receiver (IGOR) based on NASA’s Black Jack device. “After the successful transfer of commercial technology to BRE, the company further improved it—allowing for increased parts reliability and the ability to modify the digital signal processing algorithms while on orbit,” says Garth Franklin, supervisor of the advanced radiometric and gravity sensing instruments group at JPL.\n                      Benefits\n                      With one of the company’s main products being an integrated avionics unit (IAU) that provides all satellite command and data handling, electrical power system, and payload interface capability from a single box, BRE now offers an additional option, based on the NASA receiver, as a standalone GPS receiver or as part of the IAU. “We can handle power inputs, switching and distribution, uplink and downlink, and payload interfaces—it’s a tightly integrated solution for satellites. The Black Jack technology provides us with another product line of avionics to offer to our customers,” says Dan Smith, a project manager at Broad Reach Engineering.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Broad Reach Engineering Company licensed NASA technology, which is now provided through the company’s Integrated GPS Occultation Receiver.\n                        \n                      \n                      As a dual-frequency (frequencies L1 and L2) receiver, IGOR is available in two versions for low-Earth orbit: as a receiver for precision orbit determination (POD) only, or as a receiver for both POD and radio occultation. “IGOR provides orbit determination, which is similar to other GPS receivers on the market. However, the unique feature is that IGOR has the radio occultation science capability,” says Smith.\n                      IGOR also features a solid state recorder that allows the recording of extra data in case there are problems with the downlink at ground stations, and a payload controller that can control additional instruments on the satellite. “We repackaged it a little bit, but we didn’t touch any of the JPL items such as the signal acquisition and tracking algorithms. We focused on the hardware,” says Smith.\n                      Designed to meet all of the requirements of occultation science experiments, IGOR is currently being used by NASA, as well as by German, Korean, and Brazilian organizations. To date, nine IGOR receivers have been deployed on orbit: six flight units for COSMIC, one flight unit for the German TerraSAR-X, one flight unit for the German Tandem-X, and one flight unit for the U.S. Air Force Research Laboratory’s TACSAT-2 (which is no longer operational). Two additional flight units have been delivered, including one to Korea for KOMPSAT-5, and one to Brazil for LATTES. While BRE is currently working on a flight build for the Spanish PAZ, company personnel are also in discussions with Japanese customers. \n                      “Some of the international agencies collaborate with NOAA or UCAR, and they are basically building the global dataset for radio occultation,” says Smith. “As they input the radio occultation data into the operational NOAA weather models, the severe weather forecasting has improved significantly. The data is indicating that hurricane tracking predictions are improving.” \n                      According to UCAR, data from COSMIC has proven valuable for weather forecasting, hurricane forecasting, and investigation of the atmospheric boundary layer (the lowest part of the atmosphere). The data has also proven useful for testing ionospheric models, is being used for space weather models, and can potentially benefit climate studies, due to its high precision and global and daily sampling coverage. As Franklin describes, “Temperature, pressure, water vapor, and electron content can be retrieved in a widely distributed way as each of the 31 GPS spacecraft signals are observed by the six COSMIC spacecraft, cutting though Earth’s atmosphere on average of 1,500 times per day.” This is the first time such large amounts of data have been obtained on a global scale.\n                      After introducing the benefits of IGOR to the satellite industry, BRE licensed additional technology from Goddard Space Flight Center in 2011. Called Navigator, the NASA-derived GPS receiver can acquire and track the weaker signals broadcast by GPS satellites to enable navigation in geosynchronous orbits (GEO) and highly elliptical orbits (HEO), where typical GPS receivers fail to pick up a signal. “Goddard provided the software, algorithms, and Kalman filtering. Again, we repackaged the hardware and coordinated initial bench-top performance testing with Goddard. This effort allowed us to make it part of our IAU, creating another hardware option for satellites considering these type of missions,” says Smith. \n                      The first use of BRE’s version of Navigator will fly on the Air Force Research Laboratory’s Nanosatellite Guardian for Evaluating Local Space (ANGELS) mission, planned for 2012.\n                      While Smith looks forward to continued collaborations with NASA to make the next generation of GPS receivers for tracking additional frequencies, in the meantime, he says, “As we continually look for options in the best interest of flight hardware, we have a good product line based on NASA technology.\n                      \n                    \n                      NASA Technology\n                      Signals from global positioning system (GPS) satellites are now being used for more than just location and navigation information. By looking at the radio waves from GPS satellites, a technology developed at NASA’s Jet Propulsion Laboratory (JPL) not only precisely calculates its position, but can also use a technique known as radio occultation to help scientists study the Earth’s atmosphere and gravity field to improve weather forecasts, monitor climate change, and enhance space weather research.\n                      \n                        \n                        \n                          \n                        \n                        \n                          This artist’s illustration shows six microsatellites entering low-Earth orbit to form the Constellation Observing System for Meteorology, Ionosphere, and Climate.\n                        \n                      \n                      The University Corporation for Atmospheric Research (UCAR), a nonprofit group of universities in Boulder, Colorado, compares radio occultation to the appearance of a pencil when viewed though a glass of water. The water molecules change the path of visible light waves so that the pencil appears bent, just like molecules in the air bend GPS radio signals as they pass through (or are occulted by) the atmosphere. Through measurements of the amount of bending in the signals, scientists can construct detailed images of the ionosphere (the energetic upper part of the atmosphere) and also gather information about atmospheric density, pressure, temperature, and moisture. Once collected, this data can be input into weather forecasting and climate models for weather prediction and climate studies. Traditionally, such information is obtained through the use of weather balloons.\n                      In 1998, JPL started developing a new class of GPS space science receivers, called Black Jack, that could take precise measurements of how GPS signals are distorted or delayed along their way to the receiver. By 2006, the first demonstration of a GPS radio occultation constellation was launched through a collaboration among Taiwan’s National Science Council and National Space Organization, the U.S. National Science Foundation, NASA, the National Oceanic and Atmospheric Administration (NOAA), and other Federal entities. Called the Constellation Observing System for Meteorology, Ionosphere, and Climate (COSMIC), JPL was responsible for designing COSMIC’s primary instrument—based on its revolutionary Black Jack receiver.\n                      Partnership\n                      To produce the Black Jack GPS radio occultation receivers required for COSMIC, JPL turned to Tempe, Arizona-based Broad Reach Engineering Company (BRE). BRE made enhancements to JPL’s existing technology, including the addition of an internal redundancy feature and internal mass memory. BRE built the new receivers, and while delivering the flight hardware for the COSMIC program, entered into a license agreement for the technology that extends to 2017. \n                      As a result of the license agreement, BRE commercialized a new product called the Integrated GPS Occultation Receiver (IGOR) based on NASA’s Black Jack device. “After the successful transfer of commercial technology to BRE, the company further improved it—allowing for increased parts reliability and the ability to modify the digital signal processing algorithms while on orbit,” says Garth Franklin, supervisor of the advanced radiometric and gravity sensing instruments group at JPL.\n                      Benefits\n                      With one of the company’s main products being an integrated avionics unit (IAU) that provides all satellite command and data handling, electrical power system, and payload interface capability from a single box, BRE now offers an additional option, based on the NASA receiver, as a standalone GPS receiver or as part of the IAU. “We can handle power inputs, switching and distribution, uplink and downlink, and payload interfaces—it’s a tightly integrated solution for satellites. The Black Jack technology provides us with another product line of avionics to offer to our customers,” says Dan Smith, a project manager at Broad Reach Engineering.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Broad Reach Engineering Company licensed NASA technology, which is now provided through the company’s Integrated GPS Occultation Receiver.\n                        \n                      \n                      As a dual-frequency (frequencies L1 and L2) receiver, IGOR is available in two versions for low-Earth orbit: as a receiver for precision orbit determination (POD) only, or as a receiver for both POD and radio occultation. “IGOR provides orbit determination, which is similar to other GPS receivers on the market. However, the unique feature is that IGOR has the radio occultation science capability,” says Smith.\n                      IGOR also features a solid state recorder that allows the recording of extra data in case there are problems with the downlink at ground stations, and a payload controller that can control additional instruments on the satellite. “We repackaged it a little bit, but we didn’t touch any of the JPL items such as the signal acquisition and tracking algorithms. We focused on the hardware,” says Smith.\n                      Designed to meet all of the requirements of occultation science experiments, IGOR is currently being used by NASA, as well as by German, Korean, and Brazilian organizations. To date, nine IGOR receivers have been deployed on orbit: six flight units for COSMIC, one flight unit for the German TerraSAR-X, one flight unit for the German Tandem-X, and one flight unit for the U.S. Air Force Research Laboratory’s TACSAT-2 (which is no longer operational). Two additional flight units have been delivered, including one to Korea for KOMPSAT-5, and one to Brazil for LATTES. While BRE is currently working on a flight build for the Spanish PAZ, company personnel are also in discussions with Japanese customers. \n                      “Some of the international agencies collaborate with NOAA or UCAR, and they are basically building the global dataset for radio occultation,” says Smith. “As they input the radio occultation data into the operational NOAA weather models, the severe weather forecasting has improved significantly. The data is indicating that hurricane tracking predictions are improving.” \n                      According to UCAR, data from COSMIC has proven valuable for weather forecasting, hurricane forecasting, and investigation of the atmospheric boundary layer (the lowest part of the atmosphere). The data has also proven useful for testing ionospheric models, is being used for space weather models, and can potentially benefit climate studies, due to its high precision and global and daily sampling coverage. As Franklin describes, “Temperature, pressure, water vapor, and electron content can be retrieved in a widely distributed way as each of the 31 GPS spacecraft signals are observed by the six COSMIC spacecraft, cutting though Earth’s atmosphere on average of 1,500 times per day.” This is the first time such large amounts of data have been obtained on a global scale.\n                      After introducing the benefits of IGOR to the satellite industry, BRE licensed additional technology from Goddard Space Flight Center in 2011. Called Navigator, the NASA-derived GPS receiver can acquire and track the weaker signals broadcast by GPS satellites to enable navigation in geosynchronous orbits (GEO) and highly elliptical orbits (HEO), where typical GPS receivers fail to pick up a signal. “Goddard provided the software, algorithms, and Kalman filtering. Again, we repackaged the hardware and coordinated initial bench-top performance testing with Goddard. This effort allowed us to make it part of our IAU, creating another hardware option for satellites considering these type of missions,” says Smith. \n                      The first use of BRE’s version of Navigator will fly on the Air Force Research Laboratory’s Nanosatellite Guardian for Evaluating Local Space (ANGELS) mission, planned for 2012.\n                      While Smith looks forward to continued collaborations with NASA to make the next generation of GPS receivers for tracking additional frequencies, in the meantime, he says, “As we continually look for options in the best interest of flight hardware, we have a good product line based on NASA technology.\n                      "},{"href":"http://spinoff.nasa.gov/Spinoff2011/er_5.html","text":"Coating Processes Boost Performance of Solar Cells","image":"http://spinoff.nasa.gov/Spinoff2011/Images/er_8b_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            The International Space Station derives power from its massive photovoltaic panels (seen in the upper left). NASA tested new solar cell technologies in space through the Forward Technology Solar Cell Experiment (inset), part of the Materials International Space Station Experiment 5. \n                          \n                        \n                        NASA currently has spacecraft orbiting Mercury (MESSENGER), imaging the asteroid Vesta (Dawn), roaming the red plains of Mars (the Opportunity rover), and providing a laboratory for humans to advance scientific research in space \n                          (the International Space Station, or ISS). The heart \n                          of the technology that powers those missions and \n                          many others can be held in the palm of your hand—the solar cell. \n                        Solar, or photovoltaic (PV), cells are what make up the panels and arrays that draw on the Sun’s light to generate electricity for everything from the Hubble Space Telescope’s imaging equipment to the life support systems for the ISS. To enable NASA spacecraft to utilize the Sun’s energy for exploring destinations as distant as Jupiter, the Agency has invested significant research into improving solar cell design and efficiency. \n                        Glenn Research Center has been a national leader in advancing PV technology. The Center’s Photovoltaic and Power Technologies Branch has conducted numerous experiments aimed at developing lighter, more efficient solar cells that are less expensive to manufacture. Initiatives like the Forward Technology Solar Cell Experiments I and II—in which PV cells developed by NASA and private industry were mounted outside the ISS—have tested how various solar technologies perform in the harsh conditions of space. While NASA seeks to improve solar cells for space applications, the results are returning to Earth to benefit the solar energy industry.\n                        Partnership\n                        Throughout the 1980s and 1990s, Maria Faur, while conducting research for NASA Glenn (then Lewis Reseach Center), developed new techniques for enhancing solar cell manufacturing and design. In 1995, Faur founded Special Materials Research and Technology Inc. (SPECMAT) to expand these efforts. The following year, the company entered into a Space Act Agreement with Glenn, and in 1999, became one of the first tenants of the NASA Lewis Incubator for Technology. Both partnerships helped to provide SPECMAT with the means to advance a proprietary method Faur had developed while working for NASA to enhance solar cells in a way not previously achievable.\n                        SPECMAT’s room-temperature wet chemical growth (RTWCG) silicon oxide process provides a unique method to fabricate high-efficiency silicon solar cells at significantly reduced cost. Solar cells require an antireflective coating to help the cells capture the light particles, called photons, needed to generate electricity. Traditional crystalline silicon cells typically use a silicon nitride coating, sometimes in conjunction with a textured surface, to produce the necessary antireflective characteristics. But the current processes for adding antireflective coatings employ expensive machines that operate at high temperatures and require use of toxic gasses. SPECMAT’s RTWCG process involves bathing the PV cell in a room-temperature chemical solution for less than a minute, growing an antireflective layer of silicon oxide on the cell’s surface and providing the cell with a range of enhanced qualities. \n                        “The ability to grow oxide at room temperature is unique in the industry,” says Faur, president and CEO of SPECMAT. The company patented the RTWCG process, and now, says Faur, the NASA-derived innovation stands poised to become a powerful technology for use in the fabrication of solar cells, microelectronics, and photonic devices.\n                        Benefits\n                        SPECMAT has licensed the patented RTWCG process to Equity Solar Inc. and Equity Microelectronics Inc. of San Anselmo, California, to bring the technology to the commercial solar energy and microelectronics markets. \n                        “We believe the RTWCG technology has the potential to supplant traditional oxides in many different applications,” says Greg Knight, Equity Solar’s chief technology officer. For microelectronics, silicon oxide provides electrical insulation, and the rapid growth and variable thickness of the oxide layer produced by the RTWCG process makes it ideal for semiconductor applications such as microelectromechanical systems, LED displays, and power-electronic devices. The process also has potential use in optoelectronics due to certain properties of silicon oxide that make it useful as an optical waveguide. \n                        The technology currently stands to make the most immediate impact in the field of solar energy, however.\n                        \n                          \n                          \n                            \n                          \n                          \n                            OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                          \n                        \n                        “What this technology means for the solar energy business is quite profound,” says Knight. “The coatings created in this process have a lower level of reflectance than anything you can get in the market right now.” \n                        In terms of solar cell fabrication, there are four prime benefits provided by the NASA-derived RTWCG technology. First, the silicon oxide antireflective coating produces a lower reflectance than a standard textured silicon nitride coating, meaning the cell can trap more light. The coating also passivates the cell’s surface, chemically stabilizing it so that the electrons produced when light hits the surface survive in a capturable state for longer. \n                        The RTWCG process also cleans the cell’s surface and contacts and can be used to create what is known as a selective emitter, an advanced type of solar cell construction that enhances the electrical properties of the cell. All of these benefits contribute to increased solar cell efficiency and are delivered during the quick RTWCG chemical immersion. \n                        “The RTWCG technology can enable manufacturers to produce cells that have the lowest ‘cost per watt’ in the PV industry today by increasing the solar cells’ efficiency while lowering the process cost,” says Knight. Standard terrestrial PV cells have efficiencies of 15–18 percent, he explains. Expensive high-end cells can provide up to 21 percent efficiency, and Knight says Equity Solar’s licensed technology will enable cells like these with existing high-end constructions to be made at dramatically lower cost. \n                        Since cost-effectiveness is a major obstacle to the widespread implementation of PV technology as a renewable energy source, the RTWCG stands to become a critical tool for solar cell designers seeking to expand the industry.\n                         “We believe this technology has the potential to be integrated into all crystalline silicon cells in the future,” Knight says. “If this happens, it would truly have a worldwide impact.”\n                        Equity Solar is pursuing extensive validation of the technology while exploring partnerships with PV cell manufacturers to implement the process. SPECMAT, meanwhile, is glad for the fruits of the efforts that were started at Glenn. \n                        “Developing the RTWCG process has been a critical part of SPECMAT’s existence and has led to the employment of several scientists since our work with NASA commenced and following through our license agreement with Equity Solar,” says Faur. “NASA’s support of companies such as ours will yield benefits for solar cell manufacturers and ultimately industry and the general public both in the United States and worldwide.”\n                      \n                       \n                        \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            The International Space Station derives power from its massive photovoltaic panels (seen in the upper left). NASA tested new solar cell technologies in space through the Forward Technology Solar Cell Experiment (inset), part of the Materials International Space Station Experiment 5. \n                          \n                        \n                        NASA currently has spacecraft orbiting Mercury (MESSENGER), imaging the asteroid Vesta (Dawn), roaming the red plains of Mars (the Opportunity rover), and providing a laboratory for humans to advance scientific research in space \n                          (the International Space Station, or ISS). The heart \n                          of the technology that powers those missions and \n                          many others can be held in the palm of your hand—the solar cell. \n                        Solar, or photovoltaic (PV), cells are what make up the panels and arrays that draw on the Sun’s light to generate electricity for everything from the Hubble Space Telescope’s imaging equipment to the life support systems for the ISS. To enable NASA spacecraft to utilize the Sun’s energy for exploring destinations as distant as Jupiter, the Agency has invested significant research into improving solar cell design and efficiency. \n                        Glenn Research Center has been a national leader in advancing PV technology. The Center’s Photovoltaic and Power Technologies Branch has conducted numerous experiments aimed at developing lighter, more efficient solar cells that are less expensive to manufacture. Initiatives like the Forward Technology Solar Cell Experiments I and II—in which PV cells developed by NASA and private industry were mounted outside the ISS—have tested how various solar technologies perform in the harsh conditions of space. While NASA seeks to improve solar cells for space applications, the results are returning to Earth to benefit the solar energy industry.\n                        Partnership\n                        Throughout the 1980s and 1990s, Maria Faur, while conducting research for NASA Glenn (then Lewis Reseach Center), developed new techniques for enhancing solar cell manufacturing and design. In 1995, Faur founded Special Materials Research and Technology Inc. (SPECMAT) to expand these efforts. The following year, the company entered into a Space Act Agreement with Glenn, and in 1999, became one of the first tenants of the NASA Lewis Incubator for Technology. Both partnerships helped to provide SPECMAT with the means to advance a proprietary method Faur had developed while working for NASA to enhance solar cells in a way not previously achievable.\n                        SPECMAT’s room-temperature wet chemical growth (RTWCG) silicon oxide process provides a unique method to fabricate high-efficiency silicon solar cells at significantly reduced cost. Solar cells require an antireflective coating to help the cells capture the light particles, called photons, needed to generate electricity. Traditional crystalline silicon cells typically use a silicon nitride coating, sometimes in conjunction with a textured surface, to produce the necessary antireflective characteristics. But the current processes for adding antireflective coatings employ expensive machines that operate at high temperatures and require use of toxic gasses. SPECMAT’s RTWCG process involves bathing the PV cell in a room-temperature chemical solution for less than a minute, growing an antireflective layer of silicon oxide on the cell’s surface and providing the cell with a range of enhanced qualities. \n                        “The ability to grow oxide at room temperature is unique in the industry,” says Faur, president and CEO of SPECMAT. The company patented the RTWCG process, and now, says Faur, the NASA-derived innovation stands poised to become a powerful technology for use in the fabrication of solar cells, microelectronics, and photonic devices.\n                        Benefits\n                        SPECMAT has licensed the patented RTWCG process to Equity Solar Inc. and Equity Microelectronics Inc. of San Anselmo, California, to bring the technology to the commercial solar energy and microelectronics markets. \n                        “We believe the RTWCG technology has the potential to supplant traditional oxides in many different applications,” says Greg Knight, Equity Solar’s chief technology officer. For microelectronics, silicon oxide provides electrical insulation, and the rapid growth and variable thickness of the oxide layer produced by the RTWCG process makes it ideal for semiconductor applications such as microelectromechanical systems, LED displays, and power-electronic devices. The process also has potential use in optoelectronics due to certain properties of silicon oxide that make it useful as an optical waveguide. \n                        The technology currently stands to make the most immediate impact in the field of solar energy, however.\n                        \n                          \n                          \n                            \n                          \n                          \n                            OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                          \n                        \n                        “What this technology means for the solar energy business is quite profound,” says Knight. “The coatings created in this process have a lower level of reflectance than anything you can get in the market right now.” \n                        In terms of solar cell fabrication, there are four prime benefits provided by the NASA-derived RTWCG technology. First, the silicon oxide antireflective coating produces a lower reflectance than a standard textured silicon nitride coating, meaning the cell can trap more light. The coating also passivates the cell’s surface, chemically stabilizing it so that the electrons produced when light hits the surface survive in a capturable state for longer. \n                        The RTWCG process also cleans the cell’s surface and contacts and can be used to create what is known as a selective emitter, an advanced type of solar cell construction that enhances the electrical properties of the cell. All of these benefits contribute to increased solar cell efficiency and are delivered during the quick RTWCG chemical immersion. \n                        “The RTWCG technology can enable manufacturers to produce cells that have the lowest ‘cost per watt’ in the PV industry today by increasing the solar cells’ efficiency while lowering the process cost,” says Knight. Standard terrestrial PV cells have efficiencies of 15–18 percent, he explains. Expensive high-end cells can provide up to 21 percent efficiency, and Knight says Equity Solar’s licensed technology will enable cells like these with existing high-end constructions to be made at dramatically lower cost. \n                        Since cost-effectiveness is a major obstacle to the widespread implementation of PV technology as a renewable energy source, the RTWCG stands to become a critical tool for solar cell designers seeking to expand the industry.\n                         “We believe this technology has the potential to be integrated into all crystalline silicon cells in the future,” Knight says. “If this happens, it would truly have a worldwide impact.”\n                        Equity Solar is pursuing extensive validation of the technology while exploring partnerships with PV cell manufacturers to implement the process. SPECMAT, meanwhile, is glad for the fruits of the efforts that were started at Glenn. \n                        “Developing the RTWCG process has been a critical part of SPECMAT’s existence and has led to the employment of several scientists since our work with NASA commenced and following through our license agreement with Equity Solar,” says Faur. “NASA’s support of companies such as ours will yield benefits for solar cell manufacturers and ultimately industry and the general public both in the United States and worldwide.”\n                      \n                       \n                        \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            The International Space Station derives power from its massive photovoltaic panels (seen in the upper left). NASA tested new solar cell technologies in space through the Forward Technology Solar Cell Experiment (inset), part of the Materials International Space Station Experiment 5. \n                          \n                        \n                        NASA currently has spacecraft orbiting Mercury (MESSENGER), imaging the asteroid Vesta (Dawn), roaming the red plains of Mars (the Opportunity rover), and providing a laboratory for humans to advance scientific research in space \n                          (the International Space Station, or ISS). The heart \n                          of the technology that powers those missions and \n                          many others can be held in the palm of your hand—the solar cell. \n                        Solar, or photovoltaic (PV), cells are what make up the panels and arrays that draw on the Sun’s light to generate electricity for everything from the Hubble Space Telescope’s imaging equipment to the life support systems for the ISS. To enable NASA spacecraft to utilize the Sun’s energy for exploring destinations as distant as Jupiter, the Agency has invested significant research into improving solar cell design and efficiency. \n                        Glenn Research Center has been a national leader in advancing PV technology. The Center’s Photovoltaic and Power Technologies Branch has conducted numerous experiments aimed at developing lighter, more efficient solar cells that are less expensive to manufacture. Initiatives like the Forward Technology Solar Cell Experiments I and II—in which PV cells developed by NASA and private industry were mounted outside the ISS—have tested how various solar technologies perform in the harsh conditions of space. While NASA seeks to improve solar cells for space applications, the results are returning to Earth to benefit the solar energy industry.\n                        Partnership\n                        Throughout the 1980s and 1990s, Maria Faur, while conducting research for NASA Glenn (then Lewis Reseach Center), developed new techniques for enhancing solar cell manufacturing and design. In 1995, Faur founded Special Materials Research and Technology Inc. (SPECMAT) to expand these efforts. The following year, the company entered into a Space Act Agreement with Glenn, and in 1999, became one of the first tenants of the NASA Lewis Incubator for Technology. Both partnerships helped to provide SPECMAT with the means to advance a proprietary method Faur had developed while working for NASA to enhance solar cells in a way not previously achievable.\n                        SPECMAT’s room-temperature wet chemical growth (RTWCG) silicon oxide process provides a unique method to fabricate high-efficiency silicon solar cells at significantly reduced cost. Solar cells require an antireflective coating to help the cells capture the light particles, called photons, needed to generate electricity. Traditional crystalline silicon cells typically use a silicon nitride coating, sometimes in conjunction with a textured surface, to produce the necessary antireflective characteristics. But the current processes for adding antireflective coatings employ expensive machines that operate at high temperatures and require use of toxic gasses. SPECMAT’s RTWCG process involves bathing the PV cell in a room-temperature chemical solution for less than a minute, growing an antireflective layer of silicon oxide on the cell’s surface and providing the cell with a range of enhanced qualities. \n                        “The ability to grow oxide at room temperature is unique in the industry,” says Faur, president and CEO of SPECMAT. The company patented the RTWCG process, and now, says Faur, the NASA-derived innovation stands poised to become a powerful technology for use in the fabrication of solar cells, microelectronics, and photonic devices.\n                        Benefits\n                        SPECMAT has licensed the patented RTWCG process to Equity Solar Inc. and Equity Microelectronics Inc. of San Anselmo, California, to bring the technology to the commercial solar energy and microelectronics markets. \n                        “We believe the RTWCG technology has the potential to supplant traditional oxides in many different applications,” says Greg Knight, Equity Solar’s chief technology officer. For microelectronics, silicon oxide provides electrical insulation, and the rapid growth and variable thickness of the oxide layer produced by the RTWCG process makes it ideal for semiconductor applications such as microelectromechanical systems, LED displays, and power-electronic devices. The process also has potential use in optoelectronics due to certain properties of silicon oxide that make it useful as an optical waveguide. \n                        The technology currently stands to make the most immediate impact in the field of solar energy, however.\n                        \n                          \n                          \n                            \n                          \n                          \n                            OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                          \n                        \n                        “What this technology means for the solar energy business is quite profound,” says Knight. “The coatings created in this process have a lower level of reflectance than anything you can get in the market right now.” \n                        In terms of solar cell fabrication, there are four prime benefits provided by the NASA-derived RTWCG technology. First, the silicon oxide antireflective coating produces a lower reflectance than a standard textured silicon nitride coating, meaning the cell can trap more light. The coating also passivates the cell’s surface, chemically stabilizing it so that the electrons produced when light hits the surface survive in a capturable state for longer. \n                        The RTWCG process also cleans the cell’s surface and contacts and can be used to create what is known as a selective emitter, an advanced type of solar cell construction that enhances the electrical properties of the cell. All of these benefits contribute to increased solar cell efficiency and are delivered during the quick RTWCG chemical immersion. \n                        “The RTWCG technology can enable manufacturers to produce cells that have the lowest ‘cost per watt’ in the PV industry today by increasing the solar cells’ efficiency while lowering the process cost,” says Knight. Standard terrestrial PV cells have efficiencies of 15–18 percent, he explains. Expensive high-end cells can provide up to 21 percent efficiency, and Knight says Equity Solar’s licensed technology will enable cells like these with existing high-end constructions to be made at dramatically lower cost. \n                        Since cost-effectiveness is a major obstacle to the widespread implementation of PV technology as a renewable energy source, the RTWCG stands to become a critical tool for solar cell designers seeking to expand the industry.\n                         “We believe this technology has the potential to be integrated into all crystalline silicon cells in the future,” Knight says. “If this happens, it would truly have a worldwide impact.”\n                        Equity Solar is pursuing extensive validation of the technology while exploring partnerships with PV cell manufacturers to implement the process. SPECMAT, meanwhile, is glad for the fruits of the efforts that were started at Glenn. \n                        “Developing the RTWCG process has been a critical part of SPECMAT’s existence and has led to the employment of several scientists since our work with NASA commenced and following through our license agreement with Equity Solar,” says Faur. “NASA’s support of companies such as ours will yield benefits for solar cell manufacturers and ultimately industry and the general public both in the United States and worldwide.”\n                      \n                       \n                        \n                    \n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  \n                    \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            The International Space Station derives power from its massive photovoltaic panels (seen in the upper left). NASA tested new solar cell technologies in space through the Forward Technology Solar Cell Experiment (inset), part of the Materials International Space Station Experiment 5. \n                          \n                        \n                        NASA currently has spacecraft orbiting Mercury (MESSENGER), imaging the asteroid Vesta (Dawn), roaming the red plains of Mars (the Opportunity rover), and providing a laboratory for humans to advance scientific research in space \n                          (the International Space Station, or ISS). The heart \n                          of the technology that powers those missions and \n                          many others can be held in the palm of your hand—the solar cell. \n                        Solar, or photovoltaic (PV), cells are what make up the panels and arrays that draw on the Sun’s light to generate electricity for everything from the Hubble Space Telescope’s imaging equipment to the life support systems for the ISS. To enable NASA spacecraft to utilize the Sun’s energy for exploring destinations as distant as Jupiter, the Agency has invested significant research into improving solar cell design and efficiency. \n                        Glenn Research Center has been a national leader in advancing PV technology. The Center’s Photovoltaic and Power Technologies Branch has conducted numerous experiments aimed at developing lighter, more efficient solar cells that are less expensive to manufacture. Initiatives like the Forward Technology Solar Cell Experiments I and II—in which PV cells developed by NASA and private industry were mounted outside the ISS—have tested how various solar technologies perform in the harsh conditions of space. While NASA seeks to improve solar cells for space applications, the results are returning to Earth to benefit the solar energy industry.\n                        Partnership\n                        Throughout the 1980s and 1990s, Maria Faur, while conducting research for NASA Glenn (then Lewis Reseach Center), developed new techniques for enhancing solar cell manufacturing and design. In 1995, Faur founded Special Materials Research and Technology Inc. (SPECMAT) to expand these efforts. The following year, the company entered into a Space Act Agreement with Glenn, and in 1999, became one of the first tenants of the NASA Lewis Incubator for Technology. Both partnerships helped to provide SPECMAT with the means to advance a proprietary method Faur had developed while working for NASA to enhance solar cells in a way not previously achievable.\n                        SPECMAT’s room-temperature wet chemical growth (RTWCG) silicon oxide process provides a unique method to fabricate high-efficiency silicon solar cells at significantly reduced cost. Solar cells require an antireflective coating to help the cells capture the light particles, called photons, needed to generate electricity. Traditional crystalline silicon cells typically use a silicon nitride coating, sometimes in conjunction with a textured surface, to produce the necessary antireflective characteristics. But the current processes for adding antireflective coatings employ expensive machines that operate at high temperatures and require use of toxic gasses. SPECMAT’s RTWCG process involves bathing the PV cell in a room-temperature chemical solution for less than a minute, growing an antireflective layer of silicon oxide on the cell’s surface and providing the cell with a range of enhanced qualities. \n                        “The ability to grow oxide at room temperature is unique in the industry,” says Faur, president and CEO of SPECMAT. The company patented the RTWCG process, and now, says Faur, the NASA-derived innovation stands poised to become a powerful technology for use in the fabrication of solar cells, microelectronics, and photonic devices.\n                        Benefits\n                        SPECMAT has licensed the patented RTWCG process to Equity Solar Inc. and Equity Microelectronics Inc. of San Anselmo, California, to bring the technology to the commercial solar energy and microelectronics markets. \n                        “We believe the RTWCG technology has the potential to supplant traditional oxides in many different applications,” says Greg Knight, Equity Solar’s chief technology officer. For microelectronics, silicon oxide provides electrical insulation, and the rapid growth and variable thickness of the oxide layer produced by the RTWCG process makes it ideal for semiconductor applications such as microelectromechanical systems, LED displays, and power-electronic devices. The process also has potential use in optoelectronics due to certain properties of silicon oxide that make it useful as an optical waveguide. \n                        The technology currently stands to make the most immediate impact in the field of solar energy, however.\n                        \n                          \n                          \n                            \n                          \n                          \n                            OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                          \n                        \n                        “What this technology means for the solar energy business is quite profound,” says Knight. “The coatings created in this process have a lower level of reflectance than anything you can get in the market right now.” \n                        In terms of solar cell fabrication, there are four prime benefits provided by the NASA-derived RTWCG technology. First, the silicon oxide antireflective coating produces a lower reflectance than a standard textured silicon nitride coating, meaning the cell can trap more light. The coating also passivates the cell’s surface, chemically stabilizing it so that the electrons produced when light hits the surface survive in a capturable state for longer. \n                        The RTWCG process also cleans the cell’s surface and contacts and can be used to create what is known as a selective emitter, an advanced type of solar cell construction that enhances the electrical properties of the cell. All of these benefits contribute to increased solar cell efficiency and are delivered during the quick RTWCG chemical immersion. \n                        “The RTWCG technology can enable manufacturers to produce cells that have the lowest ‘cost per watt’ in the PV industry today by increasing the solar cells’ efficiency while lowering the process cost,” says Knight. Standard terrestrial PV cells have efficiencies of 15–18 percent, he explains. Expensive high-end cells can provide up to 21 percent efficiency, and Knight says Equity Solar’s licensed technology will enable cells like these with existing high-end constructions to be made at dramatically lower cost. \n                        Since cost-effectiveness is a major obstacle to the widespread implementation of PV technology as a renewable energy source, the RTWCG stands to become a critical tool for solar cell designers seeking to expand the industry.\n                         “We believe this technology has the potential to be integrated into all crystalline silicon cells in the future,” Knight says. “If this happens, it would truly have a worldwide impact.”\n                        Equity Solar is pursuing extensive validation of the technology while exploring partnerships with PV cell manufacturers to implement the process. SPECMAT, meanwhile, is glad for the fruits of the efforts that were started at Glenn. \n                        “Developing the RTWCG process has been a critical part of SPECMAT’s existence and has led to the employment of several scientists since our work with NASA commenced and following through our license agreement with Equity Solar,” says Faur. “NASA’s support of companies such as ours will yield benefits for solar cell manufacturers and ultimately industry and the general public both in the United States and worldwide.”\n                      \n                       \n                        \n                    \n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  \n                    \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            The International Space Station derives power from its massive photovoltaic panels (seen in the upper left). NASA tested new solar cell technologies in space through the Forward Technology Solar Cell Experiment (inset), part of the Materials International Space Station Experiment 5. \n                          \n                        \n                        NASA currently has spacecraft orbiting Mercury (MESSENGER), imaging the asteroid Vesta (Dawn), roaming the red plains of Mars (the Opportunity rover), and providing a laboratory for humans to advance scientific research in space \n                          (the International Space Station, or ISS). The heart \n                          of the technology that powers those missions and \n                          many others can be held in the palm of your hand—the solar cell. \n                        Solar, or photovoltaic (PV), cells are what make up the panels and arrays that draw on the Sun’s light to generate electricity for everything from the Hubble Space Telescope’s imaging equipment to the life support systems for the ISS. To enable NASA spacecraft to utilize the Sun’s energy for exploring destinations as distant as Jupiter, the Agency has invested significant research into improving solar cell design and efficiency. \n                        Glenn Research Center has been a national leader in advancing PV technology. The Center’s Photovoltaic and Power Technologies Branch has conducted numerous experiments aimed at developing lighter, more efficient solar cells that are less expensive to manufacture. Initiatives like the Forward Technology Solar Cell Experiments I and II—in which PV cells developed by NASA and private industry were mounted outside the ISS—have tested how various solar technologies perform in the harsh conditions of space. While NASA seeks to improve solar cells for space applications, the results are returning to Earth to benefit the solar energy industry.\n                        Partnership\n                        Throughout the 1980s and 1990s, Maria Faur, while conducting research for NASA Glenn (then Lewis Reseach Center), developed new techniques for enhancing solar cell manufacturing and design. In 1995, Faur founded Special Materials Research and Technology Inc. (SPECMAT) to expand these efforts. The following year, the company entered into a Space Act Agreement with Glenn, and in 1999, became one of the first tenants of the NASA Lewis Incubator for Technology. Both partnerships helped to provide SPECMAT with the means to advance a proprietary method Faur had developed while working for NASA to enhance solar cells in a way not previously achievable.\n                        SPECMAT’s room-temperature wet chemical growth (RTWCG) silicon oxide process provides a unique method to fabricate high-efficiency silicon solar cells at significantly reduced cost. Solar cells require an antireflective coating to help the cells capture the light particles, called photons, needed to generate electricity. Traditional crystalline silicon cells typically use a silicon nitride coating, sometimes in conjunction with a textured surface, to produce the necessary antireflective characteristics. But the current processes for adding antireflective coatings employ expensive machines that operate at high temperatures and require use of toxic gasses. SPECMAT’s RTWCG process involves bathing the PV cell in a room-temperature chemical solution for less than a minute, growing an antireflective layer of silicon oxide on the cell’s surface and providing the cell with a range of enhanced qualities. \n                        “The ability to grow oxide at room temperature is unique in the industry,” says Faur, president and CEO of SPECMAT. The company patented the RTWCG process, and now, says Faur, the NASA-derived innovation stands poised to become a powerful technology for use in the fabrication of solar cells, microelectronics, and photonic devices.\n                        Benefits\n                        SPECMAT has licensed the patented RTWCG process to Equity Solar Inc. and Equity Microelectronics Inc. of San Anselmo, California, to bring the technology to the commercial solar energy and microelectronics markets. \n                        “We believe the RTWCG technology has the potential to supplant traditional oxides in many different applications,” says Greg Knight, Equity Solar’s chief technology officer. For microelectronics, silicon oxide provides electrical insulation, and the rapid growth and variable thickness of the oxide layer produced by the RTWCG process makes it ideal for semiconductor applications such as microelectromechanical systems, LED displays, and power-electronic devices. The process also has potential use in optoelectronics due to certain properties of silicon oxide that make it useful as an optical waveguide. \n                        The technology currently stands to make the most immediate impact in the field of solar energy, however.\n                        \n                          \n                          \n                            \n                          \n                          \n                            OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                          \n                        \n                        “What this technology means for the solar energy business is quite profound,” says Knight. “The coatings created in this process have a lower level of reflectance than anything you can get in the market right now.” \n                        In terms of solar cell fabrication, there are four prime benefits provided by the NASA-derived RTWCG technology. First, the silicon oxide antireflective coating produces a lower reflectance than a standard textured silicon nitride coating, meaning the cell can trap more light. The coating also passivates the cell’s surface, chemically stabilizing it so that the electrons produced when light hits the surface survive in a capturable state for longer. \n                        The RTWCG process also cleans the cell’s surface and contacts and can be used to create what is known as a selective emitter, an advanced type of solar cell construction that enhances the electrical properties of the cell. All of these benefits contribute to increased solar cell efficiency and are delivered during the quick RTWCG chemical immersion. \n                        “The RTWCG technology can enable manufacturers to produce cells that have the lowest ‘cost per watt’ in the PV industry today by increasing the solar cells’ efficiency while lowering the process cost,” says Knight. Standard terrestrial PV cells have efficiencies of 15–18 percent, he explains. Expensive high-end cells can provide up to 21 percent efficiency, and Knight says Equity Solar’s licensed technology will enable cells like these with existing high-end constructions to be made at dramatically lower cost. \n                        Since cost-effectiveness is a major obstacle to the widespread implementation of PV technology as a renewable energy source, the RTWCG stands to become a critical tool for solar cell designers seeking to expand the industry.\n                         “We believe this technology has the potential to be integrated into all crystalline silicon cells in the future,” Knight says. “If this happens, it would truly have a worldwide impact.”\n                        Equity Solar is pursuing extensive validation of the technology while exploring partnerships with PV cell manufacturers to implement the process. SPECMAT, meanwhile, is glad for the fruits of the efforts that were started at Glenn. \n                        “Developing the RTWCG process has been a critical part of SPECMAT’s existence and has led to the employment of several scientists since our work with NASA commenced and following through our license agreement with Equity Solar,” says Faur. “NASA’s support of companies such as ours will yield benefits for solar cell manufacturers and ultimately industry and the general public both in the United States and worldwide.”\n                      \n                       \n                        \n                    \n                  \n                \n              \n            \n            \n              \n                \n                  \n                    \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            The International Space Station derives power from its massive photovoltaic panels (seen in the upper left). NASA tested new solar cell technologies in space through the Forward Technology Solar Cell Experiment (inset), part of the Materials International Space Station Experiment 5. \n                          \n                        \n                        NASA currently has spacecraft orbiting Mercury (MESSENGER), imaging the asteroid Vesta (Dawn), roaming the red plains of Mars (the Opportunity rover), and providing a laboratory for humans to advance scientific research in space \n                          (the International Space Station, or ISS). The heart \n                          of the technology that powers those missions and \n                          many others can be held in the palm of your hand—the solar cell. \n                        Solar, or photovoltaic (PV), cells are what make up the panels and arrays that draw on the Sun’s light to generate electricity for everything from the Hubble Space Telescope’s imaging equipment to the life support systems for the ISS. To enable NASA spacecraft to utilize the Sun’s energy for exploring destinations as distant as Jupiter, the Agency has invested significant research into improving solar cell design and efficiency. \n                        Glenn Research Center has been a national leader in advancing PV technology. The Center’s Photovoltaic and Power Technologies Branch has conducted numerous experiments aimed at developing lighter, more efficient solar cells that are less expensive to manufacture. Initiatives like the Forward Technology Solar Cell Experiments I and II—in which PV cells developed by NASA and private industry were mounted outside the ISS—have tested how various solar technologies perform in the harsh conditions of space. While NASA seeks to improve solar cells for space applications, the results are returning to Earth to benefit the solar energy industry.\n                        Partnership\n                        Throughout the 1980s and 1990s, Maria Faur, while conducting research for NASA Glenn (then Lewis Reseach Center), developed new techniques for enhancing solar cell manufacturing and design. In 1995, Faur founded Special Materials Research and Technology Inc. (SPECMAT) to expand these efforts. The following year, the company entered into a Space Act Agreement with Glenn, and in 1999, became one of the first tenants of the NASA Lewis Incubator for Technology. Both partnerships helped to provide SPECMAT with the means to advance a proprietary method Faur had developed while working for NASA to enhance solar cells in a way not previously achievable.\n                        SPECMAT’s room-temperature wet chemical growth (RTWCG) silicon oxide process provides a unique method to fabricate high-efficiency silicon solar cells at significantly reduced cost. Solar cells require an antireflective coating to help the cells capture the light particles, called photons, needed to generate electricity. Traditional crystalline silicon cells typically use a silicon nitride coating, sometimes in conjunction with a textured surface, to produce the necessary antireflective characteristics. But the current processes for adding antireflective coatings employ expensive machines that operate at high temperatures and require use of toxic gasses. SPECMAT’s RTWCG process involves bathing the PV cell in a room-temperature chemical solution for less than a minute, growing an antireflective layer of silicon oxide on the cell’s surface and providing the cell with a range of enhanced qualities. \n                        “The ability to grow oxide at room temperature is unique in the industry,” says Faur, president and CEO of SPECMAT. The company patented the RTWCG process, and now, says Faur, the NASA-derived innovation stands poised to become a powerful technology for use in the fabrication of solar cells, microelectronics, and photonic devices.\n                        Benefits\n                        SPECMAT has licensed the patented RTWCG process to Equity Solar Inc. and Equity Microelectronics Inc. of San Anselmo, California, to bring the technology to the commercial solar energy and microelectronics markets. \n                        “We believe the RTWCG technology has the potential to supplant traditional oxides in many different applications,” says Greg Knight, Equity Solar’s chief technology officer. For microelectronics, silicon oxide provides electrical insulation, and the rapid growth and variable thickness of the oxide layer produced by the RTWCG process makes it ideal for semiconductor applications such as microelectromechanical systems, LED displays, and power-electronic devices. The process also has potential use in optoelectronics due to certain properties of silicon oxide that make it useful as an optical waveguide. \n                        The technology currently stands to make the most immediate impact in the field of solar energy, however.\n                        \n                          \n                          \n                            \n                          \n                          \n                            OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                          \n                        \n                        “What this technology means for the solar energy business is quite profound,” says Knight. “The coatings created in this process have a lower level of reflectance than anything you can get in the market right now.” \n                        In terms of solar cell fabrication, there are four prime benefits provided by the NASA-derived RTWCG technology. First, the silicon oxide antireflective coating produces a lower reflectance than a standard textured silicon nitride coating, meaning the cell can trap more light. The coating also passivates the cell’s surface, chemically stabilizing it so that the electrons produced when light hits the surface survive in a capturable state for longer. \n                        The RTWCG process also cleans the cell’s surface and contacts and can be used to create what is known as a selective emitter, an advanced type of solar cell construction that enhances the electrical properties of the cell. All of these benefits contribute to increased solar cell efficiency and are delivered during the quick RTWCG chemical immersion. \n                        “The RTWCG technology can enable manufacturers to produce cells that have the lowest ‘cost per watt’ in the PV industry today by increasing the solar cells’ efficiency while lowering the process cost,” says Knight. Standard terrestrial PV cells have efficiencies of 15–18 percent, he explains. Expensive high-end cells can provide up to 21 percent efficiency, and Knight says Equity Solar’s licensed technology will enable cells like these with existing high-end constructions to be made at dramatically lower cost. \n                        Since cost-effectiveness is a major obstacle to the widespread implementation of PV technology as a renewable energy source, the RTWCG stands to become a critical tool for solar cell designers seeking to expand the industry.\n                         “We believe this technology has the potential to be integrated into all crystalline silicon cells in the future,” Knight says. “If this happens, it would truly have a worldwide impact.”\n                        Equity Solar is pursuing extensive validation of the technology while exploring partnerships with PV cell manufacturers to implement the process. SPECMAT, meanwhile, is glad for the fruits of the efforts that were started at Glenn. \n                        “Developing the RTWCG process has been a critical part of SPECMAT’s existence and has led to the employment of several scientists since our work with NASA commenced and following through our license agreement with Equity Solar,” says Faur. “NASA’s support of companies such as ours will yield benefits for solar cell manufacturers and ultimately industry and the general public both in the United States and worldwide.”\n                      \n                       \n                        \n                    \n                  \n                \n              \n                  \n                    \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            The International Space Station derives power from its massive photovoltaic panels (seen in the upper left). NASA tested new solar cell technologies in space through the Forward Technology Solar Cell Experiment (inset), part of the Materials International Space Station Experiment 5. \n                          \n                        \n                        NASA currently has spacecraft orbiting Mercury (MESSENGER), imaging the asteroid Vesta (Dawn), roaming the red plains of Mars (the Opportunity rover), and providing a laboratory for humans to advance scientific research in space \n                          (the International Space Station, or ISS). The heart \n                          of the technology that powers those missions and \n                          many others can be held in the palm of your hand—the solar cell. \n                        Solar, or photovoltaic (PV), cells are what make up the panels and arrays that draw on the Sun’s light to generate electricity for everything from the Hubble Space Telescope’s imaging equipment to the life support systems for the ISS. To enable NASA spacecraft to utilize the Sun’s energy for exploring destinations as distant as Jupiter, the Agency has invested significant research into improving solar cell design and efficiency. \n                        Glenn Research Center has been a national leader in advancing PV technology. The Center’s Photovoltaic and Power Technologies Branch has conducted numerous experiments aimed at developing lighter, more efficient solar cells that are less expensive to manufacture. Initiatives like the Forward Technology Solar Cell Experiments I and II—in which PV cells developed by NASA and private industry were mounted outside the ISS—have tested how various solar technologies perform in the harsh conditions of space. While NASA seeks to improve solar cells for space applications, the results are returning to Earth to benefit the solar energy industry.\n                        Partnership\n                        Throughout the 1980s and 1990s, Maria Faur, while conducting research for NASA Glenn (then Lewis Reseach Center), developed new techniques for enhancing solar cell manufacturing and design. In 1995, Faur founded Special Materials Research and Technology Inc. (SPECMAT) to expand these efforts. The following year, the company entered into a Space Act Agreement with Glenn, and in 1999, became one of the first tenants of the NASA Lewis Incubator for Technology. Both partnerships helped to provide SPECMAT with the means to advance a proprietary method Faur had developed while working for NASA to enhance solar cells in a way not previously achievable.\n                        SPECMAT’s room-temperature wet chemical growth (RTWCG) silicon oxide process provides a unique method to fabricate high-efficiency silicon solar cells at significantly reduced cost. Solar cells require an antireflective coating to help the cells capture the light particles, called photons, needed to generate electricity. Traditional crystalline silicon cells typically use a silicon nitride coating, sometimes in conjunction with a textured surface, to produce the necessary antireflective characteristics. But the current processes for adding antireflective coatings employ expensive machines that operate at high temperatures and require use of toxic gasses. SPECMAT’s RTWCG process involves bathing the PV cell in a room-temperature chemical solution for less than a minute, growing an antireflective layer of silicon oxide on the cell’s surface and providing the cell with a range of enhanced qualities. \n                        “The ability to grow oxide at room temperature is unique in the industry,” says Faur, president and CEO of SPECMAT. The company patented the RTWCG process, and now, says Faur, the NASA-derived innovation stands poised to become a powerful technology for use in the fabrication of solar cells, microelectronics, and photonic devices.\n                        Benefits\n                        SPECMAT has licensed the patented RTWCG process to Equity Solar Inc. and Equity Microelectronics Inc. of San Anselmo, California, to bring the technology to the commercial solar energy and microelectronics markets. \n                        “We believe the RTWCG technology has the potential to supplant traditional oxides in many different applications,” says Greg Knight, Equity Solar’s chief technology officer. For microelectronics, silicon oxide provides electrical insulation, and the rapid growth and variable thickness of the oxide layer produced by the RTWCG process makes it ideal for semiconductor applications such as microelectromechanical systems, LED displays, and power-electronic devices. The process also has potential use in optoelectronics due to certain properties of silicon oxide that make it useful as an optical waveguide. \n                        The technology currently stands to make the most immediate impact in the field of solar energy, however.\n                        \n                          \n                          \n                            \n                          \n                          \n                            OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                          \n                        \n                        “What this technology means for the solar energy business is quite profound,” says Knight. “The coatings created in this process have a lower level of reflectance than anything you can get in the market right now.” \n                        In terms of solar cell fabrication, there are four prime benefits provided by the NASA-derived RTWCG technology. First, the silicon oxide antireflective coating produces a lower reflectance than a standard textured silicon nitride coating, meaning the cell can trap more light. The coating also passivates the cell’s surface, chemically stabilizing it so that the electrons produced when light hits the surface survive in a capturable state for longer. \n                        The RTWCG process also cleans the cell’s surface and contacts and can be used to create what is known as a selective emitter, an advanced type of solar cell construction that enhances the electrical properties of the cell. All of these benefits contribute to increased solar cell efficiency and are delivered during the quick RTWCG chemical immersion. \n                        “The RTWCG technology can enable manufacturers to produce cells that have the lowest ‘cost per watt’ in the PV industry today by increasing the solar cells’ efficiency while lowering the process cost,” says Knight. Standard terrestrial PV cells have efficiencies of 15–18 percent, he explains. Expensive high-end cells can provide up to 21 percent efficiency, and Knight says Equity Solar’s licensed technology will enable cells like these with existing high-end constructions to be made at dramatically lower cost. \n                        Since cost-effectiveness is a major obstacle to the widespread implementation of PV technology as a renewable energy source, the RTWCG stands to become a critical tool for solar cell designers seeking to expand the industry.\n                         “We believe this technology has the potential to be integrated into all crystalline silicon cells in the future,” Knight says. “If this happens, it would truly have a worldwide impact.”\n                        Equity Solar is pursuing extensive validation of the technology while exploring partnerships with PV cell manufacturers to implement the process. SPECMAT, meanwhile, is glad for the fruits of the efforts that were started at Glenn. \n                        “Developing the RTWCG process has been a critical part of SPECMAT’s existence and has led to the employment of several scientists since our work with NASA commenced and following through our license agreement with Equity Solar,” says Faur. “NASA’s support of companies such as ours will yield benefits for solar cell manufacturers and ultimately industry and the general public both in the United States and worldwide.”\n                      \n                       \n                        \n                    \n                  \n                    \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            The International Space Station derives power from its massive photovoltaic panels (seen in the upper left). NASA tested new solar cell technologies in space through the Forward Technology Solar Cell Experiment (inset), part of the Materials International Space Station Experiment 5. \n                          \n                        \n                        NASA currently has spacecraft orbiting Mercury (MESSENGER), imaging the asteroid Vesta (Dawn), roaming the red plains of Mars (the Opportunity rover), and providing a laboratory for humans to advance scientific research in space \n                          (the International Space Station, or ISS). The heart \n                          of the technology that powers those missions and \n                          many others can be held in the palm of your hand—the solar cell. \n                        Solar, or photovoltaic (PV), cells are what make up the panels and arrays that draw on the Sun’s light to generate electricity for everything from the Hubble Space Telescope’s imaging equipment to the life support systems for the ISS. To enable NASA spacecraft to utilize the Sun’s energy for exploring destinations as distant as Jupiter, the Agency has invested significant research into improving solar cell design and efficiency. \n                        Glenn Research Center has been a national leader in advancing PV technology. The Center’s Photovoltaic and Power Technologies Branch has conducted numerous experiments aimed at developing lighter, more efficient solar cells that are less expensive to manufacture. Initiatives like the Forward Technology Solar Cell Experiments I and II—in which PV cells developed by NASA and private industry were mounted outside the ISS—have tested how various solar technologies perform in the harsh conditions of space. While NASA seeks to improve solar cells for space applications, the results are returning to Earth to benefit the solar energy industry.\n                        Partnership\n                        Throughout the 1980s and 1990s, Maria Faur, while conducting research for NASA Glenn (then Lewis Reseach Center), developed new techniques for enhancing solar cell manufacturing and design. In 1995, Faur founded Special Materials Research and Technology Inc. (SPECMAT) to expand these efforts. The following year, the company entered into a Space Act Agreement with Glenn, and in 1999, became one of the first tenants of the NASA Lewis Incubator for Technology. Both partnerships helped to provide SPECMAT with the means to advance a proprietary method Faur had developed while working for NASA to enhance solar cells in a way not previously achievable.\n                        SPECMAT’s room-temperature wet chemical growth (RTWCG) silicon oxide process provides a unique method to fabricate high-efficiency silicon solar cells at significantly reduced cost. Solar cells require an antireflective coating to help the cells capture the light particles, called photons, needed to generate electricity. Traditional crystalline silicon cells typically use a silicon nitride coating, sometimes in conjunction with a textured surface, to produce the necessary antireflective characteristics. But the current processes for adding antireflective coatings employ expensive machines that operate at high temperatures and require use of toxic gasses. SPECMAT’s RTWCG process involves bathing the PV cell in a room-temperature chemical solution for less than a minute, growing an antireflective layer of silicon oxide on the cell’s surface and providing the cell with a range of enhanced qualities. \n                        “The ability to grow oxide at room temperature is unique in the industry,” says Faur, president and CEO of SPECMAT. The company patented the RTWCG process, and now, says Faur, the NASA-derived innovation stands poised to become a powerful technology for use in the fabrication of solar cells, microelectronics, and photonic devices.\n                        Benefits\n                        SPECMAT has licensed the patented RTWCG process to Equity Solar Inc. and Equity Microelectronics Inc. of San Anselmo, California, to bring the technology to the commercial solar energy and microelectronics markets. \n                        “We believe the RTWCG technology has the potential to supplant traditional oxides in many different applications,” says Greg Knight, Equity Solar’s chief technology officer. For microelectronics, silicon oxide provides electrical insulation, and the rapid growth and variable thickness of the oxide layer produced by the RTWCG process makes it ideal for semiconductor applications such as microelectromechanical systems, LED displays, and power-electronic devices. The process also has potential use in optoelectronics due to certain properties of silicon oxide that make it useful as an optical waveguide. \n                        The technology currently stands to make the most immediate impact in the field of solar energy, however.\n                        \n                          \n                          \n                            \n                          \n                          \n                            OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                          \n                        \n                        “What this technology means for the solar energy business is quite profound,” says Knight. “The coatings created in this process have a lower level of reflectance than anything you can get in the market right now.” \n                        In terms of solar cell fabrication, there are four prime benefits provided by the NASA-derived RTWCG technology. First, the silicon oxide antireflective coating produces a lower reflectance than a standard textured silicon nitride coating, meaning the cell can trap more light. The coating also passivates the cell’s surface, chemically stabilizing it so that the electrons produced when light hits the surface survive in a capturable state for longer. \n                        The RTWCG process also cleans the cell’s surface and contacts and can be used to create what is known as a selective emitter, an advanced type of solar cell construction that enhances the electrical properties of the cell. All of these benefits contribute to increased solar cell efficiency and are delivered during the quick RTWCG chemical immersion. \n                        “The RTWCG technology can enable manufacturers to produce cells that have the lowest ‘cost per watt’ in the PV industry today by increasing the solar cells’ efficiency while lowering the process cost,” says Knight. Standard terrestrial PV cells have efficiencies of 15–18 percent, he explains. Expensive high-end cells can provide up to 21 percent efficiency, and Knight says Equity Solar’s licensed technology will enable cells like these with existing high-end constructions to be made at dramatically lower cost. \n                        Since cost-effectiveness is a major obstacle to the widespread implementation of PV technology as a renewable energy source, the RTWCG stands to become a critical tool for solar cell designers seeking to expand the industry.\n                         “We believe this technology has the potential to be integrated into all crystalline silicon cells in the future,” Knight says. “If this happens, it would truly have a worldwide impact.”\n                        Equity Solar is pursuing extensive validation of the technology while exploring partnerships with PV cell manufacturers to implement the process. SPECMAT, meanwhile, is glad for the fruits of the efforts that were started at Glenn. \n                        “Developing the RTWCG process has been a critical part of SPECMAT’s existence and has led to the employment of several scientists since our work with NASA commenced and following through our license agreement with Equity Solar,” says Faur. “NASA’s support of companies such as ours will yield benefits for solar cell manufacturers and ultimately industry and the general public both in the United States and worldwide.”\n                      \n                       \n                        \n                    \n                      \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            The International Space Station derives power from its massive photovoltaic panels (seen in the upper left). NASA tested new solar cell technologies in space through the Forward Technology Solar Cell Experiment (inset), part of the Materials International Space Station Experiment 5. \n                          \n                        \n                        NASA currently has spacecraft orbiting Mercury (MESSENGER), imaging the asteroid Vesta (Dawn), roaming the red plains of Mars (the Opportunity rover), and providing a laboratory for humans to advance scientific research in space \n                          (the International Space Station, or ISS). The heart \n                          of the technology that powers those missions and \n                          many others can be held in the palm of your hand—the solar cell. \n                        Solar, or photovoltaic (PV), cells are what make up the panels and arrays that draw on the Sun’s light to generate electricity for everything from the Hubble Space Telescope’s imaging equipment to the life support systems for the ISS. To enable NASA spacecraft to utilize the Sun’s energy for exploring destinations as distant as Jupiter, the Agency has invested significant research into improving solar cell design and efficiency. \n                        Glenn Research Center has been a national leader in advancing PV technology. The Center’s Photovoltaic and Power Technologies Branch has conducted numerous experiments aimed at developing lighter, more efficient solar cells that are less expensive to manufacture. Initiatives like the Forward Technology Solar Cell Experiments I and II—in which PV cells developed by NASA and private industry were mounted outside the ISS—have tested how various solar technologies perform in the harsh conditions of space. While NASA seeks to improve solar cells for space applications, the results are returning to Earth to benefit the solar energy industry.\n                        Partnership\n                        Throughout the 1980s and 1990s, Maria Faur, while conducting research for NASA Glenn (then Lewis Reseach Center), developed new techniques for enhancing solar cell manufacturing and design. In 1995, Faur founded Special Materials Research and Technology Inc. (SPECMAT) to expand these efforts. The following year, the company entered into a Space Act Agreement with Glenn, and in 1999, became one of the first tenants of the NASA Lewis Incubator for Technology. Both partnerships helped to provide SPECMAT with the means to advance a proprietary method Faur had developed while working for NASA to enhance solar cells in a way not previously achievable.\n                        SPECMAT’s room-temperature wet chemical growth (RTWCG) silicon oxide process provides a unique method to fabricate high-efficiency silicon solar cells at significantly reduced cost. Solar cells require an antireflective coating to help the cells capture the light particles, called photons, needed to generate electricity. Traditional crystalline silicon cells typically use a silicon nitride coating, sometimes in conjunction with a textured surface, to produce the necessary antireflective characteristics. But the current processes for adding antireflective coatings employ expensive machines that operate at high temperatures and require use of toxic gasses. SPECMAT’s RTWCG process involves bathing the PV cell in a room-temperature chemical solution for less than a minute, growing an antireflective layer of silicon oxide on the cell’s surface and providing the cell with a range of enhanced qualities. \n                        “The ability to grow oxide at room temperature is unique in the industry,” says Faur, president and CEO of SPECMAT. The company patented the RTWCG process, and now, says Faur, the NASA-derived innovation stands poised to become a powerful technology for use in the fabrication of solar cells, microelectronics, and photonic devices.\n                        Benefits\n                        SPECMAT has licensed the patented RTWCG process to Equity Solar Inc. and Equity Microelectronics Inc. of San Anselmo, California, to bring the technology to the commercial solar energy and microelectronics markets. \n                        “We believe the RTWCG technology has the potential to supplant traditional oxides in many different applications,” says Greg Knight, Equity Solar’s chief technology officer. For microelectronics, silicon oxide provides electrical insulation, and the rapid growth and variable thickness of the oxide layer produced by the RTWCG process makes it ideal for semiconductor applications such as microelectromechanical systems, LED displays, and power-electronic devices. The process also has potential use in optoelectronics due to certain properties of silicon oxide that make it useful as an optical waveguide. \n                        The technology currently stands to make the most immediate impact in the field of solar energy, however.\n                        \n                          \n                          \n                            \n                          \n                          \n                            OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                          \n                        \n                        “What this technology means for the solar energy business is quite profound,” says Knight. “The coatings created in this process have a lower level of reflectance than anything you can get in the market right now.” \n                        In terms of solar cell fabrication, there are four prime benefits provided by the NASA-derived RTWCG technology. First, the silicon oxide antireflective coating produces a lower reflectance than a standard textured silicon nitride coating, meaning the cell can trap more light. The coating also passivates the cell’s surface, chemically stabilizing it so that the electrons produced when light hits the surface survive in a capturable state for longer. \n                        The RTWCG process also cleans the cell’s surface and contacts and can be used to create what is known as a selective emitter, an advanced type of solar cell construction that enhances the electrical properties of the cell. All of these benefits contribute to increased solar cell efficiency and are delivered during the quick RTWCG chemical immersion. \n                        “The RTWCG technology can enable manufacturers to produce cells that have the lowest ‘cost per watt’ in the PV industry today by increasing the solar cells’ efficiency while lowering the process cost,” says Knight. Standard terrestrial PV cells have efficiencies of 15–18 percent, he explains. Expensive high-end cells can provide up to 21 percent efficiency, and Knight says Equity Solar’s licensed technology will enable cells like these with existing high-end constructions to be made at dramatically lower cost. \n                        Since cost-effectiveness is a major obstacle to the widespread implementation of PV technology as a renewable energy source, the RTWCG stands to become a critical tool for solar cell designers seeking to expand the industry.\n                         “We believe this technology has the potential to be integrated into all crystalline silicon cells in the future,” Knight says. “If this happens, it would truly have a worldwide impact.”\n                        Equity Solar is pursuing extensive validation of the technology while exploring partnerships with PV cell manufacturers to implement the process. SPECMAT, meanwhile, is glad for the fruits of the efforts that were started at Glenn. \n                        “Developing the RTWCG process has been a critical part of SPECMAT’s existence and has led to the employment of several scientists since our work with NASA commenced and following through our license agreement with Equity Solar,” says Faur. “NASA’s support of companies such as ours will yield benefits for solar cell manufacturers and ultimately industry and the general public both in the United States and worldwide.”\n                      \n                       \n                        \n                        NASA Technology\n                        \n                          \n                          \n                            \n                          \n                          \n                            The International Space Station derives power from its massive photovoltaic panels (seen in the upper left). NASA tested new solar cell technologies in space through the Forward Technology Solar Cell Experiment (inset), part of the Materials International Space Station Experiment 5. \n                          \n                        \n                        NASA currently has spacecraft orbiting Mercury (MESSENGER), imaging the asteroid Vesta (Dawn), roaming the red plains of Mars (the Opportunity rover), and providing a laboratory for humans to advance scientific research in space \n                          (the International Space Station, or ISS). The heart \n                          of the technology that powers those missions and \n                          many others can be held in the palm of your hand—the solar cell. \n                        Solar, or photovoltaic (PV), cells are what make up the panels and arrays that draw on the Sun’s light to generate electricity for everything from the Hubble Space Telescope’s imaging equipment to the life support systems for the ISS. To enable NASA spacecraft to utilize the Sun’s energy for exploring destinations as distant as Jupiter, the Agency has invested significant research into improving solar cell design and efficiency. \n                        Glenn Research Center has been a national leader in advancing PV technology. The Center’s Photovoltaic and Power Technologies Branch has conducted numerous experiments aimed at developing lighter, more efficient solar cells that are less expensive to manufacture. Initiatives like the Forward Technology Solar Cell Experiments I and II—in which PV cells developed by NASA and private industry were mounted outside the ISS—have tested how various solar technologies perform in the harsh conditions of space. While NASA seeks to improve solar cells for space applications, the results are returning to Earth to benefit the solar energy industry.\n                        Partnership\n                        Throughout the 1980s and 1990s, Maria Faur, while conducting research for NASA Glenn (then Lewis Reseach Center), developed new techniques for enhancing solar cell manufacturing and design. In 1995, Faur founded Special Materials Research and Technology Inc. (SPECMAT) to expand these efforts. The following year, the company entered into a Space Act Agreement with Glenn, and in 1999, became one of the first tenants of the NASA Lewis Incubator for Technology. Both partnerships helped to provide SPECMAT with the means to advance a proprietary method Faur had developed while working for NASA to enhance solar cells in a way not previously achievable.\n                        SPECMAT’s room-temperature wet chemical growth (RTWCG) silicon oxide process provides a unique method to fabricate high-efficiency silicon solar cells at significantly reduced cost. Solar cells require an antireflective coating to help the cells capture the light particles, called photons, needed to generate electricity. Traditional crystalline silicon cells typically use a silicon nitride coating, sometimes in conjunction with a textured surface, to produce the necessary antireflective characteristics. But the current processes for adding antireflective coatings employ expensive machines that operate at high temperatures and require use of toxic gasses. SPECMAT’s RTWCG process involves bathing the PV cell in a room-temperature chemical solution for less than a minute, growing an antireflective layer of silicon oxide on the cell’s surface and providing the cell with a range of enhanced qualities. \n                        “The ability to grow oxide at room temperature is unique in the industry,” says Faur, president and CEO of SPECMAT. The company patented the RTWCG process, and now, says Faur, the NASA-derived innovation stands poised to become a powerful technology for use in the fabrication of solar cells, microelectronics, and photonic devices.\n                        Benefits\n                        SPECMAT has licensed the patented RTWCG process to Equity Solar Inc. and Equity Microelectronics Inc. of San Anselmo, California, to bring the technology to the commercial solar energy and microelectronics markets. \n                        “We believe the RTWCG technology has the potential to supplant traditional oxides in many different applications,” says Greg Knight, Equity Solar’s chief technology officer. For microelectronics, silicon oxide provides electrical insulation, and the rapid growth and variable thickness of the oxide layer produced by the RTWCG process makes it ideal for semiconductor applications such as microelectromechanical systems, LED displays, and power-electronic devices. The process also has potential use in optoelectronics due to certain properties of silicon oxide that make it useful as an optical waveguide. \n                        The technology currently stands to make the most immediate impact in the field of solar energy, however.\n                        \n                          \n                          \n                            \n                          \n                          \n                            OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                          \n                        \n                        “What this technology means for the solar energy business is quite profound,” says Knight. “The coatings created in this process have a lower level of reflectance than anything you can get in the market right now.” \n                        In terms of solar cell fabrication, there are four prime benefits provided by the NASA-derived RTWCG technology. First, the silicon oxide antireflective coating produces a lower reflectance than a standard textured silicon nitride coating, meaning the cell can trap more light. The coating also passivates the cell’s surface, chemically stabilizing it so that the electrons produced when light hits the surface survive in a capturable state for longer. \n                        The RTWCG process also cleans the cell’s surface and contacts and can be used to create what is known as a selective emitter, an advanced type of solar cell construction that enhances the electrical properties of the cell. All of these benefits contribute to increased solar cell efficiency and are delivered during the quick RTWCG chemical immersion. \n                        “The RTWCG technology can enable manufacturers to produce cells that have the lowest ‘cost per watt’ in the PV industry today by increasing the solar cells’ efficiency while lowering the process cost,” says Knight. Standard terrestrial PV cells have efficiencies of 15–18 percent, he explains. Expensive high-end cells can provide up to 21 percent efficiency, and Knight says Equity Solar’s licensed technology will enable cells like these with existing high-end constructions to be made at dramatically lower cost. \n                        Since cost-effectiveness is a major obstacle to the widespread implementation of PV technology as a renewable energy source, the RTWCG stands to become a critical tool for solar cell designers seeking to expand the industry.\n                         “We believe this technology has the potential to be integrated into all crystalline silicon cells in the future,” Knight says. “If this happens, it would truly have a worldwide impact.”\n                        Equity Solar is pursuing extensive validation of the technology while exploring partnerships with PV cell manufacturers to implement the process. SPECMAT, meanwhile, is glad for the fruits of the efforts that were started at Glenn. \n                        “Developing the RTWCG process has been a critical part of SPECMAT’s existence and has led to the employment of several scientists since our work with NASA commenced and following through our license agreement with Equity Solar,” says Faur. “NASA’s support of companies such as ours will yield benefits for solar cell manufacturers and ultimately industry and the general public both in the United States and worldwide.”\n                      "},{"href":"http://spinoff.nasa.gov/Spinoff2011/er_6.html","text":"Analyzers Provide Water Security in Space and on Earth","image":"http://spinoff.nasa.gov/Spinoff2011/Images/er_9a_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                                                      Astronaut Sandy Magnus examines the International Space Station’s total organic carbon analyzer (TOCA). The technology was developed for NASA by OI Analytical and monitors the quality of the crew’s water supply.\n                        \n                      \n                      Resourcefulness is a key quality for living in space, and on the International Space Station (ISS), that means making the most of water supplies. In 2008, the installation of the Water Processing Assembly (WPA) onboard the ISS allowed the space station’s crew to do just that. The WPA purifies moisture from nearly every possible source—sweat, water vapor, wastewater, and even urine—for drinking and oxygen generation. Capable of producing 35 gallons of potable, recycled water a day, the system has reduced the need for water delivered to the ISS by over 1,000 gallons a year, saving significant payload costs in the process. \n                      As with any drinking water, quality is a concern, particularly when that water has been recycled. This is an issue of particular interest in space, where ISS crew members would have to deal with any illness far from the nearest medical personnel and facilities. The WPA employs sensors that monitor water quality by measuring its conductivity, and rounding out the system’s quality assurance methods is a device developed for NASA by a private industry partner. That company has now made the technology available for ensuring the purity of water for consumption and industrial uses on Earth. \n                      Partnership\n                      Known as a total organic carbon analyzer (TOCA), this device measures organic carbon levels in water, a key indicator of water quality, as carbon is present in most dangerous contaminants. Prior to the installation of the WPA, the ISS had a commercial TOCA onboard, but that technology did not fully satisfy NASA’s requirements. To develop a better solution to ensure the potability of the WPA’s recycled water, NASA contracted OI Analytical of College Station, Texas, in 2006. Working in conjunction with Wyle Laboratories, the company had proposed an advanced TOCA device that provided fast, effective monitoring of TOC levels while eliminating aspects of the technology that made it impractical for space applications. \n                      The resulting Proto-flight Unit, or PFU1, proved to be the innovative breakthrough NASA needed to fully enable the WPA. Detection of TOC in water requires an oxidation process that standard TOCAs generate using either expensive, hazardous chemicals or through high temperature combustion—neither feasible for an environment like the ISS. OI devised an electrochemical solution to create oxidation using the water itself. By applying an electrical voltage to a composite electrode in the oxidation chamber of the analyzer, the TOCA breaks down the water sample, forming hydroxyl radicals that in turn break down any organic molecules into carbon dioxide and water. The analyzer’s infrared detector then measures the concentration of carbon dioxide to provide an accurate assessment of the water’s organic carbon content. \n                      The OI device can be installed at a cost as \n                        much as 90-percent less than other \n                        TOCA systems. \n                      “The original prototype was at a level that allowed us to save two years in the development process,” says Gary Erickson, research and development manager for the TOCA project. This in turn allowed NASA to implement the WPA ahead of schedule. With the system’s recycling capabilities and now fully redundant safety measures, the ISS not only required fewer water deliveries, but it was also able to realize its full crew capacity—increasing from three members up to six. \n                      Benefits\n                      OI recognized the potential for its NASA technology as a commercial solution. Adapting it for terrestrial use, the company now sells the electrochemical-oxidation device as its 9210e On-Line Total Organic Carbon Analyzer. The NASA-derived system provides a host of benefits for water quality applications ranging from municipal and industrial water treatment to feed water and condensate return in turbines and boiler systems. \n                      “Essentially any place where large amounts of water are used, from the cleanest to the most contaminated, the need to measure organic carbon exists,” says Erickson, also market manager for the TOCA technology, “but the cost-prohibitive nature of the technology kept it from being mandated in a number of areas, and it kept commercial companies from utilizing the technology.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                        \n                      \n                      The most significant cost incurred by standard TOCA technology comes from the chemicals needed to support it, Erickson explains. The 9210e’s reagentless electrochemical oxidation eliminates the need for these chemicals, saving the typical operator as much as $500 a month, says Erickson. This adds up for industrial \n                        users that often have tens to hundreds of units installed in their plants. \n                      For combustion oxidation-based analyzers, expensive infrastructure is often required, particularly in chemical plants and petrochemical refineries where a cooled, explosion-proof housing is required, incurring costs as high as $300,000–$500,000. The OI device has a footprint roughly the size of an 11-by-7-inch piece of paper—much smaller than previous units the size of small refrigerators—and can be installed at a cost as much as 90-percent less than other TOCA systems, a comparative savings of $270,000–$450,000. \n                      “We are able to put this small-footprint device into cabinetry at a much lower price point, and the day-to-day operating costs are much less as well,” says Craig Marvin, director of sales and marketing at OI. \n                      The technology’s ease-of-use and low maintenance requirements also generate returns. One OI customer reported that it employed one technician for every two of its analyzers prior to switching to the 9210e; now the customer can service 8–10 analyzers with the same technician. \n                      Gary Engelhart, OI’s laboratory products and marketing manager, notes that the company’s NASA work has led to collaboration with the U.S. Environmental Protection Agency (EPA) on ensuring the security of the Nation’s drinking water. \n                       “TOC measurement is one of the parameters the EPA would like to use in a more widespread fashion in order to provide early warning, whether it be of intentional contamination or from natural events. It’s a key homeland security directive,” he says. He also notes that the NASA-derived TOCA technology was an important factor in the company’s recent acquisition by ITT Corporation, which “will drive OI’s presence in a lot of water treatment and purification areas.” \n                      OI’s work for NASA has been a mutually beneficial relationship, says Marvin. “Our ability to piggyback on research and development by engaging in this project provided what was at the time a small company with a means to develop technology that we may have been slow to bring to market otherwise.”\n                      Meanwhile, the technology OI developed for NASA continues to benefit the ISS. The follow-on to the company’s first NASA TOCA, PFU2, arrived at the ISS in 2011 on STS-133, Space Shuttle Discovery’s final flight, and PFU3 currently awaits a future delivery\n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                                                      Astronaut Sandy Magnus examines the International Space Station’s total organic carbon analyzer (TOCA). The technology was developed for NASA by OI Analytical and monitors the quality of the crew’s water supply.\n                        \n                      \n                      Resourcefulness is a key quality for living in space, and on the International Space Station (ISS), that means making the most of water supplies. In 2008, the installation of the Water Processing Assembly (WPA) onboard the ISS allowed the space station’s crew to do just that. The WPA purifies moisture from nearly every possible source—sweat, water vapor, wastewater, and even urine—for drinking and oxygen generation. Capable of producing 35 gallons of potable, recycled water a day, the system has reduced the need for water delivered to the ISS by over 1,000 gallons a year, saving significant payload costs in the process. \n                      As with any drinking water, quality is a concern, particularly when that water has been recycled. This is an issue of particular interest in space, where ISS crew members would have to deal with any illness far from the nearest medical personnel and facilities. The WPA employs sensors that monitor water quality by measuring its conductivity, and rounding out the system’s quality assurance methods is a device developed for NASA by a private industry partner. That company has now made the technology available for ensuring the purity of water for consumption and industrial uses on Earth. \n                      Partnership\n                      Known as a total organic carbon analyzer (TOCA), this device measures organic carbon levels in water, a key indicator of water quality, as carbon is present in most dangerous contaminants. Prior to the installation of the WPA, the ISS had a commercial TOCA onboard, but that technology did not fully satisfy NASA’s requirements. To develop a better solution to ensure the potability of the WPA’s recycled water, NASA contracted OI Analytical of College Station, Texas, in 2006. Working in conjunction with Wyle Laboratories, the company had proposed an advanced TOCA device that provided fast, effective monitoring of TOC levels while eliminating aspects of the technology that made it impractical for space applications. \n                      The resulting Proto-flight Unit, or PFU1, proved to be the innovative breakthrough NASA needed to fully enable the WPA. Detection of TOC in water requires an oxidation process that standard TOCAs generate using either expensive, hazardous chemicals or through high temperature combustion—neither feasible for an environment like the ISS. OI devised an electrochemical solution to create oxidation using the water itself. By applying an electrical voltage to a composite electrode in the oxidation chamber of the analyzer, the TOCA breaks down the water sample, forming hydroxyl radicals that in turn break down any organic molecules into carbon dioxide and water. The analyzer’s infrared detector then measures the concentration of carbon dioxide to provide an accurate assessment of the water’s organic carbon content. \n                      The OI device can be installed at a cost as \n                        much as 90-percent less than other \n                        TOCA systems. \n                      “The original prototype was at a level that allowed us to save two years in the development process,” says Gary Erickson, research and development manager for the TOCA project. This in turn allowed NASA to implement the WPA ahead of schedule. With the system’s recycling capabilities and now fully redundant safety measures, the ISS not only required fewer water deliveries, but it was also able to realize its full crew capacity—increasing from three members up to six. \n                      Benefits\n                      OI recognized the potential for its NASA technology as a commercial solution. Adapting it for terrestrial use, the company now sells the electrochemical-oxidation device as its 9210e On-Line Total Organic Carbon Analyzer. The NASA-derived system provides a host of benefits for water quality applications ranging from municipal and industrial water treatment to feed water and condensate return in turbines and boiler systems. \n                      “Essentially any place where large amounts of water are used, from the cleanest to the most contaminated, the need to measure organic carbon exists,” says Erickson, also market manager for the TOCA technology, “but the cost-prohibitive nature of the technology kept it from being mandated in a number of areas, and it kept commercial companies from utilizing the technology.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                        \n                      \n                      The most significant cost incurred by standard TOCA technology comes from the chemicals needed to support it, Erickson explains. The 9210e’s reagentless electrochemical oxidation eliminates the need for these chemicals, saving the typical operator as much as $500 a month, says Erickson. This adds up for industrial \n                        users that often have tens to hundreds of units installed in their plants. \n                      For combustion oxidation-based analyzers, expensive infrastructure is often required, particularly in chemical plants and petrochemical refineries where a cooled, explosion-proof housing is required, incurring costs as high as $300,000–$500,000. The OI device has a footprint roughly the size of an 11-by-7-inch piece of paper—much smaller than previous units the size of small refrigerators—and can be installed at a cost as much as 90-percent less than other TOCA systems, a comparative savings of $270,000–$450,000. \n                      “We are able to put this small-footprint device into cabinetry at a much lower price point, and the day-to-day operating costs are much less as well,” says Craig Marvin, director of sales and marketing at OI. \n                      The technology’s ease-of-use and low maintenance requirements also generate returns. One OI customer reported that it employed one technician for every two of its analyzers prior to switching to the 9210e; now the customer can service 8–10 analyzers with the same technician. \n                      Gary Engelhart, OI’s laboratory products and marketing manager, notes that the company’s NASA work has led to collaboration with the U.S. Environmental Protection Agency (EPA) on ensuring the security of the Nation’s drinking water. \n                       “TOC measurement is one of the parameters the EPA would like to use in a more widespread fashion in order to provide early warning, whether it be of intentional contamination or from natural events. It’s a key homeland security directive,” he says. He also notes that the NASA-derived TOCA technology was an important factor in the company’s recent acquisition by ITT Corporation, which “will drive OI’s presence in a lot of water treatment and purification areas.” \n                      OI’s work for NASA has been a mutually beneficial relationship, says Marvin. “Our ability to piggyback on research and development by engaging in this project provided what was at the time a small company with a means to develop technology that we may have been slow to bring to market otherwise.”\n                      Meanwhile, the technology OI developed for NASA continues to benefit the ISS. The follow-on to the company’s first NASA TOCA, PFU2, arrived at the ISS in 2011 on STS-133, Space Shuttle Discovery’s final flight, and PFU3 currently awaits a future delivery\n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                                                      Astronaut Sandy Magnus examines the International Space Station’s total organic carbon analyzer (TOCA). The technology was developed for NASA by OI Analytical and monitors the quality of the crew’s water supply.\n                        \n                      \n                      Resourcefulness is a key quality for living in space, and on the International Space Station (ISS), that means making the most of water supplies. In 2008, the installation of the Water Processing Assembly (WPA) onboard the ISS allowed the space station’s crew to do just that. The WPA purifies moisture from nearly every possible source—sweat, water vapor, wastewater, and even urine—for drinking and oxygen generation. Capable of producing 35 gallons of potable, recycled water a day, the system has reduced the need for water delivered to the ISS by over 1,000 gallons a year, saving significant payload costs in the process. \n                      As with any drinking water, quality is a concern, particularly when that water has been recycled. This is an issue of particular interest in space, where ISS crew members would have to deal with any illness far from the nearest medical personnel and facilities. The WPA employs sensors that monitor water quality by measuring its conductivity, and rounding out the system’s quality assurance methods is a device developed for NASA by a private industry partner. That company has now made the technology available for ensuring the purity of water for consumption and industrial uses on Earth. \n                      Partnership\n                      Known as a total organic carbon analyzer (TOCA), this device measures organic carbon levels in water, a key indicator of water quality, as carbon is present in most dangerous contaminants. Prior to the installation of the WPA, the ISS had a commercial TOCA onboard, but that technology did not fully satisfy NASA’s requirements. To develop a better solution to ensure the potability of the WPA’s recycled water, NASA contracted OI Analytical of College Station, Texas, in 2006. Working in conjunction with Wyle Laboratories, the company had proposed an advanced TOCA device that provided fast, effective monitoring of TOC levels while eliminating aspects of the technology that made it impractical for space applications. \n                      The resulting Proto-flight Unit, or PFU1, proved to be the innovative breakthrough NASA needed to fully enable the WPA. Detection of TOC in water requires an oxidation process that standard TOCAs generate using either expensive, hazardous chemicals or through high temperature combustion—neither feasible for an environment like the ISS. OI devised an electrochemical solution to create oxidation using the water itself. By applying an electrical voltage to a composite electrode in the oxidation chamber of the analyzer, the TOCA breaks down the water sample, forming hydroxyl radicals that in turn break down any organic molecules into carbon dioxide and water. The analyzer’s infrared detector then measures the concentration of carbon dioxide to provide an accurate assessment of the water’s organic carbon content. \n                      The OI device can be installed at a cost as \n                        much as 90-percent less than other \n                        TOCA systems. \n                      “The original prototype was at a level that allowed us to save two years in the development process,” says Gary Erickson, research and development manager for the TOCA project. This in turn allowed NASA to implement the WPA ahead of schedule. With the system’s recycling capabilities and now fully redundant safety measures, the ISS not only required fewer water deliveries, but it was also able to realize its full crew capacity—increasing from three members up to six. \n                      Benefits\n                      OI recognized the potential for its NASA technology as a commercial solution. Adapting it for terrestrial use, the company now sells the electrochemical-oxidation device as its 9210e On-Line Total Organic Carbon Analyzer. The NASA-derived system provides a host of benefits for water quality applications ranging from municipal and industrial water treatment to feed water and condensate return in turbines and boiler systems. \n                      “Essentially any place where large amounts of water are used, from the cleanest to the most contaminated, the need to measure organic carbon exists,” says Erickson, also market manager for the TOCA technology, “but the cost-prohibitive nature of the technology kept it from being mandated in a number of areas, and it kept commercial companies from utilizing the technology.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                        \n                      \n                      The most significant cost incurred by standard TOCA technology comes from the chemicals needed to support it, Erickson explains. The 9210e’s reagentless electrochemical oxidation eliminates the need for these chemicals, saving the typical operator as much as $500 a month, says Erickson. This adds up for industrial \n                        users that often have tens to hundreds of units installed in their plants. \n                      For combustion oxidation-based analyzers, expensive infrastructure is often required, particularly in chemical plants and petrochemical refineries where a cooled, explosion-proof housing is required, incurring costs as high as $300,000–$500,000. The OI device has a footprint roughly the size of an 11-by-7-inch piece of paper—much smaller than previous units the size of small refrigerators—and can be installed at a cost as much as 90-percent less than other TOCA systems, a comparative savings of $270,000–$450,000. \n                      “We are able to put this small-footprint device into cabinetry at a much lower price point, and the day-to-day operating costs are much less as well,” says Craig Marvin, director of sales and marketing at OI. \n                      The technology’s ease-of-use and low maintenance requirements also generate returns. One OI customer reported that it employed one technician for every two of its analyzers prior to switching to the 9210e; now the customer can service 8–10 analyzers with the same technician. \n                      Gary Engelhart, OI’s laboratory products and marketing manager, notes that the company’s NASA work has led to collaboration with the U.S. Environmental Protection Agency (EPA) on ensuring the security of the Nation’s drinking water. \n                       “TOC measurement is one of the parameters the EPA would like to use in a more widespread fashion in order to provide early warning, whether it be of intentional contamination or from natural events. It’s a key homeland security directive,” he says. He also notes that the NASA-derived TOCA technology was an important factor in the company’s recent acquisition by ITT Corporation, which “will drive OI’s presence in a lot of water treatment and purification areas.” \n                      OI’s work for NASA has been a mutually beneficial relationship, says Marvin. “Our ability to piggyback on research and development by engaging in this project provided what was at the time a small company with a means to develop technology that we may have been slow to bring to market otherwise.”\n                      Meanwhile, the technology OI developed for NASA continues to benefit the ISS. The follow-on to the company’s first NASA TOCA, PFU2, arrived at the ISS in 2011 on STS-133, Space Shuttle Discovery’s final flight, and PFU3 currently awaits a future delivery\n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                                                      Astronaut Sandy Magnus examines the International Space Station’s total organic carbon analyzer (TOCA). The technology was developed for NASA by OI Analytical and monitors the quality of the crew’s water supply.\n                        \n                      \n                      Resourcefulness is a key quality for living in space, and on the International Space Station (ISS), that means making the most of water supplies. In 2008, the installation of the Water Processing Assembly (WPA) onboard the ISS allowed the space station’s crew to do just that. The WPA purifies moisture from nearly every possible source—sweat, water vapor, wastewater, and even urine—for drinking and oxygen generation. Capable of producing 35 gallons of potable, recycled water a day, the system has reduced the need for water delivered to the ISS by over 1,000 gallons a year, saving significant payload costs in the process. \n                      As with any drinking water, quality is a concern, particularly when that water has been recycled. This is an issue of particular interest in space, where ISS crew members would have to deal with any illness far from the nearest medical personnel and facilities. The WPA employs sensors that monitor water quality by measuring its conductivity, and rounding out the system’s quality assurance methods is a device developed for NASA by a private industry partner. That company has now made the technology available for ensuring the purity of water for consumption and industrial uses on Earth. \n                      Partnership\n                      Known as a total organic carbon analyzer (TOCA), this device measures organic carbon levels in water, a key indicator of water quality, as carbon is present in most dangerous contaminants. Prior to the installation of the WPA, the ISS had a commercial TOCA onboard, but that technology did not fully satisfy NASA’s requirements. To develop a better solution to ensure the potability of the WPA’s recycled water, NASA contracted OI Analytical of College Station, Texas, in 2006. Working in conjunction with Wyle Laboratories, the company had proposed an advanced TOCA device that provided fast, effective monitoring of TOC levels while eliminating aspects of the technology that made it impractical for space applications. \n                      The resulting Proto-flight Unit, or PFU1, proved to be the innovative breakthrough NASA needed to fully enable the WPA. Detection of TOC in water requires an oxidation process that standard TOCAs generate using either expensive, hazardous chemicals or through high temperature combustion—neither feasible for an environment like the ISS. OI devised an electrochemical solution to create oxidation using the water itself. By applying an electrical voltage to a composite electrode in the oxidation chamber of the analyzer, the TOCA breaks down the water sample, forming hydroxyl radicals that in turn break down any organic molecules into carbon dioxide and water. The analyzer’s infrared detector then measures the concentration of carbon dioxide to provide an accurate assessment of the water’s organic carbon content. \n                      The OI device can be installed at a cost as \n                        much as 90-percent less than other \n                        TOCA systems. \n                      “The original prototype was at a level that allowed us to save two years in the development process,” says Gary Erickson, research and development manager for the TOCA project. This in turn allowed NASA to implement the WPA ahead of schedule. With the system’s recycling capabilities and now fully redundant safety measures, the ISS not only required fewer water deliveries, but it was also able to realize its full crew capacity—increasing from three members up to six. \n                      Benefits\n                      OI recognized the potential for its NASA technology as a commercial solution. Adapting it for terrestrial use, the company now sells the electrochemical-oxidation device as its 9210e On-Line Total Organic Carbon Analyzer. The NASA-derived system provides a host of benefits for water quality applications ranging from municipal and industrial water treatment to feed water and condensate return in turbines and boiler systems. \n                      “Essentially any place where large amounts of water are used, from the cleanest to the most contaminated, the need to measure organic carbon exists,” says Erickson, also market manager for the TOCA technology, “but the cost-prohibitive nature of the technology kept it from being mandated in a number of areas, and it kept commercial companies from utilizing the technology.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                        \n                      \n                      The most significant cost incurred by standard TOCA technology comes from the chemicals needed to support it, Erickson explains. The 9210e’s reagentless electrochemical oxidation eliminates the need for these chemicals, saving the typical operator as much as $500 a month, says Erickson. This adds up for industrial \n                        users that often have tens to hundreds of units installed in their plants. \n                      For combustion oxidation-based analyzers, expensive infrastructure is often required, particularly in chemical plants and petrochemical refineries where a cooled, explosion-proof housing is required, incurring costs as high as $300,000–$500,000. The OI device has a footprint roughly the size of an 11-by-7-inch piece of paper—much smaller than previous units the size of small refrigerators—and can be installed at a cost as much as 90-percent less than other TOCA systems, a comparative savings of $270,000–$450,000. \n                      “We are able to put this small-footprint device into cabinetry at a much lower price point, and the day-to-day operating costs are much less as well,” says Craig Marvin, director of sales and marketing at OI. \n                      The technology’s ease-of-use and low maintenance requirements also generate returns. One OI customer reported that it employed one technician for every two of its analyzers prior to switching to the 9210e; now the customer can service 8–10 analyzers with the same technician. \n                      Gary Engelhart, OI’s laboratory products and marketing manager, notes that the company’s NASA work has led to collaboration with the U.S. Environmental Protection Agency (EPA) on ensuring the security of the Nation’s drinking water. \n                       “TOC measurement is one of the parameters the EPA would like to use in a more widespread fashion in order to provide early warning, whether it be of intentional contamination or from natural events. It’s a key homeland security directive,” he says. He also notes that the NASA-derived TOCA technology was an important factor in the company’s recent acquisition by ITT Corporation, which “will drive OI’s presence in a lot of water treatment and purification areas.” \n                      OI’s work for NASA has been a mutually beneficial relationship, says Marvin. “Our ability to piggyback on research and development by engaging in this project provided what was at the time a small company with a means to develop technology that we may have been slow to bring to market otherwise.”\n                      Meanwhile, the technology OI developed for NASA continues to benefit the ISS. The follow-on to the company’s first NASA TOCA, PFU2, arrived at the ISS in 2011 on STS-133, Space Shuttle Discovery’s final flight, and PFU3 currently awaits a future delivery\n                      \n                    \n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                                                      Astronaut Sandy Magnus examines the International Space Station’s total organic carbon analyzer (TOCA). The technology was developed for NASA by OI Analytical and monitors the quality of the crew’s water supply.\n                        \n                      \n                      Resourcefulness is a key quality for living in space, and on the International Space Station (ISS), that means making the most of water supplies. In 2008, the installation of the Water Processing Assembly (WPA) onboard the ISS allowed the space station’s crew to do just that. The WPA purifies moisture from nearly every possible source—sweat, water vapor, wastewater, and even urine—for drinking and oxygen generation. Capable of producing 35 gallons of potable, recycled water a day, the system has reduced the need for water delivered to the ISS by over 1,000 gallons a year, saving significant payload costs in the process. \n                      As with any drinking water, quality is a concern, particularly when that water has been recycled. This is an issue of particular interest in space, where ISS crew members would have to deal with any illness far from the nearest medical personnel and facilities. The WPA employs sensors that monitor water quality by measuring its conductivity, and rounding out the system’s quality assurance methods is a device developed for NASA by a private industry partner. That company has now made the technology available for ensuring the purity of water for consumption and industrial uses on Earth. \n                      Partnership\n                      Known as a total organic carbon analyzer (TOCA), this device measures organic carbon levels in water, a key indicator of water quality, as carbon is present in most dangerous contaminants. Prior to the installation of the WPA, the ISS had a commercial TOCA onboard, but that technology did not fully satisfy NASA’s requirements. To develop a better solution to ensure the potability of the WPA’s recycled water, NASA contracted OI Analytical of College Station, Texas, in 2006. Working in conjunction with Wyle Laboratories, the company had proposed an advanced TOCA device that provided fast, effective monitoring of TOC levels while eliminating aspects of the technology that made it impractical for space applications. \n                      The resulting Proto-flight Unit, or PFU1, proved to be the innovative breakthrough NASA needed to fully enable the WPA. Detection of TOC in water requires an oxidation process that standard TOCAs generate using either expensive, hazardous chemicals or through high temperature combustion—neither feasible for an environment like the ISS. OI devised an electrochemical solution to create oxidation using the water itself. By applying an electrical voltage to a composite electrode in the oxidation chamber of the analyzer, the TOCA breaks down the water sample, forming hydroxyl radicals that in turn break down any organic molecules into carbon dioxide and water. The analyzer’s infrared detector then measures the concentration of carbon dioxide to provide an accurate assessment of the water’s organic carbon content. \n                      The OI device can be installed at a cost as \n                        much as 90-percent less than other \n                        TOCA systems. \n                      “The original prototype was at a level that allowed us to save two years in the development process,” says Gary Erickson, research and development manager for the TOCA project. This in turn allowed NASA to implement the WPA ahead of schedule. With the system’s recycling capabilities and now fully redundant safety measures, the ISS not only required fewer water deliveries, but it was also able to realize its full crew capacity—increasing from three members up to six. \n                      Benefits\n                      OI recognized the potential for its NASA technology as a commercial solution. Adapting it for terrestrial use, the company now sells the electrochemical-oxidation device as its 9210e On-Line Total Organic Carbon Analyzer. The NASA-derived system provides a host of benefits for water quality applications ranging from municipal and industrial water treatment to feed water and condensate return in turbines and boiler systems. \n                      “Essentially any place where large amounts of water are used, from the cleanest to the most contaminated, the need to measure organic carbon exists,” says Erickson, also market manager for the TOCA technology, “but the cost-prohibitive nature of the technology kept it from being mandated in a number of areas, and it kept commercial companies from utilizing the technology.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                        \n                      \n                      The most significant cost incurred by standard TOCA technology comes from the chemicals needed to support it, Erickson explains. The 9210e’s reagentless electrochemical oxidation eliminates the need for these chemicals, saving the typical operator as much as $500 a month, says Erickson. This adds up for industrial \n                        users that often have tens to hundreds of units installed in their plants. \n                      For combustion oxidation-based analyzers, expensive infrastructure is often required, particularly in chemical plants and petrochemical refineries where a cooled, explosion-proof housing is required, incurring costs as high as $300,000–$500,000. The OI device has a footprint roughly the size of an 11-by-7-inch piece of paper—much smaller than previous units the size of small refrigerators—and can be installed at a cost as much as 90-percent less than other TOCA systems, a comparative savings of $270,000–$450,000. \n                      “We are able to put this small-footprint device into cabinetry at a much lower price point, and the day-to-day operating costs are much less as well,” says Craig Marvin, director of sales and marketing at OI. \n                      The technology’s ease-of-use and low maintenance requirements also generate returns. One OI customer reported that it employed one technician for every two of its analyzers prior to switching to the 9210e; now the customer can service 8–10 analyzers with the same technician. \n                      Gary Engelhart, OI’s laboratory products and marketing manager, notes that the company’s NASA work has led to collaboration with the U.S. Environmental Protection Agency (EPA) on ensuring the security of the Nation’s drinking water. \n                       “TOC measurement is one of the parameters the EPA would like to use in a more widespread fashion in order to provide early warning, whether it be of intentional contamination or from natural events. It’s a key homeland security directive,” he says. He also notes that the NASA-derived TOCA technology was an important factor in the company’s recent acquisition by ITT Corporation, which “will drive OI’s presence in a lot of water treatment and purification areas.” \n                      OI’s work for NASA has been a mutually beneficial relationship, says Marvin. “Our ability to piggyback on research and development by engaging in this project provided what was at the time a small company with a means to develop technology that we may have been slow to bring to market otherwise.”\n                      Meanwhile, the technology OI developed for NASA continues to benefit the ISS. The follow-on to the company’s first NASA TOCA, PFU2, arrived at the ISS in 2011 on STS-133, Space Shuttle Discovery’s final flight, and PFU3 currently awaits a future delivery\n                      \n                    \n                  \n                \n              \n            \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                                                      Astronaut Sandy Magnus examines the International Space Station’s total organic carbon analyzer (TOCA). The technology was developed for NASA by OI Analytical and monitors the quality of the crew’s water supply.\n                        \n                      \n                      Resourcefulness is a key quality for living in space, and on the International Space Station (ISS), that means making the most of water supplies. In 2008, the installation of the Water Processing Assembly (WPA) onboard the ISS allowed the space station’s crew to do just that. The WPA purifies moisture from nearly every possible source—sweat, water vapor, wastewater, and even urine—for drinking and oxygen generation. Capable of producing 35 gallons of potable, recycled water a day, the system has reduced the need for water delivered to the ISS by over 1,000 gallons a year, saving significant payload costs in the process. \n                      As with any drinking water, quality is a concern, particularly when that water has been recycled. This is an issue of particular interest in space, where ISS crew members would have to deal with any illness far from the nearest medical personnel and facilities. The WPA employs sensors that monitor water quality by measuring its conductivity, and rounding out the system’s quality assurance methods is a device developed for NASA by a private industry partner. That company has now made the technology available for ensuring the purity of water for consumption and industrial uses on Earth. \n                      Partnership\n                      Known as a total organic carbon analyzer (TOCA), this device measures organic carbon levels in water, a key indicator of water quality, as carbon is present in most dangerous contaminants. Prior to the installation of the WPA, the ISS had a commercial TOCA onboard, but that technology did not fully satisfy NASA’s requirements. To develop a better solution to ensure the potability of the WPA’s recycled water, NASA contracted OI Analytical of College Station, Texas, in 2006. Working in conjunction with Wyle Laboratories, the company had proposed an advanced TOCA device that provided fast, effective monitoring of TOC levels while eliminating aspects of the technology that made it impractical for space applications. \n                      The resulting Proto-flight Unit, or PFU1, proved to be the innovative breakthrough NASA needed to fully enable the WPA. Detection of TOC in water requires an oxidation process that standard TOCAs generate using either expensive, hazardous chemicals or through high temperature combustion—neither feasible for an environment like the ISS. OI devised an electrochemical solution to create oxidation using the water itself. By applying an electrical voltage to a composite electrode in the oxidation chamber of the analyzer, the TOCA breaks down the water sample, forming hydroxyl radicals that in turn break down any organic molecules into carbon dioxide and water. The analyzer’s infrared detector then measures the concentration of carbon dioxide to provide an accurate assessment of the water’s organic carbon content. \n                      The OI device can be installed at a cost as \n                        much as 90-percent less than other \n                        TOCA systems. \n                      “The original prototype was at a level that allowed us to save two years in the development process,” says Gary Erickson, research and development manager for the TOCA project. This in turn allowed NASA to implement the WPA ahead of schedule. With the system’s recycling capabilities and now fully redundant safety measures, the ISS not only required fewer water deliveries, but it was also able to realize its full crew capacity—increasing from three members up to six. \n                      Benefits\n                      OI recognized the potential for its NASA technology as a commercial solution. Adapting it for terrestrial use, the company now sells the electrochemical-oxidation device as its 9210e On-Line Total Organic Carbon Analyzer. The NASA-derived system provides a host of benefits for water quality applications ranging from municipal and industrial water treatment to feed water and condensate return in turbines and boiler systems. \n                      “Essentially any place where large amounts of water are used, from the cleanest to the most contaminated, the need to measure organic carbon exists,” says Erickson, also market manager for the TOCA technology, “but the cost-prohibitive nature of the technology kept it from being mandated in a number of areas, and it kept commercial companies from utilizing the technology.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                        \n                      \n                      The most significant cost incurred by standard TOCA technology comes from the chemicals needed to support it, Erickson explains. The 9210e’s reagentless electrochemical oxidation eliminates the need for these chemicals, saving the typical operator as much as $500 a month, says Erickson. This adds up for industrial \n                        users that often have tens to hundreds of units installed in their plants. \n                      For combustion oxidation-based analyzers, expensive infrastructure is often required, particularly in chemical plants and petrochemical refineries where a cooled, explosion-proof housing is required, incurring costs as high as $300,000–$500,000. The OI device has a footprint roughly the size of an 11-by-7-inch piece of paper—much smaller than previous units the size of small refrigerators—and can be installed at a cost as much as 90-percent less than other TOCA systems, a comparative savings of $270,000–$450,000. \n                      “We are able to put this small-footprint device into cabinetry at a much lower price point, and the day-to-day operating costs are much less as well,” says Craig Marvin, director of sales and marketing at OI. \n                      The technology’s ease-of-use and low maintenance requirements also generate returns. One OI customer reported that it employed one technician for every two of its analyzers prior to switching to the 9210e; now the customer can service 8–10 analyzers with the same technician. \n                      Gary Engelhart, OI’s laboratory products and marketing manager, notes that the company’s NASA work has led to collaboration with the U.S. Environmental Protection Agency (EPA) on ensuring the security of the Nation’s drinking water. \n                       “TOC measurement is one of the parameters the EPA would like to use in a more widespread fashion in order to provide early warning, whether it be of intentional contamination or from natural events. It’s a key homeland security directive,” he says. He also notes that the NASA-derived TOCA technology was an important factor in the company’s recent acquisition by ITT Corporation, which “will drive OI’s presence in a lot of water treatment and purification areas.” \n                      OI’s work for NASA has been a mutually beneficial relationship, says Marvin. “Our ability to piggyback on research and development by engaging in this project provided what was at the time a small company with a means to develop technology that we may have been slow to bring to market otherwise.”\n                      Meanwhile, the technology OI developed for NASA continues to benefit the ISS. The follow-on to the company’s first NASA TOCA, PFU2, arrived at the ISS in 2011 on STS-133, Space Shuttle Discovery’s final flight, and PFU3 currently awaits a future delivery\n                      \n                    \n                  \n                \n              \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                                                      Astronaut Sandy Magnus examines the International Space Station’s total organic carbon analyzer (TOCA). The technology was developed for NASA by OI Analytical and monitors the quality of the crew’s water supply.\n                        \n                      \n                      Resourcefulness is a key quality for living in space, and on the International Space Station (ISS), that means making the most of water supplies. In 2008, the installation of the Water Processing Assembly (WPA) onboard the ISS allowed the space station’s crew to do just that. The WPA purifies moisture from nearly every possible source—sweat, water vapor, wastewater, and even urine—for drinking and oxygen generation. Capable of producing 35 gallons of potable, recycled water a day, the system has reduced the need for water delivered to the ISS by over 1,000 gallons a year, saving significant payload costs in the process. \n                      As with any drinking water, quality is a concern, particularly when that water has been recycled. This is an issue of particular interest in space, where ISS crew members would have to deal with any illness far from the nearest medical personnel and facilities. The WPA employs sensors that monitor water quality by measuring its conductivity, and rounding out the system’s quality assurance methods is a device developed for NASA by a private industry partner. That company has now made the technology available for ensuring the purity of water for consumption and industrial uses on Earth. \n                      Partnership\n                      Known as a total organic carbon analyzer (TOCA), this device measures organic carbon levels in water, a key indicator of water quality, as carbon is present in most dangerous contaminants. Prior to the installation of the WPA, the ISS had a commercial TOCA onboard, but that technology did not fully satisfy NASA’s requirements. To develop a better solution to ensure the potability of the WPA’s recycled water, NASA contracted OI Analytical of College Station, Texas, in 2006. Working in conjunction with Wyle Laboratories, the company had proposed an advanced TOCA device that provided fast, effective monitoring of TOC levels while eliminating aspects of the technology that made it impractical for space applications. \n                      The resulting Proto-flight Unit, or PFU1, proved to be the innovative breakthrough NASA needed to fully enable the WPA. Detection of TOC in water requires an oxidation process that standard TOCAs generate using either expensive, hazardous chemicals or through high temperature combustion—neither feasible for an environment like the ISS. OI devised an electrochemical solution to create oxidation using the water itself. By applying an electrical voltage to a composite electrode in the oxidation chamber of the analyzer, the TOCA breaks down the water sample, forming hydroxyl radicals that in turn break down any organic molecules into carbon dioxide and water. The analyzer’s infrared detector then measures the concentration of carbon dioxide to provide an accurate assessment of the water’s organic carbon content. \n                      The OI device can be installed at a cost as \n                        much as 90-percent less than other \n                        TOCA systems. \n                      “The original prototype was at a level that allowed us to save two years in the development process,” says Gary Erickson, research and development manager for the TOCA project. This in turn allowed NASA to implement the WPA ahead of schedule. With the system’s recycling capabilities and now fully redundant safety measures, the ISS not only required fewer water deliveries, but it was also able to realize its full crew capacity—increasing from three members up to six. \n                      Benefits\n                      OI recognized the potential for its NASA technology as a commercial solution. Adapting it for terrestrial use, the company now sells the electrochemical-oxidation device as its 9210e On-Line Total Organic Carbon Analyzer. The NASA-derived system provides a host of benefits for water quality applications ranging from municipal and industrial water treatment to feed water and condensate return in turbines and boiler systems. \n                      “Essentially any place where large amounts of water are used, from the cleanest to the most contaminated, the need to measure organic carbon exists,” says Erickson, also market manager for the TOCA technology, “but the cost-prohibitive nature of the technology kept it from being mandated in a number of areas, and it kept commercial companies from utilizing the technology.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                        \n                      \n                      The most significant cost incurred by standard TOCA technology comes from the chemicals needed to support it, Erickson explains. The 9210e’s reagentless electrochemical oxidation eliminates the need for these chemicals, saving the typical operator as much as $500 a month, says Erickson. This adds up for industrial \n                        users that often have tens to hundreds of units installed in their plants. \n                      For combustion oxidation-based analyzers, expensive infrastructure is often required, particularly in chemical plants and petrochemical refineries where a cooled, explosion-proof housing is required, incurring costs as high as $300,000–$500,000. The OI device has a footprint roughly the size of an 11-by-7-inch piece of paper—much smaller than previous units the size of small refrigerators—and can be installed at a cost as much as 90-percent less than other TOCA systems, a comparative savings of $270,000–$450,000. \n                      “We are able to put this small-footprint device into cabinetry at a much lower price point, and the day-to-day operating costs are much less as well,” says Craig Marvin, director of sales and marketing at OI. \n                      The technology’s ease-of-use and low maintenance requirements also generate returns. One OI customer reported that it employed one technician for every two of its analyzers prior to switching to the 9210e; now the customer can service 8–10 analyzers with the same technician. \n                      Gary Engelhart, OI’s laboratory products and marketing manager, notes that the company’s NASA work has led to collaboration with the U.S. Environmental Protection Agency (EPA) on ensuring the security of the Nation’s drinking water. \n                       “TOC measurement is one of the parameters the EPA would like to use in a more widespread fashion in order to provide early warning, whether it be of intentional contamination or from natural events. It’s a key homeland security directive,” he says. He also notes that the NASA-derived TOCA technology was an important factor in the company’s recent acquisition by ITT Corporation, which “will drive OI’s presence in a lot of water treatment and purification areas.” \n                      OI’s work for NASA has been a mutually beneficial relationship, says Marvin. “Our ability to piggyback on research and development by engaging in this project provided what was at the time a small company with a means to develop technology that we may have been slow to bring to market otherwise.”\n                      Meanwhile, the technology OI developed for NASA continues to benefit the ISS. The follow-on to the company’s first NASA TOCA, PFU2, arrived at the ISS in 2011 on STS-133, Space Shuttle Discovery’s final flight, and PFU3 currently awaits a future delivery\n                      \n                    \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                                                      Astronaut Sandy Magnus examines the International Space Station’s total organic carbon analyzer (TOCA). The technology was developed for NASA by OI Analytical and monitors the quality of the crew’s water supply.\n                        \n                      \n                      Resourcefulness is a key quality for living in space, and on the International Space Station (ISS), that means making the most of water supplies. In 2008, the installation of the Water Processing Assembly (WPA) onboard the ISS allowed the space station’s crew to do just that. The WPA purifies moisture from nearly every possible source—sweat, water vapor, wastewater, and even urine—for drinking and oxygen generation. Capable of producing 35 gallons of potable, recycled water a day, the system has reduced the need for water delivered to the ISS by over 1,000 gallons a year, saving significant payload costs in the process. \n                      As with any drinking water, quality is a concern, particularly when that water has been recycled. This is an issue of particular interest in space, where ISS crew members would have to deal with any illness far from the nearest medical personnel and facilities. The WPA employs sensors that monitor water quality by measuring its conductivity, and rounding out the system’s quality assurance methods is a device developed for NASA by a private industry partner. That company has now made the technology available for ensuring the purity of water for consumption and industrial uses on Earth. \n                      Partnership\n                      Known as a total organic carbon analyzer (TOCA), this device measures organic carbon levels in water, a key indicator of water quality, as carbon is present in most dangerous contaminants. Prior to the installation of the WPA, the ISS had a commercial TOCA onboard, but that technology did not fully satisfy NASA’s requirements. To develop a better solution to ensure the potability of the WPA’s recycled water, NASA contracted OI Analytical of College Station, Texas, in 2006. Working in conjunction with Wyle Laboratories, the company had proposed an advanced TOCA device that provided fast, effective monitoring of TOC levels while eliminating aspects of the technology that made it impractical for space applications. \n                      The resulting Proto-flight Unit, or PFU1, proved to be the innovative breakthrough NASA needed to fully enable the WPA. Detection of TOC in water requires an oxidation process that standard TOCAs generate using either expensive, hazardous chemicals or through high temperature combustion—neither feasible for an environment like the ISS. OI devised an electrochemical solution to create oxidation using the water itself. By applying an electrical voltage to a composite electrode in the oxidation chamber of the analyzer, the TOCA breaks down the water sample, forming hydroxyl radicals that in turn break down any organic molecules into carbon dioxide and water. The analyzer’s infrared detector then measures the concentration of carbon dioxide to provide an accurate assessment of the water’s organic carbon content. \n                      The OI device can be installed at a cost as \n                        much as 90-percent less than other \n                        TOCA systems. \n                      “The original prototype was at a level that allowed us to save two years in the development process,” says Gary Erickson, research and development manager for the TOCA project. This in turn allowed NASA to implement the WPA ahead of schedule. With the system’s recycling capabilities and now fully redundant safety measures, the ISS not only required fewer water deliveries, but it was also able to realize its full crew capacity—increasing from three members up to six. \n                      Benefits\n                      OI recognized the potential for its NASA technology as a commercial solution. Adapting it for terrestrial use, the company now sells the electrochemical-oxidation device as its 9210e On-Line Total Organic Carbon Analyzer. The NASA-derived system provides a host of benefits for water quality applications ranging from municipal and industrial water treatment to feed water and condensate return in turbines and boiler systems. \n                      “Essentially any place where large amounts of water are used, from the cleanest to the most contaminated, the need to measure organic carbon exists,” says Erickson, also market manager for the TOCA technology, “but the cost-prohibitive nature of the technology kept it from being mandated in a number of areas, and it kept commercial companies from utilizing the technology.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                        \n                      \n                      The most significant cost incurred by standard TOCA technology comes from the chemicals needed to support it, Erickson explains. The 9210e’s reagentless electrochemical oxidation eliminates the need for these chemicals, saving the typical operator as much as $500 a month, says Erickson. This adds up for industrial \n                        users that often have tens to hundreds of units installed in their plants. \n                      For combustion oxidation-based analyzers, expensive infrastructure is often required, particularly in chemical plants and petrochemical refineries where a cooled, explosion-proof housing is required, incurring costs as high as $300,000–$500,000. The OI device has a footprint roughly the size of an 11-by-7-inch piece of paper—much smaller than previous units the size of small refrigerators—and can be installed at a cost as much as 90-percent less than other TOCA systems, a comparative savings of $270,000–$450,000. \n                      “We are able to put this small-footprint device into cabinetry at a much lower price point, and the day-to-day operating costs are much less as well,” says Craig Marvin, director of sales and marketing at OI. \n                      The technology’s ease-of-use and low maintenance requirements also generate returns. One OI customer reported that it employed one technician for every two of its analyzers prior to switching to the 9210e; now the customer can service 8–10 analyzers with the same technician. \n                      Gary Engelhart, OI’s laboratory products and marketing manager, notes that the company’s NASA work has led to collaboration with the U.S. Environmental Protection Agency (EPA) on ensuring the security of the Nation’s drinking water. \n                       “TOC measurement is one of the parameters the EPA would like to use in a more widespread fashion in order to provide early warning, whether it be of intentional contamination or from natural events. It’s a key homeland security directive,” he says. He also notes that the NASA-derived TOCA technology was an important factor in the company’s recent acquisition by ITT Corporation, which “will drive OI’s presence in a lot of water treatment and purification areas.” \n                      OI’s work for NASA has been a mutually beneficial relationship, says Marvin. “Our ability to piggyback on research and development by engaging in this project provided what was at the time a small company with a means to develop technology that we may have been slow to bring to market otherwise.”\n                      Meanwhile, the technology OI developed for NASA continues to benefit the ISS. The follow-on to the company’s first NASA TOCA, PFU2, arrived at the ISS in 2011 on STS-133, Space Shuttle Discovery’s final flight, and PFU3 currently awaits a future delivery\n                      \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                                                      Astronaut Sandy Magnus examines the International Space Station’s total organic carbon analyzer (TOCA). The technology was developed for NASA by OI Analytical and monitors the quality of the crew’s water supply.\n                        \n                      \n                      Resourcefulness is a key quality for living in space, and on the International Space Station (ISS), that means making the most of water supplies. In 2008, the installation of the Water Processing Assembly (WPA) onboard the ISS allowed the space station’s crew to do just that. The WPA purifies moisture from nearly every possible source—sweat, water vapor, wastewater, and even urine—for drinking and oxygen generation. Capable of producing 35 gallons of potable, recycled water a day, the system has reduced the need for water delivered to the ISS by over 1,000 gallons a year, saving significant payload costs in the process. \n                      As with any drinking water, quality is a concern, particularly when that water has been recycled. This is an issue of particular interest in space, where ISS crew members would have to deal with any illness far from the nearest medical personnel and facilities. The WPA employs sensors that monitor water quality by measuring its conductivity, and rounding out the system’s quality assurance methods is a device developed for NASA by a private industry partner. That company has now made the technology available for ensuring the purity of water for consumption and industrial uses on Earth. \n                      Partnership\n                      Known as a total organic carbon analyzer (TOCA), this device measures organic carbon levels in water, a key indicator of water quality, as carbon is present in most dangerous contaminants. Prior to the installation of the WPA, the ISS had a commercial TOCA onboard, but that technology did not fully satisfy NASA’s requirements. To develop a better solution to ensure the potability of the WPA’s recycled water, NASA contracted OI Analytical of College Station, Texas, in 2006. Working in conjunction with Wyle Laboratories, the company had proposed an advanced TOCA device that provided fast, effective monitoring of TOC levels while eliminating aspects of the technology that made it impractical for space applications. \n                      The resulting Proto-flight Unit, or PFU1, proved to be the innovative breakthrough NASA needed to fully enable the WPA. Detection of TOC in water requires an oxidation process that standard TOCAs generate using either expensive, hazardous chemicals or through high temperature combustion—neither feasible for an environment like the ISS. OI devised an electrochemical solution to create oxidation using the water itself. By applying an electrical voltage to a composite electrode in the oxidation chamber of the analyzer, the TOCA breaks down the water sample, forming hydroxyl radicals that in turn break down any organic molecules into carbon dioxide and water. The analyzer’s infrared detector then measures the concentration of carbon dioxide to provide an accurate assessment of the water’s organic carbon content. \n                      The OI device can be installed at a cost as \n                        much as 90-percent less than other \n                        TOCA systems. \n                      “The original prototype was at a level that allowed us to save two years in the development process,” says Gary Erickson, research and development manager for the TOCA project. This in turn allowed NASA to implement the WPA ahead of schedule. With the system’s recycling capabilities and now fully redundant safety measures, the ISS not only required fewer water deliveries, but it was also able to realize its full crew capacity—increasing from three members up to six. \n                      Benefits\n                      OI recognized the potential for its NASA technology as a commercial solution. Adapting it for terrestrial use, the company now sells the electrochemical-oxidation device as its 9210e On-Line Total Organic Carbon Analyzer. The NASA-derived system provides a host of benefits for water quality applications ranging from municipal and industrial water treatment to feed water and condensate return in turbines and boiler systems. \n                      “Essentially any place where large amounts of water are used, from the cleanest to the most contaminated, the need to measure organic carbon exists,” says Erickson, also market manager for the TOCA technology, “but the cost-prohibitive nature of the technology kept it from being mandated in a number of areas, and it kept commercial companies from utilizing the technology.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          OI’s commercial TOCA, derived from the device the company created for NASA, is smaller and less expensive to install and maintain than comparable technologies.\n                        \n                      \n                      The most significant cost incurred by standard TOCA technology comes from the chemicals needed to support it, Erickson explains. The 9210e’s reagentless electrochemical oxidation eliminates the need for these chemicals, saving the typical operator as much as $500 a month, says Erickson. This adds up for industrial \n                        users that often have tens to hundreds of units installed in their plants. \n                      For combustion oxidation-based analyzers, expensive infrastructure is often required, particularly in chemical plants and petrochemical refineries where a cooled, explosion-proof housing is required, incurring costs as high as $300,000–$500,000. The OI device has a footprint roughly the size of an 11-by-7-inch piece of paper—much smaller than previous units the size of small refrigerators—and can be installed at a cost as much as 90-percent less than other TOCA systems, a comparative savings of $270,000–$450,000. \n                      “We are able to put this small-footprint device into cabinetry at a much lower price point, and the day-to-day operating costs are much less as well,” says Craig Marvin, director of sales and marketing at OI. \n                      The technology’s ease-of-use and low maintenance requirements also generate returns. One OI customer reported that it employed one technician for every two of its analyzers prior to switching to the 9210e; now the customer can service 8–10 analyzers with the same technician. \n                      Gary Engelhart, OI’s laboratory products and marketing manager, notes that the company’s NASA work has led to collaboration with the U.S. Environmental Protection Agency (EPA) on ensuring the security of the Nation’s drinking water. \n                       “TOC measurement is one of the parameters the EPA would like to use in a more widespread fashion in order to provide early warning, whether it be of intentional contamination or from natural events. It’s a key homeland security directive,” he says. He also notes that the NASA-derived TOCA technology was an important factor in the company’s recent acquisition by ITT Corporation, which “will drive OI’s presence in a lot of water treatment and purification areas.” \n                      OI’s work for NASA has been a mutually beneficial relationship, says Marvin. “Our ability to piggyback on research and development by engaging in this project provided what was at the time a small company with a means to develop technology that we may have been slow to bring to market otherwise.”\n                      Meanwhile, the technology OI developed for NASA continues to benefit the ISS. The follow-on to the company’s first NASA TOCA, PFU2, arrived at the ISS in 2011 on STS-133, Space Shuttle Discovery’s final flight, and PFU3 currently awaits a future delivery\n                      "},{"href":"http://spinoff.nasa.gov/Spinoff2011/er_7.html","text":"Catalyst Substrates Remove Contaminants, Produce Fuel","image":"http://spinoff.nasa.gov/Spinoff2011/Images/er_10a_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      “A spacecraft is the ultimate tight building. We don’t want any leaks, and there is very little fresh air coming in,” says Jay Perry, an aerospace engineer at Marshall Space Flight Center. “As a result, there is a huge potential for a buildup of contaminants from a host of sources.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          Inside the International Space Station’s (ISS) Cupola, Doug Wheelock, Expedition 25 commander, looks down while preparing his camera for a shot of Earth. The cabin atmosphere inside the ISS stays clean and safe thanks to its sophisticated Environmental Control and Life Support System. \n                        \n                      \n                      Inside a spacecraft, contaminants can be introduced from the materials that make spacecraft components, electronics boxes, or activities by the crew such as food preparation or cleaning. Humans also generate contaminants by breathing and through the body’s natural metabolic processes. As part of the sophisticated Environmental Control and Life Support System on the International Space Station (ISS), a trace contaminant control system removes carbon dioxide and other impurities from the cabin atmosphere. To maintain healthy levels, the system uses adsorbent media to filter chemical contaminant molecules and a high-temperature catalytic oxidizer to change the chemical structure of the contaminants to something more benign, usually carbon dioxide and water. \n                      In the 1990s, while researching air quality control technology for extended spaceflight travel, Perry and others at Marshall were looking for a regenerable process for the continuous removal of carbon dioxide and trace chemical contaminants on long-duration manned space flights. At the time, the existing technology used on U.S. spacecraft could only be used once, which meant that a spacecraft had to carry additional spare parts for use in case the first one was depleted, or the spacecraft would have to return to Earth to exchange the components.\n                      Partnership\n                      A North Haven, Connecticut-based company, Precision Combustion Inc. (PCI), previously worked with NASA’s Glenn Research Center (Spinoff 1998) to prove the viability of its Microlith technology, a very thin substrate consisting of short metal channels resembling screens or meshes, for catalytic reduction of emissions from combustion. Afterward, the company’s commercialization efforts focused on using the Microlith substrate in a catalytic combustor for gas turbines and in a catalytic converter for automotive exhaust treatment applications. \n                      “Precision Combustion had this idea of having a catalyst coating on the Microlith substrate that could be added to an existing automotive catalytic converter,” says Perry. “Because it is made out of metal, the Microlith substrate can heat very rapidly and thus eliminate the cold start emissions of an automobile, which is when most of the pollution happens.”\n                      Several years after working with Glenn, PCI worked with Marshall through the Small Business Innovation Research (SBIR) program to adapt its Microlith technology to provide a lighter and more durable rapid start-up trace contaminant removal system for spacecraft, and to meet NASA’s need for a regenerable contaminant control technology. A few years later, PCI pursued additional SBIR work with Marshall to integrate an adsorptive coating on the Microlith substrate to remove additional chemical compounds as well as carbon dioxide. \n                      “We took something that Precision Combustion was working on for an automotive application for cold start emission control and then pulled it into our need for use in a spacecraft,” says Perry. “By passing an electric current through the expanded metal, the system is up to operating temperature within less than a minute. That means that the oxidation of trace contaminants happens quickly, rather than an hour or two after powering the unit. Another advantage is the Microlith catalytic oxidation approach was practically an all-in-one contained device. With Precision Combustion’s technology, it could go from a 35-pound mass to less than 10 pounds.” \n                      Development testing successfully demonstrated the Microlith substrate for a regenerable carbon dioxide removal and trace contaminants control application. While the funding for further development and deployment of the technology ended, according to Perry the technology remains the leading catalytic oxidation technology for trace contaminant control for future space missions.\n                      Benefits\n                       Tony Anderson, the marketing and business development manager at PCI, says the SBIR work with NASA has been paramount to enhancing Microlith technology. “The interaction between PCI and NASA has been ongoing for almost 20 years now. On the catalytic oxidizer project, it has been invaluable to have the collaboration to ensure the success. Now we are using the technology as a springboard for other products.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          While working with NASA on contaminant control technology, Precision Combustion Inc. advanced its Microlith technology and then incorporated it into products such as the Regenerable Microlith Adsorber, seen here.\n                        \n                      \n                      Due to the company’s commercial success spanning more than a decade, it has received the “Tibbetts Award” twice—in 1998 and in 2006—in recognition for exemplifying the types of business, economic, and technical development goals of the SBIR program. PCI also received the “Army SBIR Achievement Award” in 2008 and 2010 for applications of its Microlith technology for military applications. The U.S. Army conducts its annual awards program to recognize efforts that exemplify the SBIR goal of bringing innovative technologies and products to the marketplace.\n                      Today, PCI develops, manufactures, and markets catalytic devices for clean and efficient combustion, emissions controls, and chemical manufacturing applications. As one of the company’s core technologies, the Microlith substrate can be coated with a variety of materials utilizing proprietary methods from PCI, including catalyst or adsorbent materials, to promote chemical reactions and to remove environmental contaminants.“Microlith substrate is a platform technology. With that, there are many different things we can do with it. A lot of the NASA support helps us to make the platform sturdy,” says Subir Roychoudhury, director of Microlith Products at PCI. \n                      In particular, the NASA-supported research has demonstrated that a certain coating on Microlith metal mesh elements can effectively adsorb a number of contaminants. Another benefit is that the technology is more compact and lightweight than the competing technology. Lastly, the Microlith substrate can be customized to target individual contaminants, and can also be integrated into existing systems. \n                      Soon after working with Marshall, the National Science Foundation started funding PCI to do fuel reforming and processing incorporating Microlith technology. That led to additional fuel reforming work with the Department of Defense, which encompasses a large portion of PCI’s business today.\n                      Roychoudhury explains how the Microlith reactor is being used for efficient hydrogen sulfide removal in fuel reforming for fuel cell systems. “The work with fuel reforming and fuel processing takes hydrocarbon materials and runs them through a catalyst that is supported on the Microlith. It converts hydrocarbon to syngas, which can operate fuel cells. Utilizing the same Microlith technology that we developed through NASA, we make fuel for fuel cells.”\n                      Microlith technology is also being incorporated into development efforts for fuel reforming on ships for the U.S. Navy, mobile applications for the Army, and fuel processing for fuel cells for U.S. Air Force aircraft, as well as several civilian applications.\n                      Microlith® is a registered trademark of Precision Combustion Inc. \n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      “A spacecraft is the ultimate tight building. We don’t want any leaks, and there is very little fresh air coming in,” says Jay Perry, an aerospace engineer at Marshall Space Flight Center. “As a result, there is a huge potential for a buildup of contaminants from a host of sources.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          Inside the International Space Station’s (ISS) Cupola, Doug Wheelock, Expedition 25 commander, looks down while preparing his camera for a shot of Earth. The cabin atmosphere inside the ISS stays clean and safe thanks to its sophisticated Environmental Control and Life Support System. \n                        \n                      \n                      Inside a spacecraft, contaminants can be introduced from the materials that make spacecraft components, electronics boxes, or activities by the crew such as food preparation or cleaning. Humans also generate contaminants by breathing and through the body’s natural metabolic processes. As part of the sophisticated Environmental Control and Life Support System on the International Space Station (ISS), a trace contaminant control system removes carbon dioxide and other impurities from the cabin atmosphere. To maintain healthy levels, the system uses adsorbent media to filter chemical contaminant molecules and a high-temperature catalytic oxidizer to change the chemical structure of the contaminants to something more benign, usually carbon dioxide and water. \n                      In the 1990s, while researching air quality control technology for extended spaceflight travel, Perry and others at Marshall were looking for a regenerable process for the continuous removal of carbon dioxide and trace chemical contaminants on long-duration manned space flights. At the time, the existing technology used on U.S. spacecraft could only be used once, which meant that a spacecraft had to carry additional spare parts for use in case the first one was depleted, or the spacecraft would have to return to Earth to exchange the components.\n                      Partnership\n                      A North Haven, Connecticut-based company, Precision Combustion Inc. (PCI), previously worked with NASA’s Glenn Research Center (Spinoff 1998) to prove the viability of its Microlith technology, a very thin substrate consisting of short metal channels resembling screens or meshes, for catalytic reduction of emissions from combustion. Afterward, the company’s commercialization efforts focused on using the Microlith substrate in a catalytic combustor for gas turbines and in a catalytic converter for automotive exhaust treatment applications. \n                      “Precision Combustion had this idea of having a catalyst coating on the Microlith substrate that could be added to an existing automotive catalytic converter,” says Perry. “Because it is made out of metal, the Microlith substrate can heat very rapidly and thus eliminate the cold start emissions of an automobile, which is when most of the pollution happens.”\n                      Several years after working with Glenn, PCI worked with Marshall through the Small Business Innovation Research (SBIR) program to adapt its Microlith technology to provide a lighter and more durable rapid start-up trace contaminant removal system for spacecraft, and to meet NASA’s need for a regenerable contaminant control technology. A few years later, PCI pursued additional SBIR work with Marshall to integrate an adsorptive coating on the Microlith substrate to remove additional chemical compounds as well as carbon dioxide. \n                      “We took something that Precision Combustion was working on for an automotive application for cold start emission control and then pulled it into our need for use in a spacecraft,” says Perry. “By passing an electric current through the expanded metal, the system is up to operating temperature within less than a minute. That means that the oxidation of trace contaminants happens quickly, rather than an hour or two after powering the unit. Another advantage is the Microlith catalytic oxidation approach was practically an all-in-one contained device. With Precision Combustion’s technology, it could go from a 35-pound mass to less than 10 pounds.” \n                      Development testing successfully demonstrated the Microlith substrate for a regenerable carbon dioxide removal and trace contaminants control application. While the funding for further development and deployment of the technology ended, according to Perry the technology remains the leading catalytic oxidation technology for trace contaminant control for future space missions.\n                      Benefits\n                       Tony Anderson, the marketing and business development manager at PCI, says the SBIR work with NASA has been paramount to enhancing Microlith technology. “The interaction between PCI and NASA has been ongoing for almost 20 years now. On the catalytic oxidizer project, it has been invaluable to have the collaboration to ensure the success. Now we are using the technology as a springboard for other products.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          While working with NASA on contaminant control technology, Precision Combustion Inc. advanced its Microlith technology and then incorporated it into products such as the Regenerable Microlith Adsorber, seen here.\n                        \n                      \n                      Due to the company’s commercial success spanning more than a decade, it has received the “Tibbetts Award” twice—in 1998 and in 2006—in recognition for exemplifying the types of business, economic, and technical development goals of the SBIR program. PCI also received the “Army SBIR Achievement Award” in 2008 and 2010 for applications of its Microlith technology for military applications. The U.S. Army conducts its annual awards program to recognize efforts that exemplify the SBIR goal of bringing innovative technologies and products to the marketplace.\n                      Today, PCI develops, manufactures, and markets catalytic devices for clean and efficient combustion, emissions controls, and chemical manufacturing applications. As one of the company’s core technologies, the Microlith substrate can be coated with a variety of materials utilizing proprietary methods from PCI, including catalyst or adsorbent materials, to promote chemical reactions and to remove environmental contaminants.“Microlith substrate is a platform technology. With that, there are many different things we can do with it. A lot of the NASA support helps us to make the platform sturdy,” says Subir Roychoudhury, director of Microlith Products at PCI. \n                      In particular, the NASA-supported research has demonstrated that a certain coating on Microlith metal mesh elements can effectively adsorb a number of contaminants. Another benefit is that the technology is more compact and lightweight than the competing technology. Lastly, the Microlith substrate can be customized to target individual contaminants, and can also be integrated into existing systems. \n                      Soon after working with Marshall, the National Science Foundation started funding PCI to do fuel reforming and processing incorporating Microlith technology. That led to additional fuel reforming work with the Department of Defense, which encompasses a large portion of PCI’s business today.\n                      Roychoudhury explains how the Microlith reactor is being used for efficient hydrogen sulfide removal in fuel reforming for fuel cell systems. “The work with fuel reforming and fuel processing takes hydrocarbon materials and runs them through a catalyst that is supported on the Microlith. It converts hydrocarbon to syngas, which can operate fuel cells. Utilizing the same Microlith technology that we developed through NASA, we make fuel for fuel cells.”\n                      Microlith technology is also being incorporated into development efforts for fuel reforming on ships for the U.S. Navy, mobile applications for the Army, and fuel processing for fuel cells for U.S. Air Force aircraft, as well as several civilian applications.\n                      Microlith® is a registered trademark of Precision Combustion Inc. \n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      “A spacecraft is the ultimate tight building. We don’t want any leaks, and there is very little fresh air coming in,” says Jay Perry, an aerospace engineer at Marshall Space Flight Center. “As a result, there is a huge potential for a buildup of contaminants from a host of sources.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          Inside the International Space Station’s (ISS) Cupola, Doug Wheelock, Expedition 25 commander, looks down while preparing his camera for a shot of Earth. The cabin atmosphere inside the ISS stays clean and safe thanks to its sophisticated Environmental Control and Life Support System. \n                        \n                      \n                      Inside a spacecraft, contaminants can be introduced from the materials that make spacecraft components, electronics boxes, or activities by the crew such as food preparation or cleaning. Humans also generate contaminants by breathing and through the body’s natural metabolic processes. As part of the sophisticated Environmental Control and Life Support System on the International Space Station (ISS), a trace contaminant control system removes carbon dioxide and other impurities from the cabin atmosphere. To maintain healthy levels, the system uses adsorbent media to filter chemical contaminant molecules and a high-temperature catalytic oxidizer to change the chemical structure of the contaminants to something more benign, usually carbon dioxide and water. \n                      In the 1990s, while researching air quality control technology for extended spaceflight travel, Perry and others at Marshall were looking for a regenerable process for the continuous removal of carbon dioxide and trace chemical contaminants on long-duration manned space flights. At the time, the existing technology used on U.S. spacecraft could only be used once, which meant that a spacecraft had to carry additional spare parts for use in case the first one was depleted, or the spacecraft would have to return to Earth to exchange the components.\n                      Partnership\n                      A North Haven, Connecticut-based company, Precision Combustion Inc. (PCI), previously worked with NASA’s Glenn Research Center (Spinoff 1998) to prove the viability of its Microlith technology, a very thin substrate consisting of short metal channels resembling screens or meshes, for catalytic reduction of emissions from combustion. Afterward, the company’s commercialization efforts focused on using the Microlith substrate in a catalytic combustor for gas turbines and in a catalytic converter for automotive exhaust treatment applications. \n                      “Precision Combustion had this idea of having a catalyst coating on the Microlith substrate that could be added to an existing automotive catalytic converter,” says Perry. “Because it is made out of metal, the Microlith substrate can heat very rapidly and thus eliminate the cold start emissions of an automobile, which is when most of the pollution happens.”\n                      Several years after working with Glenn, PCI worked with Marshall through the Small Business Innovation Research (SBIR) program to adapt its Microlith technology to provide a lighter and more durable rapid start-up trace contaminant removal system for spacecraft, and to meet NASA’s need for a regenerable contaminant control technology. A few years later, PCI pursued additional SBIR work with Marshall to integrate an adsorptive coating on the Microlith substrate to remove additional chemical compounds as well as carbon dioxide. \n                      “We took something that Precision Combustion was working on for an automotive application for cold start emission control and then pulled it into our need for use in a spacecraft,” says Perry. “By passing an electric current through the expanded metal, the system is up to operating temperature within less than a minute. That means that the oxidation of trace contaminants happens quickly, rather than an hour or two after powering the unit. Another advantage is the Microlith catalytic oxidation approach was practically an all-in-one contained device. With Precision Combustion’s technology, it could go from a 35-pound mass to less than 10 pounds.” \n                      Development testing successfully demonstrated the Microlith substrate for a regenerable carbon dioxide removal and trace contaminants control application. While the funding for further development and deployment of the technology ended, according to Perry the technology remains the leading catalytic oxidation technology for trace contaminant control for future space missions.\n                      Benefits\n                       Tony Anderson, the marketing and business development manager at PCI, says the SBIR work with NASA has been paramount to enhancing Microlith technology. “The interaction between PCI and NASA has been ongoing for almost 20 years now. On the catalytic oxidizer project, it has been invaluable to have the collaboration to ensure the success. Now we are using the technology as a springboard for other products.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          While working with NASA on contaminant control technology, Precision Combustion Inc. advanced its Microlith technology and then incorporated it into products such as the Regenerable Microlith Adsorber, seen here.\n                        \n                      \n                      Due to the company’s commercial success spanning more than a decade, it has received the “Tibbetts Award” twice—in 1998 and in 2006—in recognition for exemplifying the types of business, economic, and technical development goals of the SBIR program. PCI also received the “Army SBIR Achievement Award” in 2008 and 2010 for applications of its Microlith technology for military applications. The U.S. Army conducts its annual awards program to recognize efforts that exemplify the SBIR goal of bringing innovative technologies and products to the marketplace.\n                      Today, PCI develops, manufactures, and markets catalytic devices for clean and efficient combustion, emissions controls, and chemical manufacturing applications. As one of the company’s core technologies, the Microlith substrate can be coated with a variety of materials utilizing proprietary methods from PCI, including catalyst or adsorbent materials, to promote chemical reactions and to remove environmental contaminants.“Microlith substrate is a platform technology. With that, there are many different things we can do with it. A lot of the NASA support helps us to make the platform sturdy,” says Subir Roychoudhury, director of Microlith Products at PCI. \n                      In particular, the NASA-supported research has demonstrated that a certain coating on Microlith metal mesh elements can effectively adsorb a number of contaminants. Another benefit is that the technology is more compact and lightweight than the competing technology. Lastly, the Microlith substrate can be customized to target individual contaminants, and can also be integrated into existing systems. \n                      Soon after working with Marshall, the National Science Foundation started funding PCI to do fuel reforming and processing incorporating Microlith technology. That led to additional fuel reforming work with the Department of Defense, which encompasses a large portion of PCI’s business today.\n                      Roychoudhury explains how the Microlith reactor is being used for efficient hydrogen sulfide removal in fuel reforming for fuel cell systems. “The work with fuel reforming and fuel processing takes hydrocarbon materials and runs them through a catalyst that is supported on the Microlith. It converts hydrocarbon to syngas, which can operate fuel cells. Utilizing the same Microlith technology that we developed through NASA, we make fuel for fuel cells.”\n                      Microlith technology is also being incorporated into development efforts for fuel reforming on ships for the U.S. Navy, mobile applications for the Army, and fuel processing for fuel cells for U.S. Air Force aircraft, as well as several civilian applications.\n                      Microlith® is a registered trademark of Precision Combustion Inc. \n                      \n                    \n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      “A spacecraft is the ultimate tight building. We don’t want any leaks, and there is very little fresh air coming in,” says Jay Perry, an aerospace engineer at Marshall Space Flight Center. “As a result, there is a huge potential for a buildup of contaminants from a host of sources.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          Inside the International Space Station’s (ISS) Cupola, Doug Wheelock, Expedition 25 commander, looks down while preparing his camera for a shot of Earth. The cabin atmosphere inside the ISS stays clean and safe thanks to its sophisticated Environmental Control and Life Support System. \n                        \n                      \n                      Inside a spacecraft, contaminants can be introduced from the materials that make spacecraft components, electronics boxes, or activities by the crew such as food preparation or cleaning. Humans also generate contaminants by breathing and through the body’s natural metabolic processes. As part of the sophisticated Environmental Control and Life Support System on the International Space Station (ISS), a trace contaminant control system removes carbon dioxide and other impurities from the cabin atmosphere. To maintain healthy levels, the system uses adsorbent media to filter chemical contaminant molecules and a high-temperature catalytic oxidizer to change the chemical structure of the contaminants to something more benign, usually carbon dioxide and water. \n                      In the 1990s, while researching air quality control technology for extended spaceflight travel, Perry and others at Marshall were looking for a regenerable process for the continuous removal of carbon dioxide and trace chemical contaminants on long-duration manned space flights. At the time, the existing technology used on U.S. spacecraft could only be used once, which meant that a spacecraft had to carry additional spare parts for use in case the first one was depleted, or the spacecraft would have to return to Earth to exchange the components.\n                      Partnership\n                      A North Haven, Connecticut-based company, Precision Combustion Inc. (PCI), previously worked with NASA’s Glenn Research Center (Spinoff 1998) to prove the viability of its Microlith technology, a very thin substrate consisting of short metal channels resembling screens or meshes, for catalytic reduction of emissions from combustion. Afterward, the company’s commercialization efforts focused on using the Microlith substrate in a catalytic combustor for gas turbines and in a catalytic converter for automotive exhaust treatment applications. \n                      “Precision Combustion had this idea of having a catalyst coating on the Microlith substrate that could be added to an existing automotive catalytic converter,” says Perry. “Because it is made out of metal, the Microlith substrate can heat very rapidly and thus eliminate the cold start emissions of an automobile, which is when most of the pollution happens.”\n                      Several years after working with Glenn, PCI worked with Marshall through the Small Business Innovation Research (SBIR) program to adapt its Microlith technology to provide a lighter and more durable rapid start-up trace contaminant removal system for spacecraft, and to meet NASA’s need for a regenerable contaminant control technology. A few years later, PCI pursued additional SBIR work with Marshall to integrate an adsorptive coating on the Microlith substrate to remove additional chemical compounds as well as carbon dioxide. \n                      “We took something that Precision Combustion was working on for an automotive application for cold start emission control and then pulled it into our need for use in a spacecraft,” says Perry. “By passing an electric current through the expanded metal, the system is up to operating temperature within less than a minute. That means that the oxidation of trace contaminants happens quickly, rather than an hour or two after powering the unit. Another advantage is the Microlith catalytic oxidation approach was practically an all-in-one contained device. With Precision Combustion’s technology, it could go from a 35-pound mass to less than 10 pounds.” \n                      Development testing successfully demonstrated the Microlith substrate for a regenerable carbon dioxide removal and trace contaminants control application. While the funding for further development and deployment of the technology ended, according to Perry the technology remains the leading catalytic oxidation technology for trace contaminant control for future space missions.\n                      Benefits\n                       Tony Anderson, the marketing and business development manager at PCI, says the SBIR work with NASA has been paramount to enhancing Microlith technology. “The interaction between PCI and NASA has been ongoing for almost 20 years now. On the catalytic oxidizer project, it has been invaluable to have the collaboration to ensure the success. Now we are using the technology as a springboard for other products.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          While working with NASA on contaminant control technology, Precision Combustion Inc. advanced its Microlith technology and then incorporated it into products such as the Regenerable Microlith Adsorber, seen here.\n                        \n                      \n                      Due to the company’s commercial success spanning more than a decade, it has received the “Tibbetts Award” twice—in 1998 and in 2006—in recognition for exemplifying the types of business, economic, and technical development goals of the SBIR program. PCI also received the “Army SBIR Achievement Award” in 2008 and 2010 for applications of its Microlith technology for military applications. The U.S. Army conducts its annual awards program to recognize efforts that exemplify the SBIR goal of bringing innovative technologies and products to the marketplace.\n                      Today, PCI develops, manufactures, and markets catalytic devices for clean and efficient combustion, emissions controls, and chemical manufacturing applications. As one of the company’s core technologies, the Microlith substrate can be coated with a variety of materials utilizing proprietary methods from PCI, including catalyst or adsorbent materials, to promote chemical reactions and to remove environmental contaminants.“Microlith substrate is a platform technology. With that, there are many different things we can do with it. A lot of the NASA support helps us to make the platform sturdy,” says Subir Roychoudhury, director of Microlith Products at PCI. \n                      In particular, the NASA-supported research has demonstrated that a certain coating on Microlith metal mesh elements can effectively adsorb a number of contaminants. Another benefit is that the technology is more compact and lightweight than the competing technology. Lastly, the Microlith substrate can be customized to target individual contaminants, and can also be integrated into existing systems. \n                      Soon after working with Marshall, the National Science Foundation started funding PCI to do fuel reforming and processing incorporating Microlith technology. That led to additional fuel reforming work with the Department of Defense, which encompasses a large portion of PCI’s business today.\n                      Roychoudhury explains how the Microlith reactor is being used for efficient hydrogen sulfide removal in fuel reforming for fuel cell systems. “The work with fuel reforming and fuel processing takes hydrocarbon materials and runs them through a catalyst that is supported on the Microlith. It converts hydrocarbon to syngas, which can operate fuel cells. Utilizing the same Microlith technology that we developed through NASA, we make fuel for fuel cells.”\n                      Microlith technology is also being incorporated into development efforts for fuel reforming on ships for the U.S. Navy, mobile applications for the Army, and fuel processing for fuel cells for U.S. Air Force aircraft, as well as several civilian applications.\n                      Microlith® is a registered trademark of Precision Combustion Inc. \n                      \n                    \n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      “A spacecraft is the ultimate tight building. We don’t want any leaks, and there is very little fresh air coming in,” says Jay Perry, an aerospace engineer at Marshall Space Flight Center. “As a result, there is a huge potential for a buildup of contaminants from a host of sources.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          Inside the International Space Station’s (ISS) Cupola, Doug Wheelock, Expedition 25 commander, looks down while preparing his camera for a shot of Earth. The cabin atmosphere inside the ISS stays clean and safe thanks to its sophisticated Environmental Control and Life Support System. \n                        \n                      \n                      Inside a spacecraft, contaminants can be introduced from the materials that make spacecraft components, electronics boxes, or activities by the crew such as food preparation or cleaning. Humans also generate contaminants by breathing and through the body’s natural metabolic processes. As part of the sophisticated Environmental Control and Life Support System on the International Space Station (ISS), a trace contaminant control system removes carbon dioxide and other impurities from the cabin atmosphere. To maintain healthy levels, the system uses adsorbent media to filter chemical contaminant molecules and a high-temperature catalytic oxidizer to change the chemical structure of the contaminants to something more benign, usually carbon dioxide and water. \n                      In the 1990s, while researching air quality control technology for extended spaceflight travel, Perry and others at Marshall were looking for a regenerable process for the continuous removal of carbon dioxide and trace chemical contaminants on long-duration manned space flights. At the time, the existing technology used on U.S. spacecraft could only be used once, which meant that a spacecraft had to carry additional spare parts for use in case the first one was depleted, or the spacecraft would have to return to Earth to exchange the components.\n                      Partnership\n                      A North Haven, Connecticut-based company, Precision Combustion Inc. (PCI), previously worked with NASA’s Glenn Research Center (Spinoff 1998) to prove the viability of its Microlith technology, a very thin substrate consisting of short metal channels resembling screens or meshes, for catalytic reduction of emissions from combustion. Afterward, the company’s commercialization efforts focused on using the Microlith substrate in a catalytic combustor for gas turbines and in a catalytic converter for automotive exhaust treatment applications. \n                      “Precision Combustion had this idea of having a catalyst coating on the Microlith substrate that could be added to an existing automotive catalytic converter,” says Perry. “Because it is made out of metal, the Microlith substrate can heat very rapidly and thus eliminate the cold start emissions of an automobile, which is when most of the pollution happens.”\n                      Several years after working with Glenn, PCI worked with Marshall through the Small Business Innovation Research (SBIR) program to adapt its Microlith technology to provide a lighter and more durable rapid start-up trace contaminant removal system for spacecraft, and to meet NASA’s need for a regenerable contaminant control technology. A few years later, PCI pursued additional SBIR work with Marshall to integrate an adsorptive coating on the Microlith substrate to remove additional chemical compounds as well as carbon dioxide. \n                      “We took something that Precision Combustion was working on for an automotive application for cold start emission control and then pulled it into our need for use in a spacecraft,” says Perry. “By passing an electric current through the expanded metal, the system is up to operating temperature within less than a minute. That means that the oxidation of trace contaminants happens quickly, rather than an hour or two after powering the unit. Another advantage is the Microlith catalytic oxidation approach was practically an all-in-one contained device. With Precision Combustion’s technology, it could go from a 35-pound mass to less than 10 pounds.” \n                      Development testing successfully demonstrated the Microlith substrate for a regenerable carbon dioxide removal and trace contaminants control application. While the funding for further development and deployment of the technology ended, according to Perry the technology remains the leading catalytic oxidation technology for trace contaminant control for future space missions.\n                      Benefits\n                       Tony Anderson, the marketing and business development manager at PCI, says the SBIR work with NASA has been paramount to enhancing Microlith technology. “The interaction between PCI and NASA has been ongoing for almost 20 years now. On the catalytic oxidizer project, it has been invaluable to have the collaboration to ensure the success. Now we are using the technology as a springboard for other products.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          While working with NASA on contaminant control technology, Precision Combustion Inc. advanced its Microlith technology and then incorporated it into products such as the Regenerable Microlith Adsorber, seen here.\n                        \n                      \n                      Due to the company’s commercial success spanning more than a decade, it has received the “Tibbetts Award” twice—in 1998 and in 2006—in recognition for exemplifying the types of business, economic, and technical development goals of the SBIR program. PCI also received the “Army SBIR Achievement Award” in 2008 and 2010 for applications of its Microlith technology for military applications. The U.S. Army conducts its annual awards program to recognize efforts that exemplify the SBIR goal of bringing innovative technologies and products to the marketplace.\n                      Today, PCI develops, manufactures, and markets catalytic devices for clean and efficient combustion, emissions controls, and chemical manufacturing applications. As one of the company’s core technologies, the Microlith substrate can be coated with a variety of materials utilizing proprietary methods from PCI, including catalyst or adsorbent materials, to promote chemical reactions and to remove environmental contaminants.“Microlith substrate is a platform technology. With that, there are many different things we can do with it. A lot of the NASA support helps us to make the platform sturdy,” says Subir Roychoudhury, director of Microlith Products at PCI. \n                      In particular, the NASA-supported research has demonstrated that a certain coating on Microlith metal mesh elements can effectively adsorb a number of contaminants. Another benefit is that the technology is more compact and lightweight than the competing technology. Lastly, the Microlith substrate can be customized to target individual contaminants, and can also be integrated into existing systems. \n                      Soon after working with Marshall, the National Science Foundation started funding PCI to do fuel reforming and processing incorporating Microlith technology. That led to additional fuel reforming work with the Department of Defense, which encompasses a large portion of PCI’s business today.\n                      Roychoudhury explains how the Microlith reactor is being used for efficient hydrogen sulfide removal in fuel reforming for fuel cell systems. “The work with fuel reforming and fuel processing takes hydrocarbon materials and runs them through a catalyst that is supported on the Microlith. It converts hydrocarbon to syngas, which can operate fuel cells. Utilizing the same Microlith technology that we developed through NASA, we make fuel for fuel cells.”\n                      Microlith technology is also being incorporated into development efforts for fuel reforming on ships for the U.S. Navy, mobile applications for the Army, and fuel processing for fuel cells for U.S. Air Force aircraft, as well as several civilian applications.\n                      Microlith® is a registered trademark of Precision Combustion Inc. \n                      \n                    \n                  \n                \n              \n            \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      “A spacecraft is the ultimate tight building. We don’t want any leaks, and there is very little fresh air coming in,” says Jay Perry, an aerospace engineer at Marshall Space Flight Center. “As a result, there is a huge potential for a buildup of contaminants from a host of sources.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          Inside the International Space Station’s (ISS) Cupola, Doug Wheelock, Expedition 25 commander, looks down while preparing his camera for a shot of Earth. The cabin atmosphere inside the ISS stays clean and safe thanks to its sophisticated Environmental Control and Life Support System. \n                        \n                      \n                      Inside a spacecraft, contaminants can be introduced from the materials that make spacecraft components, electronics boxes, or activities by the crew such as food preparation or cleaning. Humans also generate contaminants by breathing and through the body’s natural metabolic processes. As part of the sophisticated Environmental Control and Life Support System on the International Space Station (ISS), a trace contaminant control system removes carbon dioxide and other impurities from the cabin atmosphere. To maintain healthy levels, the system uses adsorbent media to filter chemical contaminant molecules and a high-temperature catalytic oxidizer to change the chemical structure of the contaminants to something more benign, usually carbon dioxide and water. \n                      In the 1990s, while researching air quality control technology for extended spaceflight travel, Perry and others at Marshall were looking for a regenerable process for the continuous removal of carbon dioxide and trace chemical contaminants on long-duration manned space flights. At the time, the existing technology used on U.S. spacecraft could only be used once, which meant that a spacecraft had to carry additional spare parts for use in case the first one was depleted, or the spacecraft would have to return to Earth to exchange the components.\n                      Partnership\n                      A North Haven, Connecticut-based company, Precision Combustion Inc. (PCI), previously worked with NASA’s Glenn Research Center (Spinoff 1998) to prove the viability of its Microlith technology, a very thin substrate consisting of short metal channels resembling screens or meshes, for catalytic reduction of emissions from combustion. Afterward, the company’s commercialization efforts focused on using the Microlith substrate in a catalytic combustor for gas turbines and in a catalytic converter for automotive exhaust treatment applications. \n                      “Precision Combustion had this idea of having a catalyst coating on the Microlith substrate that could be added to an existing automotive catalytic converter,” says Perry. “Because it is made out of metal, the Microlith substrate can heat very rapidly and thus eliminate the cold start emissions of an automobile, which is when most of the pollution happens.”\n                      Several years after working with Glenn, PCI worked with Marshall through the Small Business Innovation Research (SBIR) program to adapt its Microlith technology to provide a lighter and more durable rapid start-up trace contaminant removal system for spacecraft, and to meet NASA’s need for a regenerable contaminant control technology. A few years later, PCI pursued additional SBIR work with Marshall to integrate an adsorptive coating on the Microlith substrate to remove additional chemical compounds as well as carbon dioxide. \n                      “We took something that Precision Combustion was working on for an automotive application for cold start emission control and then pulled it into our need for use in a spacecraft,” says Perry. “By passing an electric current through the expanded metal, the system is up to operating temperature within less than a minute. That means that the oxidation of trace contaminants happens quickly, rather than an hour or two after powering the unit. Another advantage is the Microlith catalytic oxidation approach was practically an all-in-one contained device. With Precision Combustion’s technology, it could go from a 35-pound mass to less than 10 pounds.” \n                      Development testing successfully demonstrated the Microlith substrate for a regenerable carbon dioxide removal and trace contaminants control application. While the funding for further development and deployment of the technology ended, according to Perry the technology remains the leading catalytic oxidation technology for trace contaminant control for future space missions.\n                      Benefits\n                       Tony Anderson, the marketing and business development manager at PCI, says the SBIR work with NASA has been paramount to enhancing Microlith technology. “The interaction between PCI and NASA has been ongoing for almost 20 years now. On the catalytic oxidizer project, it has been invaluable to have the collaboration to ensure the success. Now we are using the technology as a springboard for other products.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          While working with NASA on contaminant control technology, Precision Combustion Inc. advanced its Microlith technology and then incorporated it into products such as the Regenerable Microlith Adsorber, seen here.\n                        \n                      \n                      Due to the company’s commercial success spanning more than a decade, it has received the “Tibbetts Award” twice—in 1998 and in 2006—in recognition for exemplifying the types of business, economic, and technical development goals of the SBIR program. PCI also received the “Army SBIR Achievement Award” in 2008 and 2010 for applications of its Microlith technology for military applications. The U.S. Army conducts its annual awards program to recognize efforts that exemplify the SBIR goal of bringing innovative technologies and products to the marketplace.\n                      Today, PCI develops, manufactures, and markets catalytic devices for clean and efficient combustion, emissions controls, and chemical manufacturing applications. As one of the company’s core technologies, the Microlith substrate can be coated with a variety of materials utilizing proprietary methods from PCI, including catalyst or adsorbent materials, to promote chemical reactions and to remove environmental contaminants.“Microlith substrate is a platform technology. With that, there are many different things we can do with it. A lot of the NASA support helps us to make the platform sturdy,” says Subir Roychoudhury, director of Microlith Products at PCI. \n                      In particular, the NASA-supported research has demonstrated that a certain coating on Microlith metal mesh elements can effectively adsorb a number of contaminants. Another benefit is that the technology is more compact and lightweight than the competing technology. Lastly, the Microlith substrate can be customized to target individual contaminants, and can also be integrated into existing systems. \n                      Soon after working with Marshall, the National Science Foundation started funding PCI to do fuel reforming and processing incorporating Microlith technology. That led to additional fuel reforming work with the Department of Defense, which encompasses a large portion of PCI’s business today.\n                      Roychoudhury explains how the Microlith reactor is being used for efficient hydrogen sulfide removal in fuel reforming for fuel cell systems. “The work with fuel reforming and fuel processing takes hydrocarbon materials and runs them through a catalyst that is supported on the Microlith. It converts hydrocarbon to syngas, which can operate fuel cells. Utilizing the same Microlith technology that we developed through NASA, we make fuel for fuel cells.”\n                      Microlith technology is also being incorporated into development efforts for fuel reforming on ships for the U.S. Navy, mobile applications for the Army, and fuel processing for fuel cells for U.S. Air Force aircraft, as well as several civilian applications.\n                      Microlith® is a registered trademark of Precision Combustion Inc. \n                      \n                    \n                  \n                \n              \n                  \n                    \n                      NASA Technology\n                      “A spacecraft is the ultimate tight building. We don’t want any leaks, and there is very little fresh air coming in,” says Jay Perry, an aerospace engineer at Marshall Space Flight Center. “As a result, there is a huge potential for a buildup of contaminants from a host of sources.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          Inside the International Space Station’s (ISS) Cupola, Doug Wheelock, Expedition 25 commander, looks down while preparing his camera for a shot of Earth. The cabin atmosphere inside the ISS stays clean and safe thanks to its sophisticated Environmental Control and Life Support System. \n                        \n                      \n                      Inside a spacecraft, contaminants can be introduced from the materials that make spacecraft components, electronics boxes, or activities by the crew such as food preparation or cleaning. Humans also generate contaminants by breathing and through the body’s natural metabolic processes. As part of the sophisticated Environmental Control and Life Support System on the International Space Station (ISS), a trace contaminant control system removes carbon dioxide and other impurities from the cabin atmosphere. To maintain healthy levels, the system uses adsorbent media to filter chemical contaminant molecules and a high-temperature catalytic oxidizer to change the chemical structure of the contaminants to something more benign, usually carbon dioxide and water. \n                      In the 1990s, while researching air quality control technology for extended spaceflight travel, Perry and others at Marshall were looking for a regenerable process for the continuous removal of carbon dioxide and trace chemical contaminants on long-duration manned space flights. At the time, the existing technology used on U.S. spacecraft could only be used once, which meant that a spacecraft had to carry additional spare parts for use in case the first one was depleted, or the spacecraft would have to return to Earth to exchange the components.\n                      Partnership\n                      A North Haven, Connecticut-based company, Precision Combustion Inc. (PCI), previously worked with NASA’s Glenn Research Center (Spinoff 1998) to prove the viability of its Microlith technology, a very thin substrate consisting of short metal channels resembling screens or meshes, for catalytic reduction of emissions from combustion. Afterward, the company’s commercialization efforts focused on using the Microlith substrate in a catalytic combustor for gas turbines and in a catalytic converter for automotive exhaust treatment applications. \n                      “Precision Combustion had this idea of having a catalyst coating on the Microlith substrate that could be added to an existing automotive catalytic converter,” says Perry. “Because it is made out of metal, the Microlith substrate can heat very rapidly and thus eliminate the cold start emissions of an automobile, which is when most of the pollution happens.”\n                      Several years after working with Glenn, PCI worked with Marshall through the Small Business Innovation Research (SBIR) program to adapt its Microlith technology to provide a lighter and more durable rapid start-up trace contaminant removal system for spacecraft, and to meet NASA’s need for a regenerable contaminant control technology. A few years later, PCI pursued additional SBIR work with Marshall to integrate an adsorptive coating on the Microlith substrate to remove additional chemical compounds as well as carbon dioxide. \n                      “We took something that Precision Combustion was working on for an automotive application for cold start emission control and then pulled it into our need for use in a spacecraft,” says Perry. “By passing an electric current through the expanded metal, the system is up to operating temperature within less than a minute. That means that the oxidation of trace contaminants happens quickly, rather than an hour or two after powering the unit. Another advantage is the Microlith catalytic oxidation approach was practically an all-in-one contained device. With Precision Combustion’s technology, it could go from a 35-pound mass to less than 10 pounds.” \n                      Development testing successfully demonstrated the Microlith substrate for a regenerable carbon dioxide removal and trace contaminants control application. While the funding for further development and deployment of the technology ended, according to Perry the technology remains the leading catalytic oxidation technology for trace contaminant control for future space missions.\n                      Benefits\n                       Tony Anderson, the marketing and business development manager at PCI, says the SBIR work with NASA has been paramount to enhancing Microlith technology. “The interaction between PCI and NASA has been ongoing for almost 20 years now. On the catalytic oxidizer project, it has been invaluable to have the collaboration to ensure the success. Now we are using the technology as a springboard for other products.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          While working with NASA on contaminant control technology, Precision Combustion Inc. advanced its Microlith technology and then incorporated it into products such as the Regenerable Microlith Adsorber, seen here.\n                        \n                      \n                      Due to the company’s commercial success spanning more than a decade, it has received the “Tibbetts Award” twice—in 1998 and in 2006—in recognition for exemplifying the types of business, economic, and technical development goals of the SBIR program. PCI also received the “Army SBIR Achievement Award” in 2008 and 2010 for applications of its Microlith technology for military applications. The U.S. Army conducts its annual awards program to recognize efforts that exemplify the SBIR goal of bringing innovative technologies and products to the marketplace.\n                      Today, PCI develops, manufactures, and markets catalytic devices for clean and efficient combustion, emissions controls, and chemical manufacturing applications. As one of the company’s core technologies, the Microlith substrate can be coated with a variety of materials utilizing proprietary methods from PCI, including catalyst or adsorbent materials, to promote chemical reactions and to remove environmental contaminants.“Microlith substrate is a platform technology. With that, there are many different things we can do with it. A lot of the NASA support helps us to make the platform sturdy,” says Subir Roychoudhury, director of Microlith Products at PCI. \n                      In particular, the NASA-supported research has demonstrated that a certain coating on Microlith metal mesh elements can effectively adsorb a number of contaminants. Another benefit is that the technology is more compact and lightweight than the competing technology. Lastly, the Microlith substrate can be customized to target individual contaminants, and can also be integrated into existing systems. \n                      Soon after working with Marshall, the National Science Foundation started funding PCI to do fuel reforming and processing incorporating Microlith technology. That led to additional fuel reforming work with the Department of Defense, which encompasses a large portion of PCI’s business today.\n                      Roychoudhury explains how the Microlith reactor is being used for efficient hydrogen sulfide removal in fuel reforming for fuel cell systems. “The work with fuel reforming and fuel processing takes hydrocarbon materials and runs them through a catalyst that is supported on the Microlith. It converts hydrocarbon to syngas, which can operate fuel cells. Utilizing the same Microlith technology that we developed through NASA, we make fuel for fuel cells.”\n                      Microlith technology is also being incorporated into development efforts for fuel reforming on ships for the U.S. Navy, mobile applications for the Army, and fuel processing for fuel cells for U.S. Air Force aircraft, as well as several civilian applications.\n                      Microlith® is a registered trademark of Precision Combustion Inc. \n                      \n                    \n                  \n                    \n                      NASA Technology\n                      “A spacecraft is the ultimate tight building. We don’t want any leaks, and there is very little fresh air coming in,” says Jay Perry, an aerospace engineer at Marshall Space Flight Center. “As a result, there is a huge potential for a buildup of contaminants from a host of sources.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          Inside the International Space Station’s (ISS) Cupola, Doug Wheelock, Expedition 25 commander, looks down while preparing his camera for a shot of Earth. The cabin atmosphere inside the ISS stays clean and safe thanks to its sophisticated Environmental Control and Life Support System. \n                        \n                      \n                      Inside a spacecraft, contaminants can be introduced from the materials that make spacecraft components, electronics boxes, or activities by the crew such as food preparation or cleaning. Humans also generate contaminants by breathing and through the body’s natural metabolic processes. As part of the sophisticated Environmental Control and Life Support System on the International Space Station (ISS), a trace contaminant control system removes carbon dioxide and other impurities from the cabin atmosphere. To maintain healthy levels, the system uses adsorbent media to filter chemical contaminant molecules and a high-temperature catalytic oxidizer to change the chemical structure of the contaminants to something more benign, usually carbon dioxide and water. \n                      In the 1990s, while researching air quality control technology for extended spaceflight travel, Perry and others at Marshall were looking for a regenerable process for the continuous removal of carbon dioxide and trace chemical contaminants on long-duration manned space flights. At the time, the existing technology used on U.S. spacecraft could only be used once, which meant that a spacecraft had to carry additional spare parts for use in case the first one was depleted, or the spacecraft would have to return to Earth to exchange the components.\n                      Partnership\n                      A North Haven, Connecticut-based company, Precision Combustion Inc. (PCI), previously worked with NASA’s Glenn Research Center (Spinoff 1998) to prove the viability of its Microlith technology, a very thin substrate consisting of short metal channels resembling screens or meshes, for catalytic reduction of emissions from combustion. Afterward, the company’s commercialization efforts focused on using the Microlith substrate in a catalytic combustor for gas turbines and in a catalytic converter for automotive exhaust treatment applications. \n                      “Precision Combustion had this idea of having a catalyst coating on the Microlith substrate that could be added to an existing automotive catalytic converter,” says Perry. “Because it is made out of metal, the Microlith substrate can heat very rapidly and thus eliminate the cold start emissions of an automobile, which is when most of the pollution happens.”\n                      Several years after working with Glenn, PCI worked with Marshall through the Small Business Innovation Research (SBIR) program to adapt its Microlith technology to provide a lighter and more durable rapid start-up trace contaminant removal system for spacecraft, and to meet NASA’s need for a regenerable contaminant control technology. A few years later, PCI pursued additional SBIR work with Marshall to integrate an adsorptive coating on the Microlith substrate to remove additional chemical compounds as well as carbon dioxide. \n                      “We took something that Precision Combustion was working on for an automotive application for cold start emission control and then pulled it into our need for use in a spacecraft,” says Perry. “By passing an electric current through the expanded metal, the system is up to operating temperature within less than a minute. That means that the oxidation of trace contaminants happens quickly, rather than an hour or two after powering the unit. Another advantage is the Microlith catalytic oxidation approach was practically an all-in-one contained device. With Precision Combustion’s technology, it could go from a 35-pound mass to less than 10 pounds.” \n                      Development testing successfully demonstrated the Microlith substrate for a regenerable carbon dioxide removal and trace contaminants control application. While the funding for further development and deployment of the technology ended, according to Perry the technology remains the leading catalytic oxidation technology for trace contaminant control for future space missions.\n                      Benefits\n                       Tony Anderson, the marketing and business development manager at PCI, says the SBIR work with NASA has been paramount to enhancing Microlith technology. “The interaction between PCI and NASA has been ongoing for almost 20 years now. On the catalytic oxidizer project, it has been invaluable to have the collaboration to ensure the success. Now we are using the technology as a springboard for other products.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          While working with NASA on contaminant control technology, Precision Combustion Inc. advanced its Microlith technology and then incorporated it into products such as the Regenerable Microlith Adsorber, seen here.\n                        \n                      \n                      Due to the company’s commercial success spanning more than a decade, it has received the “Tibbetts Award” twice—in 1998 and in 2006—in recognition for exemplifying the types of business, economic, and technical development goals of the SBIR program. PCI also received the “Army SBIR Achievement Award” in 2008 and 2010 for applications of its Microlith technology for military applications. The U.S. Army conducts its annual awards program to recognize efforts that exemplify the SBIR goal of bringing innovative technologies and products to the marketplace.\n                      Today, PCI develops, manufactures, and markets catalytic devices for clean and efficient combustion, emissions controls, and chemical manufacturing applications. As one of the company’s core technologies, the Microlith substrate can be coated with a variety of materials utilizing proprietary methods from PCI, including catalyst or adsorbent materials, to promote chemical reactions and to remove environmental contaminants.“Microlith substrate is a platform technology. With that, there are many different things we can do with it. A lot of the NASA support helps us to make the platform sturdy,” says Subir Roychoudhury, director of Microlith Products at PCI. \n                      In particular, the NASA-supported research has demonstrated that a certain coating on Microlith metal mesh elements can effectively adsorb a number of contaminants. Another benefit is that the technology is more compact and lightweight than the competing technology. Lastly, the Microlith substrate can be customized to target individual contaminants, and can also be integrated into existing systems. \n                      Soon after working with Marshall, the National Science Foundation started funding PCI to do fuel reforming and processing incorporating Microlith technology. That led to additional fuel reforming work with the Department of Defense, which encompasses a large portion of PCI’s business today.\n                      Roychoudhury explains how the Microlith reactor is being used for efficient hydrogen sulfide removal in fuel reforming for fuel cell systems. “The work with fuel reforming and fuel processing takes hydrocarbon materials and runs them through a catalyst that is supported on the Microlith. It converts hydrocarbon to syngas, which can operate fuel cells. Utilizing the same Microlith technology that we developed through NASA, we make fuel for fuel cells.”\n                      Microlith technology is also being incorporated into development efforts for fuel reforming on ships for the U.S. Navy, mobile applications for the Army, and fuel processing for fuel cells for U.S. Air Force aircraft, as well as several civilian applications.\n                      Microlith® is a registered trademark of Precision Combustion Inc. \n                      \n                    \n                      NASA Technology\n                      “A spacecraft is the ultimate tight building. We don’t want any leaks, and there is very little fresh air coming in,” says Jay Perry, an aerospace engineer at Marshall Space Flight Center. “As a result, there is a huge potential for a buildup of contaminants from a host of sources.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          Inside the International Space Station’s (ISS) Cupola, Doug Wheelock, Expedition 25 commander, looks down while preparing his camera for a shot of Earth. The cabin atmosphere inside the ISS stays clean and safe thanks to its sophisticated Environmental Control and Life Support System. \n                        \n                      \n                      Inside a spacecraft, contaminants can be introduced from the materials that make spacecraft components, electronics boxes, or activities by the crew such as food preparation or cleaning. Humans also generate contaminants by breathing and through the body’s natural metabolic processes. As part of the sophisticated Environmental Control and Life Support System on the International Space Station (ISS), a trace contaminant control system removes carbon dioxide and other impurities from the cabin atmosphere. To maintain healthy levels, the system uses adsorbent media to filter chemical contaminant molecules and a high-temperature catalytic oxidizer to change the chemical structure of the contaminants to something more benign, usually carbon dioxide and water. \n                      In the 1990s, while researching air quality control technology for extended spaceflight travel, Perry and others at Marshall were looking for a regenerable process for the continuous removal of carbon dioxide and trace chemical contaminants on long-duration manned space flights. At the time, the existing technology used on U.S. spacecraft could only be used once, which meant that a spacecraft had to carry additional spare parts for use in case the first one was depleted, or the spacecraft would have to return to Earth to exchange the components.\n                      Partnership\n                      A North Haven, Connecticut-based company, Precision Combustion Inc. (PCI), previously worked with NASA’s Glenn Research Center (Spinoff 1998) to prove the viability of its Microlith technology, a very thin substrate consisting of short metal channels resembling screens or meshes, for catalytic reduction of emissions from combustion. Afterward, the company’s commercialization efforts focused on using the Microlith substrate in a catalytic combustor for gas turbines and in a catalytic converter for automotive exhaust treatment applications. \n                      “Precision Combustion had this idea of having a catalyst coating on the Microlith substrate that could be added to an existing automotive catalytic converter,” says Perry. “Because it is made out of metal, the Microlith substrate can heat very rapidly and thus eliminate the cold start emissions of an automobile, which is when most of the pollution happens.”\n                      Several years after working with Glenn, PCI worked with Marshall through the Small Business Innovation Research (SBIR) program to adapt its Microlith technology to provide a lighter and more durable rapid start-up trace contaminant removal system for spacecraft, and to meet NASA’s need for a regenerable contaminant control technology. A few years later, PCI pursued additional SBIR work with Marshall to integrate an adsorptive coating on the Microlith substrate to remove additional chemical compounds as well as carbon dioxide. \n                      “We took something that Precision Combustion was working on for an automotive application for cold start emission control and then pulled it into our need for use in a spacecraft,” says Perry. “By passing an electric current through the expanded metal, the system is up to operating temperature within less than a minute. That means that the oxidation of trace contaminants happens quickly, rather than an hour or two after powering the unit. Another advantage is the Microlith catalytic oxidation approach was practically an all-in-one contained device. With Precision Combustion’s technology, it could go from a 35-pound mass to less than 10 pounds.” \n                      Development testing successfully demonstrated the Microlith substrate for a regenerable carbon dioxide removal and trace contaminants control application. While the funding for further development and deployment of the technology ended, according to Perry the technology remains the leading catalytic oxidation technology for trace contaminant control for future space missions.\n                      Benefits\n                       Tony Anderson, the marketing and business development manager at PCI, says the SBIR work with NASA has been paramount to enhancing Microlith technology. “The interaction between PCI and NASA has been ongoing for almost 20 years now. On the catalytic oxidizer project, it has been invaluable to have the collaboration to ensure the success. Now we are using the technology as a springboard for other products.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          While working with NASA on contaminant control technology, Precision Combustion Inc. advanced its Microlith technology and then incorporated it into products such as the Regenerable Microlith Adsorber, seen here.\n                        \n                      \n                      Due to the company’s commercial success spanning more than a decade, it has received the “Tibbetts Award” twice—in 1998 and in 2006—in recognition for exemplifying the types of business, economic, and technical development goals of the SBIR program. PCI also received the “Army SBIR Achievement Award” in 2008 and 2010 for applications of its Microlith technology for military applications. The U.S. Army conducts its annual awards program to recognize efforts that exemplify the SBIR goal of bringing innovative technologies and products to the marketplace.\n                      Today, PCI develops, manufactures, and markets catalytic devices for clean and efficient combustion, emissions controls, and chemical manufacturing applications. As one of the company’s core technologies, the Microlith substrate can be coated with a variety of materials utilizing proprietary methods from PCI, including catalyst or adsorbent materials, to promote chemical reactions and to remove environmental contaminants.“Microlith substrate is a platform technology. With that, there are many different things we can do with it. A lot of the NASA support helps us to make the platform sturdy,” says Subir Roychoudhury, director of Microlith Products at PCI. \n                      In particular, the NASA-supported research has demonstrated that a certain coating on Microlith metal mesh elements can effectively adsorb a number of contaminants. Another benefit is that the technology is more compact and lightweight than the competing technology. Lastly, the Microlith substrate can be customized to target individual contaminants, and can also be integrated into existing systems. \n                      Soon after working with Marshall, the National Science Foundation started funding PCI to do fuel reforming and processing incorporating Microlith technology. That led to additional fuel reforming work with the Department of Defense, which encompasses a large portion of PCI’s business today.\n                      Roychoudhury explains how the Microlith reactor is being used for efficient hydrogen sulfide removal in fuel reforming for fuel cell systems. “The work with fuel reforming and fuel processing takes hydrocarbon materials and runs them through a catalyst that is supported on the Microlith. It converts hydrocarbon to syngas, which can operate fuel cells. Utilizing the same Microlith technology that we developed through NASA, we make fuel for fuel cells.”\n                      Microlith technology is also being incorporated into development efforts for fuel reforming on ships for the U.S. Navy, mobile applications for the Army, and fuel processing for fuel cells for U.S. Air Force aircraft, as well as several civilian applications.\n                      Microlith® is a registered trademark of Precision Combustion Inc. \n                      "},{"href":"http://spinoff.nasa.gov/Spinoff2011/er_8.html","text":"Rocket Engine Innovations Advance \n                Clean Energy","image":"http://spinoff.nasa.gov/Spinoff2011/Images/er_11a_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      During launch countdown, at approximately T-7 seconds, the Space Shuttle Main Engines (SSMEs) roar to life. When the controllers indicate normal operation, the solid rocket boosters ignite and the shuttle blasts off. Initially, the SSMEs throttle down to reduce stress during the period of maximum dynamic pressure, but soon after, they throttle up to propel the orbiter to 17,500 miles per hour. In just under 9 minutes, the three SSMEs burn over 1.6 million pounds of propellant, and temperatures inside the main combustion chamber reach 6,000 ˚F. To cool the engines, liquid hydrogen circulates through miles of tubing at -423 ˚F. \n                      From 1981to 2011, the space shuttle fleet carried crew and cargo into orbit to perform a myriad of unprecedented tasks. After 30 years and 135 missions, the feat of engineering known as the SSME boasted a 100-percent flight success rate. \n                      Partnership\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Space Shuttle Main Engine, built by Rocketdyne under contract to NASA, undergoes test firing in 1981. Marshall Space Flight Center was responsible for the shuttle’s propulsion elements, including the main engines.\n                        \n                      \n                      In the 1970s, the SSME was designed under contract to NASA by Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), a United Technologies Company based in East Hartford, Connecticut. Working with Marshall Space Flight Center, PWR developed the most efficient rocket engines in existence, with ultra-high-pressure operation of the pumps and combustion chamber, which allowed expansion of all hot gasses through a high-area-ratio exhaust nozzle.\n                      Soon after developing the highly efficient shuttle engines, PWR started creating highly efficient gasification systems. Gasification is a chemical process that converts carbon-containing materials such as coal, petcoke (a waste product from oil refineries), or biomass (organic material from plants or animals) into synthesis gas, or syngas. After the material is pulverized, it mixes with oxygen and steam at very high temperatures. The resulting syngas—comprised of carbon monoxide, hydrogen, carbon dioxide, and methane—can be burned as a fuel to create electricity, or further processed to make products such as substitute natural gas, chemicals, fertilizers, or liquid transportation fuels. \n                      “We started looking at alternate forms of energy and alternate ways of using coal during the 1970s energy crisis,” says Don Stevenson, program area manager for Clean Fossil Fueled Energy Technologies at PWR. “By applying our rocket engine expertise, we are able to increase the temperatures and pressures in a gasifier, which resulted in a much higher efficiency system.” \n                      Benefits\n                      In the 1980s, PWR built its proof-of-concept gasifier, but due to a lack of funding, the company temporarily shelved the technology. Years later, interest in the technology resurfaced, so PWR pursued new partnerships with the U.S. Department of Energy, ExxonMobil Research and Engineering, and Canada’s Alberta Innovates, to design, develop, and test the technology. By 2009, PWR had begun operating a pilot plant at the Gas Technology Institute in Des Plaines, Illinois, and in June 2011, test results established the gasifier’s successful performance and operation over a range of conditions. \n                      PWR’s experience developing rocket technology was instrumental in improving gasification technology. Stevenson says, “The result is a much more compact, efficient, and lower-cost system.”\n                      Several aspects of the compact gasification system have been influenced by the company’s experience with rocket engine design and development. The main component, however, is the rapid mix injector. “If it weren’t for the injector, which we think is the key secret ingredient, this wouldn’t be possible,” says Stevenson.\n                      PWR’s rapid mix injector allows the gasifier to mix the carbon-based material, oxygen, and steam more efficiently at higher temperatures so the reaction can happen more quickly. PWR’s experience with rocket engines, which typically run at 5,000 ˚F or more, provided the expertise needed to build a gasifier system capable of withstanding extreme temperatures. \n                      “The modeling and analysis required to understand high heat loads for rocket engines is something that we have directly applied to the gasifier. Others in the field don’t have that expertise, so they have been reluctant to go to the higher efficiencies because they can’t handle the temperatures,” says Stevenson.\n                      In addition to the smaller size, another advantage of PWR’s system is lower costs, compared to the prevailing gasifier technology. According to the company, the capital cost to build a commercial-scale compact gasification plant using PWR’s technology is estimated to be 10–20 percent less than conventional gasification plants. Another main advantage is that the system is expected to reduce carbon dioxide emissions by up to 10 percent, compared to standard gasification technologies—which are already the cleanest coal-based power systems available. For each commercial system deployed, it is equivalent to removing 50,000 cars from road.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), used its rocket engine expertise to advance gasification technology. Compared to standard gasification systems, PWR’s technology is more compact, efficient, and lower cost.\n                        \n                      \n                      These advancements hold real promise for the energy and chemical processing industries. According to the Gasification Technologies Council, worldwide gasification capacity is projected to grow 70 percent by 2015, with 80 percent of the growth occurring in Asia. In fact, PWR has already granted a license to Zero Emission Energy Plants, Inc. (ZEEP) of Katy, Texas, for commercial implementation of the compact gasifier system. “ZEEP has a unique energy plant concept, and they want to make our technology a centerpiece. They were willing to come in with an early license, and that provided some additional financial resources to support the development,” says Stevenson.\n                      In the future, PWR expects to license the technology to various national and international entities such as oil refineries, electric power, liquid fuels, and chemical plants. The next step in the commercialization efforts is to demonstrate the gasifier at a commercial scale over a long period of time. To this end, PWR is beginning to work with partners to build a commercial-scale plant in either Asia or North America. \n                      Perhaps the greatest benefits of using more efficient, cost-effective gasifiers to produce electricity, however, will be for the environment. As Stevenson says, “One of the industry’s challenges has been how to continue to use coal in an environmentally friendly way. Once gasification can be brought in as a cost-effective mechanism for a means to producing electricity, we can replace coal-fired power plants and make a huge improvement on the global emissions problem.” \n                      While the demand for energy continues to rise, coal continues to be a major source of energy, so Stevenson finds gasification of coal offers the opportunity to dramatically reduce carbon dioxide emissions into the atmosphere. By using a gasifier, the carbon dioxide can be captured much more efficiently. “Extensive research is being conducted in North America, Asia, and Europe to pump captured carbon dioxide underground and store it or use it to enhance oil recovery. There are some major pilot projects taking place to prove the technology for carbon sequestration, which will ultimately be the key enabler for near-zero emissions from these types of facilities,” he says.\n                      Stevenson suggests this type of innovation, similar to the innovation required to build the SSMEs, is what will help to meet the world’s energy and environmental goals\n                    \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      During launch countdown, at approximately T-7 seconds, the Space Shuttle Main Engines (SSMEs) roar to life. When the controllers indicate normal operation, the solid rocket boosters ignite and the shuttle blasts off. Initially, the SSMEs throttle down to reduce stress during the period of maximum dynamic pressure, but soon after, they throttle up to propel the orbiter to 17,500 miles per hour. In just under 9 minutes, the three SSMEs burn over 1.6 million pounds of propellant, and temperatures inside the main combustion chamber reach 6,000 ˚F. To cool the engines, liquid hydrogen circulates through miles of tubing at -423 ˚F. \n                      From 1981to 2011, the space shuttle fleet carried crew and cargo into orbit to perform a myriad of unprecedented tasks. After 30 years and 135 missions, the feat of engineering known as the SSME boasted a 100-percent flight success rate. \n                      Partnership\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Space Shuttle Main Engine, built by Rocketdyne under contract to NASA, undergoes test firing in 1981. Marshall Space Flight Center was responsible for the shuttle’s propulsion elements, including the main engines.\n                        \n                      \n                      In the 1970s, the SSME was designed under contract to NASA by Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), a United Technologies Company based in East Hartford, Connecticut. Working with Marshall Space Flight Center, PWR developed the most efficient rocket engines in existence, with ultra-high-pressure operation of the pumps and combustion chamber, which allowed expansion of all hot gasses through a high-area-ratio exhaust nozzle.\n                      Soon after developing the highly efficient shuttle engines, PWR started creating highly efficient gasification systems. Gasification is a chemical process that converts carbon-containing materials such as coal, petcoke (a waste product from oil refineries), or biomass (organic material from plants or animals) into synthesis gas, or syngas. After the material is pulverized, it mixes with oxygen and steam at very high temperatures. The resulting syngas—comprised of carbon monoxide, hydrogen, carbon dioxide, and methane—can be burned as a fuel to create electricity, or further processed to make products such as substitute natural gas, chemicals, fertilizers, or liquid transportation fuels. \n                      “We started looking at alternate forms of energy and alternate ways of using coal during the 1970s energy crisis,” says Don Stevenson, program area manager for Clean Fossil Fueled Energy Technologies at PWR. “By applying our rocket engine expertise, we are able to increase the temperatures and pressures in a gasifier, which resulted in a much higher efficiency system.” \n                      Benefits\n                      In the 1980s, PWR built its proof-of-concept gasifier, but due to a lack of funding, the company temporarily shelved the technology. Years later, interest in the technology resurfaced, so PWR pursued new partnerships with the U.S. Department of Energy, ExxonMobil Research and Engineering, and Canada’s Alberta Innovates, to design, develop, and test the technology. By 2009, PWR had begun operating a pilot plant at the Gas Technology Institute in Des Plaines, Illinois, and in June 2011, test results established the gasifier’s successful performance and operation over a range of conditions. \n                      PWR’s experience developing rocket technology was instrumental in improving gasification technology. Stevenson says, “The result is a much more compact, efficient, and lower-cost system.”\n                      Several aspects of the compact gasification system have been influenced by the company’s experience with rocket engine design and development. The main component, however, is the rapid mix injector. “If it weren’t for the injector, which we think is the key secret ingredient, this wouldn’t be possible,” says Stevenson.\n                      PWR’s rapid mix injector allows the gasifier to mix the carbon-based material, oxygen, and steam more efficiently at higher temperatures so the reaction can happen more quickly. PWR’s experience with rocket engines, which typically run at 5,000 ˚F or more, provided the expertise needed to build a gasifier system capable of withstanding extreme temperatures. \n                      “The modeling and analysis required to understand high heat loads for rocket engines is something that we have directly applied to the gasifier. Others in the field don’t have that expertise, so they have been reluctant to go to the higher efficiencies because they can’t handle the temperatures,” says Stevenson.\n                      In addition to the smaller size, another advantage of PWR’s system is lower costs, compared to the prevailing gasifier technology. According to the company, the capital cost to build a commercial-scale compact gasification plant using PWR’s technology is estimated to be 10–20 percent less than conventional gasification plants. Another main advantage is that the system is expected to reduce carbon dioxide emissions by up to 10 percent, compared to standard gasification technologies—which are already the cleanest coal-based power systems available. For each commercial system deployed, it is equivalent to removing 50,000 cars from road.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), used its rocket engine expertise to advance gasification technology. Compared to standard gasification systems, PWR’s technology is more compact, efficient, and lower cost.\n                        \n                      \n                      These advancements hold real promise for the energy and chemical processing industries. According to the Gasification Technologies Council, worldwide gasification capacity is projected to grow 70 percent by 2015, with 80 percent of the growth occurring in Asia. In fact, PWR has already granted a license to Zero Emission Energy Plants, Inc. (ZEEP) of Katy, Texas, for commercial implementation of the compact gasifier system. “ZEEP has a unique energy plant concept, and they want to make our technology a centerpiece. They were willing to come in with an early license, and that provided some additional financial resources to support the development,” says Stevenson.\n                      In the future, PWR expects to license the technology to various national and international entities such as oil refineries, electric power, liquid fuels, and chemical plants. The next step in the commercialization efforts is to demonstrate the gasifier at a commercial scale over a long period of time. To this end, PWR is beginning to work with partners to build a commercial-scale plant in either Asia or North America. \n                      Perhaps the greatest benefits of using more efficient, cost-effective gasifiers to produce electricity, however, will be for the environment. As Stevenson says, “One of the industry’s challenges has been how to continue to use coal in an environmentally friendly way. Once gasification can be brought in as a cost-effective mechanism for a means to producing electricity, we can replace coal-fired power plants and make a huge improvement on the global emissions problem.” \n                      While the demand for energy continues to rise, coal continues to be a major source of energy, so Stevenson finds gasification of coal offers the opportunity to dramatically reduce carbon dioxide emissions into the atmosphere. By using a gasifier, the carbon dioxide can be captured much more efficiently. “Extensive research is being conducted in North America, Asia, and Europe to pump captured carbon dioxide underground and store it or use it to enhance oil recovery. There are some major pilot projects taking place to prove the technology for carbon sequestration, which will ultimately be the key enabler for near-zero emissions from these types of facilities,” he says.\n                      Stevenson suggests this type of innovation, similar to the innovation required to build the SSMEs, is what will help to meet the world’s energy and environmental goals\n                    \n                    \n                  \n                \n              \n            \n            \n          \n        \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      During launch countdown, at approximately T-7 seconds, the Space Shuttle Main Engines (SSMEs) roar to life. When the controllers indicate normal operation, the solid rocket boosters ignite and the shuttle blasts off. Initially, the SSMEs throttle down to reduce stress during the period of maximum dynamic pressure, but soon after, they throttle up to propel the orbiter to 17,500 miles per hour. In just under 9 minutes, the three SSMEs burn over 1.6 million pounds of propellant, and temperatures inside the main combustion chamber reach 6,000 ˚F. To cool the engines, liquid hydrogen circulates through miles of tubing at -423 ˚F. \n                      From 1981to 2011, the space shuttle fleet carried crew and cargo into orbit to perform a myriad of unprecedented tasks. After 30 years and 135 missions, the feat of engineering known as the SSME boasted a 100-percent flight success rate. \n                      Partnership\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Space Shuttle Main Engine, built by Rocketdyne under contract to NASA, undergoes test firing in 1981. Marshall Space Flight Center was responsible for the shuttle’s propulsion elements, including the main engines.\n                        \n                      \n                      In the 1970s, the SSME was designed under contract to NASA by Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), a United Technologies Company based in East Hartford, Connecticut. Working with Marshall Space Flight Center, PWR developed the most efficient rocket engines in existence, with ultra-high-pressure operation of the pumps and combustion chamber, which allowed expansion of all hot gasses through a high-area-ratio exhaust nozzle.\n                      Soon after developing the highly efficient shuttle engines, PWR started creating highly efficient gasification systems. Gasification is a chemical process that converts carbon-containing materials such as coal, petcoke (a waste product from oil refineries), or biomass (organic material from plants or animals) into synthesis gas, or syngas. After the material is pulverized, it mixes with oxygen and steam at very high temperatures. The resulting syngas—comprised of carbon monoxide, hydrogen, carbon dioxide, and methane—can be burned as a fuel to create electricity, or further processed to make products such as substitute natural gas, chemicals, fertilizers, or liquid transportation fuels. \n                      “We started looking at alternate forms of energy and alternate ways of using coal during the 1970s energy crisis,” says Don Stevenson, program area manager for Clean Fossil Fueled Energy Technologies at PWR. “By applying our rocket engine expertise, we are able to increase the temperatures and pressures in a gasifier, which resulted in a much higher efficiency system.” \n                      Benefits\n                      In the 1980s, PWR built its proof-of-concept gasifier, but due to a lack of funding, the company temporarily shelved the technology. Years later, interest in the technology resurfaced, so PWR pursued new partnerships with the U.S. Department of Energy, ExxonMobil Research and Engineering, and Canada’s Alberta Innovates, to design, develop, and test the technology. By 2009, PWR had begun operating a pilot plant at the Gas Technology Institute in Des Plaines, Illinois, and in June 2011, test results established the gasifier’s successful performance and operation over a range of conditions. \n                      PWR’s experience developing rocket technology was instrumental in improving gasification technology. Stevenson says, “The result is a much more compact, efficient, and lower-cost system.”\n                      Several aspects of the compact gasification system have been influenced by the company’s experience with rocket engine design and development. The main component, however, is the rapid mix injector. “If it weren’t for the injector, which we think is the key secret ingredient, this wouldn’t be possible,” says Stevenson.\n                      PWR’s rapid mix injector allows the gasifier to mix the carbon-based material, oxygen, and steam more efficiently at higher temperatures so the reaction can happen more quickly. PWR’s experience with rocket engines, which typically run at 5,000 ˚F or more, provided the expertise needed to build a gasifier system capable of withstanding extreme temperatures. \n                      “The modeling and analysis required to understand high heat loads for rocket engines is something that we have directly applied to the gasifier. Others in the field don’t have that expertise, so they have been reluctant to go to the higher efficiencies because they can’t handle the temperatures,” says Stevenson.\n                      In addition to the smaller size, another advantage of PWR’s system is lower costs, compared to the prevailing gasifier technology. According to the company, the capital cost to build a commercial-scale compact gasification plant using PWR’s technology is estimated to be 10–20 percent less than conventional gasification plants. Another main advantage is that the system is expected to reduce carbon dioxide emissions by up to 10 percent, compared to standard gasification technologies—which are already the cleanest coal-based power systems available. For each commercial system deployed, it is equivalent to removing 50,000 cars from road.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), used its rocket engine expertise to advance gasification technology. Compared to standard gasification systems, PWR’s technology is more compact, efficient, and lower cost.\n                        \n                      \n                      These advancements hold real promise for the energy and chemical processing industries. According to the Gasification Technologies Council, worldwide gasification capacity is projected to grow 70 percent by 2015, with 80 percent of the growth occurring in Asia. In fact, PWR has already granted a license to Zero Emission Energy Plants, Inc. (ZEEP) of Katy, Texas, for commercial implementation of the compact gasifier system. “ZEEP has a unique energy plant concept, and they want to make our technology a centerpiece. They were willing to come in with an early license, and that provided some additional financial resources to support the development,” says Stevenson.\n                      In the future, PWR expects to license the technology to various national and international entities such as oil refineries, electric power, liquid fuels, and chemical plants. The next step in the commercialization efforts is to demonstrate the gasifier at a commercial scale over a long period of time. To this end, PWR is beginning to work with partners to build a commercial-scale plant in either Asia or North America. \n                      Perhaps the greatest benefits of using more efficient, cost-effective gasifiers to produce electricity, however, will be for the environment. As Stevenson says, “One of the industry’s challenges has been how to continue to use coal in an environmentally friendly way. Once gasification can be brought in as a cost-effective mechanism for a means to producing electricity, we can replace coal-fired power plants and make a huge improvement on the global emissions problem.” \n                      While the demand for energy continues to rise, coal continues to be a major source of energy, so Stevenson finds gasification of coal offers the opportunity to dramatically reduce carbon dioxide emissions into the atmosphere. By using a gasifier, the carbon dioxide can be captured much more efficiently. “Extensive research is being conducted in North America, Asia, and Europe to pump captured carbon dioxide underground and store it or use it to enhance oil recovery. There are some major pilot projects taking place to prove the technology for carbon sequestration, which will ultimately be the key enabler for near-zero emissions from these types of facilities,” he says.\n                      Stevenson suggests this type of innovation, similar to the innovation required to build the SSMEs, is what will help to meet the world’s energy and environmental goals\n                    \n                    \n                  \n                \n              \n            \n            \n          \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      During launch countdown, at approximately T-7 seconds, the Space Shuttle Main Engines (SSMEs) roar to life. When the controllers indicate normal operation, the solid rocket boosters ignite and the shuttle blasts off. Initially, the SSMEs throttle down to reduce stress during the period of maximum dynamic pressure, but soon after, they throttle up to propel the orbiter to 17,500 miles per hour. In just under 9 minutes, the three SSMEs burn over 1.6 million pounds of propellant, and temperatures inside the main combustion chamber reach 6,000 ˚F. To cool the engines, liquid hydrogen circulates through miles of tubing at -423 ˚F. \n                      From 1981to 2011, the space shuttle fleet carried crew and cargo into orbit to perform a myriad of unprecedented tasks. After 30 years and 135 missions, the feat of engineering known as the SSME boasted a 100-percent flight success rate. \n                      Partnership\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Space Shuttle Main Engine, built by Rocketdyne under contract to NASA, undergoes test firing in 1981. Marshall Space Flight Center was responsible for the shuttle’s propulsion elements, including the main engines.\n                        \n                      \n                      In the 1970s, the SSME was designed under contract to NASA by Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), a United Technologies Company based in East Hartford, Connecticut. Working with Marshall Space Flight Center, PWR developed the most efficient rocket engines in existence, with ultra-high-pressure operation of the pumps and combustion chamber, which allowed expansion of all hot gasses through a high-area-ratio exhaust nozzle.\n                      Soon after developing the highly efficient shuttle engines, PWR started creating highly efficient gasification systems. Gasification is a chemical process that converts carbon-containing materials such as coal, petcoke (a waste product from oil refineries), or biomass (organic material from plants or animals) into synthesis gas, or syngas. After the material is pulverized, it mixes with oxygen and steam at very high temperatures. The resulting syngas—comprised of carbon monoxide, hydrogen, carbon dioxide, and methane—can be burned as a fuel to create electricity, or further processed to make products such as substitute natural gas, chemicals, fertilizers, or liquid transportation fuels. \n                      “We started looking at alternate forms of energy and alternate ways of using coal during the 1970s energy crisis,” says Don Stevenson, program area manager for Clean Fossil Fueled Energy Technologies at PWR. “By applying our rocket engine expertise, we are able to increase the temperatures and pressures in a gasifier, which resulted in a much higher efficiency system.” \n                      Benefits\n                      In the 1980s, PWR built its proof-of-concept gasifier, but due to a lack of funding, the company temporarily shelved the technology. Years later, interest in the technology resurfaced, so PWR pursued new partnerships with the U.S. Department of Energy, ExxonMobil Research and Engineering, and Canada’s Alberta Innovates, to design, develop, and test the technology. By 2009, PWR had begun operating a pilot plant at the Gas Technology Institute in Des Plaines, Illinois, and in June 2011, test results established the gasifier’s successful performance and operation over a range of conditions. \n                      PWR’s experience developing rocket technology was instrumental in improving gasification technology. Stevenson says, “The result is a much more compact, efficient, and lower-cost system.”\n                      Several aspects of the compact gasification system have been influenced by the company’s experience with rocket engine design and development. The main component, however, is the rapid mix injector. “If it weren’t for the injector, which we think is the key secret ingredient, this wouldn’t be possible,” says Stevenson.\n                      PWR’s rapid mix injector allows the gasifier to mix the carbon-based material, oxygen, and steam more efficiently at higher temperatures so the reaction can happen more quickly. PWR’s experience with rocket engines, which typically run at 5,000 ˚F or more, provided the expertise needed to build a gasifier system capable of withstanding extreme temperatures. \n                      “The modeling and analysis required to understand high heat loads for rocket engines is something that we have directly applied to the gasifier. Others in the field don’t have that expertise, so they have been reluctant to go to the higher efficiencies because they can’t handle the temperatures,” says Stevenson.\n                      In addition to the smaller size, another advantage of PWR’s system is lower costs, compared to the prevailing gasifier technology. According to the company, the capital cost to build a commercial-scale compact gasification plant using PWR’s technology is estimated to be 10–20 percent less than conventional gasification plants. Another main advantage is that the system is expected to reduce carbon dioxide emissions by up to 10 percent, compared to standard gasification technologies—which are already the cleanest coal-based power systems available. For each commercial system deployed, it is equivalent to removing 50,000 cars from road.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), used its rocket engine expertise to advance gasification technology. Compared to standard gasification systems, PWR’s technology is more compact, efficient, and lower cost.\n                        \n                      \n                      These advancements hold real promise for the energy and chemical processing industries. According to the Gasification Technologies Council, worldwide gasification capacity is projected to grow 70 percent by 2015, with 80 percent of the growth occurring in Asia. In fact, PWR has already granted a license to Zero Emission Energy Plants, Inc. (ZEEP) of Katy, Texas, for commercial implementation of the compact gasifier system. “ZEEP has a unique energy plant concept, and they want to make our technology a centerpiece. They were willing to come in with an early license, and that provided some additional financial resources to support the development,” says Stevenson.\n                      In the future, PWR expects to license the technology to various national and international entities such as oil refineries, electric power, liquid fuels, and chemical plants. The next step in the commercialization efforts is to demonstrate the gasifier at a commercial scale over a long period of time. To this end, PWR is beginning to work with partners to build a commercial-scale plant in either Asia or North America. \n                      Perhaps the greatest benefits of using more efficient, cost-effective gasifiers to produce electricity, however, will be for the environment. As Stevenson says, “One of the industry’s challenges has been how to continue to use coal in an environmentally friendly way. Once gasification can be brought in as a cost-effective mechanism for a means to producing electricity, we can replace coal-fired power plants and make a huge improvement on the global emissions problem.” \n                      While the demand for energy continues to rise, coal continues to be a major source of energy, so Stevenson finds gasification of coal offers the opportunity to dramatically reduce carbon dioxide emissions into the atmosphere. By using a gasifier, the carbon dioxide can be captured much more efficiently. “Extensive research is being conducted in North America, Asia, and Europe to pump captured carbon dioxide underground and store it or use it to enhance oil recovery. There are some major pilot projects taking place to prove the technology for carbon sequestration, which will ultimately be the key enabler for near-zero emissions from these types of facilities,” he says.\n                      Stevenson suggests this type of innovation, similar to the innovation required to build the SSMEs, is what will help to meet the world’s energy and environmental goals\n                    \n                    \n                  \n                \n              \n            \n            \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      During launch countdown, at approximately T-7 seconds, the Space Shuttle Main Engines (SSMEs) roar to life. When the controllers indicate normal operation, the solid rocket boosters ignite and the shuttle blasts off. Initially, the SSMEs throttle down to reduce stress during the period of maximum dynamic pressure, but soon after, they throttle up to propel the orbiter to 17,500 miles per hour. In just under 9 minutes, the three SSMEs burn over 1.6 million pounds of propellant, and temperatures inside the main combustion chamber reach 6,000 ˚F. To cool the engines, liquid hydrogen circulates through miles of tubing at -423 ˚F. \n                      From 1981to 2011, the space shuttle fleet carried crew and cargo into orbit to perform a myriad of unprecedented tasks. After 30 years and 135 missions, the feat of engineering known as the SSME boasted a 100-percent flight success rate. \n                      Partnership\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Space Shuttle Main Engine, built by Rocketdyne under contract to NASA, undergoes test firing in 1981. Marshall Space Flight Center was responsible for the shuttle’s propulsion elements, including the main engines.\n                        \n                      \n                      In the 1970s, the SSME was designed under contract to NASA by Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), a United Technologies Company based in East Hartford, Connecticut. Working with Marshall Space Flight Center, PWR developed the most efficient rocket engines in existence, with ultra-high-pressure operation of the pumps and combustion chamber, which allowed expansion of all hot gasses through a high-area-ratio exhaust nozzle.\n                      Soon after developing the highly efficient shuttle engines, PWR started creating highly efficient gasification systems. Gasification is a chemical process that converts carbon-containing materials such as coal, petcoke (a waste product from oil refineries), or biomass (organic material from plants or animals) into synthesis gas, or syngas. After the material is pulverized, it mixes with oxygen and steam at very high temperatures. The resulting syngas—comprised of carbon monoxide, hydrogen, carbon dioxide, and methane—can be burned as a fuel to create electricity, or further processed to make products such as substitute natural gas, chemicals, fertilizers, or liquid transportation fuels. \n                      “We started looking at alternate forms of energy and alternate ways of using coal during the 1970s energy crisis,” says Don Stevenson, program area manager for Clean Fossil Fueled Energy Technologies at PWR. “By applying our rocket engine expertise, we are able to increase the temperatures and pressures in a gasifier, which resulted in a much higher efficiency system.” \n                      Benefits\n                      In the 1980s, PWR built its proof-of-concept gasifier, but due to a lack of funding, the company temporarily shelved the technology. Years later, interest in the technology resurfaced, so PWR pursued new partnerships with the U.S. Department of Energy, ExxonMobil Research and Engineering, and Canada’s Alberta Innovates, to design, develop, and test the technology. By 2009, PWR had begun operating a pilot plant at the Gas Technology Institute in Des Plaines, Illinois, and in June 2011, test results established the gasifier’s successful performance and operation over a range of conditions. \n                      PWR’s experience developing rocket technology was instrumental in improving gasification technology. Stevenson says, “The result is a much more compact, efficient, and lower-cost system.”\n                      Several aspects of the compact gasification system have been influenced by the company’s experience with rocket engine design and development. The main component, however, is the rapid mix injector. “If it weren’t for the injector, which we think is the key secret ingredient, this wouldn’t be possible,” says Stevenson.\n                      PWR’s rapid mix injector allows the gasifier to mix the carbon-based material, oxygen, and steam more efficiently at higher temperatures so the reaction can happen more quickly. PWR’s experience with rocket engines, which typically run at 5,000 ˚F or more, provided the expertise needed to build a gasifier system capable of withstanding extreme temperatures. \n                      “The modeling and analysis required to understand high heat loads for rocket engines is something that we have directly applied to the gasifier. Others in the field don’t have that expertise, so they have been reluctant to go to the higher efficiencies because they can’t handle the temperatures,” says Stevenson.\n                      In addition to the smaller size, another advantage of PWR’s system is lower costs, compared to the prevailing gasifier technology. According to the company, the capital cost to build a commercial-scale compact gasification plant using PWR’s technology is estimated to be 10–20 percent less than conventional gasification plants. Another main advantage is that the system is expected to reduce carbon dioxide emissions by up to 10 percent, compared to standard gasification technologies—which are already the cleanest coal-based power systems available. For each commercial system deployed, it is equivalent to removing 50,000 cars from road.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), used its rocket engine expertise to advance gasification technology. Compared to standard gasification systems, PWR’s technology is more compact, efficient, and lower cost.\n                        \n                      \n                      These advancements hold real promise for the energy and chemical processing industries. According to the Gasification Technologies Council, worldwide gasification capacity is projected to grow 70 percent by 2015, with 80 percent of the growth occurring in Asia. In fact, PWR has already granted a license to Zero Emission Energy Plants, Inc. (ZEEP) of Katy, Texas, for commercial implementation of the compact gasifier system. “ZEEP has a unique energy plant concept, and they want to make our technology a centerpiece. They were willing to come in with an early license, and that provided some additional financial resources to support the development,” says Stevenson.\n                      In the future, PWR expects to license the technology to various national and international entities such as oil refineries, electric power, liquid fuels, and chemical plants. The next step in the commercialization efforts is to demonstrate the gasifier at a commercial scale over a long period of time. To this end, PWR is beginning to work with partners to build a commercial-scale plant in either Asia or North America. \n                      Perhaps the greatest benefits of using more efficient, cost-effective gasifiers to produce electricity, however, will be for the environment. As Stevenson says, “One of the industry’s challenges has been how to continue to use coal in an environmentally friendly way. Once gasification can be brought in as a cost-effective mechanism for a means to producing electricity, we can replace coal-fired power plants and make a huge improvement on the global emissions problem.” \n                      While the demand for energy continues to rise, coal continues to be a major source of energy, so Stevenson finds gasification of coal offers the opportunity to dramatically reduce carbon dioxide emissions into the atmosphere. By using a gasifier, the carbon dioxide can be captured much more efficiently. “Extensive research is being conducted in North America, Asia, and Europe to pump captured carbon dioxide underground and store it or use it to enhance oil recovery. There are some major pilot projects taking place to prove the technology for carbon sequestration, which will ultimately be the key enabler for near-zero emissions from these types of facilities,” he says.\n                      Stevenson suggests this type of innovation, similar to the innovation required to build the SSMEs, is what will help to meet the world’s energy and environmental goals\n                    \n                    \n                  \n                \n              \n            \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      During launch countdown, at approximately T-7 seconds, the Space Shuttle Main Engines (SSMEs) roar to life. When the controllers indicate normal operation, the solid rocket boosters ignite and the shuttle blasts off. Initially, the SSMEs throttle down to reduce stress during the period of maximum dynamic pressure, but soon after, they throttle up to propel the orbiter to 17,500 miles per hour. In just under 9 minutes, the three SSMEs burn over 1.6 million pounds of propellant, and temperatures inside the main combustion chamber reach 6,000 ˚F. To cool the engines, liquid hydrogen circulates through miles of tubing at -423 ˚F. \n                      From 1981to 2011, the space shuttle fleet carried crew and cargo into orbit to perform a myriad of unprecedented tasks. After 30 years and 135 missions, the feat of engineering known as the SSME boasted a 100-percent flight success rate. \n                      Partnership\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Space Shuttle Main Engine, built by Rocketdyne under contract to NASA, undergoes test firing in 1981. Marshall Space Flight Center was responsible for the shuttle’s propulsion elements, including the main engines.\n                        \n                      \n                      In the 1970s, the SSME was designed under contract to NASA by Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), a United Technologies Company based in East Hartford, Connecticut. Working with Marshall Space Flight Center, PWR developed the most efficient rocket engines in existence, with ultra-high-pressure operation of the pumps and combustion chamber, which allowed expansion of all hot gasses through a high-area-ratio exhaust nozzle.\n                      Soon after developing the highly efficient shuttle engines, PWR started creating highly efficient gasification systems. Gasification is a chemical process that converts carbon-containing materials such as coal, petcoke (a waste product from oil refineries), or biomass (organic material from plants or animals) into synthesis gas, or syngas. After the material is pulverized, it mixes with oxygen and steam at very high temperatures. The resulting syngas—comprised of carbon monoxide, hydrogen, carbon dioxide, and methane—can be burned as a fuel to create electricity, or further processed to make products such as substitute natural gas, chemicals, fertilizers, or liquid transportation fuels. \n                      “We started looking at alternate forms of energy and alternate ways of using coal during the 1970s energy crisis,” says Don Stevenson, program area manager for Clean Fossil Fueled Energy Technologies at PWR. “By applying our rocket engine expertise, we are able to increase the temperatures and pressures in a gasifier, which resulted in a much higher efficiency system.” \n                      Benefits\n                      In the 1980s, PWR built its proof-of-concept gasifier, but due to a lack of funding, the company temporarily shelved the technology. Years later, interest in the technology resurfaced, so PWR pursued new partnerships with the U.S. Department of Energy, ExxonMobil Research and Engineering, and Canada’s Alberta Innovates, to design, develop, and test the technology. By 2009, PWR had begun operating a pilot plant at the Gas Technology Institute in Des Plaines, Illinois, and in June 2011, test results established the gasifier’s successful performance and operation over a range of conditions. \n                      PWR’s experience developing rocket technology was instrumental in improving gasification technology. Stevenson says, “The result is a much more compact, efficient, and lower-cost system.”\n                      Several aspects of the compact gasification system have been influenced by the company’s experience with rocket engine design and development. The main component, however, is the rapid mix injector. “If it weren’t for the injector, which we think is the key secret ingredient, this wouldn’t be possible,” says Stevenson.\n                      PWR’s rapid mix injector allows the gasifier to mix the carbon-based material, oxygen, and steam more efficiently at higher temperatures so the reaction can happen more quickly. PWR’s experience with rocket engines, which typically run at 5,000 ˚F or more, provided the expertise needed to build a gasifier system capable of withstanding extreme temperatures. \n                      “The modeling and analysis required to understand high heat loads for rocket engines is something that we have directly applied to the gasifier. Others in the field don’t have that expertise, so they have been reluctant to go to the higher efficiencies because they can’t handle the temperatures,” says Stevenson.\n                      In addition to the smaller size, another advantage of PWR’s system is lower costs, compared to the prevailing gasifier technology. According to the company, the capital cost to build a commercial-scale compact gasification plant using PWR’s technology is estimated to be 10–20 percent less than conventional gasification plants. Another main advantage is that the system is expected to reduce carbon dioxide emissions by up to 10 percent, compared to standard gasification technologies—which are already the cleanest coal-based power systems available. For each commercial system deployed, it is equivalent to removing 50,000 cars from road.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), used its rocket engine expertise to advance gasification technology. Compared to standard gasification systems, PWR’s technology is more compact, efficient, and lower cost.\n                        \n                      \n                      These advancements hold real promise for the energy and chemical processing industries. According to the Gasification Technologies Council, worldwide gasification capacity is projected to grow 70 percent by 2015, with 80 percent of the growth occurring in Asia. In fact, PWR has already granted a license to Zero Emission Energy Plants, Inc. (ZEEP) of Katy, Texas, for commercial implementation of the compact gasifier system. “ZEEP has a unique energy plant concept, and they want to make our technology a centerpiece. They were willing to come in with an early license, and that provided some additional financial resources to support the development,” says Stevenson.\n                      In the future, PWR expects to license the technology to various national and international entities such as oil refineries, electric power, liquid fuels, and chemical plants. The next step in the commercialization efforts is to demonstrate the gasifier at a commercial scale over a long period of time. To this end, PWR is beginning to work with partners to build a commercial-scale plant in either Asia or North America. \n                      Perhaps the greatest benefits of using more efficient, cost-effective gasifiers to produce electricity, however, will be for the environment. As Stevenson says, “One of the industry’s challenges has been how to continue to use coal in an environmentally friendly way. Once gasification can be brought in as a cost-effective mechanism for a means to producing electricity, we can replace coal-fired power plants and make a huge improvement on the global emissions problem.” \n                      While the demand for energy continues to rise, coal continues to be a major source of energy, so Stevenson finds gasification of coal offers the opportunity to dramatically reduce carbon dioxide emissions into the atmosphere. By using a gasifier, the carbon dioxide can be captured much more efficiently. “Extensive research is being conducted in North America, Asia, and Europe to pump captured carbon dioxide underground and store it or use it to enhance oil recovery. There are some major pilot projects taking place to prove the technology for carbon sequestration, which will ultimately be the key enabler for near-zero emissions from these types of facilities,” he says.\n                      Stevenson suggests this type of innovation, similar to the innovation required to build the SSMEs, is what will help to meet the world’s energy and environmental goals\n                    \n                    \n                  \n                \n              \n                  \n                    \n                      NASA Technology\n                      During launch countdown, at approximately T-7 seconds, the Space Shuttle Main Engines (SSMEs) roar to life. When the controllers indicate normal operation, the solid rocket boosters ignite and the shuttle blasts off. Initially, the SSMEs throttle down to reduce stress during the period of maximum dynamic pressure, but soon after, they throttle up to propel the orbiter to 17,500 miles per hour. In just under 9 minutes, the three SSMEs burn over 1.6 million pounds of propellant, and temperatures inside the main combustion chamber reach 6,000 ˚F. To cool the engines, liquid hydrogen circulates through miles of tubing at -423 ˚F. \n                      From 1981to 2011, the space shuttle fleet carried crew and cargo into orbit to perform a myriad of unprecedented tasks. After 30 years and 135 missions, the feat of engineering known as the SSME boasted a 100-percent flight success rate. \n                      Partnership\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Space Shuttle Main Engine, built by Rocketdyne under contract to NASA, undergoes test firing in 1981. Marshall Space Flight Center was responsible for the shuttle’s propulsion elements, including the main engines.\n                        \n                      \n                      In the 1970s, the SSME was designed under contract to NASA by Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), a United Technologies Company based in East Hartford, Connecticut. Working with Marshall Space Flight Center, PWR developed the most efficient rocket engines in existence, with ultra-high-pressure operation of the pumps and combustion chamber, which allowed expansion of all hot gasses through a high-area-ratio exhaust nozzle.\n                      Soon after developing the highly efficient shuttle engines, PWR started creating highly efficient gasification systems. Gasification is a chemical process that converts carbon-containing materials such as coal, petcoke (a waste product from oil refineries), or biomass (organic material from plants or animals) into synthesis gas, or syngas. After the material is pulverized, it mixes with oxygen and steam at very high temperatures. The resulting syngas—comprised of carbon monoxide, hydrogen, carbon dioxide, and methane—can be burned as a fuel to create electricity, or further processed to make products such as substitute natural gas, chemicals, fertilizers, or liquid transportation fuels. \n                      “We started looking at alternate forms of energy and alternate ways of using coal during the 1970s energy crisis,” says Don Stevenson, program area manager for Clean Fossil Fueled Energy Technologies at PWR. “By applying our rocket engine expertise, we are able to increase the temperatures and pressures in a gasifier, which resulted in a much higher efficiency system.” \n                      Benefits\n                      In the 1980s, PWR built its proof-of-concept gasifier, but due to a lack of funding, the company temporarily shelved the technology. Years later, interest in the technology resurfaced, so PWR pursued new partnerships with the U.S. Department of Energy, ExxonMobil Research and Engineering, and Canada’s Alberta Innovates, to design, develop, and test the technology. By 2009, PWR had begun operating a pilot plant at the Gas Technology Institute in Des Plaines, Illinois, and in June 2011, test results established the gasifier’s successful performance and operation over a range of conditions. \n                      PWR’s experience developing rocket technology was instrumental in improving gasification technology. Stevenson says, “The result is a much more compact, efficient, and lower-cost system.”\n                      Several aspects of the compact gasification system have been influenced by the company’s experience with rocket engine design and development. The main component, however, is the rapid mix injector. “If it weren’t for the injector, which we think is the key secret ingredient, this wouldn’t be possible,” says Stevenson.\n                      PWR’s rapid mix injector allows the gasifier to mix the carbon-based material, oxygen, and steam more efficiently at higher temperatures so the reaction can happen more quickly. PWR’s experience with rocket engines, which typically run at 5,000 ˚F or more, provided the expertise needed to build a gasifier system capable of withstanding extreme temperatures. \n                      “The modeling and analysis required to understand high heat loads for rocket engines is something that we have directly applied to the gasifier. Others in the field don’t have that expertise, so they have been reluctant to go to the higher efficiencies because they can’t handle the temperatures,” says Stevenson.\n                      In addition to the smaller size, another advantage of PWR’s system is lower costs, compared to the prevailing gasifier technology. According to the company, the capital cost to build a commercial-scale compact gasification plant using PWR’s technology is estimated to be 10–20 percent less than conventional gasification plants. Another main advantage is that the system is expected to reduce carbon dioxide emissions by up to 10 percent, compared to standard gasification technologies—which are already the cleanest coal-based power systems available. For each commercial system deployed, it is equivalent to removing 50,000 cars from road.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), used its rocket engine expertise to advance gasification technology. Compared to standard gasification systems, PWR’s technology is more compact, efficient, and lower cost.\n                        \n                      \n                      These advancements hold real promise for the energy and chemical processing industries. According to the Gasification Technologies Council, worldwide gasification capacity is projected to grow 70 percent by 2015, with 80 percent of the growth occurring in Asia. In fact, PWR has already granted a license to Zero Emission Energy Plants, Inc. (ZEEP) of Katy, Texas, for commercial implementation of the compact gasifier system. “ZEEP has a unique energy plant concept, and they want to make our technology a centerpiece. They were willing to come in with an early license, and that provided some additional financial resources to support the development,” says Stevenson.\n                      In the future, PWR expects to license the technology to various national and international entities such as oil refineries, electric power, liquid fuels, and chemical plants. The next step in the commercialization efforts is to demonstrate the gasifier at a commercial scale over a long period of time. To this end, PWR is beginning to work with partners to build a commercial-scale plant in either Asia or North America. \n                      Perhaps the greatest benefits of using more efficient, cost-effective gasifiers to produce electricity, however, will be for the environment. As Stevenson says, “One of the industry’s challenges has been how to continue to use coal in an environmentally friendly way. Once gasification can be brought in as a cost-effective mechanism for a means to producing electricity, we can replace coal-fired power plants and make a huge improvement on the global emissions problem.” \n                      While the demand for energy continues to rise, coal continues to be a major source of energy, so Stevenson finds gasification of coal offers the opportunity to dramatically reduce carbon dioxide emissions into the atmosphere. By using a gasifier, the carbon dioxide can be captured much more efficiently. “Extensive research is being conducted in North America, Asia, and Europe to pump captured carbon dioxide underground and store it or use it to enhance oil recovery. There are some major pilot projects taking place to prove the technology for carbon sequestration, which will ultimately be the key enabler for near-zero emissions from these types of facilities,” he says.\n                      Stevenson suggests this type of innovation, similar to the innovation required to build the SSMEs, is what will help to meet the world’s energy and environmental goals\n                    \n                    \n                  \n                    \n                      NASA Technology\n                      During launch countdown, at approximately T-7 seconds, the Space Shuttle Main Engines (SSMEs) roar to life. When the controllers indicate normal operation, the solid rocket boosters ignite and the shuttle blasts off. Initially, the SSMEs throttle down to reduce stress during the period of maximum dynamic pressure, but soon after, they throttle up to propel the orbiter to 17,500 miles per hour. In just under 9 minutes, the three SSMEs burn over 1.6 million pounds of propellant, and temperatures inside the main combustion chamber reach 6,000 ˚F. To cool the engines, liquid hydrogen circulates through miles of tubing at -423 ˚F. \n                      From 1981to 2011, the space shuttle fleet carried crew and cargo into orbit to perform a myriad of unprecedented tasks. After 30 years and 135 missions, the feat of engineering known as the SSME boasted a 100-percent flight success rate. \n                      Partnership\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Space Shuttle Main Engine, built by Rocketdyne under contract to NASA, undergoes test firing in 1981. Marshall Space Flight Center was responsible for the shuttle’s propulsion elements, including the main engines.\n                        \n                      \n                      In the 1970s, the SSME was designed under contract to NASA by Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), a United Technologies Company based in East Hartford, Connecticut. Working with Marshall Space Flight Center, PWR developed the most efficient rocket engines in existence, with ultra-high-pressure operation of the pumps and combustion chamber, which allowed expansion of all hot gasses through a high-area-ratio exhaust nozzle.\n                      Soon after developing the highly efficient shuttle engines, PWR started creating highly efficient gasification systems. Gasification is a chemical process that converts carbon-containing materials such as coal, petcoke (a waste product from oil refineries), or biomass (organic material from plants or animals) into synthesis gas, or syngas. After the material is pulverized, it mixes with oxygen and steam at very high temperatures. The resulting syngas—comprised of carbon monoxide, hydrogen, carbon dioxide, and methane—can be burned as a fuel to create electricity, or further processed to make products such as substitute natural gas, chemicals, fertilizers, or liquid transportation fuels. \n                      “We started looking at alternate forms of energy and alternate ways of using coal during the 1970s energy crisis,” says Don Stevenson, program area manager for Clean Fossil Fueled Energy Technologies at PWR. “By applying our rocket engine expertise, we are able to increase the temperatures and pressures in a gasifier, which resulted in a much higher efficiency system.” \n                      Benefits\n                      In the 1980s, PWR built its proof-of-concept gasifier, but due to a lack of funding, the company temporarily shelved the technology. Years later, interest in the technology resurfaced, so PWR pursued new partnerships with the U.S. Department of Energy, ExxonMobil Research and Engineering, and Canada’s Alberta Innovates, to design, develop, and test the technology. By 2009, PWR had begun operating a pilot plant at the Gas Technology Institute in Des Plaines, Illinois, and in June 2011, test results established the gasifier’s successful performance and operation over a range of conditions. \n                      PWR’s experience developing rocket technology was instrumental in improving gasification technology. Stevenson says, “The result is a much more compact, efficient, and lower-cost system.”\n                      Several aspects of the compact gasification system have been influenced by the company’s experience with rocket engine design and development. The main component, however, is the rapid mix injector. “If it weren’t for the injector, which we think is the key secret ingredient, this wouldn’t be possible,” says Stevenson.\n                      PWR’s rapid mix injector allows the gasifier to mix the carbon-based material, oxygen, and steam more efficiently at higher temperatures so the reaction can happen more quickly. PWR’s experience with rocket engines, which typically run at 5,000 ˚F or more, provided the expertise needed to build a gasifier system capable of withstanding extreme temperatures. \n                      “The modeling and analysis required to understand high heat loads for rocket engines is something that we have directly applied to the gasifier. Others in the field don’t have that expertise, so they have been reluctant to go to the higher efficiencies because they can’t handle the temperatures,” says Stevenson.\n                      In addition to the smaller size, another advantage of PWR’s system is lower costs, compared to the prevailing gasifier technology. According to the company, the capital cost to build a commercial-scale compact gasification plant using PWR’s technology is estimated to be 10–20 percent less than conventional gasification plants. Another main advantage is that the system is expected to reduce carbon dioxide emissions by up to 10 percent, compared to standard gasification technologies—which are already the cleanest coal-based power systems available. For each commercial system deployed, it is equivalent to removing 50,000 cars from road.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), used its rocket engine expertise to advance gasification technology. Compared to standard gasification systems, PWR’s technology is more compact, efficient, and lower cost.\n                        \n                      \n                      These advancements hold real promise for the energy and chemical processing industries. According to the Gasification Technologies Council, worldwide gasification capacity is projected to grow 70 percent by 2015, with 80 percent of the growth occurring in Asia. In fact, PWR has already granted a license to Zero Emission Energy Plants, Inc. (ZEEP) of Katy, Texas, for commercial implementation of the compact gasifier system. “ZEEP has a unique energy plant concept, and they want to make our technology a centerpiece. They were willing to come in with an early license, and that provided some additional financial resources to support the development,” says Stevenson.\n                      In the future, PWR expects to license the technology to various national and international entities such as oil refineries, electric power, liquid fuels, and chemical plants. The next step in the commercialization efforts is to demonstrate the gasifier at a commercial scale over a long period of time. To this end, PWR is beginning to work with partners to build a commercial-scale plant in either Asia or North America. \n                      Perhaps the greatest benefits of using more efficient, cost-effective gasifiers to produce electricity, however, will be for the environment. As Stevenson says, “One of the industry’s challenges has been how to continue to use coal in an environmentally friendly way. Once gasification can be brought in as a cost-effective mechanism for a means to producing electricity, we can replace coal-fired power plants and make a huge improvement on the global emissions problem.” \n                      While the demand for energy continues to rise, coal continues to be a major source of energy, so Stevenson finds gasification of coal offers the opportunity to dramatically reduce carbon dioxide emissions into the atmosphere. By using a gasifier, the carbon dioxide can be captured much more efficiently. “Extensive research is being conducted in North America, Asia, and Europe to pump captured carbon dioxide underground and store it or use it to enhance oil recovery. There are some major pilot projects taking place to prove the technology for carbon sequestration, which will ultimately be the key enabler for near-zero emissions from these types of facilities,” he says.\n                      Stevenson suggests this type of innovation, similar to the innovation required to build the SSMEs, is what will help to meet the world’s energy and environmental goals\n                    \n                    \n                      NASA Technology\n                      During launch countdown, at approximately T-7 seconds, the Space Shuttle Main Engines (SSMEs) roar to life. When the controllers indicate normal operation, the solid rocket boosters ignite and the shuttle blasts off. Initially, the SSMEs throttle down to reduce stress during the period of maximum dynamic pressure, but soon after, they throttle up to propel the orbiter to 17,500 miles per hour. In just under 9 minutes, the three SSMEs burn over 1.6 million pounds of propellant, and temperatures inside the main combustion chamber reach 6,000 ˚F. To cool the engines, liquid hydrogen circulates through miles of tubing at -423 ˚F. \n                      From 1981to 2011, the space shuttle fleet carried crew and cargo into orbit to perform a myriad of unprecedented tasks. After 30 years and 135 missions, the feat of engineering known as the SSME boasted a 100-percent flight success rate. \n                      Partnership\n                      \n                        \n                        \n                          \n                        \n                        \n                          A Space Shuttle Main Engine, built by Rocketdyne under contract to NASA, undergoes test firing in 1981. Marshall Space Flight Center was responsible for the shuttle’s propulsion elements, including the main engines.\n                        \n                      \n                      In the 1970s, the SSME was designed under contract to NASA by Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), a United Technologies Company based in East Hartford, Connecticut. Working with Marshall Space Flight Center, PWR developed the most efficient rocket engines in existence, with ultra-high-pressure operation of the pumps and combustion chamber, which allowed expansion of all hot gasses through a high-area-ratio exhaust nozzle.\n                      Soon after developing the highly efficient shuttle engines, PWR started creating highly efficient gasification systems. Gasification is a chemical process that converts carbon-containing materials such as coal, petcoke (a waste product from oil refineries), or biomass (organic material from plants or animals) into synthesis gas, or syngas. After the material is pulverized, it mixes with oxygen and steam at very high temperatures. The resulting syngas—comprised of carbon monoxide, hydrogen, carbon dioxide, and methane—can be burned as a fuel to create electricity, or further processed to make products such as substitute natural gas, chemicals, fertilizers, or liquid transportation fuels. \n                      “We started looking at alternate forms of energy and alternate ways of using coal during the 1970s energy crisis,” says Don Stevenson, program area manager for Clean Fossil Fueled Energy Technologies at PWR. “By applying our rocket engine expertise, we are able to increase the temperatures and pressures in a gasifier, which resulted in a much higher efficiency system.” \n                      Benefits\n                      In the 1980s, PWR built its proof-of-concept gasifier, but due to a lack of funding, the company temporarily shelved the technology. Years later, interest in the technology resurfaced, so PWR pursued new partnerships with the U.S. Department of Energy, ExxonMobil Research and Engineering, and Canada’s Alberta Innovates, to design, develop, and test the technology. By 2009, PWR had begun operating a pilot plant at the Gas Technology Institute in Des Plaines, Illinois, and in June 2011, test results established the gasifier’s successful performance and operation over a range of conditions. \n                      PWR’s experience developing rocket technology was instrumental in improving gasification technology. Stevenson says, “The result is a much more compact, efficient, and lower-cost system.”\n                      Several aspects of the compact gasification system have been influenced by the company’s experience with rocket engine design and development. The main component, however, is the rapid mix injector. “If it weren’t for the injector, which we think is the key secret ingredient, this wouldn’t be possible,” says Stevenson.\n                      PWR’s rapid mix injector allows the gasifier to mix the carbon-based material, oxygen, and steam more efficiently at higher temperatures so the reaction can happen more quickly. PWR’s experience with rocket engines, which typically run at 5,000 ˚F or more, provided the expertise needed to build a gasifier system capable of withstanding extreme temperatures. \n                      “The modeling and analysis required to understand high heat loads for rocket engines is something that we have directly applied to the gasifier. Others in the field don’t have that expertise, so they have been reluctant to go to the higher efficiencies because they can’t handle the temperatures,” says Stevenson.\n                      In addition to the smaller size, another advantage of PWR’s system is lower costs, compared to the prevailing gasifier technology. According to the company, the capital cost to build a commercial-scale compact gasification plant using PWR’s technology is estimated to be 10–20 percent less than conventional gasification plants. Another main advantage is that the system is expected to reduce carbon dioxide emissions by up to 10 percent, compared to standard gasification technologies—which are already the cleanest coal-based power systems available. For each commercial system deployed, it is equivalent to removing 50,000 cars from road.\n                      \n                        \n                        \n                          \n                        \n                        \n                          Rocketdyne, now part of Pratt & Whitney Rocketdyne (PWR), used its rocket engine expertise to advance gasification technology. Compared to standard gasification systems, PWR’s technology is more compact, efficient, and lower cost.\n                        \n                      \n                      These advancements hold real promise for the energy and chemical processing industries. According to the Gasification Technologies Council, worldwide gasification capacity is projected to grow 70 percent by 2015, with 80 percent of the growth occurring in Asia. In fact, PWR has already granted a license to Zero Emission Energy Plants, Inc. (ZEEP) of Katy, Texas, for commercial implementation of the compact gasifier system. “ZEEP has a unique energy plant concept, and they want to make our technology a centerpiece. They were willing to come in with an early license, and that provided some additional financial resources to support the development,” says Stevenson.\n                      In the future, PWR expects to license the technology to various national and international entities such as oil refineries, electric power, liquid fuels, and chemical plants. The next step in the commercialization efforts is to demonstrate the gasifier at a commercial scale over a long period of time. To this end, PWR is beginning to work with partners to build a commercial-scale plant in either Asia or North America. \n                      Perhaps the greatest benefits of using more efficient, cost-effective gasifiers to produce electricity, however, will be for the environment. As Stevenson says, “One of the industry’s challenges has been how to continue to use coal in an environmentally friendly way. Once gasification can be brought in as a cost-effective mechanism for a means to producing electricity, we can replace coal-fired power plants and make a huge improvement on the global emissions problem.” \n                      While the demand for energy continues to rise, coal continues to be a major source of energy, so Stevenson finds gasification of coal offers the opportunity to dramatically reduce carbon dioxide emissions into the atmosphere. By using a gasifier, the carbon dioxide can be captured much more efficiently. “Extensive research is being conducted in North America, Asia, and Europe to pump captured carbon dioxide underground and store it or use it to enhance oil recovery. There are some major pilot projects taking place to prove the technology for carbon sequestration, which will ultimately be the key enabler for near-zero emissions from these types of facilities,” he says.\n                      Stevenson suggests this type of innovation, similar to the innovation required to build the SSMEs, is what will help to meet the world’s energy and environmental goals\n                    "},{"href":"http://spinoff.nasa.gov/Spinoff2011/it_1.html","text":"Technologies Render Views of Earth for Virtual Navigation","image":"http://spinoff.nasa.gov/Spinoff2011/Images/it_1a_opt.jpg","story":"\n    \n      \n        NASA Technology\n        On a December night in 1995, 159 passengers and crew members died when American Airlines Flight 965 flew into the side of a mountain while in route to Cali, Colombia. A key factor in the tragedy: The pilots had lost situational awareness in the dark, unfamiliar terrain. They had no idea the plane was approaching a mountain until the ground proximity warning system sounded an alarm only seconds before impact. \n        \n          \n          \n            \n          \n          \n            Synthetic vision enhances pilots’ situational awareness—even in poor visibility conditions—by providing a graphical display of the terrain outside the cockpit, as in this TerraBlocks-enabled example.\n          \n        \n        The accident was of the kind most common at the time—CFIT, or controlled flight into terrain—says Trey Arthur, research aerospace engineer in the Crew Systems and Aviation Operations Branch at NASA’s Langley Research Center. In situations such as bad weather, fog, or nighttime flights, pilots would rely on airspeed, altitude, and other readings to get an accurate sense of location. Miscalculations and rapidly changing conditions could contribute to a fully functioning, in-control airplane flying into the ground. \n        To improve aviation safety by enhancing pilots’ situational awareness even in poor visibility, NASA began exploring the possibilities of synthetic vision—creating a graphical display of the outside terrain on a screen inside the cockpit. \n        “How do you display a mountain in the cockpit? You have to have a graphics-powered computer, a terrain database you can render, and an accurate navigation solution,” says Arthur.\n        In the mid-1990s, developing GPS technology offered a means for determining an aircraft’s position in space with high accuracy, Arthur explains. As the necessary technologies to enable synthetic vision emerged, NASA turned to an industry partner to develop the terrain graphical engine and database for creating the virtual rendering of the outside environment. \n        “Partnering with NASA has allowed us to \n          understand where the future is headed and \n          apply our innovation and technologies \n          in that direction.”\n          \n          —Greg Baxes, TerraMetrics\n        \n        Partnership\n          In 2003, Langley partnered with TerraMetrics Inc. of Littleton, Colorado, through the Small Business Innovation Research (SBIR) program to develop a 3D terrain rendering technology for flight-qualified synthetic vision systems. The company’s innovative solution, called TerraBlocks, rendered satellite imagery on top of terrain data to provide the pilot with a virtual view of the environment outside the cockpit window. This kind of rendering vastly improved on typical flat-earth displays by mapping the terrain in three dimensions on a model of the Earth’s sphere. The resulting visualization was not only more realistic, but also highly accurate. \n          To produce its visuals, TerraBlocks needed satellite imagery and terrain data. For the imagery, the company worked with the Scientific Data Purchase program at Stennis Space Center to locate the data it needed, using an archive from NASA’s Earth-observing Landsat 7 satellite that proved suitable for use in TerraBlocks. TerraMetrics chose NASA’s Shuttle Radar Topography Mission (SRTM) terrain data to provide the 3D element. Since then, NASA has used the TerraBlocks engine for multiple experiments with flight simulators for aircraft and even lunar lander vehicles, the latter using a graphical rendering of the Moon the company created. The lander tests demonstrated the potential for synthetic vision on spacecraft.\n          “If we do manned missions to asteroids or other destinations, all we need is the data and a good navigational system, and we can essentially draw that world for the pilot,” Arthur says.\n          Through the combined collaboration with the NASA centers, TerraMetrics has developed its NASA-derived innovations into products for helping pilots navigate more safely in the skies, as well as for assisting people in finding their way on the ground.\n          Benefits\n          TerraMetrics now markets its TruEarth satellite imagery and terrain data product line—incorporating the NASA source data from Stennis along with other NASA satellite sources—coupled with its SBIR-developed TerraBlocks terrain-rendering and display engine. \n          “TruEarth was developed in partnership with NASA,” says Greg Baxes, president of TerraMetrics. “Our goal was to use that data in TerraBlocks, but it also has standalone commercial viability.” \n          \n        \n          \n          \n            \n          \n          \n            The highly accurate 3D-rendering capabilities of the TerraBlocks engine are demonstrated in this exo-centric aircraft view near Mt. Fuji, Japan, generated for an in-flight entertainment application. \n          \n        \n        \n        The company offers TruEarth in 1-kilometer and 15-meter collections. (The measurements indicate the approximate area covered by each pixel in the imagery. In the 15-meter product, for example, each pixel covers an area 15 meters by 15 meters.) The company verifies the accuracy of the data and processes the original source imagery into its TruEarth natural color form to accurately reflect the appearance of the Earth’s surface. \n        While the TruEarth products have been used extensively in flight simulation and even in movies, television, and animation, most everyday users of the technology encounter it online: The TruEarth 15-meter collection forms the base layer for Google Earth. The imagery is used for views on Google Earth and Google Maps ranging from the global level all the way down to the detail seen when flying about 20,000 feet above the Earth; at greater magnifications, other imagery and data from Google vendors are laid over the TruEarth imagery to reveal details like buildings and roads. \n        While TruEarth helps Google by providing the global map many use to determine directions or just for virtual exploration, the imagery also can be combined with terrain elevation data and used in the TerraBlocks engine for flight deck displays. This requires a critical level of accuracy that goes beyond that of online mapping programs. “The terrain can’t just look pretty,” says Baxes, “it has to be displayed precisely and with absolute global positional accuracy relative to the aircraft.” \n        TerraBlocks is unique in its field, Baxes explains. “As far as a photorealistic rendering of the Earth in a flight application, TerraBlocks stands on its own,” he says. The technology utilizes a compression technique and terrain-block-based processing methodology that stores worldwide satellite imagery and terrain data in a compact, multiresolution form—reducing information that can exceed 4 terabytes down to more manageable sizes—while still allowing real-time access to the data by the TerraBlocks engine during flight. TerraMetrics has two patents on the technology, which is now in use for flight simulation applications as the company works to expand the innovation into commercial avionics, along with smartphones and tablets, using its embedded version of the TerraBlocks engine. \n        Baxes says TerraMetrics’ NASA partnerships have yielded significant benefits. \n        “NASA has the charter to look way into the future. Partnering with NASA has allowed us to understand where the future is headed and apply our innovation and technologies in that direction,” he says. “The seed money that we were able to apply to our research and development will pay vast dividends as far as meeting general public and commercial sector needs.”\n        The company has also worked on another SBIR project with Stennis to enable refinement and optimization of the processing means for overlaying scientific data on 3D geospatial browsers like Google Earth, allowing visualizations useful for everything from climate change research to emergency management. And with the help of TerraMetrics’ NASA-derived technology, the Agency continues to explore the future of flight displays. Arthur notes technologies like enhanced vision—combining synthetic vision with an array of sensors to provide comprehensive situational awareness—which could enable advances like windowless supersonic aircraft. Such possibilities are not unrealistic, Arthur says.\n        “You just never know how these things might spin-off,” he says. “Fifteen years ago, would anyone have envisioned having the Earth on your smartphone in your pocket?”\n        TerraBlocks™ is a trademark of TerraMetrics Inc.\n        TruEarth® is a registered trademark of TerraMetrics Inc\n        \n      \n    \n      \n        NASA Technology\n        On a December night in 1995, 159 passengers and crew members died when American Airlines Flight 965 flew into the side of a mountain while in route to Cali, Colombia. A key factor in the tragedy: The pilots had lost situational awareness in the dark, unfamiliar terrain. They had no idea the plane was approaching a mountain until the ground proximity warning system sounded an alarm only seconds before impact. \n        \n          \n          \n            \n          \n          \n            Synthetic vision enhances pilots’ situational awareness—even in poor visibility conditions—by providing a graphical display of the terrain outside the cockpit, as in this TerraBlocks-enabled example.\n          \n        \n        The accident was of the kind most common at the time—CFIT, or controlled flight into terrain—says Trey Arthur, research aerospace engineer in the Crew Systems and Aviation Operations Branch at NASA’s Langley Research Center. In situations such as bad weather, fog, or nighttime flights, pilots would rely on airspeed, altitude, and other readings to get an accurate sense of location. Miscalculations and rapidly changing conditions could contribute to a fully functioning, in-control airplane flying into the ground. \n        To improve aviation safety by enhancing pilots’ situational awareness even in poor visibility, NASA began exploring the possibilities of synthetic vision—creating a graphical display of the outside terrain on a screen inside the cockpit. \n        “How do you display a mountain in the cockpit? You have to have a graphics-powered computer, a terrain database you can render, and an accurate navigation solution,” says Arthur.\n        In the mid-1990s, developing GPS technology offered a means for determining an aircraft’s position in space with high accuracy, Arthur explains. As the necessary technologies to enable synthetic vision emerged, NASA turned to an industry partner to develop the terrain graphical engine and database for creating the virtual rendering of the outside environment. \n        “Partnering with NASA has allowed us to \n          understand where the future is headed and \n          apply our innovation and technologies \n          in that direction.”\n          \n          —Greg Baxes, TerraMetrics\n        \n        Partnership\n          In 2003, Langley partnered with TerraMetrics Inc. of Littleton, Colorado, through the Small Business Innovation Research (SBIR) program to develop a 3D terrain rendering technology for flight-qualified synthetic vision systems. The company’s innovative solution, called TerraBlocks, rendered satellite imagery on top of terrain data to provide the pilot with a virtual view of the environment outside the cockpit window. This kind of rendering vastly improved on typical flat-earth displays by mapping the terrain in three dimensions on a model of the Earth’s sphere. The resulting visualization was not only more realistic, but also highly accurate. \n          To produce its visuals, TerraBlocks needed satellite imagery and terrain data. For the imagery, the company worked with the Scientific Data Purchase program at Stennis Space Center to locate the data it needed, using an archive from NASA’s Earth-observing Landsat 7 satellite that proved suitable for use in TerraBlocks. TerraMetrics chose NASA’s Shuttle Radar Topography Mission (SRTM) terrain data to provide the 3D element. Since then, NASA has used the TerraBlocks engine for multiple experiments with flight simulators for aircraft and even lunar lander vehicles, the latter using a graphical rendering of the Moon the company created. The lander tests demonstrated the potential for synthetic vision on spacecraft.\n          “If we do manned missions to asteroids or other destinations, all we need is the data and a good navigational system, and we can essentially draw that world for the pilot,” Arthur says.\n          Through the combined collaboration with the NASA centers, TerraMetrics has developed its NASA-derived innovations into products for helping pilots navigate more safely in the skies, as well as for assisting people in finding their way on the ground.\n          Benefits\n          TerraMetrics now markets its TruEarth satellite imagery and terrain data product line—incorporating the NASA source data from Stennis along with other NASA satellite sources—coupled with its SBIR-developed TerraBlocks terrain-rendering and display engine. \n          “TruEarth was developed in partnership with NASA,” says Greg Baxes, president of TerraMetrics. “Our goal was to use that data in TerraBlocks, but it also has standalone commercial viability.” \n          \n        \n          \n          \n            \n          \n          \n            The highly accurate 3D-rendering capabilities of the TerraBlocks engine are demonstrated in this exo-centric aircraft view near Mt. Fuji, Japan, generated for an in-flight entertainment application. \n          \n        \n        \n        The company offers TruEarth in 1-kilometer and 15-meter collections. (The measurements indicate the approximate area covered by each pixel in the imagery. In the 15-meter product, for example, each pixel covers an area 15 meters by 15 meters.) The company verifies the accuracy of the data and processes the original source imagery into its TruEarth natural color form to accurately reflect the appearance of the Earth’s surface. \n        While the TruEarth products have been used extensively in flight simulation and even in movies, television, and animation, most everyday users of the technology encounter it online: The TruEarth 15-meter collection forms the base layer for Google Earth. The imagery is used for views on Google Earth and Google Maps ranging from the global level all the way down to the detail seen when flying about 20,000 feet above the Earth; at greater magnifications, other imagery and data from Google vendors are laid over the TruEarth imagery to reveal details like buildings and roads. \n        While TruEarth helps Google by providing the global map many use to determine directions or just for virtual exploration, the imagery also can be combined with terrain elevation data and used in the TerraBlocks engine for flight deck displays. This requires a critical level of accuracy that goes beyond that of online mapping programs. “The terrain can’t just look pretty,” says Baxes, “it has to be displayed precisely and with absolute global positional accuracy relative to the aircraft.” \n        TerraBlocks is unique in its field, Baxes explains. “As far as a photorealistic rendering of the Earth in a flight application, TerraBlocks stands on its own,” he says. The technology utilizes a compression technique and terrain-block-based processing methodology that stores worldwide satellite imagery and terrain data in a compact, multiresolution form—reducing information that can exceed 4 terabytes down to more manageable sizes—while still allowing real-time access to the data by the TerraBlocks engine during flight. TerraMetrics has two patents on the technology, which is now in use for flight simulation applications as the company works to expand the innovation into commercial avionics, along with smartphones and tablets, using its embedded version of the TerraBlocks engine. \n        Baxes says TerraMetrics’ NASA partnerships have yielded significant benefits. \n        “NASA has the charter to look way into the future. Partnering with NASA has allowed us to understand where the future is headed and apply our innovation and technologies in that direction,” he says. “The seed money that we were able to apply to our research and development will pay vast dividends as far as meeting general public and commercial sector needs.”\n        The company has also worked on another SBIR project with Stennis to enable refinement and optimization of the processing means for overlaying scientific data on 3D geospatial browsers like Google Earth, allowing visualizations useful for everything from climate change research to emergency management. And with the help of TerraMetrics’ NASA-derived technology, the Agency continues to explore the future of flight displays. Arthur notes technologies like enhanced vision—combining synthetic vision with an array of sensors to provide comprehensive situational awareness—which could enable advances like windowless supersonic aircraft. Such possibilities are not unrealistic, Arthur says.\n        “You just never know how these things might spin-off,” he says. “Fifteen years ago, would anyone have envisioned having the Earth on your smartphone in your pocket?”\n        TerraBlocks™ is a trademark of TerraMetrics Inc.\n        TruEarth® is a registered trademark of TerraMetrics Inc\n        \n      NASA TechnologyOn a December night in 1995, 159 passengers and crew members died when American Airlines Flight 965 flew into the side of a mountain while in route to Cali, Colombia. A key factor in the tragedy: The pilots had lost situational awareness in the dark, unfamiliar terrain. They had no idea the plane was approaching a mountain until the ground proximity warning system sounded an alarm only seconds before impact. The accident was of the kind most common at the time—CFIT, or controlled flight into terrain—says Trey Arthur, research aerospace engineer in the Crew Systems and Aviation Operations Branch at NASA’s Langley Research Center. In situations such as bad weather, fog, or nighttime flights, pilots would rely on airspeed, altitude, and other readings to get an accurate sense of location. Miscalculations and rapidly changing conditions could contribute to a fully functioning, in-control airplane flying into the ground. To improve aviation safety by enhancing pilots’ situational awareness even in poor visibility, NASA began exploring the possibilities of synthetic vision—creating a graphical display of the outside terrain on a screen inside the cockpit. “How do you display a mountain in the cockpit? You have to have a graphics-powered computer, a terrain database you can render, and an accurate navigation solution,” says Arthur.In the mid-1990s, developing GPS technology offered a means for determining an aircraft’s position in space with high accuracy, Arthur explains. As the necessary technologies to enable synthetic vision emerged, NASA turned to an industry partner to develop the terrain graphical engine and database for creating the virtual rendering of the outside environment. \n        Partnership\n          In 2003, Langley partnered with TerraMetrics Inc. of Littleton, Colorado, through the Small Business Innovation Research (SBIR) program to develop a 3D terrain rendering technology for flight-qualified synthetic vision systems. The company’s innovative solution, called TerraBlocks, rendered satellite imagery on top of terrain data to provide the pilot with a virtual view of the environment outside the cockpit window. This kind of rendering vastly improved on typical flat-earth displays by mapping the terrain in three dimensions on a model of the Earth’s sphere. The resulting visualization was not only more realistic, but also highly accurate. \n          To produce its visuals, TerraBlocks needed satellite imagery and terrain data. For the imagery, the company worked with the Scientific Data Purchase program at Stennis Space Center to locate the data it needed, using an archive from NASA’s Earth-observing Landsat 7 satellite that proved suitable for use in TerraBlocks. TerraMetrics chose NASA’s Shuttle Radar Topography Mission (SRTM) terrain data to provide the 3D element. Since then, NASA has used the TerraBlocks engine for multiple experiments with flight simulators for aircraft and even lunar lander vehicles, the latter using a graphical rendering of the Moon the company created. The lander tests demonstrated the potential for synthetic vision on spacecraft.\n          “If we do manned missions to asteroids or other destinations, all we need is the data and a good navigational system, and we can essentially draw that world for the pilot,” Arthur says.\n          Through the combined collaboration with the NASA centers, TerraMetrics has developed its NASA-derived innovations into products for helping pilots navigate more safely in the skies, as well as for assisting people in finding their way on the ground.\n          Benefits\n          TerraMetrics now markets its TruEarth satellite imagery and terrain data product line—incorporating the NASA source data from Stennis along with other NASA satellite sources—coupled with its SBIR-developed TerraBlocks terrain-rendering and display engine. \n          “TruEarth was developed in partnership with NASA,” says Greg Baxes, president of TerraMetrics. “Our goal was to use that data in TerraBlocks, but it also has standalone commercial viability.” \n          \n        The company offers TruEarth in 1-kilometer and 15-meter collections. (The measurements indicate the approximate area covered by each pixel in the imagery. In the 15-meter product, for example, each pixel covers an area 15 meters by 15 meters.) The company verifies the accuracy of the data and processes the original source imagery into its TruEarth natural color form to accurately reflect the appearance of the Earth’s surface. \n        While the TruEarth products have been used extensively in flight simulation and even in movies, television, and animation, most everyday users of the technology encounter it online: The TruEarth 15-meter collection forms the base layer for Google Earth. The imagery is used for views on Google Earth and Google Maps ranging from the global level all the way down to the detail seen when flying about 20,000 feet above the Earth; at greater magnifications, other imagery and data from Google vendors are laid over the TruEarth imagery to reveal details like buildings and roads. \n        While TruEarth helps Google by providing the global map many use to determine directions or just for virtual exploration, the imagery also can be combined with terrain elevation data and used in the TerraBlocks engine for flight deck displays. This requires a critical level of accuracy that goes beyond that of online mapping programs. “The terrain can’t just look pretty,” says Baxes, “it has to be displayed precisely and with absolute global positional accuracy relative to the aircraft.” \n        TerraBlocks is unique in its field, Baxes explains. “As far as a photorealistic rendering of the Earth in a flight application, TerraBlocks stands on its own,” he says. The technology utilizes a compression technique and terrain-block-based processing methodology that stores worldwide satellite imagery and terrain data in a compact, multiresolution form—reducing information that can exceed 4 terabytes down to more manageable sizes—while still allowing real-time access to the data by the TerraBlocks engine during flight. TerraMetrics has two patents on the technology, which is now in use for flight simulation applications as the company works to expand the innovation into commercial avionics, along with smartphones and tablets, using its embedded version of the TerraBlocks engine. \n        Baxes says TerraMetrics’ NASA partnerships have yielded significant benefits. \n        “NASA has the charter to look way into the future. Partnering with NASA has allowed us to understand where the future is headed and apply our innovation and technologies in that direction,” he says. “The seed money that we were able to apply to our research and development will pay vast dividends as far as meeting general public and commercial sector needs.”\n        The company has also worked on another SBIR project with Stennis to enable refinement and optimization of the processing means for overlaying scientific data on 3D geospatial browsers like Google Earth, allowing visualizations useful for everything from climate change research to emergency management. And with the help of TerraMetrics’ NASA-derived technology, the Agency continues to explore the future of flight displays. Arthur notes technologies like enhanced vision—combining synthetic vision with an array of sensors to provide comprehensive situational awareness—which could enable advances like windowless supersonic aircraft. Such possibilities are not unrealistic, Arthur says.\n        “You just never know how these things might spin-off,” he says. “Fifteen years ago, would anyone have envisioned having the Earth on your smartphone in your pocket?”\n        TerraBlocks™ is a trademark of TerraMetrics Inc.\n        TruEarth® is a registered trademark of TerraMetrics Inc\n        "},{"href":"http://spinoff.nasa.gov/Spinoff2011/it_2.html","text":"Content Platforms Meet Data Storage, Retrieval Needs","image":"http://spinoff.nasa.gov/Spinoff2011/Images/it_2a_opt.jpg","story":"\n    \n      \n        \n          NASA Technology\n          Earth is under a constant barrage of information from space. Whether from satellites orbiting our planet, spacecraft circling Mars, or probes streaking toward the far reaches of the Solar System, NASA collects massive amounts of data from its spacefaring missions each day. NASA’s Earth Observing System (EOS) satellites, for example, provide daily imagery and measurements of Earth’s atmosphere, oceans, vegetation, and more. The Earth Observing System Data and Information System (EOSDIS) collects all of that science data and processes, archives, and distributes it to researchers around the globe; EOSDIS recently reached a total archive volume of 4.5 petabytes. Try to store that amount of information in your standard, four-drawer file cabinet, and you would need 90 million to get the job done. \n          To manage the flood of information, NASA has explored technologies to efficiently collect, archive, and provide access to EOS data for scientists today and for years to come. One such technology is now providing similar capabilities to businesses and organizations worldwide.\n          Partnership\n          \n            \n            \n              \n            \n            \n              This image from the Aura satellite’s OMI instrument reveals tropospheric ozone over Indonesia. Aura monitors air pollution around the world on a daily basis. \n            \n          \n          In 2004, Archivas Inc. of Waltham, Massachusetts partnered with NASA’s Goddard Space Flight Center through the Small Business Innovation Research (SBIR) program. Founded by the former chief technology officer of The New York Times, who was seeking an effective means of digitally archiving the paper’s 100-plus years of news, Archivas innovated new software technologies for preserving and providing useful access to vast digital repositories of data. The company began work with Goddard computer scientist Curt Tilmes to develop and test a beta form of its ArC technology for NASA to collect and store data from the Ozone Monitoring Instrument (OMI) onboard NASA’s Aura EOS satellite. \n          Traditional methods of data storage at the time, such as tapes, had long proven slow to provide access to information and costly to maintain and scale up as an archive grew. NASA needed a solution for handling the large OMI data files and allowing them to be processed by different applications using different protocols. The result of the partnership with Archivas was “a single, consolidated repository of digital assets—in this case satellite images—that was accessible by multiple different applications used to process and store the images,” says Asim Zaheer, at the time vice president of marketing for the company. \n          “Working with NASA was instrumental in getting us the credibility we needed … \n            It was crucial to our early success.”\n            —Asim Zaheer, Hitachi Data Systems \n          The repository was capable of scaling up to extremely large sizes, a necessity considering the significant size of the individual satellite files. In addition, the technology enabled the quick retrieval of archived information, even years after collection, through a unique method of storing data as objects rather than files. Objects combine files with information about the file (its metadata) and a policy that provides some kind of instruction about how the information should be handled—whether it should be replicated or deleted after a certain number of years, for example.\n          The SBIR-derived technology became a long-term solution for NASA’s OMI data collection and other Earth science missions. Archivas, in the meantime, translated its NASA work into a springboard for commercialization. \n          Archivas brought the ArC software to market in 2005 and found success across a range of industries. Hospitals needed to create repositories for medical imagery and patient records, and financial services firms required a solution for the long-term retention and preservation of authenticity of financial records. Both industries have regulatory requirements that mandate record retention and the ability to recall these records as needed, and the Archivas software adapted to meet those needs.\n          “We evolved the technology from being simply a long-term record retention archival solution to a digital repository that can provide access to digital content anytime, anyplace, anywhere,” says Zaheer.\n          Recognizing the strength of the technology’s content management capabilities, Hitachi Data Systems Corporation, headquartered in Santa Clara, California, acquired Archivas in 2007. \n          Benefits \n          \n            \n            \n              \n            \n            \n              Hitachi Data System’s NASA-derived Hitachi Content Platform is an ideal tool for cloud computing applications that base computational resources on a network accessible by any number of devices.\n            \n          \n          Today, the technology Archivas advanced with NASA assistance is marketed as the Hitachi Content Platform, or HCP. Capable of scaling up to 40 petabytes in capacity in a single cluster, HCP allows users to securely store and preserve data for business, legal, compliance, and other purposes without the need for tape-based backup. HCP can be subdivided into separate tenants that can be uniquely configured with various data management policies and access rules; these tenants can be further divided into namespaces that can also be individually configured. The technology, which earned the 2009 “Information Management Innovation Award” from Information Age magazine, is adaptable to new data formats and applications, meaning users can easily maintain their repositories even as the information technology environment changes and evolves. \n          HCP provides secure content management for customers including Peak Web Consulting, Qualcomm, and Comdata. Payformance Corporation, a healthcare claim settlement solution provider, achieved an 80-percent increase in administrative efficiencies thanks to HCP technology. \n          Beyond data storage, HCP has proven to be an ideal technology for cloud computing applications—the use of computational resources based exclusively on a network rather than housed on a specific computer. HCP is now the cornerstone of Hitachi Data System’s cloud storage solutions. The technology also helps enable Hitachi Clinical Repository, a new information management solution that offers healthcare providers a consolidated view of patient information, helping improve clinical decision making and patient care. \n           “In the retail sector, heavy manufacturing, technology, telecommunications, your cell phone provider, health care—you name it. This technology is broadly, horizontally leveraged, and it’s global,” says Zaheer, now Hitachi Data Systems’ vice president of corporate and product marketing. He attributes HCP’s commercial growth to the success of the early partnership with NASA.\n          “There are young startups developing technology left and right, and everyone feels they have the world’s best widget, but a lot of target customers don’t know how credible that story really is,” says Zaheer. “Working with NASA was instrumental in getting us the credibility we needed to engage with other organizations. It was crucial to our early success.”\n          Now HCP stands to play an increasingly significant role in the field of information management as data proliferates across industries in ever greater amounts. Google currently processes over 20 petabytes of information per day. Even individuals are producing large quantities of content, such as music, photos, and video, Zaheer says.\n          “All of that content has to live somewhere.”\n          Hitachi Data Systems® is a registered trademark of Hitachi Ltd.\n          \n        \n      \n    \n      \n        \n          NASA Technology\n          Earth is under a constant barrage of information from space. Whether from satellites orbiting our planet, spacecraft circling Mars, or probes streaking toward the far reaches of the Solar System, NASA collects massive amounts of data from its spacefaring missions each day. NASA’s Earth Observing System (EOS) satellites, for example, provide daily imagery and measurements of Earth’s atmosphere, oceans, vegetation, and more. The Earth Observing System Data and Information System (EOSDIS) collects all of that science data and processes, archives, and distributes it to researchers around the globe; EOSDIS recently reached a total archive volume of 4.5 petabytes. Try to store that amount of information in your standard, four-drawer file cabinet, and you would need 90 million to get the job done. \n          To manage the flood of information, NASA has explored technologies to efficiently collect, archive, and provide access to EOS data for scientists today and for years to come. One such technology is now providing similar capabilities to businesses and organizations worldwide.\n          Partnership\n          \n            \n            \n              \n            \n            \n              This image from the Aura satellite’s OMI instrument reveals tropospheric ozone over Indonesia. Aura monitors air pollution around the world on a daily basis. \n            \n          \n          In 2004, Archivas Inc. of Waltham, Massachusetts partnered with NASA’s Goddard Space Flight Center through the Small Business Innovation Research (SBIR) program. Founded by the former chief technology officer of The New York Times, who was seeking an effective means of digitally archiving the paper’s 100-plus years of news, Archivas innovated new software technologies for preserving and providing useful access to vast digital repositories of data. The company began work with Goddard computer scientist Curt Tilmes to develop and test a beta form of its ArC technology for NASA to collect and store data from the Ozone Monitoring Instrument (OMI) onboard NASA’s Aura EOS satellite. \n          Traditional methods of data storage at the time, such as tapes, had long proven slow to provide access to information and costly to maintain and scale up as an archive grew. NASA needed a solution for handling the large OMI data files and allowing them to be processed by different applications using different protocols. The result of the partnership with Archivas was “a single, consolidated repository of digital assets—in this case satellite images—that was accessible by multiple different applications used to process and store the images,” says Asim Zaheer, at the time vice president of marketing for the company. \n          “Working with NASA was instrumental in getting us the credibility we needed … \n            It was crucial to our early success.”\n            —Asim Zaheer, Hitachi Data Systems \n          The repository was capable of scaling up to extremely large sizes, a necessity considering the significant size of the individual satellite files. In addition, the technology enabled the quick retrieval of archived information, even years after collection, through a unique method of storing data as objects rather than files. Objects combine files with information about the file (its metadata) and a policy that provides some kind of instruction about how the information should be handled—whether it should be replicated or deleted after a certain number of years, for example.\n          The SBIR-derived technology became a long-term solution for NASA’s OMI data collection and other Earth science missions. Archivas, in the meantime, translated its NASA work into a springboard for commercialization. \n          Archivas brought the ArC software to market in 2005 and found success across a range of industries. Hospitals needed to create repositories for medical imagery and patient records, and financial services firms required a solution for the long-term retention and preservation of authenticity of financial records. Both industries have regulatory requirements that mandate record retention and the ability to recall these records as needed, and the Archivas software adapted to meet those needs.\n          “We evolved the technology from being simply a long-term record retention archival solution to a digital repository that can provide access to digital content anytime, anyplace, anywhere,” says Zaheer.\n          Recognizing the strength of the technology’s content management capabilities, Hitachi Data Systems Corporation, headquartered in Santa Clara, California, acquired Archivas in 2007. \n          Benefits \n          \n            \n            \n              \n            \n            \n              Hitachi Data System’s NASA-derived Hitachi Content Platform is an ideal tool for cloud computing applications that base computational resources on a network accessible by any number of devices.\n            \n          \n          Today, the technology Archivas advanced with NASA assistance is marketed as the Hitachi Content Platform, or HCP. Capable of scaling up to 40 petabytes in capacity in a single cluster, HCP allows users to securely store and preserve data for business, legal, compliance, and other purposes without the need for tape-based backup. HCP can be subdivided into separate tenants that can be uniquely configured with various data management policies and access rules; these tenants can be further divided into namespaces that can also be individually configured. The technology, which earned the 2009 “Information Management Innovation Award” from Information Age magazine, is adaptable to new data formats and applications, meaning users can easily maintain their repositories even as the information technology environment changes and evolves. \n          HCP provides secure content management for customers including Peak Web Consulting, Qualcomm, and Comdata. Payformance Corporation, a healthcare claim settlement solution provider, achieved an 80-percent increase in administrative efficiencies thanks to HCP technology. \n          Beyond data storage, HCP has proven to be an ideal technology for cloud computing applications—the use of computational resources based exclusively on a network rather than housed on a specific computer. HCP is now the cornerstone of Hitachi Data System’s cloud storage solutions. The technology also helps enable Hitachi Clinical Repository, a new information management solution that offers healthcare providers a consolidated view of patient information, helping improve clinical decision making and patient care. \n           “In the retail sector, heavy manufacturing, technology, telecommunications, your cell phone provider, health care—you name it. This technology is broadly, horizontally leveraged, and it’s global,” says Zaheer, now Hitachi Data Systems’ vice president of corporate and product marketing. He attributes HCP’s commercial growth to the success of the early partnership with NASA.\n          “There are young startups developing technology left and right, and everyone feels they have the world’s best widget, but a lot of target customers don’t know how credible that story really is,” says Zaheer. “Working with NASA was instrumental in getting us the credibility we needed to engage with other organizations. It was crucial to our early success.”\n          Now HCP stands to play an increasingly significant role in the field of information management as data proliferates across industries in ever greater amounts. Google currently processes over 20 petabytes of information per day. Even individuals are producing large quantities of content, such as music, photos, and video, Zaheer says.\n          “All of that content has to live somewhere.”\n          Hitachi Data Systems® is a registered trademark of Hitachi Ltd.\n          \n        \n      \n          NASA Technology\n          Earth is under a constant barrage of information from space. Whether from satellites orbiting our planet, spacecraft circling Mars, or probes streaking toward the far reaches of the Solar System, NASA collects massive amounts of data from its spacefaring missions each day. NASA’s Earth Observing System (EOS) satellites, for example, provide daily imagery and measurements of Earth’s atmosphere, oceans, vegetation, and more. The Earth Observing System Data and Information System (EOSDIS) collects all of that science data and processes, archives, and distributes it to researchers around the globe; EOSDIS recently reached a total archive volume of 4.5 petabytes. Try to store that amount of information in your standard, four-drawer file cabinet, and you would need 90 million to get the job done. \n          To manage the flood of information, NASA has explored technologies to efficiently collect, archive, and provide access to EOS data for scientists today and for years to come. One such technology is now providing similar capabilities to businesses and organizations worldwide.\n          Partnership\n          \n            \n            \n              \n            \n            \n              This image from the Aura satellite’s OMI instrument reveals tropospheric ozone over Indonesia. Aura monitors air pollution around the world on a daily basis. \n            \n          \n          In 2004, Archivas Inc. of Waltham, Massachusetts partnered with NASA’s Goddard Space Flight Center through the Small Business Innovation Research (SBIR) program. Founded by the former chief technology officer of The New York Times, who was seeking an effective means of digitally archiving the paper’s 100-plus years of news, Archivas innovated new software technologies for preserving and providing useful access to vast digital repositories of data. The company began work with Goddard computer scientist Curt Tilmes to develop and test a beta form of its ArC technology for NASA to collect and store data from the Ozone Monitoring Instrument (OMI) onboard NASA’s Aura EOS satellite. \n          Traditional methods of data storage at the time, such as tapes, had long proven slow to provide access to information and costly to maintain and scale up as an archive grew. NASA needed a solution for handling the large OMI data files and allowing them to be processed by different applications using different protocols. The result of the partnership with Archivas was “a single, consolidated repository of digital assets—in this case satellite images—that was accessible by multiple different applications used to process and store the images,” says Asim Zaheer, at the time vice president of marketing for the company. \n          “Working with NASA was instrumental in getting us the credibility we needed … \n            It was crucial to our early success.”\n            —Asim Zaheer, Hitachi Data Systems \n          The repository was capable of scaling up to extremely large sizes, a necessity considering the significant size of the individual satellite files. In addition, the technology enabled the quick retrieval of archived information, even years after collection, through a unique method of storing data as objects rather than files. Objects combine files with information about the file (its metadata) and a policy that provides some kind of instruction about how the information should be handled—whether it should be replicated or deleted after a certain number of years, for example.\n          The SBIR-derived technology became a long-term solution for NASA’s OMI data collection and other Earth science missions. Archivas, in the meantime, translated its NASA work into a springboard for commercialization. \n          Archivas brought the ArC software to market in 2005 and found success across a range of industries. Hospitals needed to create repositories for medical imagery and patient records, and financial services firms required a solution for the long-term retention and preservation of authenticity of financial records. Both industries have regulatory requirements that mandate record retention and the ability to recall these records as needed, and the Archivas software adapted to meet those needs.\n          “We evolved the technology from being simply a long-term record retention archival solution to a digital repository that can provide access to digital content anytime, anyplace, anywhere,” says Zaheer.\n          Recognizing the strength of the technology’s content management capabilities, Hitachi Data Systems Corporation, headquartered in Santa Clara, California, acquired Archivas in 2007. \n          Benefits \n          \n            \n            \n              \n            \n            \n              Hitachi Data System’s NASA-derived Hitachi Content Platform is an ideal tool for cloud computing applications that base computational resources on a network accessible by any number of devices.\n            \n          \n          Today, the technology Archivas advanced with NASA assistance is marketed as the Hitachi Content Platform, or HCP. Capable of scaling up to 40 petabytes in capacity in a single cluster, HCP allows users to securely store and preserve data for business, legal, compliance, and other purposes without the need for tape-based backup. HCP can be subdivided into separate tenants that can be uniquely configured with various data management policies and access rules; these tenants can be further divided into namespaces that can also be individually configured. The technology, which earned the 2009 “Information Management Innovation Award” from Information Age magazine, is adaptable to new data formats and applications, meaning users can easily maintain their repositories even as the information technology environment changes and evolves. \n          HCP provides secure content management for customers including Peak Web Consulting, Qualcomm, and Comdata. Payformance Corporation, a healthcare claim settlement solution provider, achieved an 80-percent increase in administrative efficiencies thanks to HCP technology. \n          Beyond data storage, HCP has proven to be an ideal technology for cloud computing applications—the use of computational resources based exclusively on a network rather than housed on a specific computer. HCP is now the cornerstone of Hitachi Data System’s cloud storage solutions. The technology also helps enable Hitachi Clinical Repository, a new information management solution that offers healthcare providers a consolidated view of patient information, helping improve clinical decision making and patient care. \n           “In the retail sector, heavy manufacturing, technology, telecommunications, your cell phone provider, health care—you name it. This technology is broadly, horizontally leveraged, and it’s global,” says Zaheer, now Hitachi Data Systems’ vice president of corporate and product marketing. He attributes HCP’s commercial growth to the success of the early partnership with NASA.\n          “There are young startups developing technology left and right, and everyone feels they have the world’s best widget, but a lot of target customers don’t know how credible that story really is,” says Zaheer. “Working with NASA was instrumental in getting us the credibility we needed to engage with other organizations. It was crucial to our early success.”\n          Now HCP stands to play an increasingly significant role in the field of information management as data proliferates across industries in ever greater amounts. Google currently processes over 20 petabytes of information per day. Even individuals are producing large quantities of content, such as music, photos, and video, Zaheer says.\n          “All of that content has to live somewhere.”\n          Hitachi Data Systems® is a registered trademark of Hitachi Ltd.\n          "},{"href":"http://spinoff.nasa.gov/Spinoff2011/it_3.html","text":"Tools Ensure Reliability of Critical Software","image":"http://spinoff.nasa.gov/Spinoff2011/Images/it_3a_opt.jpg","story":"\n    \n      \n        \n          \n            NASA Technology\n            In November 2006, after attempting to make a routine maneuver, NASA’s Mars Global Surveyor (MGS) reported unexpected errors. The onboard software switched to backup resources, and a 2-day lapse in communication took place between the spacecraft and Earth. When a signal was finally received, it indicated that MGS had entered safe mode, a state of restricted activity in which the computer awaits instructions from Earth. After more than 9 years of successful operation—gathering data and snapping pictures of Mars to characterize the planet’s land and weather—communication between MGS and Earth suddenly stopped. \n            \n              \n              \n                \n              \n              \n                JPL’s Laboratory for Reliable Software (LaRS) works to ensure the reliability of spacecraft software and prevent failures like the one that cut short the operations of the Mars Global Surveyor (pictured here).\n              \n            \n            Months later, a report from NASA’s internal review board found the spacecraft’s battery failed due to an unfortunate sequence of events. Updates to the spacecraft’s software, which had taken place months earlier, were written to the wrong memory address in the spacecraft’s computer. In short, the mission ended because of a software defect.\n            Over the last decade, spacecraft have become increasingly reliant on software to carry out mission operations. In fact, the next mission to Mars, the Mars Science Laboratory, will rely on more software than all earlier missions to Mars combined. According to Gerard Holzmann, manager at the Laboratory for Reliable Software (LaRS) at NASA’s Jet Propulsion Laboratory (JPL), even the fault protection systems on a spacecraft are mostly software-based. For reasons like these, well-functioning software is critical for NASA. \n            In the same year as the failure of MGS, Holzmann presented a new approach to critical software development to help reduce risk and provide consistency. He proposed “The Power of 10: Rules for Developing Safety-Critical Code,” which is a small set of rules that can easily be remembered, clearly relate to risk, and allow compliance to be verified. The reaction at JPL was positive, and developers in the private sector embraced Holzmann’s ideas. \n            Partnership \n            To demonstrate the feasibility of using a tool to automatically check software for compliance with Holzmann’s rules, JPL awarded Small Business Innovation Research (SBIR) funding to GrammaTech Inc. of Ithaca, New York. The software development company adapted its existing software code analysis product, CodeSonar, to include verification of The Power of 10. Michael McDougall, a senior scientist at GrammaTech, says, “JPL was already using CodeSonar to check its software; however, there are things that might be acceptable in a desktop application that are unacceptable in an environment like on Mars or the Moon. CodeSonar didn’t have rules specifically crafted for this type of critical software.” After successfully adapting CodeSonar to check for the NASA-derived rules, GrammaTech transitioned the changes into its commercial version of the product in 2008. \n            Benefits\n            As a static analysis tool, CodeSonar finds problems in software without executing any part of the program. The tool produces a list of potential violations, including complex programming bugs that can result in system crashes and memory corruption. Compared to traditional software testing methods, CodeSonar checks more code in less time and saves time and expense by finding problems before the software is completed and distributed to users. \n            \n              \n              \n                \n              \n              \n                Items as varied as infusion pumps, cell phones, and aircraft components are made using CodeSonar, a product from GrammaTech Inc. that incorporates rules developed at the Jet Propulsion Laboratory, to quickly find problems in the products’ software.\n              \n            \n            The design of CodeSonar allows users to configure how thoroughly it performs a check. The tool can warn about every potential issue, only critical violations, or a combination of both. McDougall explains, “Depending on the application, the software may not need to be as reliable as a Mars rover, but it can still be troublesome if it crashes at the wrong time. Users can choose the level of compliance that suits their context.”\n            Today, CodeSonar has hundreds of users worldwide, including Fortune 500 companies, startup businesses, educational institutions, and government agencies working on satellites, avionics, industrial controls, medical devices, wireless devices, networking equipment, and consumer electronics.\n            In response to a widespread medical device recall, the U.S. Food and Drug Administration (FDA) started encouraging manufacturers of infusion pumps to utilize static code analysis tools like CodeSonar to check the pumps’ software. Commonly used to deliver fluids into a patient’s body, infusion pumps have been responsible for a number of deaths and injuries since 2005. In one instance, investigators at the FDA used CodeSonar to help determine the root cause of malfunction in a widely-deployed, commercial infusion pump. \n            Cell phone developers like LG Electronics Inc., Samsung, and Panasonic are also using CodeSonar. McDougall explains, “Cell phones are expected to function 24 hours a day, 7 days a week. The software that runs the internal cell phone, changes what is on the screen, and manages the address book, all has to be very reliable. Users do not want to have to reboot or install updates in the middle of a phone call.”\n            GE Aviation, a provider of jet engines and components, as well as avionics, electric power, and mechanical systems for aircraft, uses CodeSonar to ensure the software in aircraft functions properly. “Software is an important part of engine design, and a lot of how planes work is controlled by software. You want it to be perfect—or as close to perfect as possible,” says McDougall.\n            With public and private entities employing CodeSonar, Holzmann is hopeful that more organizations will be inspired to improve software development practice. “If the technology continues to be adopted, we will have made a contribution to making the computer systems we rely on safer and more reliable,” he says.\n            Since developing The Power of 10, Holzmann has devised a single coding standard called the JPL Institutional Coding Standard for the Development of Flight Software. McDougall expects the standard will be incorporated in the next commercial version of CodeSonar.\n            CodeSonar® is a registered trademark of GrammaTech Inc.\n            \n          \n        \n      \n    \n      \n        \n          \n            NASA Technology\n            In November 2006, after attempting to make a routine maneuver, NASA’s Mars Global Surveyor (MGS) reported unexpected errors. The onboard software switched to backup resources, and a 2-day lapse in communication took place between the spacecraft and Earth. When a signal was finally received, it indicated that MGS had entered safe mode, a state of restricted activity in which the computer awaits instructions from Earth. After more than 9 years of successful operation—gathering data and snapping pictures of Mars to characterize the planet’s land and weather—communication between MGS and Earth suddenly stopped. \n            \n              \n              \n                \n              \n              \n                JPL’s Laboratory for Reliable Software (LaRS) works to ensure the reliability of spacecraft software and prevent failures like the one that cut short the operations of the Mars Global Surveyor (pictured here).\n              \n            \n            Months later, a report from NASA’s internal review board found the spacecraft’s battery failed due to an unfortunate sequence of events. Updates to the spacecraft’s software, which had taken place months earlier, were written to the wrong memory address in the spacecraft’s computer. In short, the mission ended because of a software defect.\n            Over the last decade, spacecraft have become increasingly reliant on software to carry out mission operations. In fact, the next mission to Mars, the Mars Science Laboratory, will rely on more software than all earlier missions to Mars combined. According to Gerard Holzmann, manager at the Laboratory for Reliable Software (LaRS) at NASA’s Jet Propulsion Laboratory (JPL), even the fault protection systems on a spacecraft are mostly software-based. For reasons like these, well-functioning software is critical for NASA. \n            In the same year as the failure of MGS, Holzmann presented a new approach to critical software development to help reduce risk and provide consistency. He proposed “The Power of 10: Rules for Developing Safety-Critical Code,” which is a small set of rules that can easily be remembered, clearly relate to risk, and allow compliance to be verified. The reaction at JPL was positive, and developers in the private sector embraced Holzmann’s ideas. \n            Partnership \n            To demonstrate the feasibility of using a tool to automatically check software for compliance with Holzmann’s rules, JPL awarded Small Business Innovation Research (SBIR) funding to GrammaTech Inc. of Ithaca, New York. The software development company adapted its existing software code analysis product, CodeSonar, to include verification of The Power of 10. Michael McDougall, a senior scientist at GrammaTech, says, “JPL was already using CodeSonar to check its software; however, there are things that might be acceptable in a desktop application that are unacceptable in an environment like on Mars or the Moon. CodeSonar didn’t have rules specifically crafted for this type of critical software.” After successfully adapting CodeSonar to check for the NASA-derived rules, GrammaTech transitioned the changes into its commercial version of the product in 2008. \n            Benefits\n            As a static analysis tool, CodeSonar finds problems in software without executing any part of the program. The tool produces a list of potential violations, including complex programming bugs that can result in system crashes and memory corruption. Compared to traditional software testing methods, CodeSonar checks more code in less time and saves time and expense by finding problems before the software is completed and distributed to users. \n            \n              \n              \n                \n              \n              \n                Items as varied as infusion pumps, cell phones, and aircraft components are made using CodeSonar, a product from GrammaTech Inc. that incorporates rules developed at the Jet Propulsion Laboratory, to quickly find problems in the products’ software.\n              \n            \n            The design of CodeSonar allows users to configure how thoroughly it performs a check. The tool can warn about every potential issue, only critical violations, or a combination of both. McDougall explains, “Depending on the application, the software may not need to be as reliable as a Mars rover, but it can still be troublesome if it crashes at the wrong time. Users can choose the level of compliance that suits their context.”\n            Today, CodeSonar has hundreds of users worldwide, including Fortune 500 companies, startup businesses, educational institutions, and government agencies working on satellites, avionics, industrial controls, medical devices, wireless devices, networking equipment, and consumer electronics.\n            In response to a widespread medical device recall, the U.S. Food and Drug Administration (FDA) started encouraging manufacturers of infusion pumps to utilize static code analysis tools like CodeSonar to check the pumps’ software. Commonly used to deliver fluids into a patient’s body, infusion pumps have been responsible for a number of deaths and injuries since 2005. In one instance, investigators at the FDA used CodeSonar to help determine the root cause of malfunction in a widely-deployed, commercial infusion pump. \n            Cell phone developers like LG Electronics Inc., Samsung, and Panasonic are also using CodeSonar. McDougall explains, “Cell phones are expected to function 24 hours a day, 7 days a week. The software that runs the internal cell phone, changes what is on the screen, and manages the address book, all has to be very reliable. Users do not want to have to reboot or install updates in the middle of a phone call.”\n            GE Aviation, a provider of jet engines and components, as well as avionics, electric power, and mechanical systems for aircraft, uses CodeSonar to ensure the software in aircraft functions properly. “Software is an important part of engine design, and a lot of how planes work is controlled by software. You want it to be perfect—or as close to perfect as possible,” says McDougall.\n            With public and private entities employing CodeSonar, Holzmann is hopeful that more organizations will be inspired to improve software development practice. “If the technology continues to be adopted, we will have made a contribution to making the computer systems we rely on safer and more reliable,” he says.\n            Since developing The Power of 10, Holzmann has devised a single coding standard called the JPL Institutional Coding Standard for the Development of Flight Software. McDougall expects the standard will be incorporated in the next commercial version of CodeSonar.\n            CodeSonar® is a registered trademark of GrammaTech Inc.\n            \n          \n        \n      \n          \n            NASA Technology\n            In November 2006, after attempting to make a routine maneuver, NASA’s Mars Global Surveyor (MGS) reported unexpected errors. The onboard software switched to backup resources, and a 2-day lapse in communication took place between the spacecraft and Earth. When a signal was finally received, it indicated that MGS had entered safe mode, a state of restricted activity in which the computer awaits instructions from Earth. After more than 9 years of successful operation—gathering data and snapping pictures of Mars to characterize the planet’s land and weather—communication between MGS and Earth suddenly stopped. \n            \n              \n              \n                \n              \n              \n                JPL’s Laboratory for Reliable Software (LaRS) works to ensure the reliability of spacecraft software and prevent failures like the one that cut short the operations of the Mars Global Surveyor (pictured here).\n              \n            \n            Months later, a report from NASA’s internal review board found the spacecraft’s battery failed due to an unfortunate sequence of events. Updates to the spacecraft’s software, which had taken place months earlier, were written to the wrong memory address in the spacecraft’s computer. In short, the mission ended because of a software defect.\n            Over the last decade, spacecraft have become increasingly reliant on software to carry out mission operations. In fact, the next mission to Mars, the Mars Science Laboratory, will rely on more software than all earlier missions to Mars combined. According to Gerard Holzmann, manager at the Laboratory for Reliable Software (LaRS) at NASA’s Jet Propulsion Laboratory (JPL), even the fault protection systems on a spacecraft are mostly software-based. For reasons like these, well-functioning software is critical for NASA. \n            In the same year as the failure of MGS, Holzmann presented a new approach to critical software development to help reduce risk and provide consistency. He proposed “The Power of 10: Rules for Developing Safety-Critical Code,” which is a small set of rules that can easily be remembered, clearly relate to risk, and allow compliance to be verified. The reaction at JPL was positive, and developers in the private sector embraced Holzmann’s ideas. \n            Partnership \n            To demonstrate the feasibility of using a tool to automatically check software for compliance with Holzmann’s rules, JPL awarded Small Business Innovation Research (SBIR) funding to GrammaTech Inc. of Ithaca, New York. The software development company adapted its existing software code analysis product, CodeSonar, to include verification of The Power of 10. Michael McDougall, a senior scientist at GrammaTech, says, “JPL was already using CodeSonar to check its software; however, there are things that might be acceptable in a desktop application that are unacceptable in an environment like on Mars or the Moon. CodeSonar didn’t have rules specifically crafted for this type of critical software.” After successfully adapting CodeSonar to check for the NASA-derived rules, GrammaTech transitioned the changes into its commercial version of the product in 2008. \n            Benefits\n            As a static analysis tool, CodeSonar finds problems in software without executing any part of the program. The tool produces a list of potential violations, including complex programming bugs that can result in system crashes and memory corruption. Compared to traditional software testing methods, CodeSonar checks more code in less time and saves time and expense by finding problems before the software is completed and distributed to users. \n            \n              \n              \n                \n              \n              \n                Items as varied as infusion pumps, cell phones, and aircraft components are made using CodeSonar, a product from GrammaTech Inc. that incorporates rules developed at the Jet Propulsion Laboratory, to quickly find problems in the products’ software.\n              \n            \n            The design of CodeSonar allows users to configure how thoroughly it performs a check. The tool can warn about every potential issue, only critical violations, or a combination of both. McDougall explains, “Depending on the application, the software may not need to be as reliable as a Mars rover, but it can still be troublesome if it crashes at the wrong time. Users can choose the level of compliance that suits their context.”\n            Today, CodeSonar has hundreds of users worldwide, including Fortune 500 companies, startup businesses, educational institutions, and government agencies working on satellites, avionics, industrial controls, medical devices, wireless devices, networking equipment, and consumer electronics.\n            In response to a widespread medical device recall, the U.S. Food and Drug Administration (FDA) started encouraging manufacturers of infusion pumps to utilize static code analysis tools like CodeSonar to check the pumps’ software. Commonly used to deliver fluids into a patient’s body, infusion pumps have been responsible for a number of deaths and injuries since 2005. In one instance, investigators at the FDA used CodeSonar to help determine the root cause of malfunction in a widely-deployed, commercial infusion pump. \n            Cell phone developers like LG Electronics Inc., Samsung, and Panasonic are also using CodeSonar. McDougall explains, “Cell phones are expected to function 24 hours a day, 7 days a week. The software that runs the internal cell phone, changes what is on the screen, and manages the address book, all has to be very reliable. Users do not want to have to reboot or install updates in the middle of a phone call.”\n            GE Aviation, a provider of jet engines and components, as well as avionics, electric power, and mechanical systems for aircraft, uses CodeSonar to ensure the software in aircraft functions properly. “Software is an important part of engine design, and a lot of how planes work is controlled by software. You want it to be perfect—or as close to perfect as possible,” says McDougall.\n            With public and private entities employing CodeSonar, Holzmann is hopeful that more organizations will be inspired to improve software development practice. “If the technology continues to be adopted, we will have made a contribution to making the computer systems we rely on safer and more reliable,” he says.\n            Since developing The Power of 10, Holzmann has devised a single coding standard called the JPL Institutional Coding Standard for the Development of Flight Software. McDougall expects the standard will be incorporated in the next commercial version of CodeSonar.\n            CodeSonar® is a registered trademark of GrammaTech Inc.\n            \n          \n            NASA Technology\n            In November 2006, after attempting to make a routine maneuver, NASA’s Mars Global Surveyor (MGS) reported unexpected errors. The onboard software switched to backup resources, and a 2-day lapse in communication took place between the spacecraft and Earth. When a signal was finally received, it indicated that MGS had entered safe mode, a state of restricted activity in which the computer awaits instructions from Earth. After more than 9 years of successful operation—gathering data and snapping pictures of Mars to characterize the planet’s land and weather—communication between MGS and Earth suddenly stopped. \n            \n              \n              \n                \n              \n              \n                JPL’s Laboratory for Reliable Software (LaRS) works to ensure the reliability of spacecraft software and prevent failures like the one that cut short the operations of the Mars Global Surveyor (pictured here).\n              \n            \n            Months later, a report from NASA’s internal review board found the spacecraft’s battery failed due to an unfortunate sequence of events. Updates to the spacecraft’s software, which had taken place months earlier, were written to the wrong memory address in the spacecraft’s computer. In short, the mission ended because of a software defect.\n            Over the last decade, spacecraft have become increasingly reliant on software to carry out mission operations. In fact, the next mission to Mars, the Mars Science Laboratory, will rely on more software than all earlier missions to Mars combined. According to Gerard Holzmann, manager at the Laboratory for Reliable Software (LaRS) at NASA’s Jet Propulsion Laboratory (JPL), even the fault protection systems on a spacecraft are mostly software-based. For reasons like these, well-functioning software is critical for NASA. \n            In the same year as the failure of MGS, Holzmann presented a new approach to critical software development to help reduce risk and provide consistency. He proposed “The Power of 10: Rules for Developing Safety-Critical Code,” which is a small set of rules that can easily be remembered, clearly relate to risk, and allow compliance to be verified. The reaction at JPL was positive, and developers in the private sector embraced Holzmann’s ideas. \n            Partnership \n            To demonstrate the feasibility of using a tool to automatically check software for compliance with Holzmann’s rules, JPL awarded Small Business Innovation Research (SBIR) funding to GrammaTech Inc. of Ithaca, New York. The software development company adapted its existing software code analysis product, CodeSonar, to include verification of The Power of 10. Michael McDougall, a senior scientist at GrammaTech, says, “JPL was already using CodeSonar to check its software; however, there are things that might be acceptable in a desktop application that are unacceptable in an environment like on Mars or the Moon. CodeSonar didn’t have rules specifically crafted for this type of critical software.” After successfully adapting CodeSonar to check for the NASA-derived rules, GrammaTech transitioned the changes into its commercial version of the product in 2008. \n            Benefits\n            As a static analysis tool, CodeSonar finds problems in software without executing any part of the program. The tool produces a list of potential violations, including complex programming bugs that can result in system crashes and memory corruption. Compared to traditional software testing methods, CodeSonar checks more code in less time and saves time and expense by finding problems before the software is completed and distributed to users. \n            \n              \n              \n                \n              \n              \n                Items as varied as infusion pumps, cell phones, and aircraft components are made using CodeSonar, a product from GrammaTech Inc. that incorporates rules developed at the Jet Propulsion Laboratory, to quickly find problems in the products’ software.\n              \n            \n            The design of CodeSonar allows users to configure how thoroughly it performs a check. The tool can warn about every potential issue, only critical violations, or a combination of both. McDougall explains, “Depending on the application, the software may not need to be as reliable as a Mars rover, but it can still be troublesome if it crashes at the wrong time. Users can choose the level of compliance that suits their context.”\n            Today, CodeSonar has hundreds of users worldwide, including Fortune 500 companies, startup businesses, educational institutions, and government agencies working on satellites, avionics, industrial controls, medical devices, wireless devices, networking equipment, and consumer electronics.\n            In response to a widespread medical device recall, the U.S. Food and Drug Administration (FDA) started encouraging manufacturers of infusion pumps to utilize static code analysis tools like CodeSonar to check the pumps’ software. Commonly used to deliver fluids into a patient’s body, infusion pumps have been responsible for a number of deaths and injuries since 2005. In one instance, investigators at the FDA used CodeSonar to help determine the root cause of malfunction in a widely-deployed, commercial infusion pump. \n            Cell phone developers like LG Electronics Inc., Samsung, and Panasonic are also using CodeSonar. McDougall explains, “Cell phones are expected to function 24 hours a day, 7 days a week. The software that runs the internal cell phone, changes what is on the screen, and manages the address book, all has to be very reliable. Users do not want to have to reboot or install updates in the middle of a phone call.”\n            GE Aviation, a provider of jet engines and components, as well as avionics, electric power, and mechanical systems for aircraft, uses CodeSonar to ensure the software in aircraft functions properly. “Software is an important part of engine design, and a lot of how planes work is controlled by software. You want it to be perfect—or as close to perfect as possible,” says McDougall.\n            With public and private entities employing CodeSonar, Holzmann is hopeful that more organizations will be inspired to improve software development practice. “If the technology continues to be adopted, we will have made a contribution to making the computer systems we rely on safer and more reliable,” he says.\n            Since developing The Power of 10, Holzmann has devised a single coding standard called the JPL Institutional Coding Standard for the Development of Flight Software. McDougall expects the standard will be incorporated in the next commercial version of CodeSonar.\n            CodeSonar® is a registered trademark of GrammaTech Inc.\n            "},{"href":"http://spinoff.nasa.gov/Spinoff2011/it_4.html","text":"Electronic Handbooks Simplify Process Management","image":"http://spinoff.nasa.gov/Spinoff2011/Images/it_4a_opt.jpg","story":"\n    \n      \n        \n          \n            \n              NASA Technology \n              Getting a multitude of people to work together to manage processes across many organizations —for example, flight projects, research, technologies, or data centers and others—is not an easy task. Just ask Dr. Barry E. Jacobs, a research computer scientist at Goddard Space Flight Center. He helped NASA develop a process management solution that provided documenting tools for process developers and participants to help them quickly learn, adapt, test, and teach their views. Some of these tools included editable files for subprocess descriptions, document descriptions, role guidelines, manager worksheets, and references. \n              First utilized for NASA’s Headquarters Directives Management process, the approach led to the invention of a concept called the Electronic Handbook (EHB). This EHB concept was successfully applied to NASA’s Small Business Innovation Research (SBIR) and Small Business Technology Transfer (STTR) programs, among other NASA programs. Several Federal agencies showed interest in the concept, so Jacobs and his team visited these agencies to show them how their specific processes could be managed by the methodology, as well as to create mock-up versions of the EHBs.\n              Partnership\n              \n                \n                \n                  \n                \n                \n                  NASA’s SBIR program provides opportunities for small businesses to participate in research and development projects. The STTR program awards contracts to small businesses for cooperative research and development with a non-profit research institution, such as a university.\n                \n              \n              In partnership with NASA and under the guidance of Jacobs, REI Systems, a Herndon, Virginia-based small business, received a NASA SBIR award in 1989 to build an integrated, uniform, and extensible framework for storage, retrieval, and update of heterogeneous objects. REI’s solution employed the NASA-developed EHB paradigm. \n              Using a familiar, easy-to-learn “handbook” interface, the EHB guides each user through complicated procedures that formerly required using multiple paper documents or legacy systems. This web-based business process management system was used to automate, integrate, execute, and optimize the business processes for NASA’s SBIR and STTR programs, which receive approximately 2,500 Phase I and Phase II proposals annually.\n              The team worked closely with the stakeholders at every level in order to fully understand the roles and business processes involved, which helped ensure the successful functionality, efficiency, and usability of the system. The way Jacobs sees it, “To truly understand one’s universe, one must see it through multiple ‘eyes’ and also have tools to communicate these views.” \n              The first NASA SBIR/STTR EHB was deployed in 1996 for the Phase I Review and Selection process. Now, the NASA SBIR/STTR EHB is a complete end-to-end paperless system for management of the SBIR/STTR programs ranging from solicitation development to contract administration processes and commercialization. The EHB continues to be used by all program participants, with approximately 6,000 active users from NASA Centers and firms.\n              According to REI, each firm that uses the EHB system to apply to the NASA programs saves the costs associated with printing and mailing of eight paper copies. For NASA, there has been a more than 30-percent reduction in the time required for processing, with commensurate reductions in the effort to manage the paper submissions. \n              Benefits\n              Originally featured in Spinoff 2001, REI has grown from a startup to a large business that provides a variety of Web-enabled, database-driven knowledge management and performance support solutions for Federal agencies, State governments, and the commercial sector. REI Systems continues to innovate with the EHB concept nurtured by NASA 22 years ago.\n              \n                \n                \n                  \n                \n                \n                  With support from the NASA SBIR program, Argonide Corporation developed nanofiber water filter media to remove viruses and other particles from water. The electronic handbook system that managed this partnership—and many others—was developed by REI Systems.\n                \n              \n              REI Systems has taken its NASA Small Business Innovation Research (SBIR) domain knowledge to other agencies \n                for their SBIR programs.\n              \n              The company has applied the approach to managing information in every one of their custom software applications that manage the grants-making processes for Federal agencies as diverse as the Federal Emergency Management Agency, the Health Resources and Services Administration (HRSA), the Department of Homeland Security (DHS), the Department of Justice, and the Department of Energy (DOE). Specifically, REI’s NASA-derived EHB model has more than 60,000 users with over $6 billion in financial transactions per year. \n              REI has also taken its NASA SBIR domain knowledge to other agencies—DHS’s Science and Technology, the Small Business Administration, and DOE—where it is currently developing systems for their SBIR programs. In turn, REI has leveraged its open government and dashboarding solutions for the Office of Management and Budget and the General Services Administration (Recovery.gov, ITDashboard.gov, and USASpending.gov are some eGov sites developed by REI) and brought those solutions back to NASA to provide data visualization capabilities. Innovation with the EHB has been a two-way street.\n              According to REI, EHBs create a system that has lower maintenance, support, and upgrade costs, as well as reduced publication, distribution, and storage costs. An organization using an EHB will benefit from increased productivity and efficiency, enhanced communication and collaboration, enterprise-wide knowledge management, and increased data quality and accuracy. Samidha Manu, senior program manager at REI, says, “We look at what our customers’ needs are, and then we provide what makes the most sense in an automated tool. The big push is to make the process efficient, to make it work more effectively.” \n              REI’s largest EHB-based system supports HRSA, an agency of the Department of Health and Human Services, to provide competitively awarded grant funding to states and localities in providing healthcare and affiliated services to underserved communities nationwide. The EHB supports more than 300 grant programs and cooperative agreements, more than 10,000 grantees, and 1,500 HRSA employees. \n              Manu expresses appreciation to NASA for helping REI get to where it is today. “The tools deployed for NASA Goddard, in one form or another, have been adapted to the technology or solutions that we are deploying for other Federal agencies and doing a variety of things we probably never anticipated,” she says. “In 1998, there were hardly any Federal Internet applications to speak of. Since then, all types of Web applications have exploded.”\n            \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              NASA Technology \n              Getting a multitude of people to work together to manage processes across many organizations —for example, flight projects, research, technologies, or data centers and others—is not an easy task. Just ask Dr. Barry E. Jacobs, a research computer scientist at Goddard Space Flight Center. He helped NASA develop a process management solution that provided documenting tools for process developers and participants to help them quickly learn, adapt, test, and teach their views. Some of these tools included editable files for subprocess descriptions, document descriptions, role guidelines, manager worksheets, and references. \n              First utilized for NASA’s Headquarters Directives Management process, the approach led to the invention of a concept called the Electronic Handbook (EHB). This EHB concept was successfully applied to NASA’s Small Business Innovation Research (SBIR) and Small Business Technology Transfer (STTR) programs, among other NASA programs. Several Federal agencies showed interest in the concept, so Jacobs and his team visited these agencies to show them how their specific processes could be managed by the methodology, as well as to create mock-up versions of the EHBs.\n              Partnership\n              \n                \n                \n                  \n                \n                \n                  NASA’s SBIR program provides opportunities for small businesses to participate in research and development projects. The STTR program awards contracts to small businesses for cooperative research and development with a non-profit research institution, such as a university.\n                \n              \n              In partnership with NASA and under the guidance of Jacobs, REI Systems, a Herndon, Virginia-based small business, received a NASA SBIR award in 1989 to build an integrated, uniform, and extensible framework for storage, retrieval, and update of heterogeneous objects. REI’s solution employed the NASA-developed EHB paradigm. \n              Using a familiar, easy-to-learn “handbook” interface, the EHB guides each user through complicated procedures that formerly required using multiple paper documents or legacy systems. This web-based business process management system was used to automate, integrate, execute, and optimize the business processes for NASA’s SBIR and STTR programs, which receive approximately 2,500 Phase I and Phase II proposals annually.\n              The team worked closely with the stakeholders at every level in order to fully understand the roles and business processes involved, which helped ensure the successful functionality, efficiency, and usability of the system. The way Jacobs sees it, “To truly understand one’s universe, one must see it through multiple ‘eyes’ and also have tools to communicate these views.” \n              The first NASA SBIR/STTR EHB was deployed in 1996 for the Phase I Review and Selection process. Now, the NASA SBIR/STTR EHB is a complete end-to-end paperless system for management of the SBIR/STTR programs ranging from solicitation development to contract administration processes and commercialization. The EHB continues to be used by all program participants, with approximately 6,000 active users from NASA Centers and firms.\n              According to REI, each firm that uses the EHB system to apply to the NASA programs saves the costs associated with printing and mailing of eight paper copies. For NASA, there has been a more than 30-percent reduction in the time required for processing, with commensurate reductions in the effort to manage the paper submissions. \n              Benefits\n              Originally featured in Spinoff 2001, REI has grown from a startup to a large business that provides a variety of Web-enabled, database-driven knowledge management and performance support solutions for Federal agencies, State governments, and the commercial sector. REI Systems continues to innovate with the EHB concept nurtured by NASA 22 years ago.\n              \n                \n                \n                  \n                \n                \n                  With support from the NASA SBIR program, Argonide Corporation developed nanofiber water filter media to remove viruses and other particles from water. The electronic handbook system that managed this partnership—and many others—was developed by REI Systems.\n                \n              \n              REI Systems has taken its NASA Small Business Innovation Research (SBIR) domain knowledge to other agencies \n                for their SBIR programs.\n              \n              The company has applied the approach to managing information in every one of their custom software applications that manage the grants-making processes for Federal agencies as diverse as the Federal Emergency Management Agency, the Health Resources and Services Administration (HRSA), the Department of Homeland Security (DHS), the Department of Justice, and the Department of Energy (DOE). Specifically, REI’s NASA-derived EHB model has more than 60,000 users with over $6 billion in financial transactions per year. \n              REI has also taken its NASA SBIR domain knowledge to other agencies—DHS’s Science and Technology, the Small Business Administration, and DOE—where it is currently developing systems for their SBIR programs. In turn, REI has leveraged its open government and dashboarding solutions for the Office of Management and Budget and the General Services Administration (Recovery.gov, ITDashboard.gov, and USASpending.gov are some eGov sites developed by REI) and brought those solutions back to NASA to provide data visualization capabilities. Innovation with the EHB has been a two-way street.\n              According to REI, EHBs create a system that has lower maintenance, support, and upgrade costs, as well as reduced publication, distribution, and storage costs. An organization using an EHB will benefit from increased productivity and efficiency, enhanced communication and collaboration, enterprise-wide knowledge management, and increased data quality and accuracy. Samidha Manu, senior program manager at REI, says, “We look at what our customers’ needs are, and then we provide what makes the most sense in an automated tool. The big push is to make the process efficient, to make it work more effectively.” \n              REI’s largest EHB-based system supports HRSA, an agency of the Department of Health and Human Services, to provide competitively awarded grant funding to states and localities in providing healthcare and affiliated services to underserved communities nationwide. The EHB supports more than 300 grant programs and cooperative agreements, more than 10,000 grantees, and 1,500 HRSA employees. \n              Manu expresses appreciation to NASA for helping REI get to where it is today. “The tools deployed for NASA Goddard, in one form or another, have been adapted to the technology or solutions that we are deploying for other Federal agencies and doing a variety of things we probably never anticipated,” she says. “In 1998, there were hardly any Federal Internet applications to speak of. Since then, all types of Web applications have exploded.”\n            \n            \n          \n        \n      \n          \n            \n              NASA Technology \n              Getting a multitude of people to work together to manage processes across many organizations —for example, flight projects, research, technologies, or data centers and others—is not an easy task. Just ask Dr. Barry E. Jacobs, a research computer scientist at Goddard Space Flight Center. He helped NASA develop a process management solution that provided documenting tools for process developers and participants to help them quickly learn, adapt, test, and teach their views. Some of these tools included editable files for subprocess descriptions, document descriptions, role guidelines, manager worksheets, and references. \n              First utilized for NASA’s Headquarters Directives Management process, the approach led to the invention of a concept called the Electronic Handbook (EHB). This EHB concept was successfully applied to NASA’s Small Business Innovation Research (SBIR) and Small Business Technology Transfer (STTR) programs, among other NASA programs. Several Federal agencies showed interest in the concept, so Jacobs and his team visited these agencies to show them how their specific processes could be managed by the methodology, as well as to create mock-up versions of the EHBs.\n              Partnership\n              \n                \n                \n                  \n                \n                \n                  NASA’s SBIR program provides opportunities for small businesses to participate in research and development projects. The STTR program awards contracts to small businesses for cooperative research and development with a non-profit research institution, such as a university.\n                \n              \n              In partnership with NASA and under the guidance of Jacobs, REI Systems, a Herndon, Virginia-based small business, received a NASA SBIR award in 1989 to build an integrated, uniform, and extensible framework for storage, retrieval, and update of heterogeneous objects. REI’s solution employed the NASA-developed EHB paradigm. \n              Using a familiar, easy-to-learn “handbook” interface, the EHB guides each user through complicated procedures that formerly required using multiple paper documents or legacy systems. This web-based business process management system was used to automate, integrate, execute, and optimize the business processes for NASA’s SBIR and STTR programs, which receive approximately 2,500 Phase I and Phase II proposals annually.\n              The team worked closely with the stakeholders at every level in order to fully understand the roles and business processes involved, which helped ensure the successful functionality, efficiency, and usability of the system. The way Jacobs sees it, “To truly understand one’s universe, one must see it through multiple ‘eyes’ and also have tools to communicate these views.” \n              The first NASA SBIR/STTR EHB was deployed in 1996 for the Phase I Review and Selection process. Now, the NASA SBIR/STTR EHB is a complete end-to-end paperless system for management of the SBIR/STTR programs ranging from solicitation development to contract administration processes and commercialization. The EHB continues to be used by all program participants, with approximately 6,000 active users from NASA Centers and firms.\n              According to REI, each firm that uses the EHB system to apply to the NASA programs saves the costs associated with printing and mailing of eight paper copies. For NASA, there has been a more than 30-percent reduction in the time required for processing, with commensurate reductions in the effort to manage the paper submissions. \n              Benefits\n              Originally featured in Spinoff 2001, REI has grown from a startup to a large business that provides a variety of Web-enabled, database-driven knowledge management and performance support solutions for Federal agencies, State governments, and the commercial sector. REI Systems continues to innovate with the EHB concept nurtured by NASA 22 years ago.\n              \n                \n                \n                  \n                \n                \n                  With support from the NASA SBIR program, Argonide Corporation developed nanofiber water filter media to remove viruses and other particles from water. The electronic handbook system that managed this partnership—and many others—was developed by REI Systems.\n                \n              \n              REI Systems has taken its NASA Small Business Innovation Research (SBIR) domain knowledge to other agencies \n                for their SBIR programs.\n              \n              The company has applied the approach to managing information in every one of their custom software applications that manage the grants-making processes for Federal agencies as diverse as the Federal Emergency Management Agency, the Health Resources and Services Administration (HRSA), the Department of Homeland Security (DHS), the Department of Justice, and the Department of Energy (DOE). Specifically, REI’s NASA-derived EHB model has more than 60,000 users with over $6 billion in financial transactions per year. \n              REI has also taken its NASA SBIR domain knowledge to other agencies—DHS’s Science and Technology, the Small Business Administration, and DOE—where it is currently developing systems for their SBIR programs. In turn, REI has leveraged its open government and dashboarding solutions for the Office of Management and Budget and the General Services Administration (Recovery.gov, ITDashboard.gov, and USASpending.gov are some eGov sites developed by REI) and brought those solutions back to NASA to provide data visualization capabilities. Innovation with the EHB has been a two-way street.\n              According to REI, EHBs create a system that has lower maintenance, support, and upgrade costs, as well as reduced publication, distribution, and storage costs. An organization using an EHB will benefit from increased productivity and efficiency, enhanced communication and collaboration, enterprise-wide knowledge management, and increased data quality and accuracy. Samidha Manu, senior program manager at REI, says, “We look at what our customers’ needs are, and then we provide what makes the most sense in an automated tool. The big push is to make the process efficient, to make it work more effectively.” \n              REI’s largest EHB-based system supports HRSA, an agency of the Department of Health and Human Services, to provide competitively awarded grant funding to states and localities in providing healthcare and affiliated services to underserved communities nationwide. The EHB supports more than 300 grant programs and cooperative agreements, more than 10,000 grantees, and 1,500 HRSA employees. \n              Manu expresses appreciation to NASA for helping REI get to where it is today. “The tools deployed for NASA Goddard, in one form or another, have been adapted to the technology or solutions that we are deploying for other Federal agencies and doing a variety of things we probably never anticipated,” she says. “In 1998, there were hardly any Federal Internet applications to speak of. Since then, all types of Web applications have exploded.”\n            \n            \n          \n            \n              NASA Technology \n              Getting a multitude of people to work together to manage processes across many organizations —for example, flight projects, research, technologies, or data centers and others—is not an easy task. Just ask Dr. Barry E. Jacobs, a research computer scientist at Goddard Space Flight Center. He helped NASA develop a process management solution that provided documenting tools for process developers and participants to help them quickly learn, adapt, test, and teach their views. Some of these tools included editable files for subprocess descriptions, document descriptions, role guidelines, manager worksheets, and references. \n              First utilized for NASA’s Headquarters Directives Management process, the approach led to the invention of a concept called the Electronic Handbook (EHB). This EHB concept was successfully applied to NASA’s Small Business Innovation Research (SBIR) and Small Business Technology Transfer (STTR) programs, among other NASA programs. Several Federal agencies showed interest in the concept, so Jacobs and his team visited these agencies to show them how their specific processes could be managed by the methodology, as well as to create mock-up versions of the EHBs.\n              Partnership\n              \n                \n                \n                  \n                \n                \n                  NASA’s SBIR program provides opportunities for small businesses to participate in research and development projects. The STTR program awards contracts to small businesses for cooperative research and development with a non-profit research institution, such as a university.\n                \n              \n              In partnership with NASA and under the guidance of Jacobs, REI Systems, a Herndon, Virginia-based small business, received a NASA SBIR award in 1989 to build an integrated, uniform, and extensible framework for storage, retrieval, and update of heterogeneous objects. REI’s solution employed the NASA-developed EHB paradigm. \n              Using a familiar, easy-to-learn “handbook” interface, the EHB guides each user through complicated procedures that formerly required using multiple paper documents or legacy systems. This web-based business process management system was used to automate, integrate, execute, and optimize the business processes for NASA’s SBIR and STTR programs, which receive approximately 2,500 Phase I and Phase II proposals annually.\n              The team worked closely with the stakeholders at every level in order to fully understand the roles and business processes involved, which helped ensure the successful functionality, efficiency, and usability of the system. The way Jacobs sees it, “To truly understand one’s universe, one must see it through multiple ‘eyes’ and also have tools to communicate these views.” \n              The first NASA SBIR/STTR EHB was deployed in 1996 for the Phase I Review and Selection process. Now, the NASA SBIR/STTR EHB is a complete end-to-end paperless system for management of the SBIR/STTR programs ranging from solicitation development to contract administration processes and commercialization. The EHB continues to be used by all program participants, with approximately 6,000 active users from NASA Centers and firms.\n              According to REI, each firm that uses the EHB system to apply to the NASA programs saves the costs associated with printing and mailing of eight paper copies. For NASA, there has been a more than 30-percent reduction in the time required for processing, with commensurate reductions in the effort to manage the paper submissions. \n              Benefits\n              Originally featured in Spinoff 2001, REI has grown from a startup to a large business that provides a variety of Web-enabled, database-driven knowledge management and performance support solutions for Federal agencies, State governments, and the commercial sector. REI Systems continues to innovate with the EHB concept nurtured by NASA 22 years ago.\n              \n                \n                \n                  \n                \n                \n                  With support from the NASA SBIR program, Argonide Corporation developed nanofiber water filter media to remove viruses and other particles from water. The electronic handbook system that managed this partnership—and many others—was developed by REI Systems.\n                \n              \n              REI Systems has taken its NASA Small Business Innovation Research (SBIR) domain knowledge to other agencies \n                for their SBIR programs.\n              \n              The company has applied the approach to managing information in every one of their custom software applications that manage the grants-making processes for Federal agencies as diverse as the Federal Emergency Management Agency, the Health Resources and Services Administration (HRSA), the Department of Homeland Security (DHS), the Department of Justice, and the Department of Energy (DOE). Specifically, REI’s NASA-derived EHB model has more than 60,000 users with over $6 billion in financial transactions per year. \n              REI has also taken its NASA SBIR domain knowledge to other agencies—DHS’s Science and Technology, the Small Business Administration, and DOE—where it is currently developing systems for their SBIR programs. In turn, REI has leveraged its open government and dashboarding solutions for the Office of Management and Budget and the General Services Administration (Recovery.gov, ITDashboard.gov, and USASpending.gov are some eGov sites developed by REI) and brought those solutions back to NASA to provide data visualization capabilities. Innovation with the EHB has been a two-way street.\n              According to REI, EHBs create a system that has lower maintenance, support, and upgrade costs, as well as reduced publication, distribution, and storage costs. An organization using an EHB will benefit from increased productivity and efficiency, enhanced communication and collaboration, enterprise-wide knowledge management, and increased data quality and accuracy. Samidha Manu, senior program manager at REI, says, “We look at what our customers’ needs are, and then we provide what makes the most sense in an automated tool. The big push is to make the process efficient, to make it work more effectively.” \n              REI’s largest EHB-based system supports HRSA, an agency of the Department of Health and Human Services, to provide competitively awarded grant funding to states and localities in providing healthcare and affiliated services to underserved communities nationwide. The EHB supports more than 300 grant programs and cooperative agreements, more than 10,000 grantees, and 1,500 HRSA employees. \n              Manu expresses appreciation to NASA for helping REI get to where it is today. “The tools deployed for NASA Goddard, in one form or another, have been adapted to the technology or solutions that we are deploying for other Federal agencies and doing a variety of things we probably never anticipated,” she says. “In 1998, there were hardly any Federal Internet applications to speak of. Since then, all types of Web applications have exploded.”\n            \n            \n              NASA Technology \n              Getting a multitude of people to work together to manage processes across many organizations —for example, flight projects, research, technologies, or data centers and others—is not an easy task. Just ask Dr. Barry E. Jacobs, a research computer scientist at Goddard Space Flight Center. He helped NASA develop a process management solution that provided documenting tools for process developers and participants to help them quickly learn, adapt, test, and teach their views. Some of these tools included editable files for subprocess descriptions, document descriptions, role guidelines, manager worksheets, and references. \n              First utilized for NASA’s Headquarters Directives Management process, the approach led to the invention of a concept called the Electronic Handbook (EHB). This EHB concept was successfully applied to NASA’s Small Business Innovation Research (SBIR) and Small Business Technology Transfer (STTR) programs, among other NASA programs. Several Federal agencies showed interest in the concept, so Jacobs and his team visited these agencies to show them how their specific processes could be managed by the methodology, as well as to create mock-up versions of the EHBs.\n              Partnership\n              \n                \n                \n                  \n                \n                \n                  NASA’s SBIR program provides opportunities for small businesses to participate in research and development projects. The STTR program awards contracts to small businesses for cooperative research and development with a non-profit research institution, such as a university.\n                \n              \n              In partnership with NASA and under the guidance of Jacobs, REI Systems, a Herndon, Virginia-based small business, received a NASA SBIR award in 1989 to build an integrated, uniform, and extensible framework for storage, retrieval, and update of heterogeneous objects. REI’s solution employed the NASA-developed EHB paradigm. \n              Using a familiar, easy-to-learn “handbook” interface, the EHB guides each user through complicated procedures that formerly required using multiple paper documents or legacy systems. This web-based business process management system was used to automate, integrate, execute, and optimize the business processes for NASA’s SBIR and STTR programs, which receive approximately 2,500 Phase I and Phase II proposals annually.\n              The team worked closely with the stakeholders at every level in order to fully understand the roles and business processes involved, which helped ensure the successful functionality, efficiency, and usability of the system. The way Jacobs sees it, “To truly understand one’s universe, one must see it through multiple ‘eyes’ and also have tools to communicate these views.” \n              The first NASA SBIR/STTR EHB was deployed in 1996 for the Phase I Review and Selection process. Now, the NASA SBIR/STTR EHB is a complete end-to-end paperless system for management of the SBIR/STTR programs ranging from solicitation development to contract administration processes and commercialization. The EHB continues to be used by all program participants, with approximately 6,000 active users from NASA Centers and firms.\n              According to REI, each firm that uses the EHB system to apply to the NASA programs saves the costs associated with printing and mailing of eight paper copies. For NASA, there has been a more than 30-percent reduction in the time required for processing, with commensurate reductions in the effort to manage the paper submissions. \n              Benefits\n              Originally featured in Spinoff 2001, REI has grown from a startup to a large business that provides a variety of Web-enabled, database-driven knowledge management and performance support solutions for Federal agencies, State governments, and the commercial sector. REI Systems continues to innovate with the EHB concept nurtured by NASA 22 years ago.\n              \n                \n                \n                  \n                \n                \n                  With support from the NASA SBIR program, Argonide Corporation developed nanofiber water filter media to remove viruses and other particles from water. The electronic handbook system that managed this partnership—and many others—was developed by REI Systems.\n                \n              \n              REI Systems has taken its NASA Small Business Innovation Research (SBIR) domain knowledge to other agencies \n                for their SBIR programs.\n              \n              The company has applied the approach to managing information in every one of their custom software applications that manage the grants-making processes for Federal agencies as diverse as the Federal Emergency Management Agency, the Health Resources and Services Administration (HRSA), the Department of Homeland Security (DHS), the Department of Justice, and the Department of Energy (DOE). Specifically, REI’s NASA-derived EHB model has more than 60,000 users with over $6 billion in financial transactions per year. \n              REI has also taken its NASA SBIR domain knowledge to other agencies—DHS’s Science and Technology, the Small Business Administration, and DOE—where it is currently developing systems for their SBIR programs. In turn, REI has leveraged its open government and dashboarding solutions for the Office of Management and Budget and the General Services Administration (Recovery.gov, ITDashboard.gov, and USASpending.gov are some eGov sites developed by REI) and brought those solutions back to NASA to provide data visualization capabilities. Innovation with the EHB has been a two-way street.\n              According to REI, EHBs create a system that has lower maintenance, support, and upgrade costs, as well as reduced publication, distribution, and storage costs. An organization using an EHB will benefit from increased productivity and efficiency, enhanced communication and collaboration, enterprise-wide knowledge management, and increased data quality and accuracy. Samidha Manu, senior program manager at REI, says, “We look at what our customers’ needs are, and then we provide what makes the most sense in an automated tool. The big push is to make the process efficient, to make it work more effectively.” \n              REI’s largest EHB-based system supports HRSA, an agency of the Department of Health and Human Services, to provide competitively awarded grant funding to states and localities in providing healthcare and affiliated services to underserved communities nationwide. The EHB supports more than 300 grant programs and cooperative agreements, more than 10,000 grantees, and 1,500 HRSA employees. \n              Manu expresses appreciation to NASA for helping REI get to where it is today. “The tools deployed for NASA Goddard, in one form or another, have been adapted to the technology or solutions that we are deploying for other Federal agencies and doing a variety of things we probably never anticipated,” she says. “In 1998, there were hardly any Federal Internet applications to speak of. Since then, all types of Web applications have exploded.”\n            "},{"href":"http://spinoff.nasa.gov/Spinoff2011/it_5.html","text":"Software Innovations Speed Scientific Computing","image":"http://spinoff.nasa.gov/Spinoff2011/Images/it_5_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                NASA Technology\n                What causes the Sun to change? And what are the impacts on our planet and our daily lives? \n                These are some of the top questions that the Heliophysics Division of NASA’s Science Mission Directorate is seeking answers to through a variety of missions to study the Sun. The most recent, the Solar Dynamics Observatory (SDO), launched in 2010, beams back 150 million bits of data per second—almost 50 times more science data than any other mission in NASA history. As a result, SDO’s instruments are giving solar scientists an unprecedented look at the Sun.\n                On a similar mission, NASA’s Reuven Ramaty High Energy Solar Spectroscope Imager (RHESSI) launched in 2002 to gather a wealth of data to construct images of the Sun. To create meaningful visualizations out of the vast data, much of it has been deciphered using a computer programming language called Interactive Data Language (IDL). In addition to studying the Sun, there is widespread use of IDL throughout NASA to process data, analyze images, perform computations, and make simulation models.\n                “There are very innovative people on the Agency side who see the potential of technologies and, in collaboration with small businesses, can make leading-edge technologies happen.”\n                  —Peter Messmer, Tech-X Corporation\n                As NASA missions continue to produce an increased amount of data, and as computational procedures become increasingly complex, NASA requires ever greater computing power. \n                Partnership\n                To help reduce the time needed to analyze data from missions like those studying the Sun, Goddard Space Flight Center awarded a Small Business Innovation Research (SBIR) contract in 2004 to Tech-X Corporation of Boulder, Colorado. \n                \n                  \n                  \n                    \n                  \n                  \n                    NASA requires increased computing power to process images like this one of the Sun, created by the Solar Dynamics Observatory in September of 2010. \n                  \n                \n                Through Phase I and II SBIRs, Tech-X demonstrated software capable of running IDL applications on linked computers, or cluster systems. The computers worked together to form a single system, without requiring significant modification to the original program. \n                By enabling IDL to work on clusters, Tech-X created a technology that increased performance in a familiar programming environment for NASA scientists, while reducing the time needed to analyze large amounts of data. Today, this software is available in Tech-X’s commercial product called FastDL.\n                After the demonstration of FastDL for NASA, something unexpected happened. “Toward the end of the Phase II SBIR, we started to redirect the proposal to investigate the usability of graphics processing units to help scientists accelerate their data analysis tasks,” explains Peter Messmer, vice president of the space applications group at Tech-X. “That was the beginning of the GPULib product that we are now offering at Tech-X.” \n                At the time, graphics processing units (GPUs) were mainly used for 3D gaming graphics, but the technology was becoming more commonly used to accelerate scientific computing. Messmer says Tech-X wanted to use one piece of hardware—a GPU—rather than several pieces, to make the computations faster. \n                Today, Tech-X attributes the initial development of GPULib, which makes available a library of mathematical functions to facilitate the use of GPUs for scientific computing, to its work with NASA. “There are very innovative people on the Agency side who see the potential of technologies and, in collaboration with small businesses, can make leading-edge technologies happen,” says Messmer.\n                Benefits\n                By 2008, NASA scientists were using Tech-X’s parallel computing tools to process large quantities of visual data from the RHESSI mission 10–40 times faster than they could previously. In applying FastDL to NASA’s Solar and Heliospheric Observatory, Tech-X processed data more than seven times faster on a cluster of 12 processors. \n                Over the past 5 years, government contracts and products including FastDL and GPULib have helped the company to double its number of headquarters employees to 70. Commercially available for 6 years, FastDL has earned about $90,000 in revenue for Tech-X. GPULib, available for 2 years, has earned about $100,000 in revenue.\n                Messmer says that what makes these products so unique is that they target IDL, which is widely used by engineers, scientists, analysts, and other technical professionals in satellite, medical, and astrophysical imaging.\n                Using FastDL, scientists and developers can run IDL visualization and analyses applications using several computers at once to shorten the time required to get results. Because not every visualization and analysis problem can be solved using the same parallel computing paradigm, FastDL includes two components: TaskDL (for independent computations) and mpiDL (for interdependent computations). \n                The other NASA-derived product, GPULib, supplies a mathematical library that simplifies access to parallel computing on a GPU. It brings high-performance numerical operations to everyday desktop computers with an easy-to-use interface. According to Tech-X, the time it takes for implementations of common mathematical operations is 5–40 times faster using the technology. \n                Available under two licensing arrangements, Messmer says there have been close to 10,000 downloads of GPULib from Tech-X’s website. \n                Scientists in a variety of fields can benefit from the increased execution speed allowed by GPULib in application areas such as structural and fluid mechanics, Earth sciences, biosciences, medical and diagnostic imaging, and financial engineering. Current applications for simulation and modeling include computational fluid dynamics, tsunami modeling, galaxy formation, and neural-tissue simulations. In data analysis, applications include image enhancement, deblurring, real-time image processing, hyperspectral imaging, astronomical imaging, medical imaging, and seismic data processing.\n                At the Department of Radiation Oncology at Loyola University in Maywood, Illinois, the software is used for aligning patients on a treatment table before and after X-ray imaging, a computationally-demanding application that needs to be performed quickly. John Roeske, Director of Radiation Physics at the university, says, “Ordinarily, the approach would take 5–10 seconds. Using the GPULib we feel we can get the alignment to better than a second.” \n                Alongside medical imaging, Tech-X is focusing on providing custom products for applications in remote sensing and gaming. “The future as we see it is to provide domain-specific programs for different applications,” says Messmer. \n                What will come next? And what are the impacts on processing speed? \n                These are some of the top questions that Tech-X is seeking answers to through additional SBIRs with NASA to reveal more about Earth and the universe.\n              \n              \n              \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                NASA Technology\n                What causes the Sun to change? And what are the impacts on our planet and our daily lives? \n                These are some of the top questions that the Heliophysics Division of NASA’s Science Mission Directorate is seeking answers to through a variety of missions to study the Sun. The most recent, the Solar Dynamics Observatory (SDO), launched in 2010, beams back 150 million bits of data per second—almost 50 times more science data than any other mission in NASA history. As a result, SDO’s instruments are giving solar scientists an unprecedented look at the Sun.\n                On a similar mission, NASA’s Reuven Ramaty High Energy Solar Spectroscope Imager (RHESSI) launched in 2002 to gather a wealth of data to construct images of the Sun. To create meaningful visualizations out of the vast data, much of it has been deciphered using a computer programming language called Interactive Data Language (IDL). In addition to studying the Sun, there is widespread use of IDL throughout NASA to process data, analyze images, perform computations, and make simulation models.\n                “There are very innovative people on the Agency side who see the potential of technologies and, in collaboration with small businesses, can make leading-edge technologies happen.”\n                  —Peter Messmer, Tech-X Corporation\n                As NASA missions continue to produce an increased amount of data, and as computational procedures become increasingly complex, NASA requires ever greater computing power. \n                Partnership\n                To help reduce the time needed to analyze data from missions like those studying the Sun, Goddard Space Flight Center awarded a Small Business Innovation Research (SBIR) contract in 2004 to Tech-X Corporation of Boulder, Colorado. \n                \n                  \n                  \n                    \n                  \n                  \n                    NASA requires increased computing power to process images like this one of the Sun, created by the Solar Dynamics Observatory in September of 2010. \n                  \n                \n                Through Phase I and II SBIRs, Tech-X demonstrated software capable of running IDL applications on linked computers, or cluster systems. The computers worked together to form a single system, without requiring significant modification to the original program. \n                By enabling IDL to work on clusters, Tech-X created a technology that increased performance in a familiar programming environment for NASA scientists, while reducing the time needed to analyze large amounts of data. Today, this software is available in Tech-X’s commercial product called FastDL.\n                After the demonstration of FastDL for NASA, something unexpected happened. “Toward the end of the Phase II SBIR, we started to redirect the proposal to investigate the usability of graphics processing units to help scientists accelerate their data analysis tasks,” explains Peter Messmer, vice president of the space applications group at Tech-X. “That was the beginning of the GPULib product that we are now offering at Tech-X.” \n                At the time, graphics processing units (GPUs) were mainly used for 3D gaming graphics, but the technology was becoming more commonly used to accelerate scientific computing. Messmer says Tech-X wanted to use one piece of hardware—a GPU—rather than several pieces, to make the computations faster. \n                Today, Tech-X attributes the initial development of GPULib, which makes available a library of mathematical functions to facilitate the use of GPUs for scientific computing, to its work with NASA. “There are very innovative people on the Agency side who see the potential of technologies and, in collaboration with small businesses, can make leading-edge technologies happen,” says Messmer.\n                Benefits\n                By 2008, NASA scientists were using Tech-X’s parallel computing tools to process large quantities of visual data from the RHESSI mission 10–40 times faster than they could previously. In applying FastDL to NASA’s Solar and Heliospheric Observatory, Tech-X processed data more than seven times faster on a cluster of 12 processors. \n                Over the past 5 years, government contracts and products including FastDL and GPULib have helped the company to double its number of headquarters employees to 70. Commercially available for 6 years, FastDL has earned about $90,000 in revenue for Tech-X. GPULib, available for 2 years, has earned about $100,000 in revenue.\n                Messmer says that what makes these products so unique is that they target IDL, which is widely used by engineers, scientists, analysts, and other technical professionals in satellite, medical, and astrophysical imaging.\n                Using FastDL, scientists and developers can run IDL visualization and analyses applications using several computers at once to shorten the time required to get results. Because not every visualization and analysis problem can be solved using the same parallel computing paradigm, FastDL includes two components: TaskDL (for independent computations) and mpiDL (for interdependent computations). \n                The other NASA-derived product, GPULib, supplies a mathematical library that simplifies access to parallel computing on a GPU. It brings high-performance numerical operations to everyday desktop computers with an easy-to-use interface. According to Tech-X, the time it takes for implementations of common mathematical operations is 5–40 times faster using the technology. \n                Available under two licensing arrangements, Messmer says there have been close to 10,000 downloads of GPULib from Tech-X’s website. \n                Scientists in a variety of fields can benefit from the increased execution speed allowed by GPULib in application areas such as structural and fluid mechanics, Earth sciences, biosciences, medical and diagnostic imaging, and financial engineering. Current applications for simulation and modeling include computational fluid dynamics, tsunami modeling, galaxy formation, and neural-tissue simulations. In data analysis, applications include image enhancement, deblurring, real-time image processing, hyperspectral imaging, astronomical imaging, medical imaging, and seismic data processing.\n                At the Department of Radiation Oncology at Loyola University in Maywood, Illinois, the software is used for aligning patients on a treatment table before and after X-ray imaging, a computationally-demanding application that needs to be performed quickly. John Roeske, Director of Radiation Physics at the university, says, “Ordinarily, the approach would take 5–10 seconds. Using the GPULib we feel we can get the alignment to better than a second.” \n                Alongside medical imaging, Tech-X is focusing on providing custom products for applications in remote sensing and gaming. “The future as we see it is to provide domain-specific programs for different applications,” says Messmer. \n                What will come next? And what are the impacts on processing speed? \n                These are some of the top questions that Tech-X is seeking answers to through additional SBIRs with NASA to reveal more about Earth and the universe.\n              \n              \n              \n            \n          \n        \n      \n          \n            \n              \n                NASA Technology\n                What causes the Sun to change? And what are the impacts on our planet and our daily lives? \n                These are some of the top questions that the Heliophysics Division of NASA’s Science Mission Directorate is seeking answers to through a variety of missions to study the Sun. The most recent, the Solar Dynamics Observatory (SDO), launched in 2010, beams back 150 million bits of data per second—almost 50 times more science data than any other mission in NASA history. As a result, SDO’s instruments are giving solar scientists an unprecedented look at the Sun.\n                On a similar mission, NASA’s Reuven Ramaty High Energy Solar Spectroscope Imager (RHESSI) launched in 2002 to gather a wealth of data to construct images of the Sun. To create meaningful visualizations out of the vast data, much of it has been deciphered using a computer programming language called Interactive Data Language (IDL). In addition to studying the Sun, there is widespread use of IDL throughout NASA to process data, analyze images, perform computations, and make simulation models.\n                “There are very innovative people on the Agency side who see the potential of technologies and, in collaboration with small businesses, can make leading-edge technologies happen.”\n                  —Peter Messmer, Tech-X Corporation\n                As NASA missions continue to produce an increased amount of data, and as computational procedures become increasingly complex, NASA requires ever greater computing power. \n                Partnership\n                To help reduce the time needed to analyze data from missions like those studying the Sun, Goddard Space Flight Center awarded a Small Business Innovation Research (SBIR) contract in 2004 to Tech-X Corporation of Boulder, Colorado. \n                \n                  \n                  \n                    \n                  \n                  \n                    NASA requires increased computing power to process images like this one of the Sun, created by the Solar Dynamics Observatory in September of 2010. \n                  \n                \n                Through Phase I and II SBIRs, Tech-X demonstrated software capable of running IDL applications on linked computers, or cluster systems. The computers worked together to form a single system, without requiring significant modification to the original program. \n                By enabling IDL to work on clusters, Tech-X created a technology that increased performance in a familiar programming environment for NASA scientists, while reducing the time needed to analyze large amounts of data. Today, this software is available in Tech-X’s commercial product called FastDL.\n                After the demonstration of FastDL for NASA, something unexpected happened. “Toward the end of the Phase II SBIR, we started to redirect the proposal to investigate the usability of graphics processing units to help scientists accelerate their data analysis tasks,” explains Peter Messmer, vice president of the space applications group at Tech-X. “That was the beginning of the GPULib product that we are now offering at Tech-X.” \n                At the time, graphics processing units (GPUs) were mainly used for 3D gaming graphics, but the technology was becoming more commonly used to accelerate scientific computing. Messmer says Tech-X wanted to use one piece of hardware—a GPU—rather than several pieces, to make the computations faster. \n                Today, Tech-X attributes the initial development of GPULib, which makes available a library of mathematical functions to facilitate the use of GPUs for scientific computing, to its work with NASA. “There are very innovative people on the Agency side who see the potential of technologies and, in collaboration with small businesses, can make leading-edge technologies happen,” says Messmer.\n                Benefits\n                By 2008, NASA scientists were using Tech-X’s parallel computing tools to process large quantities of visual data from the RHESSI mission 10–40 times faster than they could previously. In applying FastDL to NASA’s Solar and Heliospheric Observatory, Tech-X processed data more than seven times faster on a cluster of 12 processors. \n                Over the past 5 years, government contracts and products including FastDL and GPULib have helped the company to double its number of headquarters employees to 70. Commercially available for 6 years, FastDL has earned about $90,000 in revenue for Tech-X. GPULib, available for 2 years, has earned about $100,000 in revenue.\n                Messmer says that what makes these products so unique is that they target IDL, which is widely used by engineers, scientists, analysts, and other technical professionals in satellite, medical, and astrophysical imaging.\n                Using FastDL, scientists and developers can run IDL visualization and analyses applications using several computers at once to shorten the time required to get results. Because not every visualization and analysis problem can be solved using the same parallel computing paradigm, FastDL includes two components: TaskDL (for independent computations) and mpiDL (for interdependent computations). \n                The other NASA-derived product, GPULib, supplies a mathematical library that simplifies access to parallel computing on a GPU. It brings high-performance numerical operations to everyday desktop computers with an easy-to-use interface. According to Tech-X, the time it takes for implementations of common mathematical operations is 5–40 times faster using the technology. \n                Available under two licensing arrangements, Messmer says there have been close to 10,000 downloads of GPULib from Tech-X’s website. \n                Scientists in a variety of fields can benefit from the increased execution speed allowed by GPULib in application areas such as structural and fluid mechanics, Earth sciences, biosciences, medical and diagnostic imaging, and financial engineering. Current applications for simulation and modeling include computational fluid dynamics, tsunami modeling, galaxy formation, and neural-tissue simulations. In data analysis, applications include image enhancement, deblurring, real-time image processing, hyperspectral imaging, astronomical imaging, medical imaging, and seismic data processing.\n                At the Department of Radiation Oncology at Loyola University in Maywood, Illinois, the software is used for aligning patients on a treatment table before and after X-ray imaging, a computationally-demanding application that needs to be performed quickly. John Roeske, Director of Radiation Physics at the university, says, “Ordinarily, the approach would take 5–10 seconds. Using the GPULib we feel we can get the alignment to better than a second.” \n                Alongside medical imaging, Tech-X is focusing on providing custom products for applications in remote sensing and gaming. “The future as we see it is to provide domain-specific programs for different applications,” says Messmer. \n                What will come next? And what are the impacts on processing speed? \n                These are some of the top questions that Tech-X is seeking answers to through additional SBIRs with NASA to reveal more about Earth and the universe.\n              \n              \n              \n            \n          \n            \n              \n                NASA Technology\n                What causes the Sun to change? And what are the impacts on our planet and our daily lives? \n                These are some of the top questions that the Heliophysics Division of NASA’s Science Mission Directorate is seeking answers to through a variety of missions to study the Sun. The most recent, the Solar Dynamics Observatory (SDO), launched in 2010, beams back 150 million bits of data per second—almost 50 times more science data than any other mission in NASA history. As a result, SDO’s instruments are giving solar scientists an unprecedented look at the Sun.\n                On a similar mission, NASA’s Reuven Ramaty High Energy Solar Spectroscope Imager (RHESSI) launched in 2002 to gather a wealth of data to construct images of the Sun. To create meaningful visualizations out of the vast data, much of it has been deciphered using a computer programming language called Interactive Data Language (IDL). In addition to studying the Sun, there is widespread use of IDL throughout NASA to process data, analyze images, perform computations, and make simulation models.\n                “There are very innovative people on the Agency side who see the potential of technologies and, in collaboration with small businesses, can make leading-edge technologies happen.”\n                  —Peter Messmer, Tech-X Corporation\n                As NASA missions continue to produce an increased amount of data, and as computational procedures become increasingly complex, NASA requires ever greater computing power. \n                Partnership\n                To help reduce the time needed to analyze data from missions like those studying the Sun, Goddard Space Flight Center awarded a Small Business Innovation Research (SBIR) contract in 2004 to Tech-X Corporation of Boulder, Colorado. \n                \n                  \n                  \n                    \n                  \n                  \n                    NASA requires increased computing power to process images like this one of the Sun, created by the Solar Dynamics Observatory in September of 2010. \n                  \n                \n                Through Phase I and II SBIRs, Tech-X demonstrated software capable of running IDL applications on linked computers, or cluster systems. The computers worked together to form a single system, without requiring significant modification to the original program. \n                By enabling IDL to work on clusters, Tech-X created a technology that increased performance in a familiar programming environment for NASA scientists, while reducing the time needed to analyze large amounts of data. Today, this software is available in Tech-X’s commercial product called FastDL.\n                After the demonstration of FastDL for NASA, something unexpected happened. “Toward the end of the Phase II SBIR, we started to redirect the proposal to investigate the usability of graphics processing units to help scientists accelerate their data analysis tasks,” explains Peter Messmer, vice president of the space applications group at Tech-X. “That was the beginning of the GPULib product that we are now offering at Tech-X.” \n                At the time, graphics processing units (GPUs) were mainly used for 3D gaming graphics, but the technology was becoming more commonly used to accelerate scientific computing. Messmer says Tech-X wanted to use one piece of hardware—a GPU—rather than several pieces, to make the computations faster. \n                Today, Tech-X attributes the initial development of GPULib, which makes available a library of mathematical functions to facilitate the use of GPUs for scientific computing, to its work with NASA. “There are very innovative people on the Agency side who see the potential of technologies and, in collaboration with small businesses, can make leading-edge technologies happen,” says Messmer.\n                Benefits\n                By 2008, NASA scientists were using Tech-X’s parallel computing tools to process large quantities of visual data from the RHESSI mission 10–40 times faster than they could previously. In applying FastDL to NASA’s Solar and Heliospheric Observatory, Tech-X processed data more than seven times faster on a cluster of 12 processors. \n                Over the past 5 years, government contracts and products including FastDL and GPULib have helped the company to double its number of headquarters employees to 70. Commercially available for 6 years, FastDL has earned about $90,000 in revenue for Tech-X. GPULib, available for 2 years, has earned about $100,000 in revenue.\n                Messmer says that what makes these products so unique is that they target IDL, which is widely used by engineers, scientists, analysts, and other technical professionals in satellite, medical, and astrophysical imaging.\n                Using FastDL, scientists and developers can run IDL visualization and analyses applications using several computers at once to shorten the time required to get results. Because not every visualization and analysis problem can be solved using the same parallel computing paradigm, FastDL includes two components: TaskDL (for independent computations) and mpiDL (for interdependent computations). \n                The other NASA-derived product, GPULib, supplies a mathematical library that simplifies access to parallel computing on a GPU. It brings high-performance numerical operations to everyday desktop computers with an easy-to-use interface. According to Tech-X, the time it takes for implementations of common mathematical operations is 5–40 times faster using the technology. \n                Available under two licensing arrangements, Messmer says there have been close to 10,000 downloads of GPULib from Tech-X’s website. \n                Scientists in a variety of fields can benefit from the increased execution speed allowed by GPULib in application areas such as structural and fluid mechanics, Earth sciences, biosciences, medical and diagnostic imaging, and financial engineering. Current applications for simulation and modeling include computational fluid dynamics, tsunami modeling, galaxy formation, and neural-tissue simulations. In data analysis, applications include image enhancement, deblurring, real-time image processing, hyperspectral imaging, astronomical imaging, medical imaging, and seismic data processing.\n                At the Department of Radiation Oncology at Loyola University in Maywood, Illinois, the software is used for aligning patients on a treatment table before and after X-ray imaging, a computationally-demanding application that needs to be performed quickly. John Roeske, Director of Radiation Physics at the university, says, “Ordinarily, the approach would take 5–10 seconds. Using the GPULib we feel we can get the alignment to better than a second.” \n                Alongside medical imaging, Tech-X is focusing on providing custom products for applications in remote sensing and gaming. “The future as we see it is to provide domain-specific programs for different applications,” says Messmer. \n                What will come next? And what are the impacts on processing speed? \n                These are some of the top questions that Tech-X is seeking answers to through additional SBIRs with NASA to reveal more about Earth and the universe.\n              \n              \n              \n            \n              \n                NASA Technology\n                What causes the Sun to change? And what are the impacts on our planet and our daily lives? \n                These are some of the top questions that the Heliophysics Division of NASA’s Science Mission Directorate is seeking answers to through a variety of missions to study the Sun. The most recent, the Solar Dynamics Observatory (SDO), launched in 2010, beams back 150 million bits of data per second—almost 50 times more science data than any other mission in NASA history. As a result, SDO’s instruments are giving solar scientists an unprecedented look at the Sun.\n                On a similar mission, NASA’s Reuven Ramaty High Energy Solar Spectroscope Imager (RHESSI) launched in 2002 to gather a wealth of data to construct images of the Sun. To create meaningful visualizations out of the vast data, much of it has been deciphered using a computer programming language called Interactive Data Language (IDL). In addition to studying the Sun, there is widespread use of IDL throughout NASA to process data, analyze images, perform computations, and make simulation models.\n                “There are very innovative people on the Agency side who see the potential of technologies and, in collaboration with small businesses, can make leading-edge technologies happen.”\n                  —Peter Messmer, Tech-X Corporation\n                As NASA missions continue to produce an increased amount of data, and as computational procedures become increasingly complex, NASA requires ever greater computing power. \n                Partnership\n                To help reduce the time needed to analyze data from missions like those studying the Sun, Goddard Space Flight Center awarded a Small Business Innovation Research (SBIR) contract in 2004 to Tech-X Corporation of Boulder, Colorado. \n                \n                  \n                  \n                    \n                  \n                  \n                    NASA requires increased computing power to process images like this one of the Sun, created by the Solar Dynamics Observatory in September of 2010. \n                  \n                \n                Through Phase I and II SBIRs, Tech-X demonstrated software capable of running IDL applications on linked computers, or cluster systems. The computers worked together to form a single system, without requiring significant modification to the original program. \n                By enabling IDL to work on clusters, Tech-X created a technology that increased performance in a familiar programming environment for NASA scientists, while reducing the time needed to analyze large amounts of data. Today, this software is available in Tech-X’s commercial product called FastDL.\n                After the demonstration of FastDL for NASA, something unexpected happened. “Toward the end of the Phase II SBIR, we started to redirect the proposal to investigate the usability of graphics processing units to help scientists accelerate their data analysis tasks,” explains Peter Messmer, vice president of the space applications group at Tech-X. “That was the beginning of the GPULib product that we are now offering at Tech-X.” \n                At the time, graphics processing units (GPUs) were mainly used for 3D gaming graphics, but the technology was becoming more commonly used to accelerate scientific computing. Messmer says Tech-X wanted to use one piece of hardware—a GPU—rather than several pieces, to make the computations faster. \n                Today, Tech-X attributes the initial development of GPULib, which makes available a library of mathematical functions to facilitate the use of GPUs for scientific computing, to its work with NASA. “There are very innovative people on the Agency side who see the potential of technologies and, in collaboration with small businesses, can make leading-edge technologies happen,” says Messmer.\n                Benefits\n                By 2008, NASA scientists were using Tech-X’s parallel computing tools to process large quantities of visual data from the RHESSI mission 10–40 times faster than they could previously. In applying FastDL to NASA’s Solar and Heliospheric Observatory, Tech-X processed data more than seven times faster on a cluster of 12 processors. \n                Over the past 5 years, government contracts and products including FastDL and GPULib have helped the company to double its number of headquarters employees to 70. Commercially available for 6 years, FastDL has earned about $90,000 in revenue for Tech-X. GPULib, available for 2 years, has earned about $100,000 in revenue.\n                Messmer says that what makes these products so unique is that they target IDL, which is widely used by engineers, scientists, analysts, and other technical professionals in satellite, medical, and astrophysical imaging.\n                Using FastDL, scientists and developers can run IDL visualization and analyses applications using several computers at once to shorten the time required to get results. Because not every visualization and analysis problem can be solved using the same parallel computing paradigm, FastDL includes two components: TaskDL (for independent computations) and mpiDL (for interdependent computations). \n                The other NASA-derived product, GPULib, supplies a mathematical library that simplifies access to parallel computing on a GPU. It brings high-performance numerical operations to everyday desktop computers with an easy-to-use interface. According to Tech-X, the time it takes for implementations of common mathematical operations is 5–40 times faster using the technology. \n                Available under two licensing arrangements, Messmer says there have been close to 10,000 downloads of GPULib from Tech-X’s website. \n                Scientists in a variety of fields can benefit from the increased execution speed allowed by GPULib in application areas such as structural and fluid mechanics, Earth sciences, biosciences, medical and diagnostic imaging, and financial engineering. Current applications for simulation and modeling include computational fluid dynamics, tsunami modeling, galaxy formation, and neural-tissue simulations. In data analysis, applications include image enhancement, deblurring, real-time image processing, hyperspectral imaging, astronomical imaging, medical imaging, and seismic data processing.\n                At the Department of Radiation Oncology at Loyola University in Maywood, Illinois, the software is used for aligning patients on a treatment table before and after X-ray imaging, a computationally-demanding application that needs to be performed quickly. John Roeske, Director of Radiation Physics at the university, says, “Ordinarily, the approach would take 5–10 seconds. Using the GPULib we feel we can get the alignment to better than a second.” \n                Alongside medical imaging, Tech-X is focusing on providing custom products for applications in remote sensing and gaming. “The future as we see it is to provide domain-specific programs for different applications,” says Messmer. \n                What will come next? And what are the impacts on processing speed? \n                These are some of the top questions that Tech-X is seeking answers to through additional SBIRs with NASA to reveal more about Earth and the universe.\n              \n              \n              \n                NASA Technology\n                What causes the Sun to change? And what are the impacts on our planet and our daily lives? \n                These are some of the top questions that the Heliophysics Division of NASA’s Science Mission Directorate is seeking answers to through a variety of missions to study the Sun. The most recent, the Solar Dynamics Observatory (SDO), launched in 2010, beams back 150 million bits of data per second—almost 50 times more science data than any other mission in NASA history. As a result, SDO’s instruments are giving solar scientists an unprecedented look at the Sun.\n                On a similar mission, NASA’s Reuven Ramaty High Energy Solar Spectroscope Imager (RHESSI) launched in 2002 to gather a wealth of data to construct images of the Sun. To create meaningful visualizations out of the vast data, much of it has been deciphered using a computer programming language called Interactive Data Language (IDL). In addition to studying the Sun, there is widespread use of IDL throughout NASA to process data, analyze images, perform computations, and make simulation models.\n                “There are very innovative people on the Agency side who see the potential of technologies and, in collaboration with small businesses, can make leading-edge technologies happen.”\n                  —Peter Messmer, Tech-X Corporation\n                As NASA missions continue to produce an increased amount of data, and as computational procedures become increasingly complex, NASA requires ever greater computing power. \n                Partnership\n                To help reduce the time needed to analyze data from missions like those studying the Sun, Goddard Space Flight Center awarded a Small Business Innovation Research (SBIR) contract in 2004 to Tech-X Corporation of Boulder, Colorado. \n                \n                  \n                  \n                    \n                  \n                  \n                    NASA requires increased computing power to process images like this one of the Sun, created by the Solar Dynamics Observatory in September of 2010. \n                  \n                \n                Through Phase I and II SBIRs, Tech-X demonstrated software capable of running IDL applications on linked computers, or cluster systems. The computers worked together to form a single system, without requiring significant modification to the original program. \n                By enabling IDL to work on clusters, Tech-X created a technology that increased performance in a familiar programming environment for NASA scientists, while reducing the time needed to analyze large amounts of data. Today, this software is available in Tech-X’s commercial product called FastDL.\n                After the demonstration of FastDL for NASA, something unexpected happened. “Toward the end of the Phase II SBIR, we started to redirect the proposal to investigate the usability of graphics processing units to help scientists accelerate their data analysis tasks,” explains Peter Messmer, vice president of the space applications group at Tech-X. “That was the beginning of the GPULib product that we are now offering at Tech-X.” \n                At the time, graphics processing units (GPUs) were mainly used for 3D gaming graphics, but the technology was becoming more commonly used to accelerate scientific computing. Messmer says Tech-X wanted to use one piece of hardware—a GPU—rather than several pieces, to make the computations faster. \n                Today, Tech-X attributes the initial development of GPULib, which makes available a library of mathematical functions to facilitate the use of GPUs for scientific computing, to its work with NASA. “There are very innovative people on the Agency side who see the potential of technologies and, in collaboration with small businesses, can make leading-edge technologies happen,” says Messmer.\n                Benefits\n                By 2008, NASA scientists were using Tech-X’s parallel computing tools to process large quantities of visual data from the RHESSI mission 10–40 times faster than they could previously. In applying FastDL to NASA’s Solar and Heliospheric Observatory, Tech-X processed data more than seven times faster on a cluster of 12 processors. \n                Over the past 5 years, government contracts and products including FastDL and GPULib have helped the company to double its number of headquarters employees to 70. Commercially available for 6 years, FastDL has earned about $90,000 in revenue for Tech-X. GPULib, available for 2 years, has earned about $100,000 in revenue.\n                Messmer says that what makes these products so unique is that they target IDL, which is widely used by engineers, scientists, analysts, and other technical professionals in satellite, medical, and astrophysical imaging.\n                Using FastDL, scientists and developers can run IDL visualization and analyses applications using several computers at once to shorten the time required to get results. Because not every visualization and analysis problem can be solved using the same parallel computing paradigm, FastDL includes two components: TaskDL (for independent computations) and mpiDL (for interdependent computations). \n                The other NASA-derived product, GPULib, supplies a mathematical library that simplifies access to parallel computing on a GPU. It brings high-performance numerical operations to everyday desktop computers with an easy-to-use interface. According to Tech-X, the time it takes for implementations of common mathematical operations is 5–40 times faster using the technology. \n                Available under two licensing arrangements, Messmer says there have been close to 10,000 downloads of GPULib from Tech-X’s website. \n                Scientists in a variety of fields can benefit from the increased execution speed allowed by GPULib in application areas such as structural and fluid mechanics, Earth sciences, biosciences, medical and diagnostic imaging, and financial engineering. Current applications for simulation and modeling include computational fluid dynamics, tsunami modeling, galaxy formation, and neural-tissue simulations. In data analysis, applications include image enhancement, deblurring, real-time image processing, hyperspectral imaging, astronomical imaging, medical imaging, and seismic data processing.\n                At the Department of Radiation Oncology at Loyola University in Maywood, Illinois, the software is used for aligning patients on a treatment table before and after X-ray imaging, a computationally-demanding application that needs to be performed quickly. John Roeske, Director of Radiation Physics at the university, says, “Ordinarily, the approach would take 5–10 seconds. Using the GPULib we feel we can get the alignment to better than a second.” \n                Alongside medical imaging, Tech-X is focusing on providing custom products for applications in remote sensing and gaming. “The future as we see it is to provide domain-specific programs for different applications,” says Messmer. \n                What will come next? And what are the impacts on processing speed? \n                These are some of the top questions that Tech-X is seeking answers to through additional SBIRs with NASA to reveal more about Earth and the universe.\n              "},{"href":"http://spinoff.nasa.gov/Spinoff2011/it_6.html","text":"Controller Chips Preserve Microprocessor Function","image":"http://spinoff.nasa.gov/Spinoff2011/Images/it_6a_opt.png","story":"\n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Above the Atlantic Ocean, off the coast of Brazil, there is a dip in the Earth’s surrounding magnetic field called the South Atlantic Anomaly. Here, space radiation can reach into Earth’s upper atmosphere to interfere with the functioning of satellites, aircraft, and even the International Space Station. “The South Atlantic Anomaly is a hot spot of radiation that the space station goes through at a certain point in orbit,” Miria Finckenor, a physicist at Marshall Space Flight Center, describes, “If there’s going to be a problem with the electronics, 90 percent of that time, it is going to be in that spot.”\n                  Space radiation can cause physical damage to microchips and can actually change the software commands in computers. When high-energy particles penetrate a satellite or other spacecraft, the electrical components can absorb the energy and temporarily switch off. If the energy is high enough, it can cause the device to enter a hung state, which can only be addressed by restarting the system. When space radiation affects the operational status of microprocessors, the occurrence is called single event functional interrupt (SEFI).\n                  SEFI happens not only to the computers onboard spacecraft in Earth orbit, but to the computers on spacecraft throughout the solar system. “One of the Mars rovers had this problem in the radiation environment and was rebooting itself several times a day. On one occasion, it rebooted 40 times in one day,” Finckenor says. “It’s hard to obtain any data when you have to constantly reboot and start over.” \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      Space radiation can interfere with the electronics on the International Space Station (ISS). High-energy particles switch electronics off and can cause them to enter a hung state. Here, the ISS is shown with Space Shuttle Endeavor on May 23, 2011.\n                    \n                  \n                  To develop a SEFI controller chip for microprocessors aboard a variety of missions, including earth sensing, solar system, and deep space, Marshall Space Flight Center worked with a San Diego-based company, Space Micro Inc., through the Small Business Innovation Research (SBIR) program in 2002. By the end of a Phase II SBIR, Space Micro developed an advanced technology to mitigate the effects of SEFI by recovering microprocessors in the middle of a hung state, rather than restarting the whole system. Called Hardened-Core, or H-Core, the technology is a combination of hardware and software that allows a system to automatically return to operational status after a SEFI event. If the system happens to be processing data at the time, less of the critical data is lost. \n                  “I think we were innovative to propose the SEFI mitigation technique, and NASA had the foresight to fund it,” says David Strobel, CEO at Space Micro. “The old fashioned way of addressing SEFI is to restart the whole system. With H-Core, the recovery from SEFI is autonomous, and it keeps the system up longer.” \n                  Shortly after the completion of the SBIRs, NASA selected a Space Micro computer, incorporating the SEFI mitigation technology, for use as the core processor for medical equipment computers on the ISS. However, that is not where use of the technology ends. \n                  “Being prepared for SEFI and having more robust computers to deal with SEFI is going to help on missions where there is a lot more radiation than in low Earth orbit,” says Finckenor. “This technology is one that we really saw a chance for success, and that’s what you want from the SBIR program. You want something that the company can continue to develop and commercialize, and that is what Space Micro has done.” \n                  As a testament to the company’s success, in 2011, Space Micro was selected by the Small Business Administration as a winner of the prestigious “Tibbetts Award” in recognition of small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program.\n                  Benefits\n                  As a provider of radiation-hardened solutions for advanced electronic systems and microelectronics, Space Micro takes technologies from the commercial sector and adapts them to meet the needs of space, aerospace, military, and domestic security. Strobel finds working with NASA was an important step in the incorporation of commercial processors in the imaging, signal processing, and space weather satellite industry. Today, the NASA-derived H-Core is embedded in Space Micro’s entire series of high-performance radiation-hardened computers for space: the Proton200k, Proton300k, and Proton400k. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Through a NASA SBIR, Space Micro Inc. developed Hardened-Core, or H-Core, to mitigate the effects of space radiation. The company now incorporates H-Core into its series of high-performance computers, including the Proton300k shown here.\n                    \n                  \n                  The Proton200k radiation-hardened, single-board computer is flight qualified for space and satellite applications, and is used for command, power, and data handling for micro- and nanosatellites. The enhanced version, the Proton200k-3X, is a triple-core, single-board computer for radiation-hardened digital signal processing for low Earth orbit or geosynchronous orbit. Space Micro’s Proton300k, a space computer platform with reconfigurable field-programmable gate arrays, brings several technologies together to provide high performance, power, and radiation hardening. Lastly, the Proton400k is a 64-bit, dual-core power PC single board computer designed to accommodate various applications for satellite and launch systems. \n                  Strobel finds the development of H-Core happened at just the right time. “Semiconductor processors were getting smaller and smaller, and hangs were becoming more and more prevalent. H-Core was a way to mitigate radiation effects in commercial microelectronics and enable fast, radiation-hardened space processing.” \n                  Customers for Space Micro’s technology represent every prime contractor in the space industry including Lockheed Martin, Boeing, Raytheon, Northrop Grumman, and Alliant Techsystems Inc. The U.S. Air Force, Department of Defense, and NASA have all used the computers with H-Core in a variety of programs. \n                  Space Micro attributes much of its success to the NASA SBIR program. Strobel believes H-Core has helped the company grow from a $1 million dollar company to an $8 million company and be recognized for fast growth several years in a row in Inc. magazine’s list of the “5000 Fastest Growing Private Companies.” \n                  “We’ve expanded from 4 employees at the beginning of the NASA SBIR to 43 employees today,” Strobel says. “I can’t say the one technology created all those jobs, but it has definitely helped.”\n                  Proton200k™, Proton300k™, Proton400k™, and H-Core™ are trademarks of Space Micro Inc.\n                \n                \n              \n              \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  NASA Technology\n                  Above the Atlantic Ocean, off the coast of Brazil, there is a dip in the Earth’s surrounding magnetic field called the South Atlantic Anomaly. Here, space radiation can reach into Earth’s upper atmosphere to interfere with the functioning of satellites, aircraft, and even the International Space Station. “The South Atlantic Anomaly is a hot spot of radiation that the space station goes through at a certain point in orbit,” Miria Finckenor, a physicist at Marshall Space Flight Center, describes, “If there’s going to be a problem with the electronics, 90 percent of that time, it is going to be in that spot.”\n                  Space radiation can cause physical damage to microchips and can actually change the software commands in computers. When high-energy particles penetrate a satellite or other spacecraft, the electrical components can absorb the energy and temporarily switch off. If the energy is high enough, it can cause the device to enter a hung state, which can only be addressed by restarting the system. When space radiation affects the operational status of microprocessors, the occurrence is called single event functional interrupt (SEFI).\n                  SEFI happens not only to the computers onboard spacecraft in Earth orbit, but to the computers on spacecraft throughout the solar system. “One of the Mars rovers had this problem in the radiation environment and was rebooting itself several times a day. On one occasion, it rebooted 40 times in one day,” Finckenor says. “It’s hard to obtain any data when you have to constantly reboot and start over.” \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      Space radiation can interfere with the electronics on the International Space Station (ISS). High-energy particles switch electronics off and can cause them to enter a hung state. Here, the ISS is shown with Space Shuttle Endeavor on May 23, 2011.\n                    \n                  \n                  To develop a SEFI controller chip for microprocessors aboard a variety of missions, including earth sensing, solar system, and deep space, Marshall Space Flight Center worked with a San Diego-based company, Space Micro Inc., through the Small Business Innovation Research (SBIR) program in 2002. By the end of a Phase II SBIR, Space Micro developed an advanced technology to mitigate the effects of SEFI by recovering microprocessors in the middle of a hung state, rather than restarting the whole system. Called Hardened-Core, or H-Core, the technology is a combination of hardware and software that allows a system to automatically return to operational status after a SEFI event. If the system happens to be processing data at the time, less of the critical data is lost. \n                  “I think we were innovative to propose the SEFI mitigation technique, and NASA had the foresight to fund it,” says David Strobel, CEO at Space Micro. “The old fashioned way of addressing SEFI is to restart the whole system. With H-Core, the recovery from SEFI is autonomous, and it keeps the system up longer.” \n                  Shortly after the completion of the SBIRs, NASA selected a Space Micro computer, incorporating the SEFI mitigation technology, for use as the core processor for medical equipment computers on the ISS. However, that is not where use of the technology ends. \n                  “Being prepared for SEFI and having more robust computers to deal with SEFI is going to help on missions where there is a lot more radiation than in low Earth orbit,” says Finckenor. “This technology is one that we really saw a chance for success, and that’s what you want from the SBIR program. You want something that the company can continue to develop and commercialize, and that is what Space Micro has done.” \n                  As a testament to the company’s success, in 2011, Space Micro was selected by the Small Business Administration as a winner of the prestigious “Tibbetts Award” in recognition of small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program.\n                  Benefits\n                  As a provider of radiation-hardened solutions for advanced electronic systems and microelectronics, Space Micro takes technologies from the commercial sector and adapts them to meet the needs of space, aerospace, military, and domestic security. Strobel finds working with NASA was an important step in the incorporation of commercial processors in the imaging, signal processing, and space weather satellite industry. Today, the NASA-derived H-Core is embedded in Space Micro’s entire series of high-performance radiation-hardened computers for space: the Proton200k, Proton300k, and Proton400k. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Through a NASA SBIR, Space Micro Inc. developed Hardened-Core, or H-Core, to mitigate the effects of space radiation. The company now incorporates H-Core into its series of high-performance computers, including the Proton300k shown here.\n                    \n                  \n                  The Proton200k radiation-hardened, single-board computer is flight qualified for space and satellite applications, and is used for command, power, and data handling for micro- and nanosatellites. The enhanced version, the Proton200k-3X, is a triple-core, single-board computer for radiation-hardened digital signal processing for low Earth orbit or geosynchronous orbit. Space Micro’s Proton300k, a space computer platform with reconfigurable field-programmable gate arrays, brings several technologies together to provide high performance, power, and radiation hardening. Lastly, the Proton400k is a 64-bit, dual-core power PC single board computer designed to accommodate various applications for satellite and launch systems. \n                  Strobel finds the development of H-Core happened at just the right time. “Semiconductor processors were getting smaller and smaller, and hangs were becoming more and more prevalent. H-Core was a way to mitigate radiation effects in commercial microelectronics and enable fast, radiation-hardened space processing.” \n                  Customers for Space Micro’s technology represent every prime contractor in the space industry including Lockheed Martin, Boeing, Raytheon, Northrop Grumman, and Alliant Techsystems Inc. The U.S. Air Force, Department of Defense, and NASA have all used the computers with H-Core in a variety of programs. \n                  Space Micro attributes much of its success to the NASA SBIR program. Strobel believes H-Core has helped the company grow from a $1 million dollar company to an $8 million company and be recognized for fast growth several years in a row in Inc. magazine’s list of the “5000 Fastest Growing Private Companies.” \n                  “We’ve expanded from 4 employees at the beginning of the NASA SBIR to 43 employees today,” Strobel says. “I can’t say the one technology created all those jobs, but it has definitely helped.”\n                  Proton200k™, Proton300k™, Proton400k™, and H-Core™ are trademarks of Space Micro Inc.\n                \n                \n              \n              \n            \n          \n        \n      \n          \n            \n              \n                \n                  NASA Technology\n                  Above the Atlantic Ocean, off the coast of Brazil, there is a dip in the Earth’s surrounding magnetic field called the South Atlantic Anomaly. Here, space radiation can reach into Earth’s upper atmosphere to interfere with the functioning of satellites, aircraft, and even the International Space Station. “The South Atlantic Anomaly is a hot spot of radiation that the space station goes through at a certain point in orbit,” Miria Finckenor, a physicist at Marshall Space Flight Center, describes, “If there’s going to be a problem with the electronics, 90 percent of that time, it is going to be in that spot.”\n                  Space radiation can cause physical damage to microchips and can actually change the software commands in computers. When high-energy particles penetrate a satellite or other spacecraft, the electrical components can absorb the energy and temporarily switch off. If the energy is high enough, it can cause the device to enter a hung state, which can only be addressed by restarting the system. When space radiation affects the operational status of microprocessors, the occurrence is called single event functional interrupt (SEFI).\n                  SEFI happens not only to the computers onboard spacecraft in Earth orbit, but to the computers on spacecraft throughout the solar system. “One of the Mars rovers had this problem in the radiation environment and was rebooting itself several times a day. On one occasion, it rebooted 40 times in one day,” Finckenor says. “It’s hard to obtain any data when you have to constantly reboot and start over.” \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      Space radiation can interfere with the electronics on the International Space Station (ISS). High-energy particles switch electronics off and can cause them to enter a hung state. Here, the ISS is shown with Space Shuttle Endeavor on May 23, 2011.\n                    \n                  \n                  To develop a SEFI controller chip for microprocessors aboard a variety of missions, including earth sensing, solar system, and deep space, Marshall Space Flight Center worked with a San Diego-based company, Space Micro Inc., through the Small Business Innovation Research (SBIR) program in 2002. By the end of a Phase II SBIR, Space Micro developed an advanced technology to mitigate the effects of SEFI by recovering microprocessors in the middle of a hung state, rather than restarting the whole system. Called Hardened-Core, or H-Core, the technology is a combination of hardware and software that allows a system to automatically return to operational status after a SEFI event. If the system happens to be processing data at the time, less of the critical data is lost. \n                  “I think we were innovative to propose the SEFI mitigation technique, and NASA had the foresight to fund it,” says David Strobel, CEO at Space Micro. “The old fashioned way of addressing SEFI is to restart the whole system. With H-Core, the recovery from SEFI is autonomous, and it keeps the system up longer.” \n                  Shortly after the completion of the SBIRs, NASA selected a Space Micro computer, incorporating the SEFI mitigation technology, for use as the core processor for medical equipment computers on the ISS. However, that is not where use of the technology ends. \n                  “Being prepared for SEFI and having more robust computers to deal with SEFI is going to help on missions where there is a lot more radiation than in low Earth orbit,” says Finckenor. “This technology is one that we really saw a chance for success, and that’s what you want from the SBIR program. You want something that the company can continue to develop and commercialize, and that is what Space Micro has done.” \n                  As a testament to the company’s success, in 2011, Space Micro was selected by the Small Business Administration as a winner of the prestigious “Tibbetts Award” in recognition of small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program.\n                  Benefits\n                  As a provider of radiation-hardened solutions for advanced electronic systems and microelectronics, Space Micro takes technologies from the commercial sector and adapts them to meet the needs of space, aerospace, military, and domestic security. Strobel finds working with NASA was an important step in the incorporation of commercial processors in the imaging, signal processing, and space weather satellite industry. Today, the NASA-derived H-Core is embedded in Space Micro’s entire series of high-performance radiation-hardened computers for space: the Proton200k, Proton300k, and Proton400k. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Through a NASA SBIR, Space Micro Inc. developed Hardened-Core, or H-Core, to mitigate the effects of space radiation. The company now incorporates H-Core into its series of high-performance computers, including the Proton300k shown here.\n                    \n                  \n                  The Proton200k radiation-hardened, single-board computer is flight qualified for space and satellite applications, and is used for command, power, and data handling for micro- and nanosatellites. The enhanced version, the Proton200k-3X, is a triple-core, single-board computer for radiation-hardened digital signal processing for low Earth orbit or geosynchronous orbit. Space Micro’s Proton300k, a space computer platform with reconfigurable field-programmable gate arrays, brings several technologies together to provide high performance, power, and radiation hardening. Lastly, the Proton400k is a 64-bit, dual-core power PC single board computer designed to accommodate various applications for satellite and launch systems. \n                  Strobel finds the development of H-Core happened at just the right time. “Semiconductor processors were getting smaller and smaller, and hangs were becoming more and more prevalent. H-Core was a way to mitigate radiation effects in commercial microelectronics and enable fast, radiation-hardened space processing.” \n                  Customers for Space Micro’s technology represent every prime contractor in the space industry including Lockheed Martin, Boeing, Raytheon, Northrop Grumman, and Alliant Techsystems Inc. The U.S. Air Force, Department of Defense, and NASA have all used the computers with H-Core in a variety of programs. \n                  Space Micro attributes much of its success to the NASA SBIR program. Strobel believes H-Core has helped the company grow from a $1 million dollar company to an $8 million company and be recognized for fast growth several years in a row in Inc. magazine’s list of the “5000 Fastest Growing Private Companies.” \n                  “We’ve expanded from 4 employees at the beginning of the NASA SBIR to 43 employees today,” Strobel says. “I can’t say the one technology created all those jobs, but it has definitely helped.”\n                  Proton200k™, Proton300k™, Proton400k™, and H-Core™ are trademarks of Space Micro Inc.\n                \n                \n              \n              \n            \n          \n            \n              \n                \n                  NASA Technology\n                  Above the Atlantic Ocean, off the coast of Brazil, there is a dip in the Earth’s surrounding magnetic field called the South Atlantic Anomaly. Here, space radiation can reach into Earth’s upper atmosphere to interfere with the functioning of satellites, aircraft, and even the International Space Station. “The South Atlantic Anomaly is a hot spot of radiation that the space station goes through at a certain point in orbit,” Miria Finckenor, a physicist at Marshall Space Flight Center, describes, “If there’s going to be a problem with the electronics, 90 percent of that time, it is going to be in that spot.”\n                  Space radiation can cause physical damage to microchips and can actually change the software commands in computers. When high-energy particles penetrate a satellite or other spacecraft, the electrical components can absorb the energy and temporarily switch off. If the energy is high enough, it can cause the device to enter a hung state, which can only be addressed by restarting the system. When space radiation affects the operational status of microprocessors, the occurrence is called single event functional interrupt (SEFI).\n                  SEFI happens not only to the computers onboard spacecraft in Earth orbit, but to the computers on spacecraft throughout the solar system. “One of the Mars rovers had this problem in the radiation environment and was rebooting itself several times a day. On one occasion, it rebooted 40 times in one day,” Finckenor says. “It’s hard to obtain any data when you have to constantly reboot and start over.” \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      Space radiation can interfere with the electronics on the International Space Station (ISS). High-energy particles switch electronics off and can cause them to enter a hung state. Here, the ISS is shown with Space Shuttle Endeavor on May 23, 2011.\n                    \n                  \n                  To develop a SEFI controller chip for microprocessors aboard a variety of missions, including earth sensing, solar system, and deep space, Marshall Space Flight Center worked with a San Diego-based company, Space Micro Inc., through the Small Business Innovation Research (SBIR) program in 2002. By the end of a Phase II SBIR, Space Micro developed an advanced technology to mitigate the effects of SEFI by recovering microprocessors in the middle of a hung state, rather than restarting the whole system. Called Hardened-Core, or H-Core, the technology is a combination of hardware and software that allows a system to automatically return to operational status after a SEFI event. If the system happens to be processing data at the time, less of the critical data is lost. \n                  “I think we were innovative to propose the SEFI mitigation technique, and NASA had the foresight to fund it,” says David Strobel, CEO at Space Micro. “The old fashioned way of addressing SEFI is to restart the whole system. With H-Core, the recovery from SEFI is autonomous, and it keeps the system up longer.” \n                  Shortly after the completion of the SBIRs, NASA selected a Space Micro computer, incorporating the SEFI mitigation technology, for use as the core processor for medical equipment computers on the ISS. However, that is not where use of the technology ends. \n                  “Being prepared for SEFI and having more robust computers to deal with SEFI is going to help on missions where there is a lot more radiation than in low Earth orbit,” says Finckenor. “This technology is one that we really saw a chance for success, and that’s what you want from the SBIR program. You want something that the company can continue to develop and commercialize, and that is what Space Micro has done.” \n                  As a testament to the company’s success, in 2011, Space Micro was selected by the Small Business Administration as a winner of the prestigious “Tibbetts Award” in recognition of small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program.\n                  Benefits\n                  As a provider of radiation-hardened solutions for advanced electronic systems and microelectronics, Space Micro takes technologies from the commercial sector and adapts them to meet the needs of space, aerospace, military, and domestic security. Strobel finds working with NASA was an important step in the incorporation of commercial processors in the imaging, signal processing, and space weather satellite industry. Today, the NASA-derived H-Core is embedded in Space Micro’s entire series of high-performance radiation-hardened computers for space: the Proton200k, Proton300k, and Proton400k. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Through a NASA SBIR, Space Micro Inc. developed Hardened-Core, or H-Core, to mitigate the effects of space radiation. The company now incorporates H-Core into its series of high-performance computers, including the Proton300k shown here.\n                    \n                  \n                  The Proton200k radiation-hardened, single-board computer is flight qualified for space and satellite applications, and is used for command, power, and data handling for micro- and nanosatellites. The enhanced version, the Proton200k-3X, is a triple-core, single-board computer for radiation-hardened digital signal processing for low Earth orbit or geosynchronous orbit. Space Micro’s Proton300k, a space computer platform with reconfigurable field-programmable gate arrays, brings several technologies together to provide high performance, power, and radiation hardening. Lastly, the Proton400k is a 64-bit, dual-core power PC single board computer designed to accommodate various applications for satellite and launch systems. \n                  Strobel finds the development of H-Core happened at just the right time. “Semiconductor processors were getting smaller and smaller, and hangs were becoming more and more prevalent. H-Core was a way to mitigate radiation effects in commercial microelectronics and enable fast, radiation-hardened space processing.” \n                  Customers for Space Micro’s technology represent every prime contractor in the space industry including Lockheed Martin, Boeing, Raytheon, Northrop Grumman, and Alliant Techsystems Inc. The U.S. Air Force, Department of Defense, and NASA have all used the computers with H-Core in a variety of programs. \n                  Space Micro attributes much of its success to the NASA SBIR program. Strobel believes H-Core has helped the company grow from a $1 million dollar company to an $8 million company and be recognized for fast growth several years in a row in Inc. magazine’s list of the “5000 Fastest Growing Private Companies.” \n                  “We’ve expanded from 4 employees at the beginning of the NASA SBIR to 43 employees today,” Strobel says. “I can’t say the one technology created all those jobs, but it has definitely helped.”\n                  Proton200k™, Proton300k™, Proton400k™, and H-Core™ are trademarks of Space Micro Inc.\n                \n                \n              \n              \n            \n              \n                \n                  NASA Technology\n                  Above the Atlantic Ocean, off the coast of Brazil, there is a dip in the Earth’s surrounding magnetic field called the South Atlantic Anomaly. Here, space radiation can reach into Earth’s upper atmosphere to interfere with the functioning of satellites, aircraft, and even the International Space Station. “The South Atlantic Anomaly is a hot spot of radiation that the space station goes through at a certain point in orbit,” Miria Finckenor, a physicist at Marshall Space Flight Center, describes, “If there’s going to be a problem with the electronics, 90 percent of that time, it is going to be in that spot.”\n                  Space radiation can cause physical damage to microchips and can actually change the software commands in computers. When high-energy particles penetrate a satellite or other spacecraft, the electrical components can absorb the energy and temporarily switch off. If the energy is high enough, it can cause the device to enter a hung state, which can only be addressed by restarting the system. When space radiation affects the operational status of microprocessors, the occurrence is called single event functional interrupt (SEFI).\n                  SEFI happens not only to the computers onboard spacecraft in Earth orbit, but to the computers on spacecraft throughout the solar system. “One of the Mars rovers had this problem in the radiation environment and was rebooting itself several times a day. On one occasion, it rebooted 40 times in one day,” Finckenor says. “It’s hard to obtain any data when you have to constantly reboot and start over.” \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      Space radiation can interfere with the electronics on the International Space Station (ISS). High-energy particles switch electronics off and can cause them to enter a hung state. Here, the ISS is shown with Space Shuttle Endeavor on May 23, 2011.\n                    \n                  \n                  To develop a SEFI controller chip for microprocessors aboard a variety of missions, including earth sensing, solar system, and deep space, Marshall Space Flight Center worked with a San Diego-based company, Space Micro Inc., through the Small Business Innovation Research (SBIR) program in 2002. By the end of a Phase II SBIR, Space Micro developed an advanced technology to mitigate the effects of SEFI by recovering microprocessors in the middle of a hung state, rather than restarting the whole system. Called Hardened-Core, or H-Core, the technology is a combination of hardware and software that allows a system to automatically return to operational status after a SEFI event. If the system happens to be processing data at the time, less of the critical data is lost. \n                  “I think we were innovative to propose the SEFI mitigation technique, and NASA had the foresight to fund it,” says David Strobel, CEO at Space Micro. “The old fashioned way of addressing SEFI is to restart the whole system. With H-Core, the recovery from SEFI is autonomous, and it keeps the system up longer.” \n                  Shortly after the completion of the SBIRs, NASA selected a Space Micro computer, incorporating the SEFI mitigation technology, for use as the core processor for medical equipment computers on the ISS. However, that is not where use of the technology ends. \n                  “Being prepared for SEFI and having more robust computers to deal with SEFI is going to help on missions where there is a lot more radiation than in low Earth orbit,” says Finckenor. “This technology is one that we really saw a chance for success, and that’s what you want from the SBIR program. You want something that the company can continue to develop and commercialize, and that is what Space Micro has done.” \n                  As a testament to the company’s success, in 2011, Space Micro was selected by the Small Business Administration as a winner of the prestigious “Tibbetts Award” in recognition of small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program.\n                  Benefits\n                  As a provider of radiation-hardened solutions for advanced electronic systems and microelectronics, Space Micro takes technologies from the commercial sector and adapts them to meet the needs of space, aerospace, military, and domestic security. Strobel finds working with NASA was an important step in the incorporation of commercial processors in the imaging, signal processing, and space weather satellite industry. Today, the NASA-derived H-Core is embedded in Space Micro’s entire series of high-performance radiation-hardened computers for space: the Proton200k, Proton300k, and Proton400k. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Through a NASA SBIR, Space Micro Inc. developed Hardened-Core, or H-Core, to mitigate the effects of space radiation. The company now incorporates H-Core into its series of high-performance computers, including the Proton300k shown here.\n                    \n                  \n                  The Proton200k radiation-hardened, single-board computer is flight qualified for space and satellite applications, and is used for command, power, and data handling for micro- and nanosatellites. The enhanced version, the Proton200k-3X, is a triple-core, single-board computer for radiation-hardened digital signal processing for low Earth orbit or geosynchronous orbit. Space Micro’s Proton300k, a space computer platform with reconfigurable field-programmable gate arrays, brings several technologies together to provide high performance, power, and radiation hardening. Lastly, the Proton400k is a 64-bit, dual-core power PC single board computer designed to accommodate various applications for satellite and launch systems. \n                  Strobel finds the development of H-Core happened at just the right time. “Semiconductor processors were getting smaller and smaller, and hangs were becoming more and more prevalent. H-Core was a way to mitigate radiation effects in commercial microelectronics and enable fast, radiation-hardened space processing.” \n                  Customers for Space Micro’s technology represent every prime contractor in the space industry including Lockheed Martin, Boeing, Raytheon, Northrop Grumman, and Alliant Techsystems Inc. The U.S. Air Force, Department of Defense, and NASA have all used the computers with H-Core in a variety of programs. \n                  Space Micro attributes much of its success to the NASA SBIR program. Strobel believes H-Core has helped the company grow from a $1 million dollar company to an $8 million company and be recognized for fast growth several years in a row in Inc. magazine’s list of the “5000 Fastest Growing Private Companies.” \n                  “We’ve expanded from 4 employees at the beginning of the NASA SBIR to 43 employees today,” Strobel says. “I can’t say the one technology created all those jobs, but it has definitely helped.”\n                  Proton200k™, Proton300k™, Proton400k™, and H-Core™ are trademarks of Space Micro Inc.\n                \n                \n              \n              \n                \n                  NASA Technology\n                  Above the Atlantic Ocean, off the coast of Brazil, there is a dip in the Earth’s surrounding magnetic field called the South Atlantic Anomaly. Here, space radiation can reach into Earth’s upper atmosphere to interfere with the functioning of satellites, aircraft, and even the International Space Station. “The South Atlantic Anomaly is a hot spot of radiation that the space station goes through at a certain point in orbit,” Miria Finckenor, a physicist at Marshall Space Flight Center, describes, “If there’s going to be a problem with the electronics, 90 percent of that time, it is going to be in that spot.”\n                  Space radiation can cause physical damage to microchips and can actually change the software commands in computers. When high-energy particles penetrate a satellite or other spacecraft, the electrical components can absorb the energy and temporarily switch off. If the energy is high enough, it can cause the device to enter a hung state, which can only be addressed by restarting the system. When space radiation affects the operational status of microprocessors, the occurrence is called single event functional interrupt (SEFI).\n                  SEFI happens not only to the computers onboard spacecraft in Earth orbit, but to the computers on spacecraft throughout the solar system. “One of the Mars rovers had this problem in the radiation environment and was rebooting itself several times a day. On one occasion, it rebooted 40 times in one day,” Finckenor says. “It’s hard to obtain any data when you have to constantly reboot and start over.” \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      Space radiation can interfere with the electronics on the International Space Station (ISS). High-energy particles switch electronics off and can cause them to enter a hung state. Here, the ISS is shown with Space Shuttle Endeavor on May 23, 2011.\n                    \n                  \n                  To develop a SEFI controller chip for microprocessors aboard a variety of missions, including earth sensing, solar system, and deep space, Marshall Space Flight Center worked with a San Diego-based company, Space Micro Inc., through the Small Business Innovation Research (SBIR) program in 2002. By the end of a Phase II SBIR, Space Micro developed an advanced technology to mitigate the effects of SEFI by recovering microprocessors in the middle of a hung state, rather than restarting the whole system. Called Hardened-Core, or H-Core, the technology is a combination of hardware and software that allows a system to automatically return to operational status after a SEFI event. If the system happens to be processing data at the time, less of the critical data is lost. \n                  “I think we were innovative to propose the SEFI mitigation technique, and NASA had the foresight to fund it,” says David Strobel, CEO at Space Micro. “The old fashioned way of addressing SEFI is to restart the whole system. With H-Core, the recovery from SEFI is autonomous, and it keeps the system up longer.” \n                  Shortly after the completion of the SBIRs, NASA selected a Space Micro computer, incorporating the SEFI mitigation technology, for use as the core processor for medical equipment computers on the ISS. However, that is not where use of the technology ends. \n                  “Being prepared for SEFI and having more robust computers to deal with SEFI is going to help on missions where there is a lot more radiation than in low Earth orbit,” says Finckenor. “This technology is one that we really saw a chance for success, and that’s what you want from the SBIR program. You want something that the company can continue to develop and commercialize, and that is what Space Micro has done.” \n                  As a testament to the company’s success, in 2011, Space Micro was selected by the Small Business Administration as a winner of the prestigious “Tibbetts Award” in recognition of small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program.\n                  Benefits\n                  As a provider of radiation-hardened solutions for advanced electronic systems and microelectronics, Space Micro takes technologies from the commercial sector and adapts them to meet the needs of space, aerospace, military, and domestic security. Strobel finds working with NASA was an important step in the incorporation of commercial processors in the imaging, signal processing, and space weather satellite industry. Today, the NASA-derived H-Core is embedded in Space Micro’s entire series of high-performance radiation-hardened computers for space: the Proton200k, Proton300k, and Proton400k. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Through a NASA SBIR, Space Micro Inc. developed Hardened-Core, or H-Core, to mitigate the effects of space radiation. The company now incorporates H-Core into its series of high-performance computers, including the Proton300k shown here.\n                    \n                  \n                  The Proton200k radiation-hardened, single-board computer is flight qualified for space and satellite applications, and is used for command, power, and data handling for micro- and nanosatellites. The enhanced version, the Proton200k-3X, is a triple-core, single-board computer for radiation-hardened digital signal processing for low Earth orbit or geosynchronous orbit. Space Micro’s Proton300k, a space computer platform with reconfigurable field-programmable gate arrays, brings several technologies together to provide high performance, power, and radiation hardening. Lastly, the Proton400k is a 64-bit, dual-core power PC single board computer designed to accommodate various applications for satellite and launch systems. \n                  Strobel finds the development of H-Core happened at just the right time. “Semiconductor processors were getting smaller and smaller, and hangs were becoming more and more prevalent. H-Core was a way to mitigate radiation effects in commercial microelectronics and enable fast, radiation-hardened space processing.” \n                  Customers for Space Micro’s technology represent every prime contractor in the space industry including Lockheed Martin, Boeing, Raytheon, Northrop Grumman, and Alliant Techsystems Inc. The U.S. Air Force, Department of Defense, and NASA have all used the computers with H-Core in a variety of programs. \n                  Space Micro attributes much of its success to the NASA SBIR program. Strobel believes H-Core has helped the company grow from a $1 million dollar company to an $8 million company and be recognized for fast growth several years in a row in Inc. magazine’s list of the “5000 Fastest Growing Private Companies.” \n                  “We’ve expanded from 4 employees at the beginning of the NASA SBIR to 43 employees today,” Strobel says. “I can’t say the one technology created all those jobs, but it has definitely helped.”\n                  Proton200k™, Proton300k™, Proton400k™, and H-Core™ are trademarks of Space Micro Inc.\n                \n                \n                  NASA Technology\n                  Above the Atlantic Ocean, off the coast of Brazil, there is a dip in the Earth’s surrounding magnetic field called the South Atlantic Anomaly. Here, space radiation can reach into Earth’s upper atmosphere to interfere with the functioning of satellites, aircraft, and even the International Space Station. “The South Atlantic Anomaly is a hot spot of radiation that the space station goes through at a certain point in orbit,” Miria Finckenor, a physicist at Marshall Space Flight Center, describes, “If there’s going to be a problem with the electronics, 90 percent of that time, it is going to be in that spot.”\n                  Space radiation can cause physical damage to microchips and can actually change the software commands in computers. When high-energy particles penetrate a satellite or other spacecraft, the electrical components can absorb the energy and temporarily switch off. If the energy is high enough, it can cause the device to enter a hung state, which can only be addressed by restarting the system. When space radiation affects the operational status of microprocessors, the occurrence is called single event functional interrupt (SEFI).\n                  SEFI happens not only to the computers onboard spacecraft in Earth orbit, but to the computers on spacecraft throughout the solar system. “One of the Mars rovers had this problem in the radiation environment and was rebooting itself several times a day. On one occasion, it rebooted 40 times in one day,” Finckenor says. “It’s hard to obtain any data when you have to constantly reboot and start over.” \n                  Partnership\n                  \n                    \n                    \n                      \n                    \n                    \n                      Space radiation can interfere with the electronics on the International Space Station (ISS). High-energy particles switch electronics off and can cause them to enter a hung state. Here, the ISS is shown with Space Shuttle Endeavor on May 23, 2011.\n                    \n                  \n                  To develop a SEFI controller chip for microprocessors aboard a variety of missions, including earth sensing, solar system, and deep space, Marshall Space Flight Center worked with a San Diego-based company, Space Micro Inc., through the Small Business Innovation Research (SBIR) program in 2002. By the end of a Phase II SBIR, Space Micro developed an advanced technology to mitigate the effects of SEFI by recovering microprocessors in the middle of a hung state, rather than restarting the whole system. Called Hardened-Core, or H-Core, the technology is a combination of hardware and software that allows a system to automatically return to operational status after a SEFI event. If the system happens to be processing data at the time, less of the critical data is lost. \n                  “I think we were innovative to propose the SEFI mitigation technique, and NASA had the foresight to fund it,” says David Strobel, CEO at Space Micro. “The old fashioned way of addressing SEFI is to restart the whole system. With H-Core, the recovery from SEFI is autonomous, and it keeps the system up longer.” \n                  Shortly after the completion of the SBIRs, NASA selected a Space Micro computer, incorporating the SEFI mitigation technology, for use as the core processor for medical equipment computers on the ISS. However, that is not where use of the technology ends. \n                  “Being prepared for SEFI and having more robust computers to deal with SEFI is going to help on missions where there is a lot more radiation than in low Earth orbit,” says Finckenor. “This technology is one that we really saw a chance for success, and that’s what you want from the SBIR program. You want something that the company can continue to develop and commercialize, and that is what Space Micro has done.” \n                  As a testament to the company’s success, in 2011, Space Micro was selected by the Small Business Administration as a winner of the prestigious “Tibbetts Award” in recognition of small businesses and SBIR support organizations exemplifying the types of business, economic, and technical development goals of the SBIR program.\n                  Benefits\n                  As a provider of radiation-hardened solutions for advanced electronic systems and microelectronics, Space Micro takes technologies from the commercial sector and adapts them to meet the needs of space, aerospace, military, and domestic security. Strobel finds working with NASA was an important step in the incorporation of commercial processors in the imaging, signal processing, and space weather satellite industry. Today, the NASA-derived H-Core is embedded in Space Micro’s entire series of high-performance radiation-hardened computers for space: the Proton200k, Proton300k, and Proton400k. \n                  \n                    \n                    \n                      \n                    \n                    \n                      Through a NASA SBIR, Space Micro Inc. developed Hardened-Core, or H-Core, to mitigate the effects of space radiation. The company now incorporates H-Core into its series of high-performance computers, including the Proton300k shown here.\n                    \n                  \n                  The Proton200k radiation-hardened, single-board computer is flight qualified for space and satellite applications, and is used for command, power, and data handling for micro- and nanosatellites. The enhanced version, the Proton200k-3X, is a triple-core, single-board computer for radiation-hardened digital signal processing for low Earth orbit or geosynchronous orbit. Space Micro’s Proton300k, a space computer platform with reconfigurable field-programmable gate arrays, brings several technologies together to provide high performance, power, and radiation hardening. Lastly, the Proton400k is a 64-bit, dual-core power PC single board computer designed to accommodate various applications for satellite and launch systems. \n                  Strobel finds the development of H-Core happened at just the right time. “Semiconductor processors were getting smaller and smaller, and hangs were becoming more and more prevalent. H-Core was a way to mitigate radiation effects in commercial microelectronics and enable fast, radiation-hardened space processing.” \n                  Customers for Space Micro’s technology represent every prime contractor in the space industry including Lockheed Martin, Boeing, Raytheon, Northrop Grumman, and Alliant Techsystems Inc. The U.S. Air Force, Department of Defense, and NASA have all used the computers with H-Core in a variety of programs. \n                  Space Micro attributes much of its success to the NASA SBIR program. Strobel believes H-Core has helped the company grow from a $1 million dollar company to an $8 million company and be recognized for fast growth several years in a row in Inc. magazine’s list of the “5000 Fastest Growing Private Companies.” \n                  “We’ve expanded from 4 employees at the beginning of the NASA SBIR to 43 employees today,” Strobel says. “I can’t say the one technology created all those jobs, but it has definitely helped.”\n                  Proton200k™, Proton300k™, Proton400k™, and H-Core™ are trademarks of Space Micro Inc.\n                "},{"href":"http://spinoff.nasa.gov/Spinoff2011/ip_1.html","text":"Nanotube Production Devices Expand Research Capabilities","image":"http://spinoff.nasa.gov/Spinoff2011/Images/ip_1a_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    NASA Technology\n                    In order for the Hubble Space Telescope to take incredible, never-seen-before shots of celestial bodies and then send them back to Earth, the spacecraft needs power. While in orbit, Hubble cannot plug into an electrical outlet or stop at a store for some batteries. One of the ways NASA supplies power aboard a spacecraft is by harnessing energy from the most powerful entity in the solar system: the Sun. Since the 1960s, photovoltaic technology, or technology that converts sunlight into electricity, has been instrumental in the exploration of space.\n                    \n                      \n                      \n                        \n                      \n                      \n                        This transmission electron microscope high-resolution image shows aligned, high-quality, low-impurity carbon nanotubes grown by a novel process and system invented at Glenn Research Center.\n                      \n                    \n                    To build upon existing photovoltaic technology, NASA’s Glenn Research Center has worked on a variety of innovative designs and materials to incorporate into photovoltaic cells, the building blocks of solar power systems. One of these materials is the carbon nanotube—a tiny structure about 50,000 times finer than the average human hair, with notably high electrical and thermal conductivity and an extreme amount of mechanical strength. Such properties give carbon nanotubes great potential to enhance the reliability of power generation and storage devices in space and on Earth.\n                    Dennis J. Flood, the branch chief of the photovoltaic division at Glenn in the 1990s, was looking into using carbon nanotubes to improve the efficiency of solar cells when he ran into a major roadblock—high-quality carbon nanotubes were not readily available. To address this problem, one of the chemists in Flood’s group came up with a process and system for growing them. \n                    A senior chemist at Glenn, Aloysius F. Hepp, devised an injection chemical vapor deposition process using a specific organometallic catalyst in a two-zone furnace. Hepp’s group found the unique process produced high-quality carbon nanotubes with less than 5 percent metal impurity. In addition, the process was more efficient than existing techniques, as it eliminated pre-patterning of the substrate used for growing the nanotubes, a timely and cost-prohibitive step.\n                    Partnership\n                    Because Glenn was more interested in the photovoltaic technology that could benefit from the incorporation of carbon nanotubes, and not in the actual production of the carbon nanotubes themselves, the Center released the technology to the inventors—Hepp and fellow researcher Jerry Harris, associate professor of chemistry at Northwest Nazarene University—in 2005. By that time, Flood had retired from NASA, and he and his son, Dennis M. Flood, founded Nanotech Innovations in Oberlin, Ohio. They filed a full patent application, and in 2010, Nanotech Innovations was awarded a patent for the process and apparatus to grow high-quality, low-impurity carbon nanotubes. \n                    “There’s going to be an influx of people that need to be trained in nanotechnology…\n                      We are starting to help to develop a curriculum that can train the next generation.”\n                      —Dennis M. Flood, Nanotech Innovations                    \n                    Benefits\n                    For several years, the company has focused on improvement. Now a portable, bench-top system, the technology can make research-scale quantities of high-quality nanotubes within just a few hours. Called the SSP-354, one of the major advantages of the NASA-derived technology is that it is a single-step process. Most processes for growing carbon nanotubes require at least a two-step process, explains the younger Flood, but the SSP-354 does not require catalyst pre-deposition or expensive substrate preparation. The user simply loads the injector and presses “Start.” \n                    According to Nanotech Innovations, the carbon nanotubes produced by the system have low catalyst content (a low amount of impurity), which has been demonstrated by tests and analysis techniques including thermogravimetric analysis, Raman spectrometry, and electron microscopy. An additional advantage is that the technology allows full control of the growth parameters for the desired nanotubes. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The NASA-derived system from Nanotech Innovations makes carbon nanotubes for science curricula, research, and product development. Carbon nanotubes show great promise for applications such as power devices, sensors, and drug delivery systems.\n                      \n                    \n                    Today, the machine is supporting the incorporation of carbon nanotubes into science curricula, research, and product development endeavors. Rice University purchased the SSP-354, and according to Andrew R. Barron, a professor of materials science at Rice, “This instrument adds fabrication of high-quality, multi-walled carbon nanotubes to our repertoire in a simple-to-use-system that even first-year undergraduate students can use.”\n                    North Dakota State’s College of Science also purchased the technology and is integrating it into their nanoscience curriculum. The Akron University Polymer Science Department purchased the SSP-354 for its laboratory and finds the system has become an integral part of its research and development efforts.\n                    “With so many next-generation devices looking to use carbon nanotubes, there’s going to be a big push for lab technicians and other people who are familiar with the synthesis, handling, and applications of carbon nanotubes,” says Flood. “There’s going to be an influx of people that need to be trained in nanotechnology, and carbon nanotubes in particular. We are starting to help to develop a curriculum that can train the next generation of lab technicians.” \n                    At the Ohio State University’s Wright Center for Photovoltaic Innovation and Commercialization, the SSP-354 gives member companies a solution for obtaining high-quality carbon nanotubes for their research and product development. “The ease of use and repeatability of results makes it an ideal instrument for anyone using carbon nanotubes in their work,” says Oleg Kuznetsov, a research scientist with member company Natcore Technology Inc.\n                    Most recently, Nanotech Innovations announced that it signed Nanoscience Instruments Inc. to be the exclusive distributor of the SSP-354 in the United States. The company also announced a new partnership with Strem Chemicals Inc. to sell nanotube arrays produced with the SSP-354. \n                    Flood says NASA played a large part in the success of Nanotech Innovations. “The fact that the genesis of this technology is a NASA technology has helped us and continues to help us,” says Flood. “Now we are the owners, but I think NASA adds a lot of credibility to what we are and what we have.\n                  \n                  \n                \n              \n              \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    NASA Technology\n                    In order for the Hubble Space Telescope to take incredible, never-seen-before shots of celestial bodies and then send them back to Earth, the spacecraft needs power. While in orbit, Hubble cannot plug into an electrical outlet or stop at a store for some batteries. One of the ways NASA supplies power aboard a spacecraft is by harnessing energy from the most powerful entity in the solar system: the Sun. Since the 1960s, photovoltaic technology, or technology that converts sunlight into electricity, has been instrumental in the exploration of space.\n                    \n                      \n                      \n                        \n                      \n                      \n                        This transmission electron microscope high-resolution image shows aligned, high-quality, low-impurity carbon nanotubes grown by a novel process and system invented at Glenn Research Center.\n                      \n                    \n                    To build upon existing photovoltaic technology, NASA’s Glenn Research Center has worked on a variety of innovative designs and materials to incorporate into photovoltaic cells, the building blocks of solar power systems. One of these materials is the carbon nanotube—a tiny structure about 50,000 times finer than the average human hair, with notably high electrical and thermal conductivity and an extreme amount of mechanical strength. Such properties give carbon nanotubes great potential to enhance the reliability of power generation and storage devices in space and on Earth.\n                    Dennis J. Flood, the branch chief of the photovoltaic division at Glenn in the 1990s, was looking into using carbon nanotubes to improve the efficiency of solar cells when he ran into a major roadblock—high-quality carbon nanotubes were not readily available. To address this problem, one of the chemists in Flood’s group came up with a process and system for growing them. \n                    A senior chemist at Glenn, Aloysius F. Hepp, devised an injection chemical vapor deposition process using a specific organometallic catalyst in a two-zone furnace. Hepp’s group found the unique process produced high-quality carbon nanotubes with less than 5 percent metal impurity. In addition, the process was more efficient than existing techniques, as it eliminated pre-patterning of the substrate used for growing the nanotubes, a timely and cost-prohibitive step.\n                    Partnership\n                    Because Glenn was more interested in the photovoltaic technology that could benefit from the incorporation of carbon nanotubes, and not in the actual production of the carbon nanotubes themselves, the Center released the technology to the inventors—Hepp and fellow researcher Jerry Harris, associate professor of chemistry at Northwest Nazarene University—in 2005. By that time, Flood had retired from NASA, and he and his son, Dennis M. Flood, founded Nanotech Innovations in Oberlin, Ohio. They filed a full patent application, and in 2010, Nanotech Innovations was awarded a patent for the process and apparatus to grow high-quality, low-impurity carbon nanotubes. \n                    “There’s going to be an influx of people that need to be trained in nanotechnology…\n                      We are starting to help to develop a curriculum that can train the next generation.”\n                      —Dennis M. Flood, Nanotech Innovations                    \n                    Benefits\n                    For several years, the company has focused on improvement. Now a portable, bench-top system, the technology can make research-scale quantities of high-quality nanotubes within just a few hours. Called the SSP-354, one of the major advantages of the NASA-derived technology is that it is a single-step process. Most processes for growing carbon nanotubes require at least a two-step process, explains the younger Flood, but the SSP-354 does not require catalyst pre-deposition or expensive substrate preparation. The user simply loads the injector and presses “Start.” \n                    According to Nanotech Innovations, the carbon nanotubes produced by the system have low catalyst content (a low amount of impurity), which has been demonstrated by tests and analysis techniques including thermogravimetric analysis, Raman spectrometry, and electron microscopy. An additional advantage is that the technology allows full control of the growth parameters for the desired nanotubes. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The NASA-derived system from Nanotech Innovations makes carbon nanotubes for science curricula, research, and product development. Carbon nanotubes show great promise for applications such as power devices, sensors, and drug delivery systems.\n                      \n                    \n                    Today, the machine is supporting the incorporation of carbon nanotubes into science curricula, research, and product development endeavors. Rice University purchased the SSP-354, and according to Andrew R. Barron, a professor of materials science at Rice, “This instrument adds fabrication of high-quality, multi-walled carbon nanotubes to our repertoire in a simple-to-use-system that even first-year undergraduate students can use.”\n                    North Dakota State’s College of Science also purchased the technology and is integrating it into their nanoscience curriculum. The Akron University Polymer Science Department purchased the SSP-354 for its laboratory and finds the system has become an integral part of its research and development efforts.\n                    “With so many next-generation devices looking to use carbon nanotubes, there’s going to be a big push for lab technicians and other people who are familiar with the synthesis, handling, and applications of carbon nanotubes,” says Flood. “There’s going to be an influx of people that need to be trained in nanotechnology, and carbon nanotubes in particular. We are starting to help to develop a curriculum that can train the next generation of lab technicians.” \n                    At the Ohio State University’s Wright Center for Photovoltaic Innovation and Commercialization, the SSP-354 gives member companies a solution for obtaining high-quality carbon nanotubes for their research and product development. “The ease of use and repeatability of results makes it an ideal instrument for anyone using carbon nanotubes in their work,” says Oleg Kuznetsov, a research scientist with member company Natcore Technology Inc.\n                    Most recently, Nanotech Innovations announced that it signed Nanoscience Instruments Inc. to be the exclusive distributor of the SSP-354 in the United States. The company also announced a new partnership with Strem Chemicals Inc. to sell nanotube arrays produced with the SSP-354. \n                    Flood says NASA played a large part in the success of Nanotech Innovations. “The fact that the genesis of this technology is a NASA technology has helped us and continues to help us,” says Flood. “Now we are the owners, but I think NASA adds a lot of credibility to what we are and what we have.\n                  \n                  \n                \n              \n              \n            \n          \n        \n      \n          \n            \n              \n                \n                  \n                    NASA Technology\n                    In order for the Hubble Space Telescope to take incredible, never-seen-before shots of celestial bodies and then send them back to Earth, the spacecraft needs power. While in orbit, Hubble cannot plug into an electrical outlet or stop at a store for some batteries. One of the ways NASA supplies power aboard a spacecraft is by harnessing energy from the most powerful entity in the solar system: the Sun. Since the 1960s, photovoltaic technology, or technology that converts sunlight into electricity, has been instrumental in the exploration of space.\n                    \n                      \n                      \n                        \n                      \n                      \n                        This transmission electron microscope high-resolution image shows aligned, high-quality, low-impurity carbon nanotubes grown by a novel process and system invented at Glenn Research Center.\n                      \n                    \n                    To build upon existing photovoltaic technology, NASA’s Glenn Research Center has worked on a variety of innovative designs and materials to incorporate into photovoltaic cells, the building blocks of solar power systems. One of these materials is the carbon nanotube—a tiny structure about 50,000 times finer than the average human hair, with notably high electrical and thermal conductivity and an extreme amount of mechanical strength. Such properties give carbon nanotubes great potential to enhance the reliability of power generation and storage devices in space and on Earth.\n                    Dennis J. Flood, the branch chief of the photovoltaic division at Glenn in the 1990s, was looking into using carbon nanotubes to improve the efficiency of solar cells when he ran into a major roadblock—high-quality carbon nanotubes were not readily available. To address this problem, one of the chemists in Flood’s group came up with a process and system for growing them. \n                    A senior chemist at Glenn, Aloysius F. Hepp, devised an injection chemical vapor deposition process using a specific organometallic catalyst in a two-zone furnace. Hepp’s group found the unique process produced high-quality carbon nanotubes with less than 5 percent metal impurity. In addition, the process was more efficient than existing techniques, as it eliminated pre-patterning of the substrate used for growing the nanotubes, a timely and cost-prohibitive step.\n                    Partnership\n                    Because Glenn was more interested in the photovoltaic technology that could benefit from the incorporation of carbon nanotubes, and not in the actual production of the carbon nanotubes themselves, the Center released the technology to the inventors—Hepp and fellow researcher Jerry Harris, associate professor of chemistry at Northwest Nazarene University—in 2005. By that time, Flood had retired from NASA, and he and his son, Dennis M. Flood, founded Nanotech Innovations in Oberlin, Ohio. They filed a full patent application, and in 2010, Nanotech Innovations was awarded a patent for the process and apparatus to grow high-quality, low-impurity carbon nanotubes. \n                    “There’s going to be an influx of people that need to be trained in nanotechnology…\n                      We are starting to help to develop a curriculum that can train the next generation.”\n                      —Dennis M. Flood, Nanotech Innovations                    \n                    Benefits\n                    For several years, the company has focused on improvement. Now a portable, bench-top system, the technology can make research-scale quantities of high-quality nanotubes within just a few hours. Called the SSP-354, one of the major advantages of the NASA-derived technology is that it is a single-step process. Most processes for growing carbon nanotubes require at least a two-step process, explains the younger Flood, but the SSP-354 does not require catalyst pre-deposition or expensive substrate preparation. The user simply loads the injector and presses “Start.” \n                    According to Nanotech Innovations, the carbon nanotubes produced by the system have low catalyst content (a low amount of impurity), which has been demonstrated by tests and analysis techniques including thermogravimetric analysis, Raman spectrometry, and electron microscopy. An additional advantage is that the technology allows full control of the growth parameters for the desired nanotubes. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The NASA-derived system from Nanotech Innovations makes carbon nanotubes for science curricula, research, and product development. Carbon nanotubes show great promise for applications such as power devices, sensors, and drug delivery systems.\n                      \n                    \n                    Today, the machine is supporting the incorporation of carbon nanotubes into science curricula, research, and product development endeavors. Rice University purchased the SSP-354, and according to Andrew R. Barron, a professor of materials science at Rice, “This instrument adds fabrication of high-quality, multi-walled carbon nanotubes to our repertoire in a simple-to-use-system that even first-year undergraduate students can use.”\n                    North Dakota State’s College of Science also purchased the technology and is integrating it into their nanoscience curriculum. The Akron University Polymer Science Department purchased the SSP-354 for its laboratory and finds the system has become an integral part of its research and development efforts.\n                    “With so many next-generation devices looking to use carbon nanotubes, there’s going to be a big push for lab technicians and other people who are familiar with the synthesis, handling, and applications of carbon nanotubes,” says Flood. “There’s going to be an influx of people that need to be trained in nanotechnology, and carbon nanotubes in particular. We are starting to help to develop a curriculum that can train the next generation of lab technicians.” \n                    At the Ohio State University’s Wright Center for Photovoltaic Innovation and Commercialization, the SSP-354 gives member companies a solution for obtaining high-quality carbon nanotubes for their research and product development. “The ease of use and repeatability of results makes it an ideal instrument for anyone using carbon nanotubes in their work,” says Oleg Kuznetsov, a research scientist with member company Natcore Technology Inc.\n                    Most recently, Nanotech Innovations announced that it signed Nanoscience Instruments Inc. to be the exclusive distributor of the SSP-354 in the United States. The company also announced a new partnership with Strem Chemicals Inc. to sell nanotube arrays produced with the SSP-354. \n                    Flood says NASA played a large part in the success of Nanotech Innovations. “The fact that the genesis of this technology is a NASA technology has helped us and continues to help us,” says Flood. “Now we are the owners, but I think NASA adds a lot of credibility to what we are and what we have.\n                  \n                  \n                \n              \n              \n            \n          \n            \n              \n                \n                  \n                    NASA Technology\n                    In order for the Hubble Space Telescope to take incredible, never-seen-before shots of celestial bodies and then send them back to Earth, the spacecraft needs power. While in orbit, Hubble cannot plug into an electrical outlet or stop at a store for some batteries. One of the ways NASA supplies power aboard a spacecraft is by harnessing energy from the most powerful entity in the solar system: the Sun. Since the 1960s, photovoltaic technology, or technology that converts sunlight into electricity, has been instrumental in the exploration of space.\n                    \n                      \n                      \n                        \n                      \n                      \n                        This transmission electron microscope high-resolution image shows aligned, high-quality, low-impurity carbon nanotubes grown by a novel process and system invented at Glenn Research Center.\n                      \n                    \n                    To build upon existing photovoltaic technology, NASA’s Glenn Research Center has worked on a variety of innovative designs and materials to incorporate into photovoltaic cells, the building blocks of solar power systems. One of these materials is the carbon nanotube—a tiny structure about 50,000 times finer than the average human hair, with notably high electrical and thermal conductivity and an extreme amount of mechanical strength. Such properties give carbon nanotubes great potential to enhance the reliability of power generation and storage devices in space and on Earth.\n                    Dennis J. Flood, the branch chief of the photovoltaic division at Glenn in the 1990s, was looking into using carbon nanotubes to improve the efficiency of solar cells when he ran into a major roadblock—high-quality carbon nanotubes were not readily available. To address this problem, one of the chemists in Flood’s group came up with a process and system for growing them. \n                    A senior chemist at Glenn, Aloysius F. Hepp, devised an injection chemical vapor deposition process using a specific organometallic catalyst in a two-zone furnace. Hepp’s group found the unique process produced high-quality carbon nanotubes with less than 5 percent metal impurity. In addition, the process was more efficient than existing techniques, as it eliminated pre-patterning of the substrate used for growing the nanotubes, a timely and cost-prohibitive step.\n                    Partnership\n                    Because Glenn was more interested in the photovoltaic technology that could benefit from the incorporation of carbon nanotubes, and not in the actual production of the carbon nanotubes themselves, the Center released the technology to the inventors—Hepp and fellow researcher Jerry Harris, associate professor of chemistry at Northwest Nazarene University—in 2005. By that time, Flood had retired from NASA, and he and his son, Dennis M. Flood, founded Nanotech Innovations in Oberlin, Ohio. They filed a full patent application, and in 2010, Nanotech Innovations was awarded a patent for the process and apparatus to grow high-quality, low-impurity carbon nanotubes. \n                    “There’s going to be an influx of people that need to be trained in nanotechnology…\n                      We are starting to help to develop a curriculum that can train the next generation.”\n                      —Dennis M. Flood, Nanotech Innovations                    \n                    Benefits\n                    For several years, the company has focused on improvement. Now a portable, bench-top system, the technology can make research-scale quantities of high-quality nanotubes within just a few hours. Called the SSP-354, one of the major advantages of the NASA-derived technology is that it is a single-step process. Most processes for growing carbon nanotubes require at least a two-step process, explains the younger Flood, but the SSP-354 does not require catalyst pre-deposition or expensive substrate preparation. The user simply loads the injector and presses “Start.” \n                    According to Nanotech Innovations, the carbon nanotubes produced by the system have low catalyst content (a low amount of impurity), which has been demonstrated by tests and analysis techniques including thermogravimetric analysis, Raman spectrometry, and electron microscopy. An additional advantage is that the technology allows full control of the growth parameters for the desired nanotubes. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The NASA-derived system from Nanotech Innovations makes carbon nanotubes for science curricula, research, and product development. Carbon nanotubes show great promise for applications such as power devices, sensors, and drug delivery systems.\n                      \n                    \n                    Today, the machine is supporting the incorporation of carbon nanotubes into science curricula, research, and product development endeavors. Rice University purchased the SSP-354, and according to Andrew R. Barron, a professor of materials science at Rice, “This instrument adds fabrication of high-quality, multi-walled carbon nanotubes to our repertoire in a simple-to-use-system that even first-year undergraduate students can use.”\n                    North Dakota State’s College of Science also purchased the technology and is integrating it into their nanoscience curriculum. The Akron University Polymer Science Department purchased the SSP-354 for its laboratory and finds the system has become an integral part of its research and development efforts.\n                    “With so many next-generation devices looking to use carbon nanotubes, there’s going to be a big push for lab technicians and other people who are familiar with the synthesis, handling, and applications of carbon nanotubes,” says Flood. “There’s going to be an influx of people that need to be trained in nanotechnology, and carbon nanotubes in particular. We are starting to help to develop a curriculum that can train the next generation of lab technicians.” \n                    At the Ohio State University’s Wright Center for Photovoltaic Innovation and Commercialization, the SSP-354 gives member companies a solution for obtaining high-quality carbon nanotubes for their research and product development. “The ease of use and repeatability of results makes it an ideal instrument for anyone using carbon nanotubes in their work,” says Oleg Kuznetsov, a research scientist with member company Natcore Technology Inc.\n                    Most recently, Nanotech Innovations announced that it signed Nanoscience Instruments Inc. to be the exclusive distributor of the SSP-354 in the United States. The company also announced a new partnership with Strem Chemicals Inc. to sell nanotube arrays produced with the SSP-354. \n                    Flood says NASA played a large part in the success of Nanotech Innovations. “The fact that the genesis of this technology is a NASA technology has helped us and continues to help us,” says Flood. “Now we are the owners, but I think NASA adds a lot of credibility to what we are and what we have.\n                  \n                  \n                \n              \n              \n            \n              \n                \n                  \n                    NASA Technology\n                    In order for the Hubble Space Telescope to take incredible, never-seen-before shots of celestial bodies and then send them back to Earth, the spacecraft needs power. While in orbit, Hubble cannot plug into an electrical outlet or stop at a store for some batteries. One of the ways NASA supplies power aboard a spacecraft is by harnessing energy from the most powerful entity in the solar system: the Sun. Since the 1960s, photovoltaic technology, or technology that converts sunlight into electricity, has been instrumental in the exploration of space.\n                    \n                      \n                      \n                        \n                      \n                      \n                        This transmission electron microscope high-resolution image shows aligned, high-quality, low-impurity carbon nanotubes grown by a novel process and system invented at Glenn Research Center.\n                      \n                    \n                    To build upon existing photovoltaic technology, NASA’s Glenn Research Center has worked on a variety of innovative designs and materials to incorporate into photovoltaic cells, the building blocks of solar power systems. One of these materials is the carbon nanotube—a tiny structure about 50,000 times finer than the average human hair, with notably high electrical and thermal conductivity and an extreme amount of mechanical strength. Such properties give carbon nanotubes great potential to enhance the reliability of power generation and storage devices in space and on Earth.\n                    Dennis J. Flood, the branch chief of the photovoltaic division at Glenn in the 1990s, was looking into using carbon nanotubes to improve the efficiency of solar cells when he ran into a major roadblock—high-quality carbon nanotubes were not readily available. To address this problem, one of the chemists in Flood’s group came up with a process and system for growing them. \n                    A senior chemist at Glenn, Aloysius F. Hepp, devised an injection chemical vapor deposition process using a specific organometallic catalyst in a two-zone furnace. Hepp’s group found the unique process produced high-quality carbon nanotubes with less than 5 percent metal impurity. In addition, the process was more efficient than existing techniques, as it eliminated pre-patterning of the substrate used for growing the nanotubes, a timely and cost-prohibitive step.\n                    Partnership\n                    Because Glenn was more interested in the photovoltaic technology that could benefit from the incorporation of carbon nanotubes, and not in the actual production of the carbon nanotubes themselves, the Center released the technology to the inventors—Hepp and fellow researcher Jerry Harris, associate professor of chemistry at Northwest Nazarene University—in 2005. By that time, Flood had retired from NASA, and he and his son, Dennis M. Flood, founded Nanotech Innovations in Oberlin, Ohio. They filed a full patent application, and in 2010, Nanotech Innovations was awarded a patent for the process and apparatus to grow high-quality, low-impurity carbon nanotubes. \n                    “There’s going to be an influx of people that need to be trained in nanotechnology…\n                      We are starting to help to develop a curriculum that can train the next generation.”\n                      —Dennis M. Flood, Nanotech Innovations                    \n                    Benefits\n                    For several years, the company has focused on improvement. Now a portable, bench-top system, the technology can make research-scale quantities of high-quality nanotubes within just a few hours. Called the SSP-354, one of the major advantages of the NASA-derived technology is that it is a single-step process. Most processes for growing carbon nanotubes require at least a two-step process, explains the younger Flood, but the SSP-354 does not require catalyst pre-deposition or expensive substrate preparation. The user simply loads the injector and presses “Start.” \n                    According to Nanotech Innovations, the carbon nanotubes produced by the system have low catalyst content (a low amount of impurity), which has been demonstrated by tests and analysis techniques including thermogravimetric analysis, Raman spectrometry, and electron microscopy. An additional advantage is that the technology allows full control of the growth parameters for the desired nanotubes. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The NASA-derived system from Nanotech Innovations makes carbon nanotubes for science curricula, research, and product development. Carbon nanotubes show great promise for applications such as power devices, sensors, and drug delivery systems.\n                      \n                    \n                    Today, the machine is supporting the incorporation of carbon nanotubes into science curricula, research, and product development endeavors. Rice University purchased the SSP-354, and according to Andrew R. Barron, a professor of materials science at Rice, “This instrument adds fabrication of high-quality, multi-walled carbon nanotubes to our repertoire in a simple-to-use-system that even first-year undergraduate students can use.”\n                    North Dakota State’s College of Science also purchased the technology and is integrating it into their nanoscience curriculum. The Akron University Polymer Science Department purchased the SSP-354 for its laboratory and finds the system has become an integral part of its research and development efforts.\n                    “With so many next-generation devices looking to use carbon nanotubes, there’s going to be a big push for lab technicians and other people who are familiar with the synthesis, handling, and applications of carbon nanotubes,” says Flood. “There’s going to be an influx of people that need to be trained in nanotechnology, and carbon nanotubes in particular. We are starting to help to develop a curriculum that can train the next generation of lab technicians.” \n                    At the Ohio State University’s Wright Center for Photovoltaic Innovation and Commercialization, the SSP-354 gives member companies a solution for obtaining high-quality carbon nanotubes for their research and product development. “The ease of use and repeatability of results makes it an ideal instrument for anyone using carbon nanotubes in their work,” says Oleg Kuznetsov, a research scientist with member company Natcore Technology Inc.\n                    Most recently, Nanotech Innovations announced that it signed Nanoscience Instruments Inc. to be the exclusive distributor of the SSP-354 in the United States. The company also announced a new partnership with Strem Chemicals Inc. to sell nanotube arrays produced with the SSP-354. \n                    Flood says NASA played a large part in the success of Nanotech Innovations. “The fact that the genesis of this technology is a NASA technology has helped us and continues to help us,” says Flood. “Now we are the owners, but I think NASA adds a lot of credibility to what we are and what we have.\n                  \n                  \n                \n              \n              \n                \n                  \n                    NASA Technology\n                    In order for the Hubble Space Telescope to take incredible, never-seen-before shots of celestial bodies and then send them back to Earth, the spacecraft needs power. While in orbit, Hubble cannot plug into an electrical outlet or stop at a store for some batteries. One of the ways NASA supplies power aboard a spacecraft is by harnessing energy from the most powerful entity in the solar system: the Sun. Since the 1960s, photovoltaic technology, or technology that converts sunlight into electricity, has been instrumental in the exploration of space.\n                    \n                      \n                      \n                        \n                      \n                      \n                        This transmission electron microscope high-resolution image shows aligned, high-quality, low-impurity carbon nanotubes grown by a novel process and system invented at Glenn Research Center.\n                      \n                    \n                    To build upon existing photovoltaic technology, NASA’s Glenn Research Center has worked on a variety of innovative designs and materials to incorporate into photovoltaic cells, the building blocks of solar power systems. One of these materials is the carbon nanotube—a tiny structure about 50,000 times finer than the average human hair, with notably high electrical and thermal conductivity and an extreme amount of mechanical strength. Such properties give carbon nanotubes great potential to enhance the reliability of power generation and storage devices in space and on Earth.\n                    Dennis J. Flood, the branch chief of the photovoltaic division at Glenn in the 1990s, was looking into using carbon nanotubes to improve the efficiency of solar cells when he ran into a major roadblock—high-quality carbon nanotubes were not readily available. To address this problem, one of the chemists in Flood’s group came up with a process and system for growing them. \n                    A senior chemist at Glenn, Aloysius F. Hepp, devised an injection chemical vapor deposition process using a specific organometallic catalyst in a two-zone furnace. Hepp’s group found the unique process produced high-quality carbon nanotubes with less than 5 percent metal impurity. In addition, the process was more efficient than existing techniques, as it eliminated pre-patterning of the substrate used for growing the nanotubes, a timely and cost-prohibitive step.\n                    Partnership\n                    Because Glenn was more interested in the photovoltaic technology that could benefit from the incorporation of carbon nanotubes, and not in the actual production of the carbon nanotubes themselves, the Center released the technology to the inventors—Hepp and fellow researcher Jerry Harris, associate professor of chemistry at Northwest Nazarene University—in 2005. By that time, Flood had retired from NASA, and he and his son, Dennis M. Flood, founded Nanotech Innovations in Oberlin, Ohio. They filed a full patent application, and in 2010, Nanotech Innovations was awarded a patent for the process and apparatus to grow high-quality, low-impurity carbon nanotubes. \n                    “There’s going to be an influx of people that need to be trained in nanotechnology…\n                      We are starting to help to develop a curriculum that can train the next generation.”\n                      —Dennis M. Flood, Nanotech Innovations                    \n                    Benefits\n                    For several years, the company has focused on improvement. Now a portable, bench-top system, the technology can make research-scale quantities of high-quality nanotubes within just a few hours. Called the SSP-354, one of the major advantages of the NASA-derived technology is that it is a single-step process. Most processes for growing carbon nanotubes require at least a two-step process, explains the younger Flood, but the SSP-354 does not require catalyst pre-deposition or expensive substrate preparation. The user simply loads the injector and presses “Start.” \n                    According to Nanotech Innovations, the carbon nanotubes produced by the system have low catalyst content (a low amount of impurity), which has been demonstrated by tests and analysis techniques including thermogravimetric analysis, Raman spectrometry, and electron microscopy. An additional advantage is that the technology allows full control of the growth parameters for the desired nanotubes. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The NASA-derived system from Nanotech Innovations makes carbon nanotubes for science curricula, research, and product development. Carbon nanotubes show great promise for applications such as power devices, sensors, and drug delivery systems.\n                      \n                    \n                    Today, the machine is supporting the incorporation of carbon nanotubes into science curricula, research, and product development endeavors. Rice University purchased the SSP-354, and according to Andrew R. Barron, a professor of materials science at Rice, “This instrument adds fabrication of high-quality, multi-walled carbon nanotubes to our repertoire in a simple-to-use-system that even first-year undergraduate students can use.”\n                    North Dakota State’s College of Science also purchased the technology and is integrating it into their nanoscience curriculum. The Akron University Polymer Science Department purchased the SSP-354 for its laboratory and finds the system has become an integral part of its research and development efforts.\n                    “With so many next-generation devices looking to use carbon nanotubes, there’s going to be a big push for lab technicians and other people who are familiar with the synthesis, handling, and applications of carbon nanotubes,” says Flood. “There’s going to be an influx of people that need to be trained in nanotechnology, and carbon nanotubes in particular. We are starting to help to develop a curriculum that can train the next generation of lab technicians.” \n                    At the Ohio State University’s Wright Center for Photovoltaic Innovation and Commercialization, the SSP-354 gives member companies a solution for obtaining high-quality carbon nanotubes for their research and product development. “The ease of use and repeatability of results makes it an ideal instrument for anyone using carbon nanotubes in their work,” says Oleg Kuznetsov, a research scientist with member company Natcore Technology Inc.\n                    Most recently, Nanotech Innovations announced that it signed Nanoscience Instruments Inc. to be the exclusive distributor of the SSP-354 in the United States. The company also announced a new partnership with Strem Chemicals Inc. to sell nanotube arrays produced with the SSP-354. \n                    Flood says NASA played a large part in the success of Nanotech Innovations. “The fact that the genesis of this technology is a NASA technology has helped us and continues to help us,” says Flood. “Now we are the owners, but I think NASA adds a lot of credibility to what we are and what we have.\n                  \n                  \n                \n                  \n                    NASA Technology\n                    In order for the Hubble Space Telescope to take incredible, never-seen-before shots of celestial bodies and then send them back to Earth, the spacecraft needs power. While in orbit, Hubble cannot plug into an electrical outlet or stop at a store for some batteries. One of the ways NASA supplies power aboard a spacecraft is by harnessing energy from the most powerful entity in the solar system: the Sun. Since the 1960s, photovoltaic technology, or technology that converts sunlight into electricity, has been instrumental in the exploration of space.\n                    \n                      \n                      \n                        \n                      \n                      \n                        This transmission electron microscope high-resolution image shows aligned, high-quality, low-impurity carbon nanotubes grown by a novel process and system invented at Glenn Research Center.\n                      \n                    \n                    To build upon existing photovoltaic technology, NASA’s Glenn Research Center has worked on a variety of innovative designs and materials to incorporate into photovoltaic cells, the building blocks of solar power systems. One of these materials is the carbon nanotube—a tiny structure about 50,000 times finer than the average human hair, with notably high electrical and thermal conductivity and an extreme amount of mechanical strength. Such properties give carbon nanotubes great potential to enhance the reliability of power generation and storage devices in space and on Earth.\n                    Dennis J. Flood, the branch chief of the photovoltaic division at Glenn in the 1990s, was looking into using carbon nanotubes to improve the efficiency of solar cells when he ran into a major roadblock—high-quality carbon nanotubes were not readily available. To address this problem, one of the chemists in Flood’s group came up with a process and system for growing them. \n                    A senior chemist at Glenn, Aloysius F. Hepp, devised an injection chemical vapor deposition process using a specific organometallic catalyst in a two-zone furnace. Hepp’s group found the unique process produced high-quality carbon nanotubes with less than 5 percent metal impurity. In addition, the process was more efficient than existing techniques, as it eliminated pre-patterning of the substrate used for growing the nanotubes, a timely and cost-prohibitive step.\n                    Partnership\n                    Because Glenn was more interested in the photovoltaic technology that could benefit from the incorporation of carbon nanotubes, and not in the actual production of the carbon nanotubes themselves, the Center released the technology to the inventors—Hepp and fellow researcher Jerry Harris, associate professor of chemistry at Northwest Nazarene University—in 2005. By that time, Flood had retired from NASA, and he and his son, Dennis M. Flood, founded Nanotech Innovations in Oberlin, Ohio. They filed a full patent application, and in 2010, Nanotech Innovations was awarded a patent for the process and apparatus to grow high-quality, low-impurity carbon nanotubes. \n                    “There’s going to be an influx of people that need to be trained in nanotechnology…\n                      We are starting to help to develop a curriculum that can train the next generation.”\n                      —Dennis M. Flood, Nanotech Innovations                    \n                    Benefits\n                    For several years, the company has focused on improvement. Now a portable, bench-top system, the technology can make research-scale quantities of high-quality nanotubes within just a few hours. Called the SSP-354, one of the major advantages of the NASA-derived technology is that it is a single-step process. Most processes for growing carbon nanotubes require at least a two-step process, explains the younger Flood, but the SSP-354 does not require catalyst pre-deposition or expensive substrate preparation. The user simply loads the injector and presses “Start.” \n                    According to Nanotech Innovations, the carbon nanotubes produced by the system have low catalyst content (a low amount of impurity), which has been demonstrated by tests and analysis techniques including thermogravimetric analysis, Raman spectrometry, and electron microscopy. An additional advantage is that the technology allows full control of the growth parameters for the desired nanotubes. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The NASA-derived system from Nanotech Innovations makes carbon nanotubes for science curricula, research, and product development. Carbon nanotubes show great promise for applications such as power devices, sensors, and drug delivery systems.\n                      \n                    \n                    Today, the machine is supporting the incorporation of carbon nanotubes into science curricula, research, and product development endeavors. Rice University purchased the SSP-354, and according to Andrew R. Barron, a professor of materials science at Rice, “This instrument adds fabrication of high-quality, multi-walled carbon nanotubes to our repertoire in a simple-to-use-system that even first-year undergraduate students can use.”\n                    North Dakota State’s College of Science also purchased the technology and is integrating it into their nanoscience curriculum. The Akron University Polymer Science Department purchased the SSP-354 for its laboratory and finds the system has become an integral part of its research and development efforts.\n                    “With so many next-generation devices looking to use carbon nanotubes, there’s going to be a big push for lab technicians and other people who are familiar with the synthesis, handling, and applications of carbon nanotubes,” says Flood. “There’s going to be an influx of people that need to be trained in nanotechnology, and carbon nanotubes in particular. We are starting to help to develop a curriculum that can train the next generation of lab technicians.” \n                    At the Ohio State University’s Wright Center for Photovoltaic Innovation and Commercialization, the SSP-354 gives member companies a solution for obtaining high-quality carbon nanotubes for their research and product development. “The ease of use and repeatability of results makes it an ideal instrument for anyone using carbon nanotubes in their work,” says Oleg Kuznetsov, a research scientist with member company Natcore Technology Inc.\n                    Most recently, Nanotech Innovations announced that it signed Nanoscience Instruments Inc. to be the exclusive distributor of the SSP-354 in the United States. The company also announced a new partnership with Strem Chemicals Inc. to sell nanotube arrays produced with the SSP-354. \n                    Flood says NASA played a large part in the success of Nanotech Innovations. “The fact that the genesis of this technology is a NASA technology has helped us and continues to help us,” says Flood. “Now we are the owners, but I think NASA adds a lot of credibility to what we are and what we have.\n                  \n                  \n                    NASA Technology\n                    In order for the Hubble Space Telescope to take incredible, never-seen-before shots of celestial bodies and then send them back to Earth, the spacecraft needs power. While in orbit, Hubble cannot plug into an electrical outlet or stop at a store for some batteries. One of the ways NASA supplies power aboard a spacecraft is by harnessing energy from the most powerful entity in the solar system: the Sun. Since the 1960s, photovoltaic technology, or technology that converts sunlight into electricity, has been instrumental in the exploration of space.\n                    \n                      \n                      \n                        \n                      \n                      \n                        This transmission electron microscope high-resolution image shows aligned, high-quality, low-impurity carbon nanotubes grown by a novel process and system invented at Glenn Research Center.\n                      \n                    \n                    To build upon existing photovoltaic technology, NASA’s Glenn Research Center has worked on a variety of innovative designs and materials to incorporate into photovoltaic cells, the building blocks of solar power systems. One of these materials is the carbon nanotube—a tiny structure about 50,000 times finer than the average human hair, with notably high electrical and thermal conductivity and an extreme amount of mechanical strength. Such properties give carbon nanotubes great potential to enhance the reliability of power generation and storage devices in space and on Earth.\n                    Dennis J. Flood, the branch chief of the photovoltaic division at Glenn in the 1990s, was looking into using carbon nanotubes to improve the efficiency of solar cells when he ran into a major roadblock—high-quality carbon nanotubes were not readily available. To address this problem, one of the chemists in Flood’s group came up with a process and system for growing them. \n                    A senior chemist at Glenn, Aloysius F. Hepp, devised an injection chemical vapor deposition process using a specific organometallic catalyst in a two-zone furnace. Hepp’s group found the unique process produced high-quality carbon nanotubes with less than 5 percent metal impurity. In addition, the process was more efficient than existing techniques, as it eliminated pre-patterning of the substrate used for growing the nanotubes, a timely and cost-prohibitive step.\n                    Partnership\n                    Because Glenn was more interested in the photovoltaic technology that could benefit from the incorporation of carbon nanotubes, and not in the actual production of the carbon nanotubes themselves, the Center released the technology to the inventors—Hepp and fellow researcher Jerry Harris, associate professor of chemistry at Northwest Nazarene University—in 2005. By that time, Flood had retired from NASA, and he and his son, Dennis M. Flood, founded Nanotech Innovations in Oberlin, Ohio. They filed a full patent application, and in 2010, Nanotech Innovations was awarded a patent for the process and apparatus to grow high-quality, low-impurity carbon nanotubes. \n                    “There’s going to be an influx of people that need to be trained in nanotechnology…\n                      We are starting to help to develop a curriculum that can train the next generation.”\n                      —Dennis M. Flood, Nanotech Innovations                    \n                    Benefits\n                    For several years, the company has focused on improvement. Now a portable, bench-top system, the technology can make research-scale quantities of high-quality nanotubes within just a few hours. Called the SSP-354, one of the major advantages of the NASA-derived technology is that it is a single-step process. Most processes for growing carbon nanotubes require at least a two-step process, explains the younger Flood, but the SSP-354 does not require catalyst pre-deposition or expensive substrate preparation. The user simply loads the injector and presses “Start.” \n                    According to Nanotech Innovations, the carbon nanotubes produced by the system have low catalyst content (a low amount of impurity), which has been demonstrated by tests and analysis techniques including thermogravimetric analysis, Raman spectrometry, and electron microscopy. An additional advantage is that the technology allows full control of the growth parameters for the desired nanotubes. \n                    \n                      \n                      \n                        \n                      \n                      \n                        The NASA-derived system from Nanotech Innovations makes carbon nanotubes for science curricula, research, and product development. Carbon nanotubes show great promise for applications such as power devices, sensors, and drug delivery systems.\n                      \n                    \n                    Today, the machine is supporting the incorporation of carbon nanotubes into science curricula, research, and product development endeavors. Rice University purchased the SSP-354, and according to Andrew R. Barron, a professor of materials science at Rice, “This instrument adds fabrication of high-quality, multi-walled carbon nanotubes to our repertoire in a simple-to-use-system that even first-year undergraduate students can use.”\n                    North Dakota State’s College of Science also purchased the technology and is integrating it into their nanoscience curriculum. The Akron University Polymer Science Department purchased the SSP-354 for its laboratory and finds the system has become an integral part of its research and development efforts.\n                    “With so many next-generation devices looking to use carbon nanotubes, there’s going to be a big push for lab technicians and other people who are familiar with the synthesis, handling, and applications of carbon nanotubes,” says Flood. “There’s going to be an influx of people that need to be trained in nanotechnology, and carbon nanotubes in particular. We are starting to help to develop a curriculum that can train the next generation of lab technicians.” \n                    At the Ohio State University’s Wright Center for Photovoltaic Innovation and Commercialization, the SSP-354 gives member companies a solution for obtaining high-quality carbon nanotubes for their research and product development. “The ease of use and repeatability of results makes it an ideal instrument for anyone using carbon nanotubes in their work,” says Oleg Kuznetsov, a research scientist with member company Natcore Technology Inc.\n                    Most recently, Nanotech Innovations announced that it signed Nanoscience Instruments Inc. to be the exclusive distributor of the SSP-354 in the United States. The company also announced a new partnership with Strem Chemicals Inc. to sell nanotube arrays produced with the SSP-354. \n                    Flood says NASA played a large part in the success of Nanotech Innovations. “The fact that the genesis of this technology is a NASA technology has helped us and continues to help us,” says Flood. “Now we are the owners, but I think NASA adds a lot of credibility to what we are and what we have.\n                  "},{"href":"http://spinoff.nasa.gov/Spinoff2011/ip_2.html","text":"Custom Machines Advance Composite Manufacturing","image":"http://spinoff.nasa.gov/Spinoff2011/Images/ip_2a_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology \n                      \n                                    \n                            \n                            \n                              \n                            \n                            \n                              The Composite Crew Module allows NASA researchers to test materials and methods that may one day be applied to spacecraft constructed using composite materials.\n                            \n                                                                                        \n                                    Here is a brief list of materials that NASA will not be using to construct spacecraft: wood, adobe, fiberglass, bone. While it might be obvious why these materials would not make for safe space travel, they do share a common characteristic with materials that may well be the future foundation of spacecraft design: They all are composites. Formed of two or more unlike materials—such as cellulose and lignin in the case of wood, or glass fibers and plastic resin in the case of fiberglass—composites provide enhanced mechanical and physical properties through the combination of their constituent materials. For this reason, composites are used in everything from buildings, bathtubs, and countertops to boats, racecars, and sports equipment.\n                                    NASA continually works to develop new materials to enable future space missions—lighter, less expensive materials that can still withstand the extreme demands of space travel. Composites such as carbon fiber materials offer promising solutions in this regard, providing strength and stiffness comparable to metals like aluminum but with less weight, allowing for benefits like better fuel efficiency and simpler propulsion system design. Composites can also be made fatigue tolerant and thermally stable—useful in space where temperatures can swing hundreds of degrees.\n                                    NASA has recently explored the use of composites for aerospace applications through projects like the Composite Crew Module (CCM), a composite-constructed version of the aluminum-lithium Multipurpose Crew Capsule. The CCM was designed to give NASA engineers a chance to gain valuable experience developing and testing composite aerospace structures. \n                                    Partnership\n                                    Composites are an increasingly significant part of terrestrial applications, from transportation (the largely plastic composite airframe of the new Boeing 787 Dreamliner, for example) to medicine (composite prostheses among other uses). As the composites industry has matured, says Brian Jensen, materials scientist at Langley Research Center, NASA “started an effort to not only improve the performance of composites, but also to lower the cost.” Cost is a major challenge to composite manufacturing. Composites are traditionally fabricated by layering prepreg materials—sheets of reinforcement material, such as carbon fiber, already pre-impregnated with the bonding resin—in a mold, either by an automated process or, often, by hand. The mold is then placed in an autoclave, a pressurized oven, to cure. Large composite structures like parts of rockets, airplane wings, and wind turbine blades require massive, extremely expensive autoclaves for curing. \n                                    To help develop less costly, out-of-autoclave composite manufacturing techniques, Langley partnered with Accudyne Systems Inc., of Newark, Delaware, through the Small Business Innovation Research (SBIR) program. Through this partnership, Accudyne applied its expertise in creating custom automation equipment for composite manufacturing to develop an automated thermoplastic tape laydown head. Unlike a thermoset composite, which once cured cannot be reshaped or reprocessed, a thermoplastic can be reheated for remolding or to heal flaws in its structure. The Accudyne device deposits preheated strips of the thermoplastic materials, welding the strips together through heat and pressure to build up structures layer by layer—eliminating the need for an autoclave. \n                                    “It’s been a dual effort between Langley and Accudyne, where Langley is trying to develop the thermoplastics that work well, and Accudyne has been fine-tuning the heated head to make this process happen in a reasonable time and yield a high-quality part,” Jensen says.\n                                    Benefits\n                                    While the tape laydown head currently features as part of an Accudyne-built machine at Langley, the company’s SBIR work has yielded technology for its commercial products, as well. Autoclave-cured thermoset materials still dominate composites manufacturing, explains John Melilli, Accudyne’s vice president of sales and marketing, and the company’s commercially available deposition heads for thermoset systems employ technology created for the SBIR-developed laydown head. Through another NASA SBIR, Accudyne also developed nanoparticle technology that, when mixed with a composite resin, helps the material develop improved properties—allowing high-quality parts to be made more quickly at lower cost, Melilli says. The company has patented the innovation and expects significant commercial interest. \n                                    “NASA’s support of manufacturing is important to maintaining and advancing the Nation’s technological capabilities.”\n                                    —John Melilli, Accudyne Systems Inc.\n                                    Accudyne is currently working with major aerospace companies to develop machines for manufacturing composite rocket parts and components for helicopter rotors. The company’s automated solutions enable the production of higher quality parts at lower costs, while not threatening the jobs of the workers who previously fabricated the composite parts by hand. \n                                    \n                      \n                        \n                        \n                          \n                        \n                        \n                          The automated thermoplastic tape laydown head developed by Accudyne Systems Inc. provides Langley Research Center engineers and others with a unique tool for advancing out-of-autoclave thermoplastics manufacturing.\n                        \n                      \n                      \n                      “This is not about replacing people with machines,” Melilli says. “The people end up working with the machines, and the rate of production goes up.” \n                      The kind of support that NASA has provided to composite manufacturing innovators like Accudyne has been essential to the continued development of the entire industry, Melilli notes. “The reality is that the work, connections, and references that NASA has continued to provide have been crucial to keeping this technology going.” \n                      In a broader sense, he says, “NASA’s support of manufacturing in general is important to maintaining and advancing the Nation’s technological capabilities. Manufacturing is so important because you end up applying all of the process lessons you have learned over time. The United States runs the risk of falling behind in developing new processes and manufacturing technologies if, as is the current trend, manufacturing continues to migrate to foreign countries. We end up being ‘distributors’ as opposed to ‘manufacturers.’ The skills are different and the compensation is as well.”\n                      This learning process is still very much underway at Langley, where the Accudyne-built machine is available for researchers and partners in private industry to use. \n                      “That machine is going to be indispensable in helping to develop a database of processes and parts made from thermoplastics,” Melilli says. In the meantime, Accudyne is currently engaged in a Small Business Technology Transfer (STTR) project with Langley and the University of Delaware to improve the properties of parts made with the SBIR-derived tape laydown head. \n                      The results indicate a bright future for out-of-autoclave thermoplastics manufacturing. Jensen notes that these parts initially exhibited performance properties 70–80 percent of those made using an autoclave. Through the STTR partnership, those results are now around 90–95 percent\n                      \n                    \n                  \n                \n              \n              \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology \n                      \n                                    \n                            \n                            \n                              \n                            \n                            \n                              The Composite Crew Module allows NASA researchers to test materials and methods that may one day be applied to spacecraft constructed using composite materials.\n                            \n                                                                                        \n                                    Here is a brief list of materials that NASA will not be using to construct spacecraft: wood, adobe, fiberglass, bone. While it might be obvious why these materials would not make for safe space travel, they do share a common characteristic with materials that may well be the future foundation of spacecraft design: They all are composites. Formed of two or more unlike materials—such as cellulose and lignin in the case of wood, or glass fibers and plastic resin in the case of fiberglass—composites provide enhanced mechanical and physical properties through the combination of their constituent materials. For this reason, composites are used in everything from buildings, bathtubs, and countertops to boats, racecars, and sports equipment.\n                                    NASA continually works to develop new materials to enable future space missions—lighter, less expensive materials that can still withstand the extreme demands of space travel. Composites such as carbon fiber materials offer promising solutions in this regard, providing strength and stiffness comparable to metals like aluminum but with less weight, allowing for benefits like better fuel efficiency and simpler propulsion system design. Composites can also be made fatigue tolerant and thermally stable—useful in space where temperatures can swing hundreds of degrees.\n                                    NASA has recently explored the use of composites for aerospace applications through projects like the Composite Crew Module (CCM), a composite-constructed version of the aluminum-lithium Multipurpose Crew Capsule. The CCM was designed to give NASA engineers a chance to gain valuable experience developing and testing composite aerospace structures. \n                                    Partnership\n                                    Composites are an increasingly significant part of terrestrial applications, from transportation (the largely plastic composite airframe of the new Boeing 787 Dreamliner, for example) to medicine (composite prostheses among other uses). As the composites industry has matured, says Brian Jensen, materials scientist at Langley Research Center, NASA “started an effort to not only improve the performance of composites, but also to lower the cost.” Cost is a major challenge to composite manufacturing. Composites are traditionally fabricated by layering prepreg materials—sheets of reinforcement material, such as carbon fiber, already pre-impregnated with the bonding resin—in a mold, either by an automated process or, often, by hand. The mold is then placed in an autoclave, a pressurized oven, to cure. Large composite structures like parts of rockets, airplane wings, and wind turbine blades require massive, extremely expensive autoclaves for curing. \n                                    To help develop less costly, out-of-autoclave composite manufacturing techniques, Langley partnered with Accudyne Systems Inc., of Newark, Delaware, through the Small Business Innovation Research (SBIR) program. Through this partnership, Accudyne applied its expertise in creating custom automation equipment for composite manufacturing to develop an automated thermoplastic tape laydown head. Unlike a thermoset composite, which once cured cannot be reshaped or reprocessed, a thermoplastic can be reheated for remolding or to heal flaws in its structure. The Accudyne device deposits preheated strips of the thermoplastic materials, welding the strips together through heat and pressure to build up structures layer by layer—eliminating the need for an autoclave. \n                                    “It’s been a dual effort between Langley and Accudyne, where Langley is trying to develop the thermoplastics that work well, and Accudyne has been fine-tuning the heated head to make this process happen in a reasonable time and yield a high-quality part,” Jensen says.\n                                    Benefits\n                                    While the tape laydown head currently features as part of an Accudyne-built machine at Langley, the company’s SBIR work has yielded technology for its commercial products, as well. Autoclave-cured thermoset materials still dominate composites manufacturing, explains John Melilli, Accudyne’s vice president of sales and marketing, and the company’s commercially available deposition heads for thermoset systems employ technology created for the SBIR-developed laydown head. Through another NASA SBIR, Accudyne also developed nanoparticle technology that, when mixed with a composite resin, helps the material develop improved properties—allowing high-quality parts to be made more quickly at lower cost, Melilli says. The company has patented the innovation and expects significant commercial interest. \n                                    “NASA’s support of manufacturing is important to maintaining and advancing the Nation’s technological capabilities.”\n                                    —John Melilli, Accudyne Systems Inc.\n                                    Accudyne is currently working with major aerospace companies to develop machines for manufacturing composite rocket parts and components for helicopter rotors. The company’s automated solutions enable the production of higher quality parts at lower costs, while not threatening the jobs of the workers who previously fabricated the composite parts by hand. \n                                    \n                      \n                        \n                        \n                          \n                        \n                        \n                          The automated thermoplastic tape laydown head developed by Accudyne Systems Inc. provides Langley Research Center engineers and others with a unique tool for advancing out-of-autoclave thermoplastics manufacturing.\n                        \n                      \n                      \n                      “This is not about replacing people with machines,” Melilli says. “The people end up working with the machines, and the rate of production goes up.” \n                      The kind of support that NASA has provided to composite manufacturing innovators like Accudyne has been essential to the continued development of the entire industry, Melilli notes. “The reality is that the work, connections, and references that NASA has continued to provide have been crucial to keeping this technology going.” \n                      In a broader sense, he says, “NASA’s support of manufacturing in general is important to maintaining and advancing the Nation’s technological capabilities. Manufacturing is so important because you end up applying all of the process lessons you have learned over time. The United States runs the risk of falling behind in developing new processes and manufacturing technologies if, as is the current trend, manufacturing continues to migrate to foreign countries. We end up being ‘distributors’ as opposed to ‘manufacturers.’ The skills are different and the compensation is as well.”\n                      This learning process is still very much underway at Langley, where the Accudyne-built machine is available for researchers and partners in private industry to use. \n                      “That machine is going to be indispensable in helping to develop a database of processes and parts made from thermoplastics,” Melilli says. In the meantime, Accudyne is currently engaged in a Small Business Technology Transfer (STTR) project with Langley and the University of Delaware to improve the properties of parts made with the SBIR-derived tape laydown head. \n                      The results indicate a bright future for out-of-autoclave thermoplastics manufacturing. Jensen notes that these parts initially exhibited performance properties 70–80 percent of those made using an autoclave. Through the STTR partnership, those results are now around 90–95 percent\n                      \n                    \n                  \n                \n              \n              \n            \n          \n        \n      \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology \n                      \n                                    \n                            \n                            \n                              \n                            \n                            \n                              The Composite Crew Module allows NASA researchers to test materials and methods that may one day be applied to spacecraft constructed using composite materials.\n                            \n                                                                                        \n                                    Here is a brief list of materials that NASA will not be using to construct spacecraft: wood, adobe, fiberglass, bone. While it might be obvious why these materials would not make for safe space travel, they do share a common characteristic with materials that may well be the future foundation of spacecraft design: They all are composites. Formed of two or more unlike materials—such as cellulose and lignin in the case of wood, or glass fibers and plastic resin in the case of fiberglass—composites provide enhanced mechanical and physical properties through the combination of their constituent materials. For this reason, composites are used in everything from buildings, bathtubs, and countertops to boats, racecars, and sports equipment.\n                                    NASA continually works to develop new materials to enable future space missions—lighter, less expensive materials that can still withstand the extreme demands of space travel. Composites such as carbon fiber materials offer promising solutions in this regard, providing strength and stiffness comparable to metals like aluminum but with less weight, allowing for benefits like better fuel efficiency and simpler propulsion system design. Composites can also be made fatigue tolerant and thermally stable—useful in space where temperatures can swing hundreds of degrees.\n                                    NASA has recently explored the use of composites for aerospace applications through projects like the Composite Crew Module (CCM), a composite-constructed version of the aluminum-lithium Multipurpose Crew Capsule. The CCM was designed to give NASA engineers a chance to gain valuable experience developing and testing composite aerospace structures. \n                                    Partnership\n                                    Composites are an increasingly significant part of terrestrial applications, from transportation (the largely plastic composite airframe of the new Boeing 787 Dreamliner, for example) to medicine (composite prostheses among other uses). As the composites industry has matured, says Brian Jensen, materials scientist at Langley Research Center, NASA “started an effort to not only improve the performance of composites, but also to lower the cost.” Cost is a major challenge to composite manufacturing. Composites are traditionally fabricated by layering prepreg materials—sheets of reinforcement material, such as carbon fiber, already pre-impregnated with the bonding resin—in a mold, either by an automated process or, often, by hand. The mold is then placed in an autoclave, a pressurized oven, to cure. Large composite structures like parts of rockets, airplane wings, and wind turbine blades require massive, extremely expensive autoclaves for curing. \n                                    To help develop less costly, out-of-autoclave composite manufacturing techniques, Langley partnered with Accudyne Systems Inc., of Newark, Delaware, through the Small Business Innovation Research (SBIR) program. Through this partnership, Accudyne applied its expertise in creating custom automation equipment for composite manufacturing to develop an automated thermoplastic tape laydown head. Unlike a thermoset composite, which once cured cannot be reshaped or reprocessed, a thermoplastic can be reheated for remolding or to heal flaws in its structure. The Accudyne device deposits preheated strips of the thermoplastic materials, welding the strips together through heat and pressure to build up structures layer by layer—eliminating the need for an autoclave. \n                                    “It’s been a dual effort between Langley and Accudyne, where Langley is trying to develop the thermoplastics that work well, and Accudyne has been fine-tuning the heated head to make this process happen in a reasonable time and yield a high-quality part,” Jensen says.\n                                    Benefits\n                                    While the tape laydown head currently features as part of an Accudyne-built machine at Langley, the company’s SBIR work has yielded technology for its commercial products, as well. Autoclave-cured thermoset materials still dominate composites manufacturing, explains John Melilli, Accudyne’s vice president of sales and marketing, and the company’s commercially available deposition heads for thermoset systems employ technology created for the SBIR-developed laydown head. Through another NASA SBIR, Accudyne also developed nanoparticle technology that, when mixed with a composite resin, helps the material develop improved properties—allowing high-quality parts to be made more quickly at lower cost, Melilli says. The company has patented the innovation and expects significant commercial interest. \n                                    “NASA’s support of manufacturing is important to maintaining and advancing the Nation’s technological capabilities.”\n                                    —John Melilli, Accudyne Systems Inc.\n                                    Accudyne is currently working with major aerospace companies to develop machines for manufacturing composite rocket parts and components for helicopter rotors. The company’s automated solutions enable the production of higher quality parts at lower costs, while not threatening the jobs of the workers who previously fabricated the composite parts by hand. \n                                    \n                      \n                        \n                        \n                          \n                        \n                        \n                          The automated thermoplastic tape laydown head developed by Accudyne Systems Inc. provides Langley Research Center engineers and others with a unique tool for advancing out-of-autoclave thermoplastics manufacturing.\n                        \n                      \n                      \n                      “This is not about replacing people with machines,” Melilli says. “The people end up working with the machines, and the rate of production goes up.” \n                      The kind of support that NASA has provided to composite manufacturing innovators like Accudyne has been essential to the continued development of the entire industry, Melilli notes. “The reality is that the work, connections, and references that NASA has continued to provide have been crucial to keeping this technology going.” \n                      In a broader sense, he says, “NASA’s support of manufacturing in general is important to maintaining and advancing the Nation’s technological capabilities. Manufacturing is so important because you end up applying all of the process lessons you have learned over time. The United States runs the risk of falling behind in developing new processes and manufacturing technologies if, as is the current trend, manufacturing continues to migrate to foreign countries. We end up being ‘distributors’ as opposed to ‘manufacturers.’ The skills are different and the compensation is as well.”\n                      This learning process is still very much underway at Langley, where the Accudyne-built machine is available for researchers and partners in private industry to use. \n                      “That machine is going to be indispensable in helping to develop a database of processes and parts made from thermoplastics,” Melilli says. In the meantime, Accudyne is currently engaged in a Small Business Technology Transfer (STTR) project with Langley and the University of Delaware to improve the properties of parts made with the SBIR-derived tape laydown head. \n                      The results indicate a bright future for out-of-autoclave thermoplastics manufacturing. Jensen notes that these parts initially exhibited performance properties 70–80 percent of those made using an autoclave. Through the STTR partnership, those results are now around 90–95 percent\n                      \n                    \n                  \n                \n              \n              \n            \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology \n                      \n                                    \n                            \n                            \n                              \n                            \n                            \n                              The Composite Crew Module allows NASA researchers to test materials and methods that may one day be applied to spacecraft constructed using composite materials.\n                            \n                                                                                        \n                                    Here is a brief list of materials that NASA will not be using to construct spacecraft: wood, adobe, fiberglass, bone. While it might be obvious why these materials would not make for safe space travel, they do share a common characteristic with materials that may well be the future foundation of spacecraft design: They all are composites. Formed of two or more unlike materials—such as cellulose and lignin in the case of wood, or glass fibers and plastic resin in the case of fiberglass—composites provide enhanced mechanical and physical properties through the combination of their constituent materials. For this reason, composites are used in everything from buildings, bathtubs, and countertops to boats, racecars, and sports equipment.\n                                    NASA continually works to develop new materials to enable future space missions—lighter, less expensive materials that can still withstand the extreme demands of space travel. Composites such as carbon fiber materials offer promising solutions in this regard, providing strength and stiffness comparable to metals like aluminum but with less weight, allowing for benefits like better fuel efficiency and simpler propulsion system design. Composites can also be made fatigue tolerant and thermally stable—useful in space where temperatures can swing hundreds of degrees.\n                                    NASA has recently explored the use of composites for aerospace applications through projects like the Composite Crew Module (CCM), a composite-constructed version of the aluminum-lithium Multipurpose Crew Capsule. The CCM was designed to give NASA engineers a chance to gain valuable experience developing and testing composite aerospace structures. \n                                    Partnership\n                                    Composites are an increasingly significant part of terrestrial applications, from transportation (the largely plastic composite airframe of the new Boeing 787 Dreamliner, for example) to medicine (composite prostheses among other uses). As the composites industry has matured, says Brian Jensen, materials scientist at Langley Research Center, NASA “started an effort to not only improve the performance of composites, but also to lower the cost.” Cost is a major challenge to composite manufacturing. Composites are traditionally fabricated by layering prepreg materials—sheets of reinforcement material, such as carbon fiber, already pre-impregnated with the bonding resin—in a mold, either by an automated process or, often, by hand. The mold is then placed in an autoclave, a pressurized oven, to cure. Large composite structures like parts of rockets, airplane wings, and wind turbine blades require massive, extremely expensive autoclaves for curing. \n                                    To help develop less costly, out-of-autoclave composite manufacturing techniques, Langley partnered with Accudyne Systems Inc., of Newark, Delaware, through the Small Business Innovation Research (SBIR) program. Through this partnership, Accudyne applied its expertise in creating custom automation equipment for composite manufacturing to develop an automated thermoplastic tape laydown head. Unlike a thermoset composite, which once cured cannot be reshaped or reprocessed, a thermoplastic can be reheated for remolding or to heal flaws in its structure. The Accudyne device deposits preheated strips of the thermoplastic materials, welding the strips together through heat and pressure to build up structures layer by layer—eliminating the need for an autoclave. \n                                    “It’s been a dual effort between Langley and Accudyne, where Langley is trying to develop the thermoplastics that work well, and Accudyne has been fine-tuning the heated head to make this process happen in a reasonable time and yield a high-quality part,” Jensen says.\n                                    Benefits\n                                    While the tape laydown head currently features as part of an Accudyne-built machine at Langley, the company’s SBIR work has yielded technology for its commercial products, as well. Autoclave-cured thermoset materials still dominate composites manufacturing, explains John Melilli, Accudyne’s vice president of sales and marketing, and the company’s commercially available deposition heads for thermoset systems employ technology created for the SBIR-developed laydown head. Through another NASA SBIR, Accudyne also developed nanoparticle technology that, when mixed with a composite resin, helps the material develop improved properties—allowing high-quality parts to be made more quickly at lower cost, Melilli says. The company has patented the innovation and expects significant commercial interest. \n                                    “NASA’s support of manufacturing is important to maintaining and advancing the Nation’s technological capabilities.”\n                                    —John Melilli, Accudyne Systems Inc.\n                                    Accudyne is currently working with major aerospace companies to develop machines for manufacturing composite rocket parts and components for helicopter rotors. The company’s automated solutions enable the production of higher quality parts at lower costs, while not threatening the jobs of the workers who previously fabricated the composite parts by hand. \n                                    \n                      \n                        \n                        \n                          \n                        \n                        \n                          The automated thermoplastic tape laydown head developed by Accudyne Systems Inc. provides Langley Research Center engineers and others with a unique tool for advancing out-of-autoclave thermoplastics manufacturing.\n                        \n                      \n                      \n                      “This is not about replacing people with machines,” Melilli says. “The people end up working with the machines, and the rate of production goes up.” \n                      The kind of support that NASA has provided to composite manufacturing innovators like Accudyne has been essential to the continued development of the entire industry, Melilli notes. “The reality is that the work, connections, and references that NASA has continued to provide have been crucial to keeping this technology going.” \n                      In a broader sense, he says, “NASA’s support of manufacturing in general is important to maintaining and advancing the Nation’s technological capabilities. Manufacturing is so important because you end up applying all of the process lessons you have learned over time. The United States runs the risk of falling behind in developing new processes and manufacturing technologies if, as is the current trend, manufacturing continues to migrate to foreign countries. We end up being ‘distributors’ as opposed to ‘manufacturers.’ The skills are different and the compensation is as well.”\n                      This learning process is still very much underway at Langley, where the Accudyne-built machine is available for researchers and partners in private industry to use. \n                      “That machine is going to be indispensable in helping to develop a database of processes and parts made from thermoplastics,” Melilli says. In the meantime, Accudyne is currently engaged in a Small Business Technology Transfer (STTR) project with Langley and the University of Delaware to improve the properties of parts made with the SBIR-derived tape laydown head. \n                      The results indicate a bright future for out-of-autoclave thermoplastics manufacturing. Jensen notes that these parts initially exhibited performance properties 70–80 percent of those made using an autoclave. Through the STTR partnership, those results are now around 90–95 percent\n                      \n                    \n                  \n                \n              \n              \n            \n              \n                \n                  \n                    \n                      NASA Technology \n                      \n                                    \n                            \n                            \n                              \n                            \n                            \n                              The Composite Crew Module allows NASA researchers to test materials and methods that may one day be applied to spacecraft constructed using composite materials.\n                            \n                                                                                        \n                                    Here is a brief list of materials that NASA will not be using to construct spacecraft: wood, adobe, fiberglass, bone. While it might be obvious why these materials would not make for safe space travel, they do share a common characteristic with materials that may well be the future foundation of spacecraft design: They all are composites. Formed of two or more unlike materials—such as cellulose and lignin in the case of wood, or glass fibers and plastic resin in the case of fiberglass—composites provide enhanced mechanical and physical properties through the combination of their constituent materials. For this reason, composites are used in everything from buildings, bathtubs, and countertops to boats, racecars, and sports equipment.\n                                    NASA continually works to develop new materials to enable future space missions—lighter, less expensive materials that can still withstand the extreme demands of space travel. Composites such as carbon fiber materials offer promising solutions in this regard, providing strength and stiffness comparable to metals like aluminum but with less weight, allowing for benefits like better fuel efficiency and simpler propulsion system design. Composites can also be made fatigue tolerant and thermally stable—useful in space where temperatures can swing hundreds of degrees.\n                                    NASA has recently explored the use of composites for aerospace applications through projects like the Composite Crew Module (CCM), a composite-constructed version of the aluminum-lithium Multipurpose Crew Capsule. The CCM was designed to give NASA engineers a chance to gain valuable experience developing and testing composite aerospace structures. \n                                    Partnership\n                                    Composites are an increasingly significant part of terrestrial applications, from transportation (the largely plastic composite airframe of the new Boeing 787 Dreamliner, for example) to medicine (composite prostheses among other uses). As the composites industry has matured, says Brian Jensen, materials scientist at Langley Research Center, NASA “started an effort to not only improve the performance of composites, but also to lower the cost.” Cost is a major challenge to composite manufacturing. Composites are traditionally fabricated by layering prepreg materials—sheets of reinforcement material, such as carbon fiber, already pre-impregnated with the bonding resin—in a mold, either by an automated process or, often, by hand. The mold is then placed in an autoclave, a pressurized oven, to cure. Large composite structures like parts of rockets, airplane wings, and wind turbine blades require massive, extremely expensive autoclaves for curing. \n                                    To help develop less costly, out-of-autoclave composite manufacturing techniques, Langley partnered with Accudyne Systems Inc., of Newark, Delaware, through the Small Business Innovation Research (SBIR) program. Through this partnership, Accudyne applied its expertise in creating custom automation equipment for composite manufacturing to develop an automated thermoplastic tape laydown head. Unlike a thermoset composite, which once cured cannot be reshaped or reprocessed, a thermoplastic can be reheated for remolding or to heal flaws in its structure. The Accudyne device deposits preheated strips of the thermoplastic materials, welding the strips together through heat and pressure to build up structures layer by layer—eliminating the need for an autoclave. \n                                    “It’s been a dual effort between Langley and Accudyne, where Langley is trying to develop the thermoplastics that work well, and Accudyne has been fine-tuning the heated head to make this process happen in a reasonable time and yield a high-quality part,” Jensen says.\n                                    Benefits\n                                    While the tape laydown head currently features as part of an Accudyne-built machine at Langley, the company’s SBIR work has yielded technology for its commercial products, as well. Autoclave-cured thermoset materials still dominate composites manufacturing, explains John Melilli, Accudyne’s vice president of sales and marketing, and the company’s commercially available deposition heads for thermoset systems employ technology created for the SBIR-developed laydown head. Through another NASA SBIR, Accudyne also developed nanoparticle technology that, when mixed with a composite resin, helps the material develop improved properties—allowing high-quality parts to be made more quickly at lower cost, Melilli says. The company has patented the innovation and expects significant commercial interest. \n                                    “NASA’s support of manufacturing is important to maintaining and advancing the Nation’s technological capabilities.”\n                                    —John Melilli, Accudyne Systems Inc.\n                                    Accudyne is currently working with major aerospace companies to develop machines for manufacturing composite rocket parts and components for helicopter rotors. The company’s automated solutions enable the production of higher quality parts at lower costs, while not threatening the jobs of the workers who previously fabricated the composite parts by hand. \n                                    \n                      \n                        \n                        \n                          \n                        \n                        \n                          The automated thermoplastic tape laydown head developed by Accudyne Systems Inc. provides Langley Research Center engineers and others with a unique tool for advancing out-of-autoclave thermoplastics manufacturing.\n                        \n                      \n                      \n                      “This is not about replacing people with machines,” Melilli says. “The people end up working with the machines, and the rate of production goes up.” \n                      The kind of support that NASA has provided to composite manufacturing innovators like Accudyne has been essential to the continued development of the entire industry, Melilli notes. “The reality is that the work, connections, and references that NASA has continued to provide have been crucial to keeping this technology going.” \n                      In a broader sense, he says, “NASA’s support of manufacturing in general is important to maintaining and advancing the Nation’s technological capabilities. Manufacturing is so important because you end up applying all of the process lessons you have learned over time. The United States runs the risk of falling behind in developing new processes and manufacturing technologies if, as is the current trend, manufacturing continues to migrate to foreign countries. We end up being ‘distributors’ as opposed to ‘manufacturers.’ The skills are different and the compensation is as well.”\n                      This learning process is still very much underway at Langley, where the Accudyne-built machine is available for researchers and partners in private industry to use. \n                      “That machine is going to be indispensable in helping to develop a database of processes and parts made from thermoplastics,” Melilli says. In the meantime, Accudyne is currently engaged in a Small Business Technology Transfer (STTR) project with Langley and the University of Delaware to improve the properties of parts made with the SBIR-derived tape laydown head. \n                      The results indicate a bright future for out-of-autoclave thermoplastics manufacturing. Jensen notes that these parts initially exhibited performance properties 70–80 percent of those made using an autoclave. Through the STTR partnership, those results are now around 90–95 percent\n                      \n                    \n                  \n                \n              \n              \n                \n                  \n                    \n                      NASA Technology \n                      \n                                    \n                            \n                            \n                              \n                            \n                            \n                              The Composite Crew Module allows NASA researchers to test materials and methods that may one day be applied to spacecraft constructed using composite materials.\n                            \n                                                                                        \n                                    Here is a brief list of materials that NASA will not be using to construct spacecraft: wood, adobe, fiberglass, bone. While it might be obvious why these materials would not make for safe space travel, they do share a common characteristic with materials that may well be the future foundation of spacecraft design: They all are composites. Formed of two or more unlike materials—such as cellulose and lignin in the case of wood, or glass fibers and plastic resin in the case of fiberglass—composites provide enhanced mechanical and physical properties through the combination of their constituent materials. For this reason, composites are used in everything from buildings, bathtubs, and countertops to boats, racecars, and sports equipment.\n                                    NASA continually works to develop new materials to enable future space missions—lighter, less expensive materials that can still withstand the extreme demands of space travel. Composites such as carbon fiber materials offer promising solutions in this regard, providing strength and stiffness comparable to metals like aluminum but with less weight, allowing for benefits like better fuel efficiency and simpler propulsion system design. Composites can also be made fatigue tolerant and thermally stable—useful in space where temperatures can swing hundreds of degrees.\n                                    NASA has recently explored the use of composites for aerospace applications through projects like the Composite Crew Module (CCM), a composite-constructed version of the aluminum-lithium Multipurpose Crew Capsule. The CCM was designed to give NASA engineers a chance to gain valuable experience developing and testing composite aerospace structures. \n                                    Partnership\n                                    Composites are an increasingly significant part of terrestrial applications, from transportation (the largely plastic composite airframe of the new Boeing 787 Dreamliner, for example) to medicine (composite prostheses among other uses). As the composites industry has matured, says Brian Jensen, materials scientist at Langley Research Center, NASA “started an effort to not only improve the performance of composites, but also to lower the cost.” Cost is a major challenge to composite manufacturing. Composites are traditionally fabricated by layering prepreg materials—sheets of reinforcement material, such as carbon fiber, already pre-impregnated with the bonding resin—in a mold, either by an automated process or, often, by hand. The mold is then placed in an autoclave, a pressurized oven, to cure. Large composite structures like parts of rockets, airplane wings, and wind turbine blades require massive, extremely expensive autoclaves for curing. \n                                    To help develop less costly, out-of-autoclave composite manufacturing techniques, Langley partnered with Accudyne Systems Inc., of Newark, Delaware, through the Small Business Innovation Research (SBIR) program. Through this partnership, Accudyne applied its expertise in creating custom automation equipment for composite manufacturing to develop an automated thermoplastic tape laydown head. Unlike a thermoset composite, which once cured cannot be reshaped or reprocessed, a thermoplastic can be reheated for remolding or to heal flaws in its structure. The Accudyne device deposits preheated strips of the thermoplastic materials, welding the strips together through heat and pressure to build up structures layer by layer—eliminating the need for an autoclave. \n                                    “It’s been a dual effort between Langley and Accudyne, where Langley is trying to develop the thermoplastics that work well, and Accudyne has been fine-tuning the heated head to make this process happen in a reasonable time and yield a high-quality part,” Jensen says.\n                                    Benefits\n                                    While the tape laydown head currently features as part of an Accudyne-built machine at Langley, the company’s SBIR work has yielded technology for its commercial products, as well. Autoclave-cured thermoset materials still dominate composites manufacturing, explains John Melilli, Accudyne’s vice president of sales and marketing, and the company’s commercially available deposition heads for thermoset systems employ technology created for the SBIR-developed laydown head. Through another NASA SBIR, Accudyne also developed nanoparticle technology that, when mixed with a composite resin, helps the material develop improved properties—allowing high-quality parts to be made more quickly at lower cost, Melilli says. The company has patented the innovation and expects significant commercial interest. \n                                    “NASA’s support of manufacturing is important to maintaining and advancing the Nation’s technological capabilities.”\n                                    —John Melilli, Accudyne Systems Inc.\n                                    Accudyne is currently working with major aerospace companies to develop machines for manufacturing composite rocket parts and components for helicopter rotors. The company’s automated solutions enable the production of higher quality parts at lower costs, while not threatening the jobs of the workers who previously fabricated the composite parts by hand. \n                                    \n                      \n                        \n                        \n                          \n                        \n                        \n                          The automated thermoplastic tape laydown head developed by Accudyne Systems Inc. provides Langley Research Center engineers and others with a unique tool for advancing out-of-autoclave thermoplastics manufacturing.\n                        \n                      \n                      \n                      “This is not about replacing people with machines,” Melilli says. “The people end up working with the machines, and the rate of production goes up.” \n                      The kind of support that NASA has provided to composite manufacturing innovators like Accudyne has been essential to the continued development of the entire industry, Melilli notes. “The reality is that the work, connections, and references that NASA has continued to provide have been crucial to keeping this technology going.” \n                      In a broader sense, he says, “NASA’s support of manufacturing in general is important to maintaining and advancing the Nation’s technological capabilities. Manufacturing is so important because you end up applying all of the process lessons you have learned over time. The United States runs the risk of falling behind in developing new processes and manufacturing technologies if, as is the current trend, manufacturing continues to migrate to foreign countries. We end up being ‘distributors’ as opposed to ‘manufacturers.’ The skills are different and the compensation is as well.”\n                      This learning process is still very much underway at Langley, where the Accudyne-built machine is available for researchers and partners in private industry to use. \n                      “That machine is going to be indispensable in helping to develop a database of processes and parts made from thermoplastics,” Melilli says. In the meantime, Accudyne is currently engaged in a Small Business Technology Transfer (STTR) project with Langley and the University of Delaware to improve the properties of parts made with the SBIR-derived tape laydown head. \n                      The results indicate a bright future for out-of-autoclave thermoplastics manufacturing. Jensen notes that these parts initially exhibited performance properties 70–80 percent of those made using an autoclave. Through the STTR partnership, those results are now around 90–95 percent\n                      \n                    \n                  \n                \n                  \n                    \n                      NASA Technology \n                      \n                                    \n                            \n                            \n                              \n                            \n                            \n                              The Composite Crew Module allows NASA researchers to test materials and methods that may one day be applied to spacecraft constructed using composite materials.\n                            \n                                                                                        \n                                    Here is a brief list of materials that NASA will not be using to construct spacecraft: wood, adobe, fiberglass, bone. While it might be obvious why these materials would not make for safe space travel, they do share a common characteristic with materials that may well be the future foundation of spacecraft design: They all are composites. Formed of two or more unlike materials—such as cellulose and lignin in the case of wood, or glass fibers and plastic resin in the case of fiberglass—composites provide enhanced mechanical and physical properties through the combination of their constituent materials. For this reason, composites are used in everything from buildings, bathtubs, and countertops to boats, racecars, and sports equipment.\n                                    NASA continually works to develop new materials to enable future space missions—lighter, less expensive materials that can still withstand the extreme demands of space travel. Composites such as carbon fiber materials offer promising solutions in this regard, providing strength and stiffness comparable to metals like aluminum but with less weight, allowing for benefits like better fuel efficiency and simpler propulsion system design. Composites can also be made fatigue tolerant and thermally stable—useful in space where temperatures can swing hundreds of degrees.\n                                    NASA has recently explored the use of composites for aerospace applications through projects like the Composite Crew Module (CCM), a composite-constructed version of the aluminum-lithium Multipurpose Crew Capsule. The CCM was designed to give NASA engineers a chance to gain valuable experience developing and testing composite aerospace structures. \n                                    Partnership\n                                    Composites are an increasingly significant part of terrestrial applications, from transportation (the largely plastic composite airframe of the new Boeing 787 Dreamliner, for example) to medicine (composite prostheses among other uses). As the composites industry has matured, says Brian Jensen, materials scientist at Langley Research Center, NASA “started an effort to not only improve the performance of composites, but also to lower the cost.” Cost is a major challenge to composite manufacturing. Composites are traditionally fabricated by layering prepreg materials—sheets of reinforcement material, such as carbon fiber, already pre-impregnated with the bonding resin—in a mold, either by an automated process or, often, by hand. The mold is then placed in an autoclave, a pressurized oven, to cure. Large composite structures like parts of rockets, airplane wings, and wind turbine blades require massive, extremely expensive autoclaves for curing. \n                                    To help develop less costly, out-of-autoclave composite manufacturing techniques, Langley partnered with Accudyne Systems Inc., of Newark, Delaware, through the Small Business Innovation Research (SBIR) program. Through this partnership, Accudyne applied its expertise in creating custom automation equipment for composite manufacturing to develop an automated thermoplastic tape laydown head. Unlike a thermoset composite, which once cured cannot be reshaped or reprocessed, a thermoplastic can be reheated for remolding or to heal flaws in its structure. The Accudyne device deposits preheated strips of the thermoplastic materials, welding the strips together through heat and pressure to build up structures layer by layer—eliminating the need for an autoclave. \n                                    “It’s been a dual effort between Langley and Accudyne, where Langley is trying to develop the thermoplastics that work well, and Accudyne has been fine-tuning the heated head to make this process happen in a reasonable time and yield a high-quality part,” Jensen says.\n                                    Benefits\n                                    While the tape laydown head currently features as part of an Accudyne-built machine at Langley, the company’s SBIR work has yielded technology for its commercial products, as well. Autoclave-cured thermoset materials still dominate composites manufacturing, explains John Melilli, Accudyne’s vice president of sales and marketing, and the company’s commercially available deposition heads for thermoset systems employ technology created for the SBIR-developed laydown head. Through another NASA SBIR, Accudyne also developed nanoparticle technology that, when mixed with a composite resin, helps the material develop improved properties—allowing high-quality parts to be made more quickly at lower cost, Melilli says. The company has patented the innovation and expects significant commercial interest. \n                                    “NASA’s support of manufacturing is important to maintaining and advancing the Nation’s technological capabilities.”\n                                    —John Melilli, Accudyne Systems Inc.\n                                    Accudyne is currently working with major aerospace companies to develop machines for manufacturing composite rocket parts and components for helicopter rotors. The company’s automated solutions enable the production of higher quality parts at lower costs, while not threatening the jobs of the workers who previously fabricated the composite parts by hand. \n                                    \n                      \n                        \n                        \n                          \n                        \n                        \n                          The automated thermoplastic tape laydown head developed by Accudyne Systems Inc. provides Langley Research Center engineers and others with a unique tool for advancing out-of-autoclave thermoplastics manufacturing.\n                        \n                      \n                      \n                      “This is not about replacing people with machines,” Melilli says. “The people end up working with the machines, and the rate of production goes up.” \n                      The kind of support that NASA has provided to composite manufacturing innovators like Accudyne has been essential to the continued development of the entire industry, Melilli notes. “The reality is that the work, connections, and references that NASA has continued to provide have been crucial to keeping this technology going.” \n                      In a broader sense, he says, “NASA’s support of manufacturing in general is important to maintaining and advancing the Nation’s technological capabilities. Manufacturing is so important because you end up applying all of the process lessons you have learned over time. The United States runs the risk of falling behind in developing new processes and manufacturing technologies if, as is the current trend, manufacturing continues to migrate to foreign countries. We end up being ‘distributors’ as opposed to ‘manufacturers.’ The skills are different and the compensation is as well.”\n                      This learning process is still very much underway at Langley, where the Accudyne-built machine is available for researchers and partners in private industry to use. \n                      “That machine is going to be indispensable in helping to develop a database of processes and parts made from thermoplastics,” Melilli says. In the meantime, Accudyne is currently engaged in a Small Business Technology Transfer (STTR) project with Langley and the University of Delaware to improve the properties of parts made with the SBIR-derived tape laydown head. \n                      The results indicate a bright future for out-of-autoclave thermoplastics manufacturing. Jensen notes that these parts initially exhibited performance properties 70–80 percent of those made using an autoclave. Through the STTR partnership, those results are now around 90–95 percent\n                      \n                    \n                  \n                    \n                      NASA Technology \n                      \n                                    \n                            \n                            \n                              \n                            \n                            \n                              The Composite Crew Module allows NASA researchers to test materials and methods that may one day be applied to spacecraft constructed using composite materials.\n                            \n                                                                                        \n                                    Here is a brief list of materials that NASA will not be using to construct spacecraft: wood, adobe, fiberglass, bone. While it might be obvious why these materials would not make for safe space travel, they do share a common characteristic with materials that may well be the future foundation of spacecraft design: They all are composites. Formed of two or more unlike materials—such as cellulose and lignin in the case of wood, or glass fibers and plastic resin in the case of fiberglass—composites provide enhanced mechanical and physical properties through the combination of their constituent materials. For this reason, composites are used in everything from buildings, bathtubs, and countertops to boats, racecars, and sports equipment.\n                                    NASA continually works to develop new materials to enable future space missions—lighter, less expensive materials that can still withstand the extreme demands of space travel. Composites such as carbon fiber materials offer promising solutions in this regard, providing strength and stiffness comparable to metals like aluminum but with less weight, allowing for benefits like better fuel efficiency and simpler propulsion system design. Composites can also be made fatigue tolerant and thermally stable—useful in space where temperatures can swing hundreds of degrees.\n                                    NASA has recently explored the use of composites for aerospace applications through projects like the Composite Crew Module (CCM), a composite-constructed version of the aluminum-lithium Multipurpose Crew Capsule. The CCM was designed to give NASA engineers a chance to gain valuable experience developing and testing composite aerospace structures. \n                                    Partnership\n                                    Composites are an increasingly significant part of terrestrial applications, from transportation (the largely plastic composite airframe of the new Boeing 787 Dreamliner, for example) to medicine (composite prostheses among other uses). As the composites industry has matured, says Brian Jensen, materials scientist at Langley Research Center, NASA “started an effort to not only improve the performance of composites, but also to lower the cost.” Cost is a major challenge to composite manufacturing. Composites are traditionally fabricated by layering prepreg materials—sheets of reinforcement material, such as carbon fiber, already pre-impregnated with the bonding resin—in a mold, either by an automated process or, often, by hand. The mold is then placed in an autoclave, a pressurized oven, to cure. Large composite structures like parts of rockets, airplane wings, and wind turbine blades require massive, extremely expensive autoclaves for curing. \n                                    To help develop less costly, out-of-autoclave composite manufacturing techniques, Langley partnered with Accudyne Systems Inc., of Newark, Delaware, through the Small Business Innovation Research (SBIR) program. Through this partnership, Accudyne applied its expertise in creating custom automation equipment for composite manufacturing to develop an automated thermoplastic tape laydown head. Unlike a thermoset composite, which once cured cannot be reshaped or reprocessed, a thermoplastic can be reheated for remolding or to heal flaws in its structure. The Accudyne device deposits preheated strips of the thermoplastic materials, welding the strips together through heat and pressure to build up structures layer by layer—eliminating the need for an autoclave. \n                                    “It’s been a dual effort between Langley and Accudyne, where Langley is trying to develop the thermoplastics that work well, and Accudyne has been fine-tuning the heated head to make this process happen in a reasonable time and yield a high-quality part,” Jensen says.\n                                    Benefits\n                                    While the tape laydown head currently features as part of an Accudyne-built machine at Langley, the company’s SBIR work has yielded technology for its commercial products, as well. Autoclave-cured thermoset materials still dominate composites manufacturing, explains John Melilli, Accudyne’s vice president of sales and marketing, and the company’s commercially available deposition heads for thermoset systems employ technology created for the SBIR-developed laydown head. Through another NASA SBIR, Accudyne also developed nanoparticle technology that, when mixed with a composite resin, helps the material develop improved properties—allowing high-quality parts to be made more quickly at lower cost, Melilli says. The company has patented the innovation and expects significant commercial interest. \n                                    “NASA’s support of manufacturing is important to maintaining and advancing the Nation’s technological capabilities.”\n                                    —John Melilli, Accudyne Systems Inc.\n                                    Accudyne is currently working with major aerospace companies to develop machines for manufacturing composite rocket parts and components for helicopter rotors. The company’s automated solutions enable the production of higher quality parts at lower costs, while not threatening the jobs of the workers who previously fabricated the composite parts by hand. \n                                    \n                      \n                        \n                        \n                          \n                        \n                        \n                          The automated thermoplastic tape laydown head developed by Accudyne Systems Inc. provides Langley Research Center engineers and others with a unique tool for advancing out-of-autoclave thermoplastics manufacturing.\n                        \n                      \n                      \n                      “This is not about replacing people with machines,” Melilli says. “The people end up working with the machines, and the rate of production goes up.” \n                      The kind of support that NASA has provided to composite manufacturing innovators like Accudyne has been essential to the continued development of the entire industry, Melilli notes. “The reality is that the work, connections, and references that NASA has continued to provide have been crucial to keeping this technology going.” \n                      In a broader sense, he says, “NASA’s support of manufacturing in general is important to maintaining and advancing the Nation’s technological capabilities. Manufacturing is so important because you end up applying all of the process lessons you have learned over time. The United States runs the risk of falling behind in developing new processes and manufacturing technologies if, as is the current trend, manufacturing continues to migrate to foreign countries. We end up being ‘distributors’ as opposed to ‘manufacturers.’ The skills are different and the compensation is as well.”\n                      This learning process is still very much underway at Langley, where the Accudyne-built machine is available for researchers and partners in private industry to use. \n                      “That machine is going to be indispensable in helping to develop a database of processes and parts made from thermoplastics,” Melilli says. In the meantime, Accudyne is currently engaged in a Small Business Technology Transfer (STTR) project with Langley and the University of Delaware to improve the properties of parts made with the SBIR-derived tape laydown head. \n                      The results indicate a bright future for out-of-autoclave thermoplastics manufacturing. Jensen notes that these parts initially exhibited performance properties 70–80 percent of those made using an autoclave. Through the STTR partnership, those results are now around 90–95 percent\n                      \n                    \n                                    \n                            \n                            \n                              \n                            \n                            \n                              The Composite Crew Module allows NASA researchers to test materials and methods that may one day be applied to spacecraft constructed using composite materials.\n                            \n                                                                                        \n                                    Here is a brief list of materials that NASA will not be using to construct spacecraft: wood, adobe, fiberglass, bone. While it might be obvious why these materials would not make for safe space travel, they do share a common characteristic with materials that may well be the future foundation of spacecraft design: They all are composites. Formed of two or more unlike materials—such as cellulose and lignin in the case of wood, or glass fibers and plastic resin in the case of fiberglass—composites provide enhanced mechanical and physical properties through the combination of their constituent materials. For this reason, composites are used in everything from buildings, bathtubs, and countertops to boats, racecars, and sports equipment.\n                                    NASA continually works to develop new materials to enable future space missions—lighter, less expensive materials that can still withstand the extreme demands of space travel. Composites such as carbon fiber materials offer promising solutions in this regard, providing strength and stiffness comparable to metals like aluminum but with less weight, allowing for benefits like better fuel efficiency and simpler propulsion system design. Composites can also be made fatigue tolerant and thermally stable—useful in space where temperatures can swing hundreds of degrees.\n                                    NASA has recently explored the use of composites for aerospace applications through projects like the Composite Crew Module (CCM), a composite-constructed version of the aluminum-lithium Multipurpose Crew Capsule. The CCM was designed to give NASA engineers a chance to gain valuable experience developing and testing composite aerospace structures. \n                                    Partnership\n                                    Composites are an increasingly significant part of terrestrial applications, from transportation (the largely plastic composite airframe of the new Boeing 787 Dreamliner, for example) to medicine (composite prostheses among other uses). As the composites industry has matured, says Brian Jensen, materials scientist at Langley Research Center, NASA “started an effort to not only improve the performance of composites, but also to lower the cost.” Cost is a major challenge to composite manufacturing. Composites are traditionally fabricated by layering prepreg materials—sheets of reinforcement material, such as carbon fiber, already pre-impregnated with the bonding resin—in a mold, either by an automated process or, often, by hand. The mold is then placed in an autoclave, a pressurized oven, to cure. Large composite structures like parts of rockets, airplane wings, and wind turbine blades require massive, extremely expensive autoclaves for curing. \n                                    To help develop less costly, out-of-autoclave composite manufacturing techniques, Langley partnered with Accudyne Systems Inc., of Newark, Delaware, through the Small Business Innovation Research (SBIR) program. Through this partnership, Accudyne applied its expertise in creating custom automation equipment for composite manufacturing to develop an automated thermoplastic tape laydown head. Unlike a thermoset composite, which once cured cannot be reshaped or reprocessed, a thermoplastic can be reheated for remolding or to heal flaws in its structure. The Accudyne device deposits preheated strips of the thermoplastic materials, welding the strips together through heat and pressure to build up structures layer by layer—eliminating the need for an autoclave. \n                                    “It’s been a dual effort between Langley and Accudyne, where Langley is trying to develop the thermoplastics that work well, and Accudyne has been fine-tuning the heated head to make this process happen in a reasonable time and yield a high-quality part,” Jensen says.\n                                    Benefits\n                                    While the tape laydown head currently features as part of an Accudyne-built machine at Langley, the company’s SBIR work has yielded technology for its commercial products, as well. Autoclave-cured thermoset materials still dominate composites manufacturing, explains John Melilli, Accudyne’s vice president of sales and marketing, and the company’s commercially available deposition heads for thermoset systems employ technology created for the SBIR-developed laydown head. Through another NASA SBIR, Accudyne also developed nanoparticle technology that, when mixed with a composite resin, helps the material develop improved properties—allowing high-quality parts to be made more quickly at lower cost, Melilli says. The company has patented the innovation and expects significant commercial interest. \n                                    “NASA’s support of manufacturing is important to maintaining and advancing the Nation’s technological capabilities.”\n                                    —John Melilli, Accudyne Systems Inc.\n                                    Accudyne is currently working with major aerospace companies to develop machines for manufacturing composite rocket parts and components for helicopter rotors. The company’s automated solutions enable the production of higher quality parts at lower costs, while not threatening the jobs of the workers who previously fabricated the composite parts by hand. \n                                    \n                      “This is not about replacing people with machines,” Melilli says. “The people end up working with the machines, and the rate of production goes up.” \n                      The kind of support that NASA has provided to composite manufacturing innovators like Accudyne has been essential to the continued development of the entire industry, Melilli notes. “The reality is that the work, connections, and references that NASA has continued to provide have been crucial to keeping this technology going.” \n                      In a broader sense, he says, “NASA’s support of manufacturing in general is important to maintaining and advancing the Nation’s technological capabilities. Manufacturing is so important because you end up applying all of the process lessons you have learned over time. The United States runs the risk of falling behind in developing new processes and manufacturing technologies if, as is the current trend, manufacturing continues to migrate to foreign countries. We end up being ‘distributors’ as opposed to ‘manufacturers.’ The skills are different and the compensation is as well.”\n                      This learning process is still very much underway at Langley, where the Accudyne-built machine is available for researchers and partners in private industry to use. \n                      “That machine is going to be indispensable in helping to develop a database of processes and parts made from thermoplastics,” Melilli says. In the meantime, Accudyne is currently engaged in a Small Business Technology Transfer (STTR) project with Langley and the University of Delaware to improve the properties of parts made with the SBIR-derived tape laydown head. \n                      The results indicate a bright future for out-of-autoclave thermoplastics manufacturing. Jensen notes that these parts initially exhibited performance properties 70–80 percent of those made using an autoclave. Through the STTR partnership, those results are now around 90–95 percent\n                      "},{"href":"http://spinoff.nasa.gov/Spinoff2011/ip_3.html","text":"Polyimide Foams Offer Superior Insulation","image":"http://spinoff.nasa.gov/Spinoff2011/Images/ip_3a_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      At Langley Research Center, Erik Weiser and his colleagues in the Advanced Materials and Processing Branch were working with a new substance for fabricating composites for use in supersonic aircraft. The team, however, was experiencing some frustration. Every time they tried to create a solid composite from the polyimide (an advanced polymer) material, it bubbled and foamed. \n                      It seemed like the team had reached a dead end in their research—until they had another idea. \n                      “We said, ‘This isn’t going to work for composites, but maybe we could make a foam out of it,’” Weiser says. “That was kind of our eureka moment, to see if we could go in a whole other direction. And it worked.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT LLC’s highly flexible polyimide foam—seen here during testing at Kennedy Space Center—provides an ideal insulation for pipes in cryogenic and other industrial and marine applications.\n                        \n                      \n                      Weiser and his colleagues invented a new kind of polyimide foam insulation they named TEEK. The innovation displayed a host of advantages over existing insulation options. Compared to other commercial foams, Weiser explains, polyimide foams perform well across a broad range of temperatures, noting that the NASA TEEK foams provide effective structural insulation up to 600 °F and down to cryogenic temperatures. The foam does not burn or off-gas toxic fumes, and even at -423 °F—the temperature of liquid hydrogen—the material stays flexible. The inventors could produce the TEEK foam at a range of densities, from 0.5 pounds per cubic foot up to 20 pounds per cubic foot, making the foam ideal for a range of applications, including as insulation for reusable launch vehicles and for cryogenic tanks and lines. They also developed a unique, friable balloon format for manufacturing the foam, producing it as hollow microspheres that allowed the foam to be molded and then cured into any desired shape—perfect for insulating pipes of different sizes and configurations. \n                      The team’s originally unplanned invention won an “R&D 100” award, and a later form of the foam, called LaRC FPF-44 (Spinoff 2009), was named “NASA Invention of the Year” in 2007. \n                      Partnership \n                      In 2002, NASA licensed the TEEK family of foams to GFT LLC, based in Pennville, Indiana. GFT helped Langley manufacture samples of the foam for potential space applications, such as for insulating the external tank of the space shuttle. The company also optimized the technology to create the first highly flexible foam from polyimide microspheres, allowing for the production of intricate pipe covers of different diameters and wall thicknesses. Kennedy Space Center also researched potential shuttle and cryogenic test equipment applications of the GFT-manufactured foams. \n                      Benefits\n                      GFT now offers the NASA-derived polyimide foam technologies as its PerForma-H and VersaFlex product lines. The company produces the foams in varying densities and formats, from sheets to foam-filled honeycombs and panels to hollow microspheres. GFT’s VersaFlex foams provide the added capability of extreme physical flexibility over a 1,000-degree temperature range (-423 °F to more than 600 °F). Customers are taking notice of the foam’s special characteristics, says GFT CEO Phil Griffith, who admits to being “enamored” with the material himself. \n                      “Not only is it an excellent thermal insulator, but it’s also nonflammable and nontoxic in a fire,” he says. “There are a lot of insulating materials out there, but of those that are both fireproof and nontoxic, there are only a few. You find even less at the density of these materials that display outstanding mechanical properties. In fact, you find only PerForma-H and VersaFlex.” \n                      The performance-to-weight ratio of the GFT foams, Griffith says, is better than any available alternatives, providing substantial savings for customers: “You can use less of the polyimide foam to get the same insulating properties as traditional materials, and it weighs about one-seventh as much as calcium silicate and is on par with fiberglass.” Griffith notes that one of GFT’s large marine customers has realized a 90-percent reduction in labor costs from the adoption of PerForma-H as piping insulation, as documented during the customer’s shipboard installations on active duty vessels. The reduction comes as a result of lowered installation and maintenance costs, reusability, and an increased life cycle due to the foam’s high performance in heavy traffic areas and harsh environments. \n                      \n                        “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.”\n                          —Phil Griffith, GFT LLC \n                      \n                      Griffith also points out that the material is environmentally friendly, manufactured without \n                        any poisonous halogenated substances and using solvents that are completely recoverable. Manufacturing the NASA-developed foams is essentially “a wasteless process,” he says. \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT’s NASA-derived foams (seen as preformed clamshells in the inset image) find significant use in engine rooms and other areas of marine vessels that require highly durable pipe insulation.\n                        \n                      \n                      Providing pipe insulation that is easily installed on marine vessels is currently the main use for GFT’s foams. The small company recently entered into product deals that Griffith says will keep GFT manufacturing for the next 10 to 15 years—a major accomplishment considering the single significant disadvantage of the polyimide foams is that they are presently somewhat expensive to manufacture. \n                      “The foams have been expensive to make for a variety of reasons, one being the limited availability of certain components,” Griffith explains. “We’ve addressed that supply issue to adequately support a commercial ramp.” \n                      The technology’s NASA origin lends immediate credibility to GFT’s products and opens doors for investment, Griffith says. “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.” \n                      Weiser, in the meantime, is working on acoustic insulation applications for polyimide foams, a potentially safer replacement for the more flammable fiberglass insulation used to dampen noise in commercial aircraft. He also notes interest in the technology for safe, ecologically sound building insulation. “If you have a fire, this foam isn’t going to burn or produce smoke,” he says, a boon for buildings from suburban homes to downtown high rises. \n                      Industry applications outside of NASA are something that Weiser always keeps in mind. “We want to meet NASA’s goals first,” he says, “but the value of the technology will go up for NASA if industry can use it for other purposes.”\n                      PerForma-H® and VersaFlex® are registered trademarks of GFT LLC\n                    \n                    \n                  \n                \n              \n              \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      At Langley Research Center, Erik Weiser and his colleagues in the Advanced Materials and Processing Branch were working with a new substance for fabricating composites for use in supersonic aircraft. The team, however, was experiencing some frustration. Every time they tried to create a solid composite from the polyimide (an advanced polymer) material, it bubbled and foamed. \n                      It seemed like the team had reached a dead end in their research—until they had another idea. \n                      “We said, ‘This isn’t going to work for composites, but maybe we could make a foam out of it,’” Weiser says. “That was kind of our eureka moment, to see if we could go in a whole other direction. And it worked.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT LLC’s highly flexible polyimide foam—seen here during testing at Kennedy Space Center—provides an ideal insulation for pipes in cryogenic and other industrial and marine applications.\n                        \n                      \n                      Weiser and his colleagues invented a new kind of polyimide foam insulation they named TEEK. The innovation displayed a host of advantages over existing insulation options. Compared to other commercial foams, Weiser explains, polyimide foams perform well across a broad range of temperatures, noting that the NASA TEEK foams provide effective structural insulation up to 600 °F and down to cryogenic temperatures. The foam does not burn or off-gas toxic fumes, and even at -423 °F—the temperature of liquid hydrogen—the material stays flexible. The inventors could produce the TEEK foam at a range of densities, from 0.5 pounds per cubic foot up to 20 pounds per cubic foot, making the foam ideal for a range of applications, including as insulation for reusable launch vehicles and for cryogenic tanks and lines. They also developed a unique, friable balloon format for manufacturing the foam, producing it as hollow microspheres that allowed the foam to be molded and then cured into any desired shape—perfect for insulating pipes of different sizes and configurations. \n                      The team’s originally unplanned invention won an “R&D 100” award, and a later form of the foam, called LaRC FPF-44 (Spinoff 2009), was named “NASA Invention of the Year” in 2007. \n                      Partnership \n                      In 2002, NASA licensed the TEEK family of foams to GFT LLC, based in Pennville, Indiana. GFT helped Langley manufacture samples of the foam for potential space applications, such as for insulating the external tank of the space shuttle. The company also optimized the technology to create the first highly flexible foam from polyimide microspheres, allowing for the production of intricate pipe covers of different diameters and wall thicknesses. Kennedy Space Center also researched potential shuttle and cryogenic test equipment applications of the GFT-manufactured foams. \n                      Benefits\n                      GFT now offers the NASA-derived polyimide foam technologies as its PerForma-H and VersaFlex product lines. The company produces the foams in varying densities and formats, from sheets to foam-filled honeycombs and panels to hollow microspheres. GFT’s VersaFlex foams provide the added capability of extreme physical flexibility over a 1,000-degree temperature range (-423 °F to more than 600 °F). Customers are taking notice of the foam’s special characteristics, says GFT CEO Phil Griffith, who admits to being “enamored” with the material himself. \n                      “Not only is it an excellent thermal insulator, but it’s also nonflammable and nontoxic in a fire,” he says. “There are a lot of insulating materials out there, but of those that are both fireproof and nontoxic, there are only a few. You find even less at the density of these materials that display outstanding mechanical properties. In fact, you find only PerForma-H and VersaFlex.” \n                      The performance-to-weight ratio of the GFT foams, Griffith says, is better than any available alternatives, providing substantial savings for customers: “You can use less of the polyimide foam to get the same insulating properties as traditional materials, and it weighs about one-seventh as much as calcium silicate and is on par with fiberglass.” Griffith notes that one of GFT’s large marine customers has realized a 90-percent reduction in labor costs from the adoption of PerForma-H as piping insulation, as documented during the customer’s shipboard installations on active duty vessels. The reduction comes as a result of lowered installation and maintenance costs, reusability, and an increased life cycle due to the foam’s high performance in heavy traffic areas and harsh environments. \n                      \n                        “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.”\n                          —Phil Griffith, GFT LLC \n                      \n                      Griffith also points out that the material is environmentally friendly, manufactured without \n                        any poisonous halogenated substances and using solvents that are completely recoverable. Manufacturing the NASA-developed foams is essentially “a wasteless process,” he says. \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT’s NASA-derived foams (seen as preformed clamshells in the inset image) find significant use in engine rooms and other areas of marine vessels that require highly durable pipe insulation.\n                        \n                      \n                      Providing pipe insulation that is easily installed on marine vessels is currently the main use for GFT’s foams. The small company recently entered into product deals that Griffith says will keep GFT manufacturing for the next 10 to 15 years—a major accomplishment considering the single significant disadvantage of the polyimide foams is that they are presently somewhat expensive to manufacture. \n                      “The foams have been expensive to make for a variety of reasons, one being the limited availability of certain components,” Griffith explains. “We’ve addressed that supply issue to adequately support a commercial ramp.” \n                      The technology’s NASA origin lends immediate credibility to GFT’s products and opens doors for investment, Griffith says. “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.” \n                      Weiser, in the meantime, is working on acoustic insulation applications for polyimide foams, a potentially safer replacement for the more flammable fiberglass insulation used to dampen noise in commercial aircraft. He also notes interest in the technology for safe, ecologically sound building insulation. “If you have a fire, this foam isn’t going to burn or produce smoke,” he says, a boon for buildings from suburban homes to downtown high rises. \n                      Industry applications outside of NASA are something that Weiser always keeps in mind. “We want to meet NASA’s goals first,” he says, “but the value of the technology will go up for NASA if industry can use it for other purposes.”\n                      PerForma-H® and VersaFlex® are registered trademarks of GFT LLC\n                    \n                    \n                  \n                \n              \n              \n            \n          \n        \n      \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      At Langley Research Center, Erik Weiser and his colleagues in the Advanced Materials and Processing Branch were working with a new substance for fabricating composites for use in supersonic aircraft. The team, however, was experiencing some frustration. Every time they tried to create a solid composite from the polyimide (an advanced polymer) material, it bubbled and foamed. \n                      It seemed like the team had reached a dead end in their research—until they had another idea. \n                      “We said, ‘This isn’t going to work for composites, but maybe we could make a foam out of it,’” Weiser says. “That was kind of our eureka moment, to see if we could go in a whole other direction. And it worked.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT LLC’s highly flexible polyimide foam—seen here during testing at Kennedy Space Center—provides an ideal insulation for pipes in cryogenic and other industrial and marine applications.\n                        \n                      \n                      Weiser and his colleagues invented a new kind of polyimide foam insulation they named TEEK. The innovation displayed a host of advantages over existing insulation options. Compared to other commercial foams, Weiser explains, polyimide foams perform well across a broad range of temperatures, noting that the NASA TEEK foams provide effective structural insulation up to 600 °F and down to cryogenic temperatures. The foam does not burn or off-gas toxic fumes, and even at -423 °F—the temperature of liquid hydrogen—the material stays flexible. The inventors could produce the TEEK foam at a range of densities, from 0.5 pounds per cubic foot up to 20 pounds per cubic foot, making the foam ideal for a range of applications, including as insulation for reusable launch vehicles and for cryogenic tanks and lines. They also developed a unique, friable balloon format for manufacturing the foam, producing it as hollow microspheres that allowed the foam to be molded and then cured into any desired shape—perfect for insulating pipes of different sizes and configurations. \n                      The team’s originally unplanned invention won an “R&D 100” award, and a later form of the foam, called LaRC FPF-44 (Spinoff 2009), was named “NASA Invention of the Year” in 2007. \n                      Partnership \n                      In 2002, NASA licensed the TEEK family of foams to GFT LLC, based in Pennville, Indiana. GFT helped Langley manufacture samples of the foam for potential space applications, such as for insulating the external tank of the space shuttle. The company also optimized the technology to create the first highly flexible foam from polyimide microspheres, allowing for the production of intricate pipe covers of different diameters and wall thicknesses. Kennedy Space Center also researched potential shuttle and cryogenic test equipment applications of the GFT-manufactured foams. \n                      Benefits\n                      GFT now offers the NASA-derived polyimide foam technologies as its PerForma-H and VersaFlex product lines. The company produces the foams in varying densities and formats, from sheets to foam-filled honeycombs and panels to hollow microspheres. GFT’s VersaFlex foams provide the added capability of extreme physical flexibility over a 1,000-degree temperature range (-423 °F to more than 600 °F). Customers are taking notice of the foam’s special characteristics, says GFT CEO Phil Griffith, who admits to being “enamored” with the material himself. \n                      “Not only is it an excellent thermal insulator, but it’s also nonflammable and nontoxic in a fire,” he says. “There are a lot of insulating materials out there, but of those that are both fireproof and nontoxic, there are only a few. You find even less at the density of these materials that display outstanding mechanical properties. In fact, you find only PerForma-H and VersaFlex.” \n                      The performance-to-weight ratio of the GFT foams, Griffith says, is better than any available alternatives, providing substantial savings for customers: “You can use less of the polyimide foam to get the same insulating properties as traditional materials, and it weighs about one-seventh as much as calcium silicate and is on par with fiberglass.” Griffith notes that one of GFT’s large marine customers has realized a 90-percent reduction in labor costs from the adoption of PerForma-H as piping insulation, as documented during the customer’s shipboard installations on active duty vessels. The reduction comes as a result of lowered installation and maintenance costs, reusability, and an increased life cycle due to the foam’s high performance in heavy traffic areas and harsh environments. \n                      \n                        “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.”\n                          —Phil Griffith, GFT LLC \n                      \n                      Griffith also points out that the material is environmentally friendly, manufactured without \n                        any poisonous halogenated substances and using solvents that are completely recoverable. Manufacturing the NASA-developed foams is essentially “a wasteless process,” he says. \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT’s NASA-derived foams (seen as preformed clamshells in the inset image) find significant use in engine rooms and other areas of marine vessels that require highly durable pipe insulation.\n                        \n                      \n                      Providing pipe insulation that is easily installed on marine vessels is currently the main use for GFT’s foams. The small company recently entered into product deals that Griffith says will keep GFT manufacturing for the next 10 to 15 years—a major accomplishment considering the single significant disadvantage of the polyimide foams is that they are presently somewhat expensive to manufacture. \n                      “The foams have been expensive to make for a variety of reasons, one being the limited availability of certain components,” Griffith explains. “We’ve addressed that supply issue to adequately support a commercial ramp.” \n                      The technology’s NASA origin lends immediate credibility to GFT’s products and opens doors for investment, Griffith says. “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.” \n                      Weiser, in the meantime, is working on acoustic insulation applications for polyimide foams, a potentially safer replacement for the more flammable fiberglass insulation used to dampen noise in commercial aircraft. He also notes interest in the technology for safe, ecologically sound building insulation. “If you have a fire, this foam isn’t going to burn or produce smoke,” he says, a boon for buildings from suburban homes to downtown high rises. \n                      Industry applications outside of NASA are something that Weiser always keeps in mind. “We want to meet NASA’s goals first,” he says, “but the value of the technology will go up for NASA if industry can use it for other purposes.”\n                      PerForma-H® and VersaFlex® are registered trademarks of GFT LLC\n                    \n                    \n                  \n                \n              \n              \n            \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      At Langley Research Center, Erik Weiser and his colleagues in the Advanced Materials and Processing Branch were working with a new substance for fabricating composites for use in supersonic aircraft. The team, however, was experiencing some frustration. Every time they tried to create a solid composite from the polyimide (an advanced polymer) material, it bubbled and foamed. \n                      It seemed like the team had reached a dead end in their research—until they had another idea. \n                      “We said, ‘This isn’t going to work for composites, but maybe we could make a foam out of it,’” Weiser says. “That was kind of our eureka moment, to see if we could go in a whole other direction. And it worked.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT LLC’s highly flexible polyimide foam—seen here during testing at Kennedy Space Center—provides an ideal insulation for pipes in cryogenic and other industrial and marine applications.\n                        \n                      \n                      Weiser and his colleagues invented a new kind of polyimide foam insulation they named TEEK. The innovation displayed a host of advantages over existing insulation options. Compared to other commercial foams, Weiser explains, polyimide foams perform well across a broad range of temperatures, noting that the NASA TEEK foams provide effective structural insulation up to 600 °F and down to cryogenic temperatures. The foam does not burn or off-gas toxic fumes, and even at -423 °F—the temperature of liquid hydrogen—the material stays flexible. The inventors could produce the TEEK foam at a range of densities, from 0.5 pounds per cubic foot up to 20 pounds per cubic foot, making the foam ideal for a range of applications, including as insulation for reusable launch vehicles and for cryogenic tanks and lines. They also developed a unique, friable balloon format for manufacturing the foam, producing it as hollow microspheres that allowed the foam to be molded and then cured into any desired shape—perfect for insulating pipes of different sizes and configurations. \n                      The team’s originally unplanned invention won an “R&D 100” award, and a later form of the foam, called LaRC FPF-44 (Spinoff 2009), was named “NASA Invention of the Year” in 2007. \n                      Partnership \n                      In 2002, NASA licensed the TEEK family of foams to GFT LLC, based in Pennville, Indiana. GFT helped Langley manufacture samples of the foam for potential space applications, such as for insulating the external tank of the space shuttle. The company also optimized the technology to create the first highly flexible foam from polyimide microspheres, allowing for the production of intricate pipe covers of different diameters and wall thicknesses. Kennedy Space Center also researched potential shuttle and cryogenic test equipment applications of the GFT-manufactured foams. \n                      Benefits\n                      GFT now offers the NASA-derived polyimide foam technologies as its PerForma-H and VersaFlex product lines. The company produces the foams in varying densities and formats, from sheets to foam-filled honeycombs and panels to hollow microspheres. GFT’s VersaFlex foams provide the added capability of extreme physical flexibility over a 1,000-degree temperature range (-423 °F to more than 600 °F). Customers are taking notice of the foam’s special characteristics, says GFT CEO Phil Griffith, who admits to being “enamored” with the material himself. \n                      “Not only is it an excellent thermal insulator, but it’s also nonflammable and nontoxic in a fire,” he says. “There are a lot of insulating materials out there, but of those that are both fireproof and nontoxic, there are only a few. You find even less at the density of these materials that display outstanding mechanical properties. In fact, you find only PerForma-H and VersaFlex.” \n                      The performance-to-weight ratio of the GFT foams, Griffith says, is better than any available alternatives, providing substantial savings for customers: “You can use less of the polyimide foam to get the same insulating properties as traditional materials, and it weighs about one-seventh as much as calcium silicate and is on par with fiberglass.” Griffith notes that one of GFT’s large marine customers has realized a 90-percent reduction in labor costs from the adoption of PerForma-H as piping insulation, as documented during the customer’s shipboard installations on active duty vessels. The reduction comes as a result of lowered installation and maintenance costs, reusability, and an increased life cycle due to the foam’s high performance in heavy traffic areas and harsh environments. \n                      \n                        “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.”\n                          —Phil Griffith, GFT LLC \n                      \n                      Griffith also points out that the material is environmentally friendly, manufactured without \n                        any poisonous halogenated substances and using solvents that are completely recoverable. Manufacturing the NASA-developed foams is essentially “a wasteless process,” he says. \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT’s NASA-derived foams (seen as preformed clamshells in the inset image) find significant use in engine rooms and other areas of marine vessels that require highly durable pipe insulation.\n                        \n                      \n                      Providing pipe insulation that is easily installed on marine vessels is currently the main use for GFT’s foams. The small company recently entered into product deals that Griffith says will keep GFT manufacturing for the next 10 to 15 years—a major accomplishment considering the single significant disadvantage of the polyimide foams is that they are presently somewhat expensive to manufacture. \n                      “The foams have been expensive to make for a variety of reasons, one being the limited availability of certain components,” Griffith explains. “We’ve addressed that supply issue to adequately support a commercial ramp.” \n                      The technology’s NASA origin lends immediate credibility to GFT’s products and opens doors for investment, Griffith says. “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.” \n                      Weiser, in the meantime, is working on acoustic insulation applications for polyimide foams, a potentially safer replacement for the more flammable fiberglass insulation used to dampen noise in commercial aircraft. He also notes interest in the technology for safe, ecologically sound building insulation. “If you have a fire, this foam isn’t going to burn or produce smoke,” he says, a boon for buildings from suburban homes to downtown high rises. \n                      Industry applications outside of NASA are something that Weiser always keeps in mind. “We want to meet NASA’s goals first,” he says, “but the value of the technology will go up for NASA if industry can use it for other purposes.”\n                      PerForma-H® and VersaFlex® are registered trademarks of GFT LLC\n                    \n                    \n                  \n                \n              \n              \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      At Langley Research Center, Erik Weiser and his colleagues in the Advanced Materials and Processing Branch were working with a new substance for fabricating composites for use in supersonic aircraft. The team, however, was experiencing some frustration. Every time they tried to create a solid composite from the polyimide (an advanced polymer) material, it bubbled and foamed. \n                      It seemed like the team had reached a dead end in their research—until they had another idea. \n                      “We said, ‘This isn’t going to work for composites, but maybe we could make a foam out of it,’” Weiser says. “That was kind of our eureka moment, to see if we could go in a whole other direction. And it worked.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT LLC’s highly flexible polyimide foam—seen here during testing at Kennedy Space Center—provides an ideal insulation for pipes in cryogenic and other industrial and marine applications.\n                        \n                      \n                      Weiser and his colleagues invented a new kind of polyimide foam insulation they named TEEK. The innovation displayed a host of advantages over existing insulation options. Compared to other commercial foams, Weiser explains, polyimide foams perform well across a broad range of temperatures, noting that the NASA TEEK foams provide effective structural insulation up to 600 °F and down to cryogenic temperatures. The foam does not burn or off-gas toxic fumes, and even at -423 °F—the temperature of liquid hydrogen—the material stays flexible. The inventors could produce the TEEK foam at a range of densities, from 0.5 pounds per cubic foot up to 20 pounds per cubic foot, making the foam ideal for a range of applications, including as insulation for reusable launch vehicles and for cryogenic tanks and lines. They also developed a unique, friable balloon format for manufacturing the foam, producing it as hollow microspheres that allowed the foam to be molded and then cured into any desired shape—perfect for insulating pipes of different sizes and configurations. \n                      The team’s originally unplanned invention won an “R&D 100” award, and a later form of the foam, called LaRC FPF-44 (Spinoff 2009), was named “NASA Invention of the Year” in 2007. \n                      Partnership \n                      In 2002, NASA licensed the TEEK family of foams to GFT LLC, based in Pennville, Indiana. GFT helped Langley manufacture samples of the foam for potential space applications, such as for insulating the external tank of the space shuttle. The company also optimized the technology to create the first highly flexible foam from polyimide microspheres, allowing for the production of intricate pipe covers of different diameters and wall thicknesses. Kennedy Space Center also researched potential shuttle and cryogenic test equipment applications of the GFT-manufactured foams. \n                      Benefits\n                      GFT now offers the NASA-derived polyimide foam technologies as its PerForma-H and VersaFlex product lines. The company produces the foams in varying densities and formats, from sheets to foam-filled honeycombs and panels to hollow microspheres. GFT’s VersaFlex foams provide the added capability of extreme physical flexibility over a 1,000-degree temperature range (-423 °F to more than 600 °F). Customers are taking notice of the foam’s special characteristics, says GFT CEO Phil Griffith, who admits to being “enamored” with the material himself. \n                      “Not only is it an excellent thermal insulator, but it’s also nonflammable and nontoxic in a fire,” he says. “There are a lot of insulating materials out there, but of those that are both fireproof and nontoxic, there are only a few. You find even less at the density of these materials that display outstanding mechanical properties. In fact, you find only PerForma-H and VersaFlex.” \n                      The performance-to-weight ratio of the GFT foams, Griffith says, is better than any available alternatives, providing substantial savings for customers: “You can use less of the polyimide foam to get the same insulating properties as traditional materials, and it weighs about one-seventh as much as calcium silicate and is on par with fiberglass.” Griffith notes that one of GFT’s large marine customers has realized a 90-percent reduction in labor costs from the adoption of PerForma-H as piping insulation, as documented during the customer’s shipboard installations on active duty vessels. The reduction comes as a result of lowered installation and maintenance costs, reusability, and an increased life cycle due to the foam’s high performance in heavy traffic areas and harsh environments. \n                      \n                        “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.”\n                          —Phil Griffith, GFT LLC \n                      \n                      Griffith also points out that the material is environmentally friendly, manufactured without \n                        any poisonous halogenated substances and using solvents that are completely recoverable. Manufacturing the NASA-developed foams is essentially “a wasteless process,” he says. \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT’s NASA-derived foams (seen as preformed clamshells in the inset image) find significant use in engine rooms and other areas of marine vessels that require highly durable pipe insulation.\n                        \n                      \n                      Providing pipe insulation that is easily installed on marine vessels is currently the main use for GFT’s foams. The small company recently entered into product deals that Griffith says will keep GFT manufacturing for the next 10 to 15 years—a major accomplishment considering the single significant disadvantage of the polyimide foams is that they are presently somewhat expensive to manufacture. \n                      “The foams have been expensive to make for a variety of reasons, one being the limited availability of certain components,” Griffith explains. “We’ve addressed that supply issue to adequately support a commercial ramp.” \n                      The technology’s NASA origin lends immediate credibility to GFT’s products and opens doors for investment, Griffith says. “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.” \n                      Weiser, in the meantime, is working on acoustic insulation applications for polyimide foams, a potentially safer replacement for the more flammable fiberglass insulation used to dampen noise in commercial aircraft. He also notes interest in the technology for safe, ecologically sound building insulation. “If you have a fire, this foam isn’t going to burn or produce smoke,” he says, a boon for buildings from suburban homes to downtown high rises. \n                      Industry applications outside of NASA are something that Weiser always keeps in mind. “We want to meet NASA’s goals first,” he says, “but the value of the technology will go up for NASA if industry can use it for other purposes.”\n                      PerForma-H® and VersaFlex® are registered trademarks of GFT LLC\n                    \n                    \n                  \n                \n              \n              \n                \n                  \n                    \n                      NASA Technology\n                      At Langley Research Center, Erik Weiser and his colleagues in the Advanced Materials and Processing Branch were working with a new substance for fabricating composites for use in supersonic aircraft. The team, however, was experiencing some frustration. Every time they tried to create a solid composite from the polyimide (an advanced polymer) material, it bubbled and foamed. \n                      It seemed like the team had reached a dead end in their research—until they had another idea. \n                      “We said, ‘This isn’t going to work for composites, but maybe we could make a foam out of it,’” Weiser says. “That was kind of our eureka moment, to see if we could go in a whole other direction. And it worked.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT LLC’s highly flexible polyimide foam—seen here during testing at Kennedy Space Center—provides an ideal insulation for pipes in cryogenic and other industrial and marine applications.\n                        \n                      \n                      Weiser and his colleagues invented a new kind of polyimide foam insulation they named TEEK. The innovation displayed a host of advantages over existing insulation options. Compared to other commercial foams, Weiser explains, polyimide foams perform well across a broad range of temperatures, noting that the NASA TEEK foams provide effective structural insulation up to 600 °F and down to cryogenic temperatures. The foam does not burn or off-gas toxic fumes, and even at -423 °F—the temperature of liquid hydrogen—the material stays flexible. The inventors could produce the TEEK foam at a range of densities, from 0.5 pounds per cubic foot up to 20 pounds per cubic foot, making the foam ideal for a range of applications, including as insulation for reusable launch vehicles and for cryogenic tanks and lines. They also developed a unique, friable balloon format for manufacturing the foam, producing it as hollow microspheres that allowed the foam to be molded and then cured into any desired shape—perfect for insulating pipes of different sizes and configurations. \n                      The team’s originally unplanned invention won an “R&D 100” award, and a later form of the foam, called LaRC FPF-44 (Spinoff 2009), was named “NASA Invention of the Year” in 2007. \n                      Partnership \n                      In 2002, NASA licensed the TEEK family of foams to GFT LLC, based in Pennville, Indiana. GFT helped Langley manufacture samples of the foam for potential space applications, such as for insulating the external tank of the space shuttle. The company also optimized the technology to create the first highly flexible foam from polyimide microspheres, allowing for the production of intricate pipe covers of different diameters and wall thicknesses. Kennedy Space Center also researched potential shuttle and cryogenic test equipment applications of the GFT-manufactured foams. \n                      Benefits\n                      GFT now offers the NASA-derived polyimide foam technologies as its PerForma-H and VersaFlex product lines. The company produces the foams in varying densities and formats, from sheets to foam-filled honeycombs and panels to hollow microspheres. GFT’s VersaFlex foams provide the added capability of extreme physical flexibility over a 1,000-degree temperature range (-423 °F to more than 600 °F). Customers are taking notice of the foam’s special characteristics, says GFT CEO Phil Griffith, who admits to being “enamored” with the material himself. \n                      “Not only is it an excellent thermal insulator, but it’s also nonflammable and nontoxic in a fire,” he says. “There are a lot of insulating materials out there, but of those that are both fireproof and nontoxic, there are only a few. You find even less at the density of these materials that display outstanding mechanical properties. In fact, you find only PerForma-H and VersaFlex.” \n                      The performance-to-weight ratio of the GFT foams, Griffith says, is better than any available alternatives, providing substantial savings for customers: “You can use less of the polyimide foam to get the same insulating properties as traditional materials, and it weighs about one-seventh as much as calcium silicate and is on par with fiberglass.” Griffith notes that one of GFT’s large marine customers has realized a 90-percent reduction in labor costs from the adoption of PerForma-H as piping insulation, as documented during the customer’s shipboard installations on active duty vessels. The reduction comes as a result of lowered installation and maintenance costs, reusability, and an increased life cycle due to the foam’s high performance in heavy traffic areas and harsh environments. \n                      \n                        “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.”\n                          —Phil Griffith, GFT LLC \n                      \n                      Griffith also points out that the material is environmentally friendly, manufactured without \n                        any poisonous halogenated substances and using solvents that are completely recoverable. Manufacturing the NASA-developed foams is essentially “a wasteless process,” he says. \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT’s NASA-derived foams (seen as preformed clamshells in the inset image) find significant use in engine rooms and other areas of marine vessels that require highly durable pipe insulation.\n                        \n                      \n                      Providing pipe insulation that is easily installed on marine vessels is currently the main use for GFT’s foams. The small company recently entered into product deals that Griffith says will keep GFT manufacturing for the next 10 to 15 years—a major accomplishment considering the single significant disadvantage of the polyimide foams is that they are presently somewhat expensive to manufacture. \n                      “The foams have been expensive to make for a variety of reasons, one being the limited availability of certain components,” Griffith explains. “We’ve addressed that supply issue to adequately support a commercial ramp.” \n                      The technology’s NASA origin lends immediate credibility to GFT’s products and opens doors for investment, Griffith says. “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.” \n                      Weiser, in the meantime, is working on acoustic insulation applications for polyimide foams, a potentially safer replacement for the more flammable fiberglass insulation used to dampen noise in commercial aircraft. He also notes interest in the technology for safe, ecologically sound building insulation. “If you have a fire, this foam isn’t going to burn or produce smoke,” he says, a boon for buildings from suburban homes to downtown high rises. \n                      Industry applications outside of NASA are something that Weiser always keeps in mind. “We want to meet NASA’s goals first,” he says, “but the value of the technology will go up for NASA if industry can use it for other purposes.”\n                      PerForma-H® and VersaFlex® are registered trademarks of GFT LLC\n                    \n                    \n                  \n                \n                  \n                    \n                      NASA Technology\n                      At Langley Research Center, Erik Weiser and his colleagues in the Advanced Materials and Processing Branch were working with a new substance for fabricating composites for use in supersonic aircraft. The team, however, was experiencing some frustration. Every time they tried to create a solid composite from the polyimide (an advanced polymer) material, it bubbled and foamed. \n                      It seemed like the team had reached a dead end in their research—until they had another idea. \n                      “We said, ‘This isn’t going to work for composites, but maybe we could make a foam out of it,’” Weiser says. “That was kind of our eureka moment, to see if we could go in a whole other direction. And it worked.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT LLC’s highly flexible polyimide foam—seen here during testing at Kennedy Space Center—provides an ideal insulation for pipes in cryogenic and other industrial and marine applications.\n                        \n                      \n                      Weiser and his colleagues invented a new kind of polyimide foam insulation they named TEEK. The innovation displayed a host of advantages over existing insulation options. Compared to other commercial foams, Weiser explains, polyimide foams perform well across a broad range of temperatures, noting that the NASA TEEK foams provide effective structural insulation up to 600 °F and down to cryogenic temperatures. The foam does not burn or off-gas toxic fumes, and even at -423 °F—the temperature of liquid hydrogen—the material stays flexible. The inventors could produce the TEEK foam at a range of densities, from 0.5 pounds per cubic foot up to 20 pounds per cubic foot, making the foam ideal for a range of applications, including as insulation for reusable launch vehicles and for cryogenic tanks and lines. They also developed a unique, friable balloon format for manufacturing the foam, producing it as hollow microspheres that allowed the foam to be molded and then cured into any desired shape—perfect for insulating pipes of different sizes and configurations. \n                      The team’s originally unplanned invention won an “R&D 100” award, and a later form of the foam, called LaRC FPF-44 (Spinoff 2009), was named “NASA Invention of the Year” in 2007. \n                      Partnership \n                      In 2002, NASA licensed the TEEK family of foams to GFT LLC, based in Pennville, Indiana. GFT helped Langley manufacture samples of the foam for potential space applications, such as for insulating the external tank of the space shuttle. The company also optimized the technology to create the first highly flexible foam from polyimide microspheres, allowing for the production of intricate pipe covers of different diameters and wall thicknesses. Kennedy Space Center also researched potential shuttle and cryogenic test equipment applications of the GFT-manufactured foams. \n                      Benefits\n                      GFT now offers the NASA-derived polyimide foam technologies as its PerForma-H and VersaFlex product lines. The company produces the foams in varying densities and formats, from sheets to foam-filled honeycombs and panels to hollow microspheres. GFT’s VersaFlex foams provide the added capability of extreme physical flexibility over a 1,000-degree temperature range (-423 °F to more than 600 °F). Customers are taking notice of the foam’s special characteristics, says GFT CEO Phil Griffith, who admits to being “enamored” with the material himself. \n                      “Not only is it an excellent thermal insulator, but it’s also nonflammable and nontoxic in a fire,” he says. “There are a lot of insulating materials out there, but of those that are both fireproof and nontoxic, there are only a few. You find even less at the density of these materials that display outstanding mechanical properties. In fact, you find only PerForma-H and VersaFlex.” \n                      The performance-to-weight ratio of the GFT foams, Griffith says, is better than any available alternatives, providing substantial savings for customers: “You can use less of the polyimide foam to get the same insulating properties as traditional materials, and it weighs about one-seventh as much as calcium silicate and is on par with fiberglass.” Griffith notes that one of GFT’s large marine customers has realized a 90-percent reduction in labor costs from the adoption of PerForma-H as piping insulation, as documented during the customer’s shipboard installations on active duty vessels. The reduction comes as a result of lowered installation and maintenance costs, reusability, and an increased life cycle due to the foam’s high performance in heavy traffic areas and harsh environments. \n                      \n                        “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.”\n                          —Phil Griffith, GFT LLC \n                      \n                      Griffith also points out that the material is environmentally friendly, manufactured without \n                        any poisonous halogenated substances and using solvents that are completely recoverable. Manufacturing the NASA-developed foams is essentially “a wasteless process,” he says. \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT’s NASA-derived foams (seen as preformed clamshells in the inset image) find significant use in engine rooms and other areas of marine vessels that require highly durable pipe insulation.\n                        \n                      \n                      Providing pipe insulation that is easily installed on marine vessels is currently the main use for GFT’s foams. The small company recently entered into product deals that Griffith says will keep GFT manufacturing for the next 10 to 15 years—a major accomplishment considering the single significant disadvantage of the polyimide foams is that they are presently somewhat expensive to manufacture. \n                      “The foams have been expensive to make for a variety of reasons, one being the limited availability of certain components,” Griffith explains. “We’ve addressed that supply issue to adequately support a commercial ramp.” \n                      The technology’s NASA origin lends immediate credibility to GFT’s products and opens doors for investment, Griffith says. “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.” \n                      Weiser, in the meantime, is working on acoustic insulation applications for polyimide foams, a potentially safer replacement for the more flammable fiberglass insulation used to dampen noise in commercial aircraft. He also notes interest in the technology for safe, ecologically sound building insulation. “If you have a fire, this foam isn’t going to burn or produce smoke,” he says, a boon for buildings from suburban homes to downtown high rises. \n                      Industry applications outside of NASA are something that Weiser always keeps in mind. “We want to meet NASA’s goals first,” he says, “but the value of the technology will go up for NASA if industry can use it for other purposes.”\n                      PerForma-H® and VersaFlex® are registered trademarks of GFT LLC\n                    \n                    \n                  \n                    \n                      NASA Technology\n                      At Langley Research Center, Erik Weiser and his colleagues in the Advanced Materials and Processing Branch were working with a new substance for fabricating composites for use in supersonic aircraft. The team, however, was experiencing some frustration. Every time they tried to create a solid composite from the polyimide (an advanced polymer) material, it bubbled and foamed. \n                      It seemed like the team had reached a dead end in their research—until they had another idea. \n                      “We said, ‘This isn’t going to work for composites, but maybe we could make a foam out of it,’” Weiser says. “That was kind of our eureka moment, to see if we could go in a whole other direction. And it worked.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT LLC’s highly flexible polyimide foam—seen here during testing at Kennedy Space Center—provides an ideal insulation for pipes in cryogenic and other industrial and marine applications.\n                        \n                      \n                      Weiser and his colleagues invented a new kind of polyimide foam insulation they named TEEK. The innovation displayed a host of advantages over existing insulation options. Compared to other commercial foams, Weiser explains, polyimide foams perform well across a broad range of temperatures, noting that the NASA TEEK foams provide effective structural insulation up to 600 °F and down to cryogenic temperatures. The foam does not burn or off-gas toxic fumes, and even at -423 °F—the temperature of liquid hydrogen—the material stays flexible. The inventors could produce the TEEK foam at a range of densities, from 0.5 pounds per cubic foot up to 20 pounds per cubic foot, making the foam ideal for a range of applications, including as insulation for reusable launch vehicles and for cryogenic tanks and lines. They also developed a unique, friable balloon format for manufacturing the foam, producing it as hollow microspheres that allowed the foam to be molded and then cured into any desired shape—perfect for insulating pipes of different sizes and configurations. \n                      The team’s originally unplanned invention won an “R&D 100” award, and a later form of the foam, called LaRC FPF-44 (Spinoff 2009), was named “NASA Invention of the Year” in 2007. \n                      Partnership \n                      In 2002, NASA licensed the TEEK family of foams to GFT LLC, based in Pennville, Indiana. GFT helped Langley manufacture samples of the foam for potential space applications, such as for insulating the external tank of the space shuttle. The company also optimized the technology to create the first highly flexible foam from polyimide microspheres, allowing for the production of intricate pipe covers of different diameters and wall thicknesses. Kennedy Space Center also researched potential shuttle and cryogenic test equipment applications of the GFT-manufactured foams. \n                      Benefits\n                      GFT now offers the NASA-derived polyimide foam technologies as its PerForma-H and VersaFlex product lines. The company produces the foams in varying densities and formats, from sheets to foam-filled honeycombs and panels to hollow microspheres. GFT’s VersaFlex foams provide the added capability of extreme physical flexibility over a 1,000-degree temperature range (-423 °F to more than 600 °F). Customers are taking notice of the foam’s special characteristics, says GFT CEO Phil Griffith, who admits to being “enamored” with the material himself. \n                      “Not only is it an excellent thermal insulator, but it’s also nonflammable and nontoxic in a fire,” he says. “There are a lot of insulating materials out there, but of those that are both fireproof and nontoxic, there are only a few. You find even less at the density of these materials that display outstanding mechanical properties. In fact, you find only PerForma-H and VersaFlex.” \n                      The performance-to-weight ratio of the GFT foams, Griffith says, is better than any available alternatives, providing substantial savings for customers: “You can use less of the polyimide foam to get the same insulating properties as traditional materials, and it weighs about one-seventh as much as calcium silicate and is on par with fiberglass.” Griffith notes that one of GFT’s large marine customers has realized a 90-percent reduction in labor costs from the adoption of PerForma-H as piping insulation, as documented during the customer’s shipboard installations on active duty vessels. The reduction comes as a result of lowered installation and maintenance costs, reusability, and an increased life cycle due to the foam’s high performance in heavy traffic areas and harsh environments. \n                      \n                        “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.”\n                          —Phil Griffith, GFT LLC \n                      \n                      Griffith also points out that the material is environmentally friendly, manufactured without \n                        any poisonous halogenated substances and using solvents that are completely recoverable. Manufacturing the NASA-developed foams is essentially “a wasteless process,” he says. \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT’s NASA-derived foams (seen as preformed clamshells in the inset image) find significant use in engine rooms and other areas of marine vessels that require highly durable pipe insulation.\n                        \n                      \n                      Providing pipe insulation that is easily installed on marine vessels is currently the main use for GFT’s foams. The small company recently entered into product deals that Griffith says will keep GFT manufacturing for the next 10 to 15 years—a major accomplishment considering the single significant disadvantage of the polyimide foams is that they are presently somewhat expensive to manufacture. \n                      “The foams have been expensive to make for a variety of reasons, one being the limited availability of certain components,” Griffith explains. “We’ve addressed that supply issue to adequately support a commercial ramp.” \n                      The technology’s NASA origin lends immediate credibility to GFT’s products and opens doors for investment, Griffith says. “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.” \n                      Weiser, in the meantime, is working on acoustic insulation applications for polyimide foams, a potentially safer replacement for the more flammable fiberglass insulation used to dampen noise in commercial aircraft. He also notes interest in the technology for safe, ecologically sound building insulation. “If you have a fire, this foam isn’t going to burn or produce smoke,” he says, a boon for buildings from suburban homes to downtown high rises. \n                      Industry applications outside of NASA are something that Weiser always keeps in mind. “We want to meet NASA’s goals first,” he says, “but the value of the technology will go up for NASA if industry can use it for other purposes.”\n                      PerForma-H® and VersaFlex® are registered trademarks of GFT LLC\n                    \n                    \n                      NASA Technology\n                      At Langley Research Center, Erik Weiser and his colleagues in the Advanced Materials and Processing Branch were working with a new substance for fabricating composites for use in supersonic aircraft. The team, however, was experiencing some frustration. Every time they tried to create a solid composite from the polyimide (an advanced polymer) material, it bubbled and foamed. \n                      It seemed like the team had reached a dead end in their research—until they had another idea. \n                      “We said, ‘This isn’t going to work for composites, but maybe we could make a foam out of it,’” Weiser says. “That was kind of our eureka moment, to see if we could go in a whole other direction. And it worked.” \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT LLC’s highly flexible polyimide foam—seen here during testing at Kennedy Space Center—provides an ideal insulation for pipes in cryogenic and other industrial and marine applications.\n                        \n                      \n                      Weiser and his colleagues invented a new kind of polyimide foam insulation they named TEEK. The innovation displayed a host of advantages over existing insulation options. Compared to other commercial foams, Weiser explains, polyimide foams perform well across a broad range of temperatures, noting that the NASA TEEK foams provide effective structural insulation up to 600 °F and down to cryogenic temperatures. The foam does not burn or off-gas toxic fumes, and even at -423 °F—the temperature of liquid hydrogen—the material stays flexible. The inventors could produce the TEEK foam at a range of densities, from 0.5 pounds per cubic foot up to 20 pounds per cubic foot, making the foam ideal for a range of applications, including as insulation for reusable launch vehicles and for cryogenic tanks and lines. They also developed a unique, friable balloon format for manufacturing the foam, producing it as hollow microspheres that allowed the foam to be molded and then cured into any desired shape—perfect for insulating pipes of different sizes and configurations. \n                      The team’s originally unplanned invention won an “R&D 100” award, and a later form of the foam, called LaRC FPF-44 (Spinoff 2009), was named “NASA Invention of the Year” in 2007. \n                      Partnership \n                      In 2002, NASA licensed the TEEK family of foams to GFT LLC, based in Pennville, Indiana. GFT helped Langley manufacture samples of the foam for potential space applications, such as for insulating the external tank of the space shuttle. The company also optimized the technology to create the first highly flexible foam from polyimide microspheres, allowing for the production of intricate pipe covers of different diameters and wall thicknesses. Kennedy Space Center also researched potential shuttle and cryogenic test equipment applications of the GFT-manufactured foams. \n                      Benefits\n                      GFT now offers the NASA-derived polyimide foam technologies as its PerForma-H and VersaFlex product lines. The company produces the foams in varying densities and formats, from sheets to foam-filled honeycombs and panels to hollow microspheres. GFT’s VersaFlex foams provide the added capability of extreme physical flexibility over a 1,000-degree temperature range (-423 °F to more than 600 °F). Customers are taking notice of the foam’s special characteristics, says GFT CEO Phil Griffith, who admits to being “enamored” with the material himself. \n                      “Not only is it an excellent thermal insulator, but it’s also nonflammable and nontoxic in a fire,” he says. “There are a lot of insulating materials out there, but of those that are both fireproof and nontoxic, there are only a few. You find even less at the density of these materials that display outstanding mechanical properties. In fact, you find only PerForma-H and VersaFlex.” \n                      The performance-to-weight ratio of the GFT foams, Griffith says, is better than any available alternatives, providing substantial savings for customers: “You can use less of the polyimide foam to get the same insulating properties as traditional materials, and it weighs about one-seventh as much as calcium silicate and is on par with fiberglass.” Griffith notes that one of GFT’s large marine customers has realized a 90-percent reduction in labor costs from the adoption of PerForma-H as piping insulation, as documented during the customer’s shipboard installations on active duty vessels. The reduction comes as a result of lowered installation and maintenance costs, reusability, and an increased life cycle due to the foam’s high performance in heavy traffic areas and harsh environments. \n                      \n                        “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.”\n                          —Phil Griffith, GFT LLC \n                      \n                      Griffith also points out that the material is environmentally friendly, manufactured without \n                        any poisonous halogenated substances and using solvents that are completely recoverable. Manufacturing the NASA-developed foams is essentially “a wasteless process,” he says. \n                      \n                        \n                        \n                          \n                        \n                        \n                          GFT’s NASA-derived foams (seen as preformed clamshells in the inset image) find significant use in engine rooms and other areas of marine vessels that require highly durable pipe insulation.\n                        \n                      \n                      Providing pipe insulation that is easily installed on marine vessels is currently the main use for GFT’s foams. The small company recently entered into product deals that Griffith says will keep GFT manufacturing for the next 10 to 15 years—a major accomplishment considering the single significant disadvantage of the polyimide foams is that they are presently somewhat expensive to manufacture. \n                      “The foams have been expensive to make for a variety of reasons, one being the limited availability of certain components,” Griffith explains. “We’ve addressed that supply issue to adequately support a commercial ramp.” \n                      The technology’s NASA origin lends immediate credibility to GFT’s products and opens doors for investment, Griffith says. “You can’t get the technology NASA offers anywhere else. NASA technology provides a number of benefits that small businesses should seriously consider.” \n                      Weiser, in the meantime, is working on acoustic insulation applications for polyimide foams, a potentially safer replacement for the more flammable fiberglass insulation used to dampen noise in commercial aircraft. He also notes interest in the technology for safe, ecologically sound building insulation. “If you have a fire, this foam isn’t going to burn or produce smoke,” he says, a boon for buildings from suburban homes to downtown high rises. \n                      Industry applications outside of NASA are something that Weiser always keeps in mind. “We want to meet NASA’s goals first,” he says, “but the value of the technology will go up for NASA if industry can use it for other purposes.”\n                      PerForma-H® and VersaFlex® are registered trademarks of GFT LLC\n                    "},{"href":"http://spinoff.nasa.gov/Spinoff2011/ip_4.html","text":"Beam Steering Devices Reduce Payload Weight","image":"http://spinoff.nasa.gov/Spinoff2011/Images/ip_4a_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      Scientists have long been able to shift the direction of a laser beam, steering it toward a target, but often the strength and focus of the light is altered. For precision applications, where the quality of the beam cannot be compromised, scientists have typically turned to mechanical steering methods, redirecting the source of the beam by swinging the entire laser apparatus toward the target. \n                      \n                        \n                        \n                          \n                        \n                        \n                          This computer rendering shows one possible application for the optical phase array (OPA) technology developed by Boulder Nonlinear Systems Inc. (BNS) through the SBIR program. The rendering shows laser communication using NASA’s Organism/Organic Exposure to Orbital Stresses, or O/OREOS nanosatellites.\n                        \n                      \n                      Just as the mechanical methods used for turning cars has evolved into simpler, lighter, “power steering” methods, so has the means by which researchers can direct lasers. Some of the typical contraptions used to redirect lasers are large and bulky, relying on steering gimbals—pivoted, rotating supports—to shift the device toward its intended target. These devices, some as large and awkward as a piece of heavy luggage, are subject to the same issues confronted by mechanical parts: Components rub, wear out, and get stuck. The poor reliability and bulk—not to mention the power requirements to run one of the machines—have made mechanical beam steering components less than ideal for use in applications where weight, bulk, and maneuverability are prime concerns, such as on an unmanned aerial vehicle (UAV) or a microscope. \n                      The solution to developing reliable, lighter weight, nonmechanical steering methods to replace the hefty steering boxes was to think “outside the box,” and a NASA research partner did just that by developing a new beam steering method that bends and redirects the beam, as opposed to shifting the entire apparatus. The benefits include lower power requirements, a smaller footprint, reduced weight, and better control and flexibility in steering capabilities. Such benefits are realized without sacrificing aperture size, efficiency, or scanning range, and can be applied to myriad uses: propulsion systems, structures, radiation protection systems, and landing systems. \n                      Partnership\n                      Through Small Business Innovation Research (SBIR) contracts with both Johnson Space Center and Langley Research Center, Boulder Nonlinear Systems Inc. (BNS), of Lafayette, Colorado, developed a solution to some of the problems of mechanical beam steering, using advanced optical phase array (OPA) chips. Instead of changing the direction of the entire device, OPA chips allow the beam itself to be deflected and thus redirected. The high-resolution, high-speed, fully programmable system developed by BNS shows promise not only for NASA research needs, but for a variety of commercial and industrial needs as well. \n                      While OPA chips are not new technologies, appearing first in the 1980s, BNS worked to improve both the construction and functionality. Before teaming up with NASA, the company had been working with the University of Colorado’s Optical Computing Center, one of the National Science Foundation’s Centers of Excellence, to develop new chip technologies. \n                      Through its first two NASA SBIRs with Johnson in the early 1990s, BNS began experimenting with liquid crystals on silicon (LCOS) chips, creating a functional OPA, but one that was limited in usefulness as a steering component due to a small aperture and low voltage operation. The company continued work on the project with a 2002 Phase II SBIR with Langley to develop high-speed, high-resolution, fully programmable, nonmechanical beam steering. Within two years, BNS had completed the project, developing an OPA chip capable of driving high-speed liquid crystal phase modulators. \n                      Benefits\n                      The OPA chips combine high-speed liquid crystal phase modulators and high-voltage, very large scale integration (VLSI) silicon back planes that contain thousands of integrated, transistor-based circuits created through the VLSI foundry process. The transistor-based circuits transmit high-voltage signals to the liquid crystal components, reorienting the liquid crystals. This reorientation alters the modulator’s refractive index, creating a phase modulation that allows the beam to be shifted or deflected with a great deal of control and very fine resolution. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The liquid crystal on silicon OPA chip from BNS enables accurate and precise laser beam steering. Together, its features create a compact, low-power, lightweight OPA chip that provides improved control of the steering along with increased flexibility for applications in a variety of areas.\n                        \n                      \n                      The use of the higher voltages allows faster crystal response times and faster beam steering. The uniformity and flatness of the OPA chips also enables more accurate and precise steering. Together, these features combine to allow for a compact, low-power, lightweight OPA chip that provides better control of the steering along with increased flexibility. \n                      These new OPAs have applications across fields as varied as scientific research, aeronautics, defense, telecommunications, and biomedical engineering. In the biomedical field, the devices help to improve pulse shaping for photon microscopy for researchers working on early detection of Alzheimer’s disease and certain cancers. According to Steve Serati, president of BNS, “Researchers use the device to improve their ability to view biological samples, thus enabling early detection of some diseases.” \n                      Large aerospace and defense contractors like Northrop Grumman use the devices for military sensing and ground avoidance. The arrays are also helping to develop improved laser imaging and light detection and ranging capabilities along with laser-sighted weaponry. This technology also has applications in forensics and other areas that can benefit from finer resolution and larger views of microscopic samples. Because of the lower weight of the arrays and decreased energy consumption required to move the beam, the OPAs have been incorporated into satellite-based systems. \n                      Serati estimates that BNS’s NASA-derived devices have been used by nearly all of the major aerospace companies and over 100 research laboratories across governments, private sectors, and universities—and he expects this number will continue to grow.\n                    \n                    \n                  \n                \n              \n              \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      Scientists have long been able to shift the direction of a laser beam, steering it toward a target, but often the strength and focus of the light is altered. For precision applications, where the quality of the beam cannot be compromised, scientists have typically turned to mechanical steering methods, redirecting the source of the beam by swinging the entire laser apparatus toward the target. \n                      \n                        \n                        \n                          \n                        \n                        \n                          This computer rendering shows one possible application for the optical phase array (OPA) technology developed by Boulder Nonlinear Systems Inc. (BNS) through the SBIR program. The rendering shows laser communication using NASA’s Organism/Organic Exposure to Orbital Stresses, or O/OREOS nanosatellites.\n                        \n                      \n                      Just as the mechanical methods used for turning cars has evolved into simpler, lighter, “power steering” methods, so has the means by which researchers can direct lasers. Some of the typical contraptions used to redirect lasers are large and bulky, relying on steering gimbals—pivoted, rotating supports—to shift the device toward its intended target. These devices, some as large and awkward as a piece of heavy luggage, are subject to the same issues confronted by mechanical parts: Components rub, wear out, and get stuck. The poor reliability and bulk—not to mention the power requirements to run one of the machines—have made mechanical beam steering components less than ideal for use in applications where weight, bulk, and maneuverability are prime concerns, such as on an unmanned aerial vehicle (UAV) or a microscope. \n                      The solution to developing reliable, lighter weight, nonmechanical steering methods to replace the hefty steering boxes was to think “outside the box,” and a NASA research partner did just that by developing a new beam steering method that bends and redirects the beam, as opposed to shifting the entire apparatus. The benefits include lower power requirements, a smaller footprint, reduced weight, and better control and flexibility in steering capabilities. Such benefits are realized without sacrificing aperture size, efficiency, or scanning range, and can be applied to myriad uses: propulsion systems, structures, radiation protection systems, and landing systems. \n                      Partnership\n                      Through Small Business Innovation Research (SBIR) contracts with both Johnson Space Center and Langley Research Center, Boulder Nonlinear Systems Inc. (BNS), of Lafayette, Colorado, developed a solution to some of the problems of mechanical beam steering, using advanced optical phase array (OPA) chips. Instead of changing the direction of the entire device, OPA chips allow the beam itself to be deflected and thus redirected. The high-resolution, high-speed, fully programmable system developed by BNS shows promise not only for NASA research needs, but for a variety of commercial and industrial needs as well. \n                      While OPA chips are not new technologies, appearing first in the 1980s, BNS worked to improve both the construction and functionality. Before teaming up with NASA, the company had been working with the University of Colorado’s Optical Computing Center, one of the National Science Foundation’s Centers of Excellence, to develop new chip technologies. \n                      Through its first two NASA SBIRs with Johnson in the early 1990s, BNS began experimenting with liquid crystals on silicon (LCOS) chips, creating a functional OPA, but one that was limited in usefulness as a steering component due to a small aperture and low voltage operation. The company continued work on the project with a 2002 Phase II SBIR with Langley to develop high-speed, high-resolution, fully programmable, nonmechanical beam steering. Within two years, BNS had completed the project, developing an OPA chip capable of driving high-speed liquid crystal phase modulators. \n                      Benefits\n                      The OPA chips combine high-speed liquid crystal phase modulators and high-voltage, very large scale integration (VLSI) silicon back planes that contain thousands of integrated, transistor-based circuits created through the VLSI foundry process. The transistor-based circuits transmit high-voltage signals to the liquid crystal components, reorienting the liquid crystals. This reorientation alters the modulator’s refractive index, creating a phase modulation that allows the beam to be shifted or deflected with a great deal of control and very fine resolution. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The liquid crystal on silicon OPA chip from BNS enables accurate and precise laser beam steering. Together, its features create a compact, low-power, lightweight OPA chip that provides improved control of the steering along with increased flexibility for applications in a variety of areas.\n                        \n                      \n                      The use of the higher voltages allows faster crystal response times and faster beam steering. The uniformity and flatness of the OPA chips also enables more accurate and precise steering. Together, these features combine to allow for a compact, low-power, lightweight OPA chip that provides better control of the steering along with increased flexibility. \n                      These new OPAs have applications across fields as varied as scientific research, aeronautics, defense, telecommunications, and biomedical engineering. In the biomedical field, the devices help to improve pulse shaping for photon microscopy for researchers working on early detection of Alzheimer’s disease and certain cancers. According to Steve Serati, president of BNS, “Researchers use the device to improve their ability to view biological samples, thus enabling early detection of some diseases.” \n                      Large aerospace and defense contractors like Northrop Grumman use the devices for military sensing and ground avoidance. The arrays are also helping to develop improved laser imaging and light detection and ranging capabilities along with laser-sighted weaponry. This technology also has applications in forensics and other areas that can benefit from finer resolution and larger views of microscopic samples. Because of the lower weight of the arrays and decreased energy consumption required to move the beam, the OPAs have been incorporated into satellite-based systems. \n                      Serati estimates that BNS’s NASA-derived devices have been used by nearly all of the major aerospace companies and over 100 research laboratories across governments, private sectors, and universities—and he expects this number will continue to grow.\n                    \n                    \n                  \n                \n              \n              \n            \n          \n        \n      \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      Scientists have long been able to shift the direction of a laser beam, steering it toward a target, but often the strength and focus of the light is altered. For precision applications, where the quality of the beam cannot be compromised, scientists have typically turned to mechanical steering methods, redirecting the source of the beam by swinging the entire laser apparatus toward the target. \n                      \n                        \n                        \n                          \n                        \n                        \n                          This computer rendering shows one possible application for the optical phase array (OPA) technology developed by Boulder Nonlinear Systems Inc. (BNS) through the SBIR program. The rendering shows laser communication using NASA’s Organism/Organic Exposure to Orbital Stresses, or O/OREOS nanosatellites.\n                        \n                      \n                      Just as the mechanical methods used for turning cars has evolved into simpler, lighter, “power steering” methods, so has the means by which researchers can direct lasers. Some of the typical contraptions used to redirect lasers are large and bulky, relying on steering gimbals—pivoted, rotating supports—to shift the device toward its intended target. These devices, some as large and awkward as a piece of heavy luggage, are subject to the same issues confronted by mechanical parts: Components rub, wear out, and get stuck. The poor reliability and bulk—not to mention the power requirements to run one of the machines—have made mechanical beam steering components less than ideal for use in applications where weight, bulk, and maneuverability are prime concerns, such as on an unmanned aerial vehicle (UAV) or a microscope. \n                      The solution to developing reliable, lighter weight, nonmechanical steering methods to replace the hefty steering boxes was to think “outside the box,” and a NASA research partner did just that by developing a new beam steering method that bends and redirects the beam, as opposed to shifting the entire apparatus. The benefits include lower power requirements, a smaller footprint, reduced weight, and better control and flexibility in steering capabilities. Such benefits are realized without sacrificing aperture size, efficiency, or scanning range, and can be applied to myriad uses: propulsion systems, structures, radiation protection systems, and landing systems. \n                      Partnership\n                      Through Small Business Innovation Research (SBIR) contracts with both Johnson Space Center and Langley Research Center, Boulder Nonlinear Systems Inc. (BNS), of Lafayette, Colorado, developed a solution to some of the problems of mechanical beam steering, using advanced optical phase array (OPA) chips. Instead of changing the direction of the entire device, OPA chips allow the beam itself to be deflected and thus redirected. The high-resolution, high-speed, fully programmable system developed by BNS shows promise not only for NASA research needs, but for a variety of commercial and industrial needs as well. \n                      While OPA chips are not new technologies, appearing first in the 1980s, BNS worked to improve both the construction and functionality. Before teaming up with NASA, the company had been working with the University of Colorado’s Optical Computing Center, one of the National Science Foundation’s Centers of Excellence, to develop new chip technologies. \n                      Through its first two NASA SBIRs with Johnson in the early 1990s, BNS began experimenting with liquid crystals on silicon (LCOS) chips, creating a functional OPA, but one that was limited in usefulness as a steering component due to a small aperture and low voltage operation. The company continued work on the project with a 2002 Phase II SBIR with Langley to develop high-speed, high-resolution, fully programmable, nonmechanical beam steering. Within two years, BNS had completed the project, developing an OPA chip capable of driving high-speed liquid crystal phase modulators. \n                      Benefits\n                      The OPA chips combine high-speed liquid crystal phase modulators and high-voltage, very large scale integration (VLSI) silicon back planes that contain thousands of integrated, transistor-based circuits created through the VLSI foundry process. The transistor-based circuits transmit high-voltage signals to the liquid crystal components, reorienting the liquid crystals. This reorientation alters the modulator’s refractive index, creating a phase modulation that allows the beam to be shifted or deflected with a great deal of control and very fine resolution. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The liquid crystal on silicon OPA chip from BNS enables accurate and precise laser beam steering. Together, its features create a compact, low-power, lightweight OPA chip that provides improved control of the steering along with increased flexibility for applications in a variety of areas.\n                        \n                      \n                      The use of the higher voltages allows faster crystal response times and faster beam steering. The uniformity and flatness of the OPA chips also enables more accurate and precise steering. Together, these features combine to allow for a compact, low-power, lightweight OPA chip that provides better control of the steering along with increased flexibility. \n                      These new OPAs have applications across fields as varied as scientific research, aeronautics, defense, telecommunications, and biomedical engineering. In the biomedical field, the devices help to improve pulse shaping for photon microscopy for researchers working on early detection of Alzheimer’s disease and certain cancers. According to Steve Serati, president of BNS, “Researchers use the device to improve their ability to view biological samples, thus enabling early detection of some diseases.” \n                      Large aerospace and defense contractors like Northrop Grumman use the devices for military sensing and ground avoidance. The arrays are also helping to develop improved laser imaging and light detection and ranging capabilities along with laser-sighted weaponry. This technology also has applications in forensics and other areas that can benefit from finer resolution and larger views of microscopic samples. Because of the lower weight of the arrays and decreased energy consumption required to move the beam, the OPAs have been incorporated into satellite-based systems. \n                      Serati estimates that BNS’s NASA-derived devices have been used by nearly all of the major aerospace companies and over 100 research laboratories across governments, private sectors, and universities—and he expects this number will continue to grow.\n                    \n                    \n                  \n                \n              \n              \n            \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      Scientists have long been able to shift the direction of a laser beam, steering it toward a target, but often the strength and focus of the light is altered. For precision applications, where the quality of the beam cannot be compromised, scientists have typically turned to mechanical steering methods, redirecting the source of the beam by swinging the entire laser apparatus toward the target. \n                      \n                        \n                        \n                          \n                        \n                        \n                          This computer rendering shows one possible application for the optical phase array (OPA) technology developed by Boulder Nonlinear Systems Inc. (BNS) through the SBIR program. The rendering shows laser communication using NASA’s Organism/Organic Exposure to Orbital Stresses, or O/OREOS nanosatellites.\n                        \n                      \n                      Just as the mechanical methods used for turning cars has evolved into simpler, lighter, “power steering” methods, so has the means by which researchers can direct lasers. Some of the typical contraptions used to redirect lasers are large and bulky, relying on steering gimbals—pivoted, rotating supports—to shift the device toward its intended target. These devices, some as large and awkward as a piece of heavy luggage, are subject to the same issues confronted by mechanical parts: Components rub, wear out, and get stuck. The poor reliability and bulk—not to mention the power requirements to run one of the machines—have made mechanical beam steering components less than ideal for use in applications where weight, bulk, and maneuverability are prime concerns, such as on an unmanned aerial vehicle (UAV) or a microscope. \n                      The solution to developing reliable, lighter weight, nonmechanical steering methods to replace the hefty steering boxes was to think “outside the box,” and a NASA research partner did just that by developing a new beam steering method that bends and redirects the beam, as opposed to shifting the entire apparatus. The benefits include lower power requirements, a smaller footprint, reduced weight, and better control and flexibility in steering capabilities. Such benefits are realized without sacrificing aperture size, efficiency, or scanning range, and can be applied to myriad uses: propulsion systems, structures, radiation protection systems, and landing systems. \n                      Partnership\n                      Through Small Business Innovation Research (SBIR) contracts with both Johnson Space Center and Langley Research Center, Boulder Nonlinear Systems Inc. (BNS), of Lafayette, Colorado, developed a solution to some of the problems of mechanical beam steering, using advanced optical phase array (OPA) chips. Instead of changing the direction of the entire device, OPA chips allow the beam itself to be deflected and thus redirected. The high-resolution, high-speed, fully programmable system developed by BNS shows promise not only for NASA research needs, but for a variety of commercial and industrial needs as well. \n                      While OPA chips are not new technologies, appearing first in the 1980s, BNS worked to improve both the construction and functionality. Before teaming up with NASA, the company had been working with the University of Colorado’s Optical Computing Center, one of the National Science Foundation’s Centers of Excellence, to develop new chip technologies. \n                      Through its first two NASA SBIRs with Johnson in the early 1990s, BNS began experimenting with liquid crystals on silicon (LCOS) chips, creating a functional OPA, but one that was limited in usefulness as a steering component due to a small aperture and low voltage operation. The company continued work on the project with a 2002 Phase II SBIR with Langley to develop high-speed, high-resolution, fully programmable, nonmechanical beam steering. Within two years, BNS had completed the project, developing an OPA chip capable of driving high-speed liquid crystal phase modulators. \n                      Benefits\n                      The OPA chips combine high-speed liquid crystal phase modulators and high-voltage, very large scale integration (VLSI) silicon back planes that contain thousands of integrated, transistor-based circuits created through the VLSI foundry process. The transistor-based circuits transmit high-voltage signals to the liquid crystal components, reorienting the liquid crystals. This reorientation alters the modulator’s refractive index, creating a phase modulation that allows the beam to be shifted or deflected with a great deal of control and very fine resolution. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The liquid crystal on silicon OPA chip from BNS enables accurate and precise laser beam steering. Together, its features create a compact, low-power, lightweight OPA chip that provides improved control of the steering along with increased flexibility for applications in a variety of areas.\n                        \n                      \n                      The use of the higher voltages allows faster crystal response times and faster beam steering. The uniformity and flatness of the OPA chips also enables more accurate and precise steering. Together, these features combine to allow for a compact, low-power, lightweight OPA chip that provides better control of the steering along with increased flexibility. \n                      These new OPAs have applications across fields as varied as scientific research, aeronautics, defense, telecommunications, and biomedical engineering. In the biomedical field, the devices help to improve pulse shaping for photon microscopy for researchers working on early detection of Alzheimer’s disease and certain cancers. According to Steve Serati, president of BNS, “Researchers use the device to improve their ability to view biological samples, thus enabling early detection of some diseases.” \n                      Large aerospace and defense contractors like Northrop Grumman use the devices for military sensing and ground avoidance. The arrays are also helping to develop improved laser imaging and light detection and ranging capabilities along with laser-sighted weaponry. This technology also has applications in forensics and other areas that can benefit from finer resolution and larger views of microscopic samples. Because of the lower weight of the arrays and decreased energy consumption required to move the beam, the OPAs have been incorporated into satellite-based systems. \n                      Serati estimates that BNS’s NASA-derived devices have been used by nearly all of the major aerospace companies and over 100 research laboratories across governments, private sectors, and universities—and he expects this number will continue to grow.\n                    \n                    \n                  \n                \n              \n              \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      Scientists have long been able to shift the direction of a laser beam, steering it toward a target, but often the strength and focus of the light is altered. For precision applications, where the quality of the beam cannot be compromised, scientists have typically turned to mechanical steering methods, redirecting the source of the beam by swinging the entire laser apparatus toward the target. \n                      \n                        \n                        \n                          \n                        \n                        \n                          This computer rendering shows one possible application for the optical phase array (OPA) technology developed by Boulder Nonlinear Systems Inc. (BNS) through the SBIR program. The rendering shows laser communication using NASA’s Organism/Organic Exposure to Orbital Stresses, or O/OREOS nanosatellites.\n                        \n                      \n                      Just as the mechanical methods used for turning cars has evolved into simpler, lighter, “power steering” methods, so has the means by which researchers can direct lasers. Some of the typical contraptions used to redirect lasers are large and bulky, relying on steering gimbals—pivoted, rotating supports—to shift the device toward its intended target. These devices, some as large and awkward as a piece of heavy luggage, are subject to the same issues confronted by mechanical parts: Components rub, wear out, and get stuck. The poor reliability and bulk—not to mention the power requirements to run one of the machines—have made mechanical beam steering components less than ideal for use in applications where weight, bulk, and maneuverability are prime concerns, such as on an unmanned aerial vehicle (UAV) or a microscope. \n                      The solution to developing reliable, lighter weight, nonmechanical steering methods to replace the hefty steering boxes was to think “outside the box,” and a NASA research partner did just that by developing a new beam steering method that bends and redirects the beam, as opposed to shifting the entire apparatus. The benefits include lower power requirements, a smaller footprint, reduced weight, and better control and flexibility in steering capabilities. Such benefits are realized without sacrificing aperture size, efficiency, or scanning range, and can be applied to myriad uses: propulsion systems, structures, radiation protection systems, and landing systems. \n                      Partnership\n                      Through Small Business Innovation Research (SBIR) contracts with both Johnson Space Center and Langley Research Center, Boulder Nonlinear Systems Inc. (BNS), of Lafayette, Colorado, developed a solution to some of the problems of mechanical beam steering, using advanced optical phase array (OPA) chips. Instead of changing the direction of the entire device, OPA chips allow the beam itself to be deflected and thus redirected. The high-resolution, high-speed, fully programmable system developed by BNS shows promise not only for NASA research needs, but for a variety of commercial and industrial needs as well. \n                      While OPA chips are not new technologies, appearing first in the 1980s, BNS worked to improve both the construction and functionality. Before teaming up with NASA, the company had been working with the University of Colorado’s Optical Computing Center, one of the National Science Foundation’s Centers of Excellence, to develop new chip technologies. \n                      Through its first two NASA SBIRs with Johnson in the early 1990s, BNS began experimenting with liquid crystals on silicon (LCOS) chips, creating a functional OPA, but one that was limited in usefulness as a steering component due to a small aperture and low voltage operation. The company continued work on the project with a 2002 Phase II SBIR with Langley to develop high-speed, high-resolution, fully programmable, nonmechanical beam steering. Within two years, BNS had completed the project, developing an OPA chip capable of driving high-speed liquid crystal phase modulators. \n                      Benefits\n                      The OPA chips combine high-speed liquid crystal phase modulators and high-voltage, very large scale integration (VLSI) silicon back planes that contain thousands of integrated, transistor-based circuits created through the VLSI foundry process. The transistor-based circuits transmit high-voltage signals to the liquid crystal components, reorienting the liquid crystals. This reorientation alters the modulator’s refractive index, creating a phase modulation that allows the beam to be shifted or deflected with a great deal of control and very fine resolution. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The liquid crystal on silicon OPA chip from BNS enables accurate and precise laser beam steering. Together, its features create a compact, low-power, lightweight OPA chip that provides improved control of the steering along with increased flexibility for applications in a variety of areas.\n                        \n                      \n                      The use of the higher voltages allows faster crystal response times and faster beam steering. The uniformity and flatness of the OPA chips also enables more accurate and precise steering. Together, these features combine to allow for a compact, low-power, lightweight OPA chip that provides better control of the steering along with increased flexibility. \n                      These new OPAs have applications across fields as varied as scientific research, aeronautics, defense, telecommunications, and biomedical engineering. In the biomedical field, the devices help to improve pulse shaping for photon microscopy for researchers working on early detection of Alzheimer’s disease and certain cancers. According to Steve Serati, president of BNS, “Researchers use the device to improve their ability to view biological samples, thus enabling early detection of some diseases.” \n                      Large aerospace and defense contractors like Northrop Grumman use the devices for military sensing and ground avoidance. The arrays are also helping to develop improved laser imaging and light detection and ranging capabilities along with laser-sighted weaponry. This technology also has applications in forensics and other areas that can benefit from finer resolution and larger views of microscopic samples. Because of the lower weight of the arrays and decreased energy consumption required to move the beam, the OPAs have been incorporated into satellite-based systems. \n                      Serati estimates that BNS’s NASA-derived devices have been used by nearly all of the major aerospace companies and over 100 research laboratories across governments, private sectors, and universities—and he expects this number will continue to grow.\n                    \n                    \n                  \n                \n              \n              \n                \n                  \n                    \n                      NASA Technology\n                      Scientists have long been able to shift the direction of a laser beam, steering it toward a target, but often the strength and focus of the light is altered. For precision applications, where the quality of the beam cannot be compromised, scientists have typically turned to mechanical steering methods, redirecting the source of the beam by swinging the entire laser apparatus toward the target. \n                      \n                        \n                        \n                          \n                        \n                        \n                          This computer rendering shows one possible application for the optical phase array (OPA) technology developed by Boulder Nonlinear Systems Inc. (BNS) through the SBIR program. The rendering shows laser communication using NASA’s Organism/Organic Exposure to Orbital Stresses, or O/OREOS nanosatellites.\n                        \n                      \n                      Just as the mechanical methods used for turning cars has evolved into simpler, lighter, “power steering” methods, so has the means by which researchers can direct lasers. Some of the typical contraptions used to redirect lasers are large and bulky, relying on steering gimbals—pivoted, rotating supports—to shift the device toward its intended target. These devices, some as large and awkward as a piece of heavy luggage, are subject to the same issues confronted by mechanical parts: Components rub, wear out, and get stuck. The poor reliability and bulk—not to mention the power requirements to run one of the machines—have made mechanical beam steering components less than ideal for use in applications where weight, bulk, and maneuverability are prime concerns, such as on an unmanned aerial vehicle (UAV) or a microscope. \n                      The solution to developing reliable, lighter weight, nonmechanical steering methods to replace the hefty steering boxes was to think “outside the box,” and a NASA research partner did just that by developing a new beam steering method that bends and redirects the beam, as opposed to shifting the entire apparatus. The benefits include lower power requirements, a smaller footprint, reduced weight, and better control and flexibility in steering capabilities. Such benefits are realized without sacrificing aperture size, efficiency, or scanning range, and can be applied to myriad uses: propulsion systems, structures, radiation protection systems, and landing systems. \n                      Partnership\n                      Through Small Business Innovation Research (SBIR) contracts with both Johnson Space Center and Langley Research Center, Boulder Nonlinear Systems Inc. (BNS), of Lafayette, Colorado, developed a solution to some of the problems of mechanical beam steering, using advanced optical phase array (OPA) chips. Instead of changing the direction of the entire device, OPA chips allow the beam itself to be deflected and thus redirected. The high-resolution, high-speed, fully programmable system developed by BNS shows promise not only for NASA research needs, but for a variety of commercial and industrial needs as well. \n                      While OPA chips are not new technologies, appearing first in the 1980s, BNS worked to improve both the construction and functionality. Before teaming up with NASA, the company had been working with the University of Colorado’s Optical Computing Center, one of the National Science Foundation’s Centers of Excellence, to develop new chip technologies. \n                      Through its first two NASA SBIRs with Johnson in the early 1990s, BNS began experimenting with liquid crystals on silicon (LCOS) chips, creating a functional OPA, but one that was limited in usefulness as a steering component due to a small aperture and low voltage operation. The company continued work on the project with a 2002 Phase II SBIR with Langley to develop high-speed, high-resolution, fully programmable, nonmechanical beam steering. Within two years, BNS had completed the project, developing an OPA chip capable of driving high-speed liquid crystal phase modulators. \n                      Benefits\n                      The OPA chips combine high-speed liquid crystal phase modulators and high-voltage, very large scale integration (VLSI) silicon back planes that contain thousands of integrated, transistor-based circuits created through the VLSI foundry process. The transistor-based circuits transmit high-voltage signals to the liquid crystal components, reorienting the liquid crystals. This reorientation alters the modulator’s refractive index, creating a phase modulation that allows the beam to be shifted or deflected with a great deal of control and very fine resolution. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The liquid crystal on silicon OPA chip from BNS enables accurate and precise laser beam steering. Together, its features create a compact, low-power, lightweight OPA chip that provides improved control of the steering along with increased flexibility for applications in a variety of areas.\n                        \n                      \n                      The use of the higher voltages allows faster crystal response times and faster beam steering. The uniformity and flatness of the OPA chips also enables more accurate and precise steering. Together, these features combine to allow for a compact, low-power, lightweight OPA chip that provides better control of the steering along with increased flexibility. \n                      These new OPAs have applications across fields as varied as scientific research, aeronautics, defense, telecommunications, and biomedical engineering. In the biomedical field, the devices help to improve pulse shaping for photon microscopy for researchers working on early detection of Alzheimer’s disease and certain cancers. According to Steve Serati, president of BNS, “Researchers use the device to improve their ability to view biological samples, thus enabling early detection of some diseases.” \n                      Large aerospace and defense contractors like Northrop Grumman use the devices for military sensing and ground avoidance. The arrays are also helping to develop improved laser imaging and light detection and ranging capabilities along with laser-sighted weaponry. This technology also has applications in forensics and other areas that can benefit from finer resolution and larger views of microscopic samples. Because of the lower weight of the arrays and decreased energy consumption required to move the beam, the OPAs have been incorporated into satellite-based systems. \n                      Serati estimates that BNS’s NASA-derived devices have been used by nearly all of the major aerospace companies and over 100 research laboratories across governments, private sectors, and universities—and he expects this number will continue to grow.\n                    \n                    \n                  \n                \n                  \n                    \n                      NASA Technology\n                      Scientists have long been able to shift the direction of a laser beam, steering it toward a target, but often the strength and focus of the light is altered. For precision applications, where the quality of the beam cannot be compromised, scientists have typically turned to mechanical steering methods, redirecting the source of the beam by swinging the entire laser apparatus toward the target. \n                      \n                        \n                        \n                          \n                        \n                        \n                          This computer rendering shows one possible application for the optical phase array (OPA) technology developed by Boulder Nonlinear Systems Inc. (BNS) through the SBIR program. The rendering shows laser communication using NASA’s Organism/Organic Exposure to Orbital Stresses, or O/OREOS nanosatellites.\n                        \n                      \n                      Just as the mechanical methods used for turning cars has evolved into simpler, lighter, “power steering” methods, so has the means by which researchers can direct lasers. Some of the typical contraptions used to redirect lasers are large and bulky, relying on steering gimbals—pivoted, rotating supports—to shift the device toward its intended target. These devices, some as large and awkward as a piece of heavy luggage, are subject to the same issues confronted by mechanical parts: Components rub, wear out, and get stuck. The poor reliability and bulk—not to mention the power requirements to run one of the machines—have made mechanical beam steering components less than ideal for use in applications where weight, bulk, and maneuverability are prime concerns, such as on an unmanned aerial vehicle (UAV) or a microscope. \n                      The solution to developing reliable, lighter weight, nonmechanical steering methods to replace the hefty steering boxes was to think “outside the box,” and a NASA research partner did just that by developing a new beam steering method that bends and redirects the beam, as opposed to shifting the entire apparatus. The benefits include lower power requirements, a smaller footprint, reduced weight, and better control and flexibility in steering capabilities. Such benefits are realized without sacrificing aperture size, efficiency, or scanning range, and can be applied to myriad uses: propulsion systems, structures, radiation protection systems, and landing systems. \n                      Partnership\n                      Through Small Business Innovation Research (SBIR) contracts with both Johnson Space Center and Langley Research Center, Boulder Nonlinear Systems Inc. (BNS), of Lafayette, Colorado, developed a solution to some of the problems of mechanical beam steering, using advanced optical phase array (OPA) chips. Instead of changing the direction of the entire device, OPA chips allow the beam itself to be deflected and thus redirected. The high-resolution, high-speed, fully programmable system developed by BNS shows promise not only for NASA research needs, but for a variety of commercial and industrial needs as well. \n                      While OPA chips are not new technologies, appearing first in the 1980s, BNS worked to improve both the construction and functionality. Before teaming up with NASA, the company had been working with the University of Colorado’s Optical Computing Center, one of the National Science Foundation’s Centers of Excellence, to develop new chip technologies. \n                      Through its first two NASA SBIRs with Johnson in the early 1990s, BNS began experimenting with liquid crystals on silicon (LCOS) chips, creating a functional OPA, but one that was limited in usefulness as a steering component due to a small aperture and low voltage operation. The company continued work on the project with a 2002 Phase II SBIR with Langley to develop high-speed, high-resolution, fully programmable, nonmechanical beam steering. Within two years, BNS had completed the project, developing an OPA chip capable of driving high-speed liquid crystal phase modulators. \n                      Benefits\n                      The OPA chips combine high-speed liquid crystal phase modulators and high-voltage, very large scale integration (VLSI) silicon back planes that contain thousands of integrated, transistor-based circuits created through the VLSI foundry process. The transistor-based circuits transmit high-voltage signals to the liquid crystal components, reorienting the liquid crystals. This reorientation alters the modulator’s refractive index, creating a phase modulation that allows the beam to be shifted or deflected with a great deal of control and very fine resolution. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The liquid crystal on silicon OPA chip from BNS enables accurate and precise laser beam steering. Together, its features create a compact, low-power, lightweight OPA chip that provides improved control of the steering along with increased flexibility for applications in a variety of areas.\n                        \n                      \n                      The use of the higher voltages allows faster crystal response times and faster beam steering. The uniformity and flatness of the OPA chips also enables more accurate and precise steering. Together, these features combine to allow for a compact, low-power, lightweight OPA chip that provides better control of the steering along with increased flexibility. \n                      These new OPAs have applications across fields as varied as scientific research, aeronautics, defense, telecommunications, and biomedical engineering. In the biomedical field, the devices help to improve pulse shaping for photon microscopy for researchers working on early detection of Alzheimer’s disease and certain cancers. According to Steve Serati, president of BNS, “Researchers use the device to improve their ability to view biological samples, thus enabling early detection of some diseases.” \n                      Large aerospace and defense contractors like Northrop Grumman use the devices for military sensing and ground avoidance. The arrays are also helping to develop improved laser imaging and light detection and ranging capabilities along with laser-sighted weaponry. This technology also has applications in forensics and other areas that can benefit from finer resolution and larger views of microscopic samples. Because of the lower weight of the arrays and decreased energy consumption required to move the beam, the OPAs have been incorporated into satellite-based systems. \n                      Serati estimates that BNS’s NASA-derived devices have been used by nearly all of the major aerospace companies and over 100 research laboratories across governments, private sectors, and universities—and he expects this number will continue to grow.\n                    \n                    \n                  \n                    \n                      NASA Technology\n                      Scientists have long been able to shift the direction of a laser beam, steering it toward a target, but often the strength and focus of the light is altered. For precision applications, where the quality of the beam cannot be compromised, scientists have typically turned to mechanical steering methods, redirecting the source of the beam by swinging the entire laser apparatus toward the target. \n                      \n                        \n                        \n                          \n                        \n                        \n                          This computer rendering shows one possible application for the optical phase array (OPA) technology developed by Boulder Nonlinear Systems Inc. (BNS) through the SBIR program. The rendering shows laser communication using NASA’s Organism/Organic Exposure to Orbital Stresses, or O/OREOS nanosatellites.\n                        \n                      \n                      Just as the mechanical methods used for turning cars has evolved into simpler, lighter, “power steering” methods, so has the means by which researchers can direct lasers. Some of the typical contraptions used to redirect lasers are large and bulky, relying on steering gimbals—pivoted, rotating supports—to shift the device toward its intended target. These devices, some as large and awkward as a piece of heavy luggage, are subject to the same issues confronted by mechanical parts: Components rub, wear out, and get stuck. The poor reliability and bulk—not to mention the power requirements to run one of the machines—have made mechanical beam steering components less than ideal for use in applications where weight, bulk, and maneuverability are prime concerns, such as on an unmanned aerial vehicle (UAV) or a microscope. \n                      The solution to developing reliable, lighter weight, nonmechanical steering methods to replace the hefty steering boxes was to think “outside the box,” and a NASA research partner did just that by developing a new beam steering method that bends and redirects the beam, as opposed to shifting the entire apparatus. The benefits include lower power requirements, a smaller footprint, reduced weight, and better control and flexibility in steering capabilities. Such benefits are realized without sacrificing aperture size, efficiency, or scanning range, and can be applied to myriad uses: propulsion systems, structures, radiation protection systems, and landing systems. \n                      Partnership\n                      Through Small Business Innovation Research (SBIR) contracts with both Johnson Space Center and Langley Research Center, Boulder Nonlinear Systems Inc. (BNS), of Lafayette, Colorado, developed a solution to some of the problems of mechanical beam steering, using advanced optical phase array (OPA) chips. Instead of changing the direction of the entire device, OPA chips allow the beam itself to be deflected and thus redirected. The high-resolution, high-speed, fully programmable system developed by BNS shows promise not only for NASA research needs, but for a variety of commercial and industrial needs as well. \n                      While OPA chips are not new technologies, appearing first in the 1980s, BNS worked to improve both the construction and functionality. Before teaming up with NASA, the company had been working with the University of Colorado’s Optical Computing Center, one of the National Science Foundation’s Centers of Excellence, to develop new chip technologies. \n                      Through its first two NASA SBIRs with Johnson in the early 1990s, BNS began experimenting with liquid crystals on silicon (LCOS) chips, creating a functional OPA, but one that was limited in usefulness as a steering component due to a small aperture and low voltage operation. The company continued work on the project with a 2002 Phase II SBIR with Langley to develop high-speed, high-resolution, fully programmable, nonmechanical beam steering. Within two years, BNS had completed the project, developing an OPA chip capable of driving high-speed liquid crystal phase modulators. \n                      Benefits\n                      The OPA chips combine high-speed liquid crystal phase modulators and high-voltage, very large scale integration (VLSI) silicon back planes that contain thousands of integrated, transistor-based circuits created through the VLSI foundry process. The transistor-based circuits transmit high-voltage signals to the liquid crystal components, reorienting the liquid crystals. This reorientation alters the modulator’s refractive index, creating a phase modulation that allows the beam to be shifted or deflected with a great deal of control and very fine resolution. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The liquid crystal on silicon OPA chip from BNS enables accurate and precise laser beam steering. Together, its features create a compact, low-power, lightweight OPA chip that provides improved control of the steering along with increased flexibility for applications in a variety of areas.\n                        \n                      \n                      The use of the higher voltages allows faster crystal response times and faster beam steering. The uniformity and flatness of the OPA chips also enables more accurate and precise steering. Together, these features combine to allow for a compact, low-power, lightweight OPA chip that provides better control of the steering along with increased flexibility. \n                      These new OPAs have applications across fields as varied as scientific research, aeronautics, defense, telecommunications, and biomedical engineering. In the biomedical field, the devices help to improve pulse shaping for photon microscopy for researchers working on early detection of Alzheimer’s disease and certain cancers. According to Steve Serati, president of BNS, “Researchers use the device to improve their ability to view biological samples, thus enabling early detection of some diseases.” \n                      Large aerospace and defense contractors like Northrop Grumman use the devices for military sensing and ground avoidance. The arrays are also helping to develop improved laser imaging and light detection and ranging capabilities along with laser-sighted weaponry. This technology also has applications in forensics and other areas that can benefit from finer resolution and larger views of microscopic samples. Because of the lower weight of the arrays and decreased energy consumption required to move the beam, the OPAs have been incorporated into satellite-based systems. \n                      Serati estimates that BNS’s NASA-derived devices have been used by nearly all of the major aerospace companies and over 100 research laboratories across governments, private sectors, and universities—and he expects this number will continue to grow.\n                    \n                    \n                      NASA Technology\n                      Scientists have long been able to shift the direction of a laser beam, steering it toward a target, but often the strength and focus of the light is altered. For precision applications, where the quality of the beam cannot be compromised, scientists have typically turned to mechanical steering methods, redirecting the source of the beam by swinging the entire laser apparatus toward the target. \n                      \n                        \n                        \n                          \n                        \n                        \n                          This computer rendering shows one possible application for the optical phase array (OPA) technology developed by Boulder Nonlinear Systems Inc. (BNS) through the SBIR program. The rendering shows laser communication using NASA’s Organism/Organic Exposure to Orbital Stresses, or O/OREOS nanosatellites.\n                        \n                      \n                      Just as the mechanical methods used for turning cars has evolved into simpler, lighter, “power steering” methods, so has the means by which researchers can direct lasers. Some of the typical contraptions used to redirect lasers are large and bulky, relying on steering gimbals—pivoted, rotating supports—to shift the device toward its intended target. These devices, some as large and awkward as a piece of heavy luggage, are subject to the same issues confronted by mechanical parts: Components rub, wear out, and get stuck. The poor reliability and bulk—not to mention the power requirements to run one of the machines—have made mechanical beam steering components less than ideal for use in applications where weight, bulk, and maneuverability are prime concerns, such as on an unmanned aerial vehicle (UAV) or a microscope. \n                      The solution to developing reliable, lighter weight, nonmechanical steering methods to replace the hefty steering boxes was to think “outside the box,” and a NASA research partner did just that by developing a new beam steering method that bends and redirects the beam, as opposed to shifting the entire apparatus. The benefits include lower power requirements, a smaller footprint, reduced weight, and better control and flexibility in steering capabilities. Such benefits are realized without sacrificing aperture size, efficiency, or scanning range, and can be applied to myriad uses: propulsion systems, structures, radiation protection systems, and landing systems. \n                      Partnership\n                      Through Small Business Innovation Research (SBIR) contracts with both Johnson Space Center and Langley Research Center, Boulder Nonlinear Systems Inc. (BNS), of Lafayette, Colorado, developed a solution to some of the problems of mechanical beam steering, using advanced optical phase array (OPA) chips. Instead of changing the direction of the entire device, OPA chips allow the beam itself to be deflected and thus redirected. The high-resolution, high-speed, fully programmable system developed by BNS shows promise not only for NASA research needs, but for a variety of commercial and industrial needs as well. \n                      While OPA chips are not new technologies, appearing first in the 1980s, BNS worked to improve both the construction and functionality. Before teaming up with NASA, the company had been working with the University of Colorado’s Optical Computing Center, one of the National Science Foundation’s Centers of Excellence, to develop new chip technologies. \n                      Through its first two NASA SBIRs with Johnson in the early 1990s, BNS began experimenting with liquid crystals on silicon (LCOS) chips, creating a functional OPA, but one that was limited in usefulness as a steering component due to a small aperture and low voltage operation. The company continued work on the project with a 2002 Phase II SBIR with Langley to develop high-speed, high-resolution, fully programmable, nonmechanical beam steering. Within two years, BNS had completed the project, developing an OPA chip capable of driving high-speed liquid crystal phase modulators. \n                      Benefits\n                      The OPA chips combine high-speed liquid crystal phase modulators and high-voltage, very large scale integration (VLSI) silicon back planes that contain thousands of integrated, transistor-based circuits created through the VLSI foundry process. The transistor-based circuits transmit high-voltage signals to the liquid crystal components, reorienting the liquid crystals. This reorientation alters the modulator’s refractive index, creating a phase modulation that allows the beam to be shifted or deflected with a great deal of control and very fine resolution. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The liquid crystal on silicon OPA chip from BNS enables accurate and precise laser beam steering. Together, its features create a compact, low-power, lightweight OPA chip that provides improved control of the steering along with increased flexibility for applications in a variety of areas.\n                        \n                      \n                      The use of the higher voltages allows faster crystal response times and faster beam steering. The uniformity and flatness of the OPA chips also enables more accurate and precise steering. Together, these features combine to allow for a compact, low-power, lightweight OPA chip that provides better control of the steering along with increased flexibility. \n                      These new OPAs have applications across fields as varied as scientific research, aeronautics, defense, telecommunications, and biomedical engineering. In the biomedical field, the devices help to improve pulse shaping for photon microscopy for researchers working on early detection of Alzheimer’s disease and certain cancers. According to Steve Serati, president of BNS, “Researchers use the device to improve their ability to view biological samples, thus enabling early detection of some diseases.” \n                      Large aerospace and defense contractors like Northrop Grumman use the devices for military sensing and ground avoidance. The arrays are also helping to develop improved laser imaging and light detection and ranging capabilities along with laser-sighted weaponry. This technology also has applications in forensics and other areas that can benefit from finer resolution and larger views of microscopic samples. Because of the lower weight of the arrays and decreased energy consumption required to move the beam, the OPAs have been incorporated into satellite-based systems. \n                      Serati estimates that BNS’s NASA-derived devices have been used by nearly all of the major aerospace companies and over 100 research laboratories across governments, private sectors, and universities—and he expects this number will continue to grow.\n                    "},{"href":"http://spinoff.nasa.gov/Spinoff2011/ip_5.html","text":"Models Support Energy-Saving Microwave Technologies","image":"http://spinoff.nasa.gov/Spinoff2011/Images/ip_5a_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          When the fender of a lunar rover suffered damage, astronauts on Apollo 17 repaired it with maps, clamps, and duct tape. Without a fender, the rover kicked up a plume of abrasive lunar dust that stuck to the astronauts and their equipment.\n                        \n                      \n                      During the Apollo Program, astronauts on the Moon encountered a small menace that created big problems: lunar dust. Similar to how tiny bits of Styrofoam behave on Earth—adhering to anything they touch—lunar dust sticks to spacesuits, spacecraft, tools, and equipment, and is extremely difficult to remove. The clingy nature of the substance is partly due to its electrostatic charge but is also due to its physical characteristics: The sharp, irregularly shaped grains have edges like burrs and feel like abrasive talcum powder to the touch. \n                      Not only a nuisance, Moon dust is also a potential health and safety risk. Because it is often laden with ultraviolet radiation and high iron content, it can be detrimental if it gets into the eyes or lungs. In fact, some of the particles are so small that the human body does not even detect them in order to expel them. On the Apollo missions, equipment covered with the dark-colored Moon dust suffered from the absorption of sunlight and tended to overheat. \n                       NASA has investigated tools and techniques to manage the sticky stuff, including magnets, vacuums, and shields. In 2009, Kennedy Space Center collaborated with a small business to investigate a method to harden the Moon’s surface—in a sense, to “pave” the surface—so astronauts and robots could land, drive, and work without disrupting and scattering the material. \n                      Partnership\n                      Kennedy awarded Small Business Innovation Research (SBIR) funding to Troy, New York-based Ceralink Inc., a leader in the development of microwave processing technologies, to demonstrate a microwave system that could heat lunar soil to over 2,000 ˚F, temperatures high enough to solidify the surface. The company performed demonstrations using microwave technology, which could be incorporated into a roving lunar system, to heat the surface of a large bed of 8-inch deep simulated lunar soil.\n                       “When you heat the dust, it densifies or melts, becoming glassy and hard,” says Holly Shulman, president and CTO of Ceralink. “The technology could potentially be used to make miles of road on the Moon.” \n                      The technique employed through the SBIR applied microwave heat only to the surface of a material rather than an entire object. In addition to demonstrating this new approach, Ceralink also examined the feasibility of using computer modeling software to simulate microwave heating on a larger scale. \n                       As part of the SBIR, Ceralink teamed with Rensselaer Polytechnic Institute (RPI) and Gerling Applied Engineering to investigate and refine the computer modeling technology. This opportunity allowed the team to test the modeling program against an experiment. “By the end of the project, the model was at the point where it was matching up very well with what we were doing in the lab,” says Shawn Allan, Ceralink’s principal investigator on the project. “We had experiments and also a computer model that was backing up our experiments.” \n                       As a result, the team advanced a computer modeling capability that is now incorporated into Ceralink’s commercial services. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through an SBIR with Kennedy Space Center, Ceralink Inc. demonstrated a microwave system that could heat lunar soil enough to solidify it. The images above show simulated lunar soil before, during, and after Ceralink’s microwave heating. As a result of the SBIR, Ceralink refined a computer modeling program that is now offered as part of Ceralink’s commercial services.\n                        \n                      \n                      Ceralink specializes in microwaves, materials, processing, and design, providing microwave technology for research and manufacturing of ceramic materials, glass, metals, and polymers. The company’s microwave testing center boasts a range of heating equipment for a variety of processes, and when customers are interested in exploring microwave heating, Ceralink performs the tests in its lab. “The customer might be interested in energy savings, or running their process faster, or looking to see if they can get better properties by using microwave,” says Allan. \n                      Thanks to the NASA SBIR, the company is now using the resulting computer modeling technology to predict how materials like ceramics, metals, and glass behave with microwave heat. The new capability is like having an extra tool, says Allan. “We can do the experimental work, and we can also model what we are doing. That’s an ability for us that we didn’t really have before the NASA project.” \n                      The program allows Ceralink to take what is learned from a process developed in the lab for a small microwave furnace and apply the information to simulate how the same process would work in a much larger furnace. The company simply inputs the material properties, and the model runs the specific configuration, including the amount of microwave power that would be required on a larger level. “It makes us better prepared to help our customers scale up microwave heating for manufacturing,” says Allan. \n                      Ceralink is currently using the NASA-enhanced program for a U.S. Department of Energy project to design and test microwave technology for cracking hydrocarbons like ethane and turning it into ethylene for making plastics like polyethylene and polyester. “The process takes long chains of hydrocarbons and breaks them down to make other things like ethylene gas. A microwave is being used to crack it down as an energy-saving method,” says Shulman.\n                      The model has applicability for other Ceralink customers as well. For example, the company recently built \n                        a system for making specialty carbon foam for composites tooling for aircraft, spacecraft, and automobiles. \n                        The process required the materials to be heated to over 1,800 ˚F, and with conventional heating methods, it took 1 week to fire the material. With a small system developed in Ceralink’s lab, the firing was complete in less than a day. Together with other companies, Ceralink built a successful larger system, but, as Allan says, “If we had the modeling tool at the time, it would have helped to simplify the design and building of the system.” \n                      Allan also envisions use for the modeling program for tape cast machine applications, which move materials on a belt through a microwave; for alumina substrates for electronics and computers; zirconia for solid oxide fuel cells; and other electronics ceramic materials that go into capacitors and resistors, fuel cell materials, and battery materials.\n                      As the new tool impacts Ceralink’s current innovations, it has the potential to impact NASA’s future developments. In 2011, the company began working on an SBIR to apply microwave technology for curing epoxy composites for aircraft, helicopters, and spacecraft. “We are currently developing it in our lab on a small scale, but I’m optimistic,” says Allan. “If we proceed in the development, the model will be very helpful.”\n                    \n                    \n                  \n                \n              \n              \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          When the fender of a lunar rover suffered damage, astronauts on Apollo 17 repaired it with maps, clamps, and duct tape. Without a fender, the rover kicked up a plume of abrasive lunar dust that stuck to the astronauts and their equipment.\n                        \n                      \n                      During the Apollo Program, astronauts on the Moon encountered a small menace that created big problems: lunar dust. Similar to how tiny bits of Styrofoam behave on Earth—adhering to anything they touch—lunar dust sticks to spacesuits, spacecraft, tools, and equipment, and is extremely difficult to remove. The clingy nature of the substance is partly due to its electrostatic charge but is also due to its physical characteristics: The sharp, irregularly shaped grains have edges like burrs and feel like abrasive talcum powder to the touch. \n                      Not only a nuisance, Moon dust is also a potential health and safety risk. Because it is often laden with ultraviolet radiation and high iron content, it can be detrimental if it gets into the eyes or lungs. In fact, some of the particles are so small that the human body does not even detect them in order to expel them. On the Apollo missions, equipment covered with the dark-colored Moon dust suffered from the absorption of sunlight and tended to overheat. \n                       NASA has investigated tools and techniques to manage the sticky stuff, including magnets, vacuums, and shields. In 2009, Kennedy Space Center collaborated with a small business to investigate a method to harden the Moon’s surface—in a sense, to “pave” the surface—so astronauts and robots could land, drive, and work without disrupting and scattering the material. \n                      Partnership\n                      Kennedy awarded Small Business Innovation Research (SBIR) funding to Troy, New York-based Ceralink Inc., a leader in the development of microwave processing technologies, to demonstrate a microwave system that could heat lunar soil to over 2,000 ˚F, temperatures high enough to solidify the surface. The company performed demonstrations using microwave technology, which could be incorporated into a roving lunar system, to heat the surface of a large bed of 8-inch deep simulated lunar soil.\n                       “When you heat the dust, it densifies or melts, becoming glassy and hard,” says Holly Shulman, president and CTO of Ceralink. “The technology could potentially be used to make miles of road on the Moon.” \n                      The technique employed through the SBIR applied microwave heat only to the surface of a material rather than an entire object. In addition to demonstrating this new approach, Ceralink also examined the feasibility of using computer modeling software to simulate microwave heating on a larger scale. \n                       As part of the SBIR, Ceralink teamed with Rensselaer Polytechnic Institute (RPI) and Gerling Applied Engineering to investigate and refine the computer modeling technology. This opportunity allowed the team to test the modeling program against an experiment. “By the end of the project, the model was at the point where it was matching up very well with what we were doing in the lab,” says Shawn Allan, Ceralink’s principal investigator on the project. “We had experiments and also a computer model that was backing up our experiments.” \n                       As a result, the team advanced a computer modeling capability that is now incorporated into Ceralink’s commercial services. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through an SBIR with Kennedy Space Center, Ceralink Inc. demonstrated a microwave system that could heat lunar soil enough to solidify it. The images above show simulated lunar soil before, during, and after Ceralink’s microwave heating. As a result of the SBIR, Ceralink refined a computer modeling program that is now offered as part of Ceralink’s commercial services.\n                        \n                      \n                      Ceralink specializes in microwaves, materials, processing, and design, providing microwave technology for research and manufacturing of ceramic materials, glass, metals, and polymers. The company’s microwave testing center boasts a range of heating equipment for a variety of processes, and when customers are interested in exploring microwave heating, Ceralink performs the tests in its lab. “The customer might be interested in energy savings, or running their process faster, or looking to see if they can get better properties by using microwave,” says Allan. \n                      Thanks to the NASA SBIR, the company is now using the resulting computer modeling technology to predict how materials like ceramics, metals, and glass behave with microwave heat. The new capability is like having an extra tool, says Allan. “We can do the experimental work, and we can also model what we are doing. That’s an ability for us that we didn’t really have before the NASA project.” \n                      The program allows Ceralink to take what is learned from a process developed in the lab for a small microwave furnace and apply the information to simulate how the same process would work in a much larger furnace. The company simply inputs the material properties, and the model runs the specific configuration, including the amount of microwave power that would be required on a larger level. “It makes us better prepared to help our customers scale up microwave heating for manufacturing,” says Allan. \n                      Ceralink is currently using the NASA-enhanced program for a U.S. Department of Energy project to design and test microwave technology for cracking hydrocarbons like ethane and turning it into ethylene for making plastics like polyethylene and polyester. “The process takes long chains of hydrocarbons and breaks them down to make other things like ethylene gas. A microwave is being used to crack it down as an energy-saving method,” says Shulman.\n                      The model has applicability for other Ceralink customers as well. For example, the company recently built \n                        a system for making specialty carbon foam for composites tooling for aircraft, spacecraft, and automobiles. \n                        The process required the materials to be heated to over 1,800 ˚F, and with conventional heating methods, it took 1 week to fire the material. With a small system developed in Ceralink’s lab, the firing was complete in less than a day. Together with other companies, Ceralink built a successful larger system, but, as Allan says, “If we had the modeling tool at the time, it would have helped to simplify the design and building of the system.” \n                      Allan also envisions use for the modeling program for tape cast machine applications, which move materials on a belt through a microwave; for alumina substrates for electronics and computers; zirconia for solid oxide fuel cells; and other electronics ceramic materials that go into capacitors and resistors, fuel cell materials, and battery materials.\n                      As the new tool impacts Ceralink’s current innovations, it has the potential to impact NASA’s future developments. In 2011, the company began working on an SBIR to apply microwave technology for curing epoxy composites for aircraft, helicopters, and spacecraft. “We are currently developing it in our lab on a small scale, but I’m optimistic,” says Allan. “If we proceed in the development, the model will be very helpful.”\n                    \n                    \n                  \n                \n              \n              \n            \n          \n        \n      \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          When the fender of a lunar rover suffered damage, astronauts on Apollo 17 repaired it with maps, clamps, and duct tape. Without a fender, the rover kicked up a plume of abrasive lunar dust that stuck to the astronauts and their equipment.\n                        \n                      \n                      During the Apollo Program, astronauts on the Moon encountered a small menace that created big problems: lunar dust. Similar to how tiny bits of Styrofoam behave on Earth—adhering to anything they touch—lunar dust sticks to spacesuits, spacecraft, tools, and equipment, and is extremely difficult to remove. The clingy nature of the substance is partly due to its electrostatic charge but is also due to its physical characteristics: The sharp, irregularly shaped grains have edges like burrs and feel like abrasive talcum powder to the touch. \n                      Not only a nuisance, Moon dust is also a potential health and safety risk. Because it is often laden with ultraviolet radiation and high iron content, it can be detrimental if it gets into the eyes or lungs. In fact, some of the particles are so small that the human body does not even detect them in order to expel them. On the Apollo missions, equipment covered with the dark-colored Moon dust suffered from the absorption of sunlight and tended to overheat. \n                       NASA has investigated tools and techniques to manage the sticky stuff, including magnets, vacuums, and shields. In 2009, Kennedy Space Center collaborated with a small business to investigate a method to harden the Moon’s surface—in a sense, to “pave” the surface—so astronauts and robots could land, drive, and work without disrupting and scattering the material. \n                      Partnership\n                      Kennedy awarded Small Business Innovation Research (SBIR) funding to Troy, New York-based Ceralink Inc., a leader in the development of microwave processing technologies, to demonstrate a microwave system that could heat lunar soil to over 2,000 ˚F, temperatures high enough to solidify the surface. The company performed demonstrations using microwave technology, which could be incorporated into a roving lunar system, to heat the surface of a large bed of 8-inch deep simulated lunar soil.\n                       “When you heat the dust, it densifies or melts, becoming glassy and hard,” says Holly Shulman, president and CTO of Ceralink. “The technology could potentially be used to make miles of road on the Moon.” \n                      The technique employed through the SBIR applied microwave heat only to the surface of a material rather than an entire object. In addition to demonstrating this new approach, Ceralink also examined the feasibility of using computer modeling software to simulate microwave heating on a larger scale. \n                       As part of the SBIR, Ceralink teamed with Rensselaer Polytechnic Institute (RPI) and Gerling Applied Engineering to investigate and refine the computer modeling technology. This opportunity allowed the team to test the modeling program against an experiment. “By the end of the project, the model was at the point where it was matching up very well with what we were doing in the lab,” says Shawn Allan, Ceralink’s principal investigator on the project. “We had experiments and also a computer model that was backing up our experiments.” \n                       As a result, the team advanced a computer modeling capability that is now incorporated into Ceralink’s commercial services. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through an SBIR with Kennedy Space Center, Ceralink Inc. demonstrated a microwave system that could heat lunar soil enough to solidify it. The images above show simulated lunar soil before, during, and after Ceralink’s microwave heating. As a result of the SBIR, Ceralink refined a computer modeling program that is now offered as part of Ceralink’s commercial services.\n                        \n                      \n                      Ceralink specializes in microwaves, materials, processing, and design, providing microwave technology for research and manufacturing of ceramic materials, glass, metals, and polymers. The company’s microwave testing center boasts a range of heating equipment for a variety of processes, and when customers are interested in exploring microwave heating, Ceralink performs the tests in its lab. “The customer might be interested in energy savings, or running their process faster, or looking to see if they can get better properties by using microwave,” says Allan. \n                      Thanks to the NASA SBIR, the company is now using the resulting computer modeling technology to predict how materials like ceramics, metals, and glass behave with microwave heat. The new capability is like having an extra tool, says Allan. “We can do the experimental work, and we can also model what we are doing. That’s an ability for us that we didn’t really have before the NASA project.” \n                      The program allows Ceralink to take what is learned from a process developed in the lab for a small microwave furnace and apply the information to simulate how the same process would work in a much larger furnace. The company simply inputs the material properties, and the model runs the specific configuration, including the amount of microwave power that would be required on a larger level. “It makes us better prepared to help our customers scale up microwave heating for manufacturing,” says Allan. \n                      Ceralink is currently using the NASA-enhanced program for a U.S. Department of Energy project to design and test microwave technology for cracking hydrocarbons like ethane and turning it into ethylene for making plastics like polyethylene and polyester. “The process takes long chains of hydrocarbons and breaks them down to make other things like ethylene gas. A microwave is being used to crack it down as an energy-saving method,” says Shulman.\n                      The model has applicability for other Ceralink customers as well. For example, the company recently built \n                        a system for making specialty carbon foam for composites tooling for aircraft, spacecraft, and automobiles. \n                        The process required the materials to be heated to over 1,800 ˚F, and with conventional heating methods, it took 1 week to fire the material. With a small system developed in Ceralink’s lab, the firing was complete in less than a day. Together with other companies, Ceralink built a successful larger system, but, as Allan says, “If we had the modeling tool at the time, it would have helped to simplify the design and building of the system.” \n                      Allan also envisions use for the modeling program for tape cast machine applications, which move materials on a belt through a microwave; for alumina substrates for electronics and computers; zirconia for solid oxide fuel cells; and other electronics ceramic materials that go into capacitors and resistors, fuel cell materials, and battery materials.\n                      As the new tool impacts Ceralink’s current innovations, it has the potential to impact NASA’s future developments. In 2011, the company began working on an SBIR to apply microwave technology for curing epoxy composites for aircraft, helicopters, and spacecraft. “We are currently developing it in our lab on a small scale, but I’m optimistic,” says Allan. “If we proceed in the development, the model will be very helpful.”\n                    \n                    \n                  \n                \n              \n              \n            \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          When the fender of a lunar rover suffered damage, astronauts on Apollo 17 repaired it with maps, clamps, and duct tape. Without a fender, the rover kicked up a plume of abrasive lunar dust that stuck to the astronauts and their equipment.\n                        \n                      \n                      During the Apollo Program, astronauts on the Moon encountered a small menace that created big problems: lunar dust. Similar to how tiny bits of Styrofoam behave on Earth—adhering to anything they touch—lunar dust sticks to spacesuits, spacecraft, tools, and equipment, and is extremely difficult to remove. The clingy nature of the substance is partly due to its electrostatic charge but is also due to its physical characteristics: The sharp, irregularly shaped grains have edges like burrs and feel like abrasive talcum powder to the touch. \n                      Not only a nuisance, Moon dust is also a potential health and safety risk. Because it is often laden with ultraviolet radiation and high iron content, it can be detrimental if it gets into the eyes or lungs. In fact, some of the particles are so small that the human body does not even detect them in order to expel them. On the Apollo missions, equipment covered with the dark-colored Moon dust suffered from the absorption of sunlight and tended to overheat. \n                       NASA has investigated tools and techniques to manage the sticky stuff, including magnets, vacuums, and shields. In 2009, Kennedy Space Center collaborated with a small business to investigate a method to harden the Moon’s surface—in a sense, to “pave” the surface—so astronauts and robots could land, drive, and work without disrupting and scattering the material. \n                      Partnership\n                      Kennedy awarded Small Business Innovation Research (SBIR) funding to Troy, New York-based Ceralink Inc., a leader in the development of microwave processing technologies, to demonstrate a microwave system that could heat lunar soil to over 2,000 ˚F, temperatures high enough to solidify the surface. The company performed demonstrations using microwave technology, which could be incorporated into a roving lunar system, to heat the surface of a large bed of 8-inch deep simulated lunar soil.\n                       “When you heat the dust, it densifies or melts, becoming glassy and hard,” says Holly Shulman, president and CTO of Ceralink. “The technology could potentially be used to make miles of road on the Moon.” \n                      The technique employed through the SBIR applied microwave heat only to the surface of a material rather than an entire object. In addition to demonstrating this new approach, Ceralink also examined the feasibility of using computer modeling software to simulate microwave heating on a larger scale. \n                       As part of the SBIR, Ceralink teamed with Rensselaer Polytechnic Institute (RPI) and Gerling Applied Engineering to investigate and refine the computer modeling technology. This opportunity allowed the team to test the modeling program against an experiment. “By the end of the project, the model was at the point where it was matching up very well with what we were doing in the lab,” says Shawn Allan, Ceralink’s principal investigator on the project. “We had experiments and also a computer model that was backing up our experiments.” \n                       As a result, the team advanced a computer modeling capability that is now incorporated into Ceralink’s commercial services. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through an SBIR with Kennedy Space Center, Ceralink Inc. demonstrated a microwave system that could heat lunar soil enough to solidify it. The images above show simulated lunar soil before, during, and after Ceralink’s microwave heating. As a result of the SBIR, Ceralink refined a computer modeling program that is now offered as part of Ceralink’s commercial services.\n                        \n                      \n                      Ceralink specializes in microwaves, materials, processing, and design, providing microwave technology for research and manufacturing of ceramic materials, glass, metals, and polymers. The company’s microwave testing center boasts a range of heating equipment for a variety of processes, and when customers are interested in exploring microwave heating, Ceralink performs the tests in its lab. “The customer might be interested in energy savings, or running their process faster, or looking to see if they can get better properties by using microwave,” says Allan. \n                      Thanks to the NASA SBIR, the company is now using the resulting computer modeling technology to predict how materials like ceramics, metals, and glass behave with microwave heat. The new capability is like having an extra tool, says Allan. “We can do the experimental work, and we can also model what we are doing. That’s an ability for us that we didn’t really have before the NASA project.” \n                      The program allows Ceralink to take what is learned from a process developed in the lab for a small microwave furnace and apply the information to simulate how the same process would work in a much larger furnace. The company simply inputs the material properties, and the model runs the specific configuration, including the amount of microwave power that would be required on a larger level. “It makes us better prepared to help our customers scale up microwave heating for manufacturing,” says Allan. \n                      Ceralink is currently using the NASA-enhanced program for a U.S. Department of Energy project to design and test microwave technology for cracking hydrocarbons like ethane and turning it into ethylene for making plastics like polyethylene and polyester. “The process takes long chains of hydrocarbons and breaks them down to make other things like ethylene gas. A microwave is being used to crack it down as an energy-saving method,” says Shulman.\n                      The model has applicability for other Ceralink customers as well. For example, the company recently built \n                        a system for making specialty carbon foam for composites tooling for aircraft, spacecraft, and automobiles. \n                        The process required the materials to be heated to over 1,800 ˚F, and with conventional heating methods, it took 1 week to fire the material. With a small system developed in Ceralink’s lab, the firing was complete in less than a day. Together with other companies, Ceralink built a successful larger system, but, as Allan says, “If we had the modeling tool at the time, it would have helped to simplify the design and building of the system.” \n                      Allan also envisions use for the modeling program for tape cast machine applications, which move materials on a belt through a microwave; for alumina substrates for electronics and computers; zirconia for solid oxide fuel cells; and other electronics ceramic materials that go into capacitors and resistors, fuel cell materials, and battery materials.\n                      As the new tool impacts Ceralink’s current innovations, it has the potential to impact NASA’s future developments. In 2011, the company began working on an SBIR to apply microwave technology for curing epoxy composites for aircraft, helicopters, and spacecraft. “We are currently developing it in our lab on a small scale, but I’m optimistic,” says Allan. “If we proceed in the development, the model will be very helpful.”\n                    \n                    \n                  \n                \n              \n              \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          When the fender of a lunar rover suffered damage, astronauts on Apollo 17 repaired it with maps, clamps, and duct tape. Without a fender, the rover kicked up a plume of abrasive lunar dust that stuck to the astronauts and their equipment.\n                        \n                      \n                      During the Apollo Program, astronauts on the Moon encountered a small menace that created big problems: lunar dust. Similar to how tiny bits of Styrofoam behave on Earth—adhering to anything they touch—lunar dust sticks to spacesuits, spacecraft, tools, and equipment, and is extremely difficult to remove. The clingy nature of the substance is partly due to its electrostatic charge but is also due to its physical characteristics: The sharp, irregularly shaped grains have edges like burrs and feel like abrasive talcum powder to the touch. \n                      Not only a nuisance, Moon dust is also a potential health and safety risk. Because it is often laden with ultraviolet radiation and high iron content, it can be detrimental if it gets into the eyes or lungs. In fact, some of the particles are so small that the human body does not even detect them in order to expel them. On the Apollo missions, equipment covered with the dark-colored Moon dust suffered from the absorption of sunlight and tended to overheat. \n                       NASA has investigated tools and techniques to manage the sticky stuff, including magnets, vacuums, and shields. In 2009, Kennedy Space Center collaborated with a small business to investigate a method to harden the Moon’s surface—in a sense, to “pave” the surface—so astronauts and robots could land, drive, and work without disrupting and scattering the material. \n                      Partnership\n                      Kennedy awarded Small Business Innovation Research (SBIR) funding to Troy, New York-based Ceralink Inc., a leader in the development of microwave processing technologies, to demonstrate a microwave system that could heat lunar soil to over 2,000 ˚F, temperatures high enough to solidify the surface. The company performed demonstrations using microwave technology, which could be incorporated into a roving lunar system, to heat the surface of a large bed of 8-inch deep simulated lunar soil.\n                       “When you heat the dust, it densifies or melts, becoming glassy and hard,” says Holly Shulman, president and CTO of Ceralink. “The technology could potentially be used to make miles of road on the Moon.” \n                      The technique employed through the SBIR applied microwave heat only to the surface of a material rather than an entire object. In addition to demonstrating this new approach, Ceralink also examined the feasibility of using computer modeling software to simulate microwave heating on a larger scale. \n                       As part of the SBIR, Ceralink teamed with Rensselaer Polytechnic Institute (RPI) and Gerling Applied Engineering to investigate and refine the computer modeling technology. This opportunity allowed the team to test the modeling program against an experiment. “By the end of the project, the model was at the point where it was matching up very well with what we were doing in the lab,” says Shawn Allan, Ceralink’s principal investigator on the project. “We had experiments and also a computer model that was backing up our experiments.” \n                       As a result, the team advanced a computer modeling capability that is now incorporated into Ceralink’s commercial services. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through an SBIR with Kennedy Space Center, Ceralink Inc. demonstrated a microwave system that could heat lunar soil enough to solidify it. The images above show simulated lunar soil before, during, and after Ceralink’s microwave heating. As a result of the SBIR, Ceralink refined a computer modeling program that is now offered as part of Ceralink’s commercial services.\n                        \n                      \n                      Ceralink specializes in microwaves, materials, processing, and design, providing microwave technology for research and manufacturing of ceramic materials, glass, metals, and polymers. The company’s microwave testing center boasts a range of heating equipment for a variety of processes, and when customers are interested in exploring microwave heating, Ceralink performs the tests in its lab. “The customer might be interested in energy savings, or running their process faster, or looking to see if they can get better properties by using microwave,” says Allan. \n                      Thanks to the NASA SBIR, the company is now using the resulting computer modeling technology to predict how materials like ceramics, metals, and glass behave with microwave heat. The new capability is like having an extra tool, says Allan. “We can do the experimental work, and we can also model what we are doing. That’s an ability for us that we didn’t really have before the NASA project.” \n                      The program allows Ceralink to take what is learned from a process developed in the lab for a small microwave furnace and apply the information to simulate how the same process would work in a much larger furnace. The company simply inputs the material properties, and the model runs the specific configuration, including the amount of microwave power that would be required on a larger level. “It makes us better prepared to help our customers scale up microwave heating for manufacturing,” says Allan. \n                      Ceralink is currently using the NASA-enhanced program for a U.S. Department of Energy project to design and test microwave technology for cracking hydrocarbons like ethane and turning it into ethylene for making plastics like polyethylene and polyester. “The process takes long chains of hydrocarbons and breaks them down to make other things like ethylene gas. A microwave is being used to crack it down as an energy-saving method,” says Shulman.\n                      The model has applicability for other Ceralink customers as well. For example, the company recently built \n                        a system for making specialty carbon foam for composites tooling for aircraft, spacecraft, and automobiles. \n                        The process required the materials to be heated to over 1,800 ˚F, and with conventional heating methods, it took 1 week to fire the material. With a small system developed in Ceralink’s lab, the firing was complete in less than a day. Together with other companies, Ceralink built a successful larger system, but, as Allan says, “If we had the modeling tool at the time, it would have helped to simplify the design and building of the system.” \n                      Allan also envisions use for the modeling program for tape cast machine applications, which move materials on a belt through a microwave; for alumina substrates for electronics and computers; zirconia for solid oxide fuel cells; and other electronics ceramic materials that go into capacitors and resistors, fuel cell materials, and battery materials.\n                      As the new tool impacts Ceralink’s current innovations, it has the potential to impact NASA’s future developments. In 2011, the company began working on an SBIR to apply microwave technology for curing epoxy composites for aircraft, helicopters, and spacecraft. “We are currently developing it in our lab on a small scale, but I’m optimistic,” says Allan. “If we proceed in the development, the model will be very helpful.”\n                    \n                    \n                  \n                \n              \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          When the fender of a lunar rover suffered damage, astronauts on Apollo 17 repaired it with maps, clamps, and duct tape. Without a fender, the rover kicked up a plume of abrasive lunar dust that stuck to the astronauts and their equipment.\n                        \n                      \n                      During the Apollo Program, astronauts on the Moon encountered a small menace that created big problems: lunar dust. Similar to how tiny bits of Styrofoam behave on Earth—adhering to anything they touch—lunar dust sticks to spacesuits, spacecraft, tools, and equipment, and is extremely difficult to remove. The clingy nature of the substance is partly due to its electrostatic charge but is also due to its physical characteristics: The sharp, irregularly shaped grains have edges like burrs and feel like abrasive talcum powder to the touch. \n                      Not only a nuisance, Moon dust is also a potential health and safety risk. Because it is often laden with ultraviolet radiation and high iron content, it can be detrimental if it gets into the eyes or lungs. In fact, some of the particles are so small that the human body does not even detect them in order to expel them. On the Apollo missions, equipment covered with the dark-colored Moon dust suffered from the absorption of sunlight and tended to overheat. \n                       NASA has investigated tools and techniques to manage the sticky stuff, including magnets, vacuums, and shields. In 2009, Kennedy Space Center collaborated with a small business to investigate a method to harden the Moon’s surface—in a sense, to “pave” the surface—so astronauts and robots could land, drive, and work without disrupting and scattering the material. \n                      Partnership\n                      Kennedy awarded Small Business Innovation Research (SBIR) funding to Troy, New York-based Ceralink Inc., a leader in the development of microwave processing technologies, to demonstrate a microwave system that could heat lunar soil to over 2,000 ˚F, temperatures high enough to solidify the surface. The company performed demonstrations using microwave technology, which could be incorporated into a roving lunar system, to heat the surface of a large bed of 8-inch deep simulated lunar soil.\n                       “When you heat the dust, it densifies or melts, becoming glassy and hard,” says Holly Shulman, president and CTO of Ceralink. “The technology could potentially be used to make miles of road on the Moon.” \n                      The technique employed through the SBIR applied microwave heat only to the surface of a material rather than an entire object. In addition to demonstrating this new approach, Ceralink also examined the feasibility of using computer modeling software to simulate microwave heating on a larger scale. \n                       As part of the SBIR, Ceralink teamed with Rensselaer Polytechnic Institute (RPI) and Gerling Applied Engineering to investigate and refine the computer modeling technology. This opportunity allowed the team to test the modeling program against an experiment. “By the end of the project, the model was at the point where it was matching up very well with what we were doing in the lab,” says Shawn Allan, Ceralink’s principal investigator on the project. “We had experiments and also a computer model that was backing up our experiments.” \n                       As a result, the team advanced a computer modeling capability that is now incorporated into Ceralink’s commercial services. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through an SBIR with Kennedy Space Center, Ceralink Inc. demonstrated a microwave system that could heat lunar soil enough to solidify it. The images above show simulated lunar soil before, during, and after Ceralink’s microwave heating. As a result of the SBIR, Ceralink refined a computer modeling program that is now offered as part of Ceralink’s commercial services.\n                        \n                      \n                      Ceralink specializes in microwaves, materials, processing, and design, providing microwave technology for research and manufacturing of ceramic materials, glass, metals, and polymers. The company’s microwave testing center boasts a range of heating equipment for a variety of processes, and when customers are interested in exploring microwave heating, Ceralink performs the tests in its lab. “The customer might be interested in energy savings, or running their process faster, or looking to see if they can get better properties by using microwave,” says Allan. \n                      Thanks to the NASA SBIR, the company is now using the resulting computer modeling technology to predict how materials like ceramics, metals, and glass behave with microwave heat. The new capability is like having an extra tool, says Allan. “We can do the experimental work, and we can also model what we are doing. That’s an ability for us that we didn’t really have before the NASA project.” \n                      The program allows Ceralink to take what is learned from a process developed in the lab for a small microwave furnace and apply the information to simulate how the same process would work in a much larger furnace. The company simply inputs the material properties, and the model runs the specific configuration, including the amount of microwave power that would be required on a larger level. “It makes us better prepared to help our customers scale up microwave heating for manufacturing,” says Allan. \n                      Ceralink is currently using the NASA-enhanced program for a U.S. Department of Energy project to design and test microwave technology for cracking hydrocarbons like ethane and turning it into ethylene for making plastics like polyethylene and polyester. “The process takes long chains of hydrocarbons and breaks them down to make other things like ethylene gas. A microwave is being used to crack it down as an energy-saving method,” says Shulman.\n                      The model has applicability for other Ceralink customers as well. For example, the company recently built \n                        a system for making specialty carbon foam for composites tooling for aircraft, spacecraft, and automobiles. \n                        The process required the materials to be heated to over 1,800 ˚F, and with conventional heating methods, it took 1 week to fire the material. With a small system developed in Ceralink’s lab, the firing was complete in less than a day. Together with other companies, Ceralink built a successful larger system, but, as Allan says, “If we had the modeling tool at the time, it would have helped to simplify the design and building of the system.” \n                      Allan also envisions use for the modeling program for tape cast machine applications, which move materials on a belt through a microwave; for alumina substrates for electronics and computers; zirconia for solid oxide fuel cells; and other electronics ceramic materials that go into capacitors and resistors, fuel cell materials, and battery materials.\n                      As the new tool impacts Ceralink’s current innovations, it has the potential to impact NASA’s future developments. In 2011, the company began working on an SBIR to apply microwave technology for curing epoxy composites for aircraft, helicopters, and spacecraft. “We are currently developing it in our lab on a small scale, but I’m optimistic,” says Allan. “If we proceed in the development, the model will be very helpful.”\n                    \n                    \n                  \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          When the fender of a lunar rover suffered damage, astronauts on Apollo 17 repaired it with maps, clamps, and duct tape. Without a fender, the rover kicked up a plume of abrasive lunar dust that stuck to the astronauts and their equipment.\n                        \n                      \n                      During the Apollo Program, astronauts on the Moon encountered a small menace that created big problems: lunar dust. Similar to how tiny bits of Styrofoam behave on Earth—adhering to anything they touch—lunar dust sticks to spacesuits, spacecraft, tools, and equipment, and is extremely difficult to remove. The clingy nature of the substance is partly due to its electrostatic charge but is also due to its physical characteristics: The sharp, irregularly shaped grains have edges like burrs and feel like abrasive talcum powder to the touch. \n                      Not only a nuisance, Moon dust is also a potential health and safety risk. Because it is often laden with ultraviolet radiation and high iron content, it can be detrimental if it gets into the eyes or lungs. In fact, some of the particles are so small that the human body does not even detect them in order to expel them. On the Apollo missions, equipment covered with the dark-colored Moon dust suffered from the absorption of sunlight and tended to overheat. \n                       NASA has investigated tools and techniques to manage the sticky stuff, including magnets, vacuums, and shields. In 2009, Kennedy Space Center collaborated with a small business to investigate a method to harden the Moon’s surface—in a sense, to “pave” the surface—so astronauts and robots could land, drive, and work without disrupting and scattering the material. \n                      Partnership\n                      Kennedy awarded Small Business Innovation Research (SBIR) funding to Troy, New York-based Ceralink Inc., a leader in the development of microwave processing technologies, to demonstrate a microwave system that could heat lunar soil to over 2,000 ˚F, temperatures high enough to solidify the surface. The company performed demonstrations using microwave technology, which could be incorporated into a roving lunar system, to heat the surface of a large bed of 8-inch deep simulated lunar soil.\n                       “When you heat the dust, it densifies or melts, becoming glassy and hard,” says Holly Shulman, president and CTO of Ceralink. “The technology could potentially be used to make miles of road on the Moon.” \n                      The technique employed through the SBIR applied microwave heat only to the surface of a material rather than an entire object. In addition to demonstrating this new approach, Ceralink also examined the feasibility of using computer modeling software to simulate microwave heating on a larger scale. \n                       As part of the SBIR, Ceralink teamed with Rensselaer Polytechnic Institute (RPI) and Gerling Applied Engineering to investigate and refine the computer modeling technology. This opportunity allowed the team to test the modeling program against an experiment. “By the end of the project, the model was at the point where it was matching up very well with what we were doing in the lab,” says Shawn Allan, Ceralink’s principal investigator on the project. “We had experiments and also a computer model that was backing up our experiments.” \n                       As a result, the team advanced a computer modeling capability that is now incorporated into Ceralink’s commercial services. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through an SBIR with Kennedy Space Center, Ceralink Inc. demonstrated a microwave system that could heat lunar soil enough to solidify it. The images above show simulated lunar soil before, during, and after Ceralink’s microwave heating. As a result of the SBIR, Ceralink refined a computer modeling program that is now offered as part of Ceralink’s commercial services.\n                        \n                      \n                      Ceralink specializes in microwaves, materials, processing, and design, providing microwave technology for research and manufacturing of ceramic materials, glass, metals, and polymers. The company’s microwave testing center boasts a range of heating equipment for a variety of processes, and when customers are interested in exploring microwave heating, Ceralink performs the tests in its lab. “The customer might be interested in energy savings, or running their process faster, or looking to see if they can get better properties by using microwave,” says Allan. \n                      Thanks to the NASA SBIR, the company is now using the resulting computer modeling technology to predict how materials like ceramics, metals, and glass behave with microwave heat. The new capability is like having an extra tool, says Allan. “We can do the experimental work, and we can also model what we are doing. That’s an ability for us that we didn’t really have before the NASA project.” \n                      The program allows Ceralink to take what is learned from a process developed in the lab for a small microwave furnace and apply the information to simulate how the same process would work in a much larger furnace. The company simply inputs the material properties, and the model runs the specific configuration, including the amount of microwave power that would be required on a larger level. “It makes us better prepared to help our customers scale up microwave heating for manufacturing,” says Allan. \n                      Ceralink is currently using the NASA-enhanced program for a U.S. Department of Energy project to design and test microwave technology for cracking hydrocarbons like ethane and turning it into ethylene for making plastics like polyethylene and polyester. “The process takes long chains of hydrocarbons and breaks them down to make other things like ethylene gas. A microwave is being used to crack it down as an energy-saving method,” says Shulman.\n                      The model has applicability for other Ceralink customers as well. For example, the company recently built \n                        a system for making specialty carbon foam for composites tooling for aircraft, spacecraft, and automobiles. \n                        The process required the materials to be heated to over 1,800 ˚F, and with conventional heating methods, it took 1 week to fire the material. With a small system developed in Ceralink’s lab, the firing was complete in less than a day. Together with other companies, Ceralink built a successful larger system, but, as Allan says, “If we had the modeling tool at the time, it would have helped to simplify the design and building of the system.” \n                      Allan also envisions use for the modeling program for tape cast machine applications, which move materials on a belt through a microwave; for alumina substrates for electronics and computers; zirconia for solid oxide fuel cells; and other electronics ceramic materials that go into capacitors and resistors, fuel cell materials, and battery materials.\n                      As the new tool impacts Ceralink’s current innovations, it has the potential to impact NASA’s future developments. In 2011, the company began working on an SBIR to apply microwave technology for curing epoxy composites for aircraft, helicopters, and spacecraft. “We are currently developing it in our lab on a small scale, but I’m optimistic,” says Allan. “If we proceed in the development, the model will be very helpful.”\n                    \n                    \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          When the fender of a lunar rover suffered damage, astronauts on Apollo 17 repaired it with maps, clamps, and duct tape. Without a fender, the rover kicked up a plume of abrasive lunar dust that stuck to the astronauts and their equipment.\n                        \n                      \n                      During the Apollo Program, astronauts on the Moon encountered a small menace that created big problems: lunar dust. Similar to how tiny bits of Styrofoam behave on Earth—adhering to anything they touch—lunar dust sticks to spacesuits, spacecraft, tools, and equipment, and is extremely difficult to remove. The clingy nature of the substance is partly due to its electrostatic charge but is also due to its physical characteristics: The sharp, irregularly shaped grains have edges like burrs and feel like abrasive talcum powder to the touch. \n                      Not only a nuisance, Moon dust is also a potential health and safety risk. Because it is often laden with ultraviolet radiation and high iron content, it can be detrimental if it gets into the eyes or lungs. In fact, some of the particles are so small that the human body does not even detect them in order to expel them. On the Apollo missions, equipment covered with the dark-colored Moon dust suffered from the absorption of sunlight and tended to overheat. \n                       NASA has investigated tools and techniques to manage the sticky stuff, including magnets, vacuums, and shields. In 2009, Kennedy Space Center collaborated with a small business to investigate a method to harden the Moon’s surface—in a sense, to “pave” the surface—so astronauts and robots could land, drive, and work without disrupting and scattering the material. \n                      Partnership\n                      Kennedy awarded Small Business Innovation Research (SBIR) funding to Troy, New York-based Ceralink Inc., a leader in the development of microwave processing technologies, to demonstrate a microwave system that could heat lunar soil to over 2,000 ˚F, temperatures high enough to solidify the surface. The company performed demonstrations using microwave technology, which could be incorporated into a roving lunar system, to heat the surface of a large bed of 8-inch deep simulated lunar soil.\n                       “When you heat the dust, it densifies or melts, becoming glassy and hard,” says Holly Shulman, president and CTO of Ceralink. “The technology could potentially be used to make miles of road on the Moon.” \n                      The technique employed through the SBIR applied microwave heat only to the surface of a material rather than an entire object. In addition to demonstrating this new approach, Ceralink also examined the feasibility of using computer modeling software to simulate microwave heating on a larger scale. \n                       As part of the SBIR, Ceralink teamed with Rensselaer Polytechnic Institute (RPI) and Gerling Applied Engineering to investigate and refine the computer modeling technology. This opportunity allowed the team to test the modeling program against an experiment. “By the end of the project, the model was at the point where it was matching up very well with what we were doing in the lab,” says Shawn Allan, Ceralink’s principal investigator on the project. “We had experiments and also a computer model that was backing up our experiments.” \n                       As a result, the team advanced a computer modeling capability that is now incorporated into Ceralink’s commercial services. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through an SBIR with Kennedy Space Center, Ceralink Inc. demonstrated a microwave system that could heat lunar soil enough to solidify it. The images above show simulated lunar soil before, during, and after Ceralink’s microwave heating. As a result of the SBIR, Ceralink refined a computer modeling program that is now offered as part of Ceralink’s commercial services.\n                        \n                      \n                      Ceralink specializes in microwaves, materials, processing, and design, providing microwave technology for research and manufacturing of ceramic materials, glass, metals, and polymers. The company’s microwave testing center boasts a range of heating equipment for a variety of processes, and when customers are interested in exploring microwave heating, Ceralink performs the tests in its lab. “The customer might be interested in energy savings, or running their process faster, or looking to see if they can get better properties by using microwave,” says Allan. \n                      Thanks to the NASA SBIR, the company is now using the resulting computer modeling technology to predict how materials like ceramics, metals, and glass behave with microwave heat. The new capability is like having an extra tool, says Allan. “We can do the experimental work, and we can also model what we are doing. That’s an ability for us that we didn’t really have before the NASA project.” \n                      The program allows Ceralink to take what is learned from a process developed in the lab for a small microwave furnace and apply the information to simulate how the same process would work in a much larger furnace. The company simply inputs the material properties, and the model runs the specific configuration, including the amount of microwave power that would be required on a larger level. “It makes us better prepared to help our customers scale up microwave heating for manufacturing,” says Allan. \n                      Ceralink is currently using the NASA-enhanced program for a U.S. Department of Energy project to design and test microwave technology for cracking hydrocarbons like ethane and turning it into ethylene for making plastics like polyethylene and polyester. “The process takes long chains of hydrocarbons and breaks them down to make other things like ethylene gas. A microwave is being used to crack it down as an energy-saving method,” says Shulman.\n                      The model has applicability for other Ceralink customers as well. For example, the company recently built \n                        a system for making specialty carbon foam for composites tooling for aircraft, spacecraft, and automobiles. \n                        The process required the materials to be heated to over 1,800 ˚F, and with conventional heating methods, it took 1 week to fire the material. With a small system developed in Ceralink’s lab, the firing was complete in less than a day. Together with other companies, Ceralink built a successful larger system, but, as Allan says, “If we had the modeling tool at the time, it would have helped to simplify the design and building of the system.” \n                      Allan also envisions use for the modeling program for tape cast machine applications, which move materials on a belt through a microwave; for alumina substrates for electronics and computers; zirconia for solid oxide fuel cells; and other electronics ceramic materials that go into capacitors and resistors, fuel cell materials, and battery materials.\n                      As the new tool impacts Ceralink’s current innovations, it has the potential to impact NASA’s future developments. In 2011, the company began working on an SBIR to apply microwave technology for curing epoxy composites for aircraft, helicopters, and spacecraft. “We are currently developing it in our lab on a small scale, but I’m optimistic,” says Allan. “If we proceed in the development, the model will be very helpful.”\n                    \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          When the fender of a lunar rover suffered damage, astronauts on Apollo 17 repaired it with maps, clamps, and duct tape. Without a fender, the rover kicked up a plume of abrasive lunar dust that stuck to the astronauts and their equipment.\n                        \n                      \n                      During the Apollo Program, astronauts on the Moon encountered a small menace that created big problems: lunar dust. Similar to how tiny bits of Styrofoam behave on Earth—adhering to anything they touch—lunar dust sticks to spacesuits, spacecraft, tools, and equipment, and is extremely difficult to remove. The clingy nature of the substance is partly due to its electrostatic charge but is also due to its physical characteristics: The sharp, irregularly shaped grains have edges like burrs and feel like abrasive talcum powder to the touch. \n                      Not only a nuisance, Moon dust is also a potential health and safety risk. Because it is often laden with ultraviolet radiation and high iron content, it can be detrimental if it gets into the eyes or lungs. In fact, some of the particles are so small that the human body does not even detect them in order to expel them. On the Apollo missions, equipment covered with the dark-colored Moon dust suffered from the absorption of sunlight and tended to overheat. \n                       NASA has investigated tools and techniques to manage the sticky stuff, including magnets, vacuums, and shields. In 2009, Kennedy Space Center collaborated with a small business to investigate a method to harden the Moon’s surface—in a sense, to “pave” the surface—so astronauts and robots could land, drive, and work without disrupting and scattering the material. \n                      Partnership\n                      Kennedy awarded Small Business Innovation Research (SBIR) funding to Troy, New York-based Ceralink Inc., a leader in the development of microwave processing technologies, to demonstrate a microwave system that could heat lunar soil to over 2,000 ˚F, temperatures high enough to solidify the surface. The company performed demonstrations using microwave technology, which could be incorporated into a roving lunar system, to heat the surface of a large bed of 8-inch deep simulated lunar soil.\n                       “When you heat the dust, it densifies or melts, becoming glassy and hard,” says Holly Shulman, president and CTO of Ceralink. “The technology could potentially be used to make miles of road on the Moon.” \n                      The technique employed through the SBIR applied microwave heat only to the surface of a material rather than an entire object. In addition to demonstrating this new approach, Ceralink also examined the feasibility of using computer modeling software to simulate microwave heating on a larger scale. \n                       As part of the SBIR, Ceralink teamed with Rensselaer Polytechnic Institute (RPI) and Gerling Applied Engineering to investigate and refine the computer modeling technology. This opportunity allowed the team to test the modeling program against an experiment. “By the end of the project, the model was at the point where it was matching up very well with what we were doing in the lab,” says Shawn Allan, Ceralink’s principal investigator on the project. “We had experiments and also a computer model that was backing up our experiments.” \n                       As a result, the team advanced a computer modeling capability that is now incorporated into Ceralink’s commercial services. \n                      Benefits\n                      \n                        \n                        \n                          \n                        \n                        \n                          Through an SBIR with Kennedy Space Center, Ceralink Inc. demonstrated a microwave system that could heat lunar soil enough to solidify it. The images above show simulated lunar soil before, during, and after Ceralink’s microwave heating. As a result of the SBIR, Ceralink refined a computer modeling program that is now offered as part of Ceralink’s commercial services.\n                        \n                      \n                      Ceralink specializes in microwaves, materials, processing, and design, providing microwave technology for research and manufacturing of ceramic materials, glass, metals, and polymers. The company’s microwave testing center boasts a range of heating equipment for a variety of processes, and when customers are interested in exploring microwave heating, Ceralink performs the tests in its lab. “The customer might be interested in energy savings, or running their process faster, or looking to see if they can get better properties by using microwave,” says Allan. \n                      Thanks to the NASA SBIR, the company is now using the resulting computer modeling technology to predict how materials like ceramics, metals, and glass behave with microwave heat. The new capability is like having an extra tool, says Allan. “We can do the experimental work, and we can also model what we are doing. That’s an ability for us that we didn’t really have before the NASA project.” \n                      The program allows Ceralink to take what is learned from a process developed in the lab for a small microwave furnace and apply the information to simulate how the same process would work in a much larger furnace. The company simply inputs the material properties, and the model runs the specific configuration, including the amount of microwave power that would be required on a larger level. “It makes us better prepared to help our customers scale up microwave heating for manufacturing,” says Allan. \n                      Ceralink is currently using the NASA-enhanced program for a U.S. Department of Energy project to design and test microwave technology for cracking hydrocarbons like ethane and turning it into ethylene for making plastics like polyethylene and polyester. “The process takes long chains of hydrocarbons and breaks them down to make other things like ethylene gas. A microwave is being used to crack it down as an energy-saving method,” says Shulman.\n                      The model has applicability for other Ceralink customers as well. For example, the company recently built \n                        a system for making specialty carbon foam for composites tooling for aircraft, spacecraft, and automobiles. \n                        The process required the materials to be heated to over 1,800 ˚F, and with conventional heating methods, it took 1 week to fire the material. With a small system developed in Ceralink’s lab, the firing was complete in less than a day. Together with other companies, Ceralink built a successful larger system, but, as Allan says, “If we had the modeling tool at the time, it would have helped to simplify the design and building of the system.” \n                      Allan also envisions use for the modeling program for tape cast machine applications, which move materials on a belt through a microwave; for alumina substrates for electronics and computers; zirconia for solid oxide fuel cells; and other electronics ceramic materials that go into capacitors and resistors, fuel cell materials, and battery materials.\n                      As the new tool impacts Ceralink’s current innovations, it has the potential to impact NASA’s future developments. In 2011, the company began working on an SBIR to apply microwave technology for curing epoxy composites for aircraft, helicopters, and spacecraft. “We are currently developing it in our lab on a small scale, but I’m optimistic,” says Allan. “If we proceed in the development, the model will be very helpful.”\n                    "},{"href":"http://spinoff.nasa.gov/Spinoff2011/ip_6.html","text":"Materials Advance Chemical Propulsion Technology","image":"http://spinoff.nasa.gov/Spinoff2011/Images/ip_6ba_opt.jpg","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      In the future, the Planetary Science Division of NASA’s Science Mission Directorate hopes to use better-performing and lower-cost propulsion systems to send rovers, probes, and observers to places like Mars, Jupiter, and Saturn. For such purposes, a new propulsion technology called the Advanced Materials Bipropellant Rocket (AMBR) was developed under NASA’s In-Space Propulsion Technology (ISPT) project, located at Glenn Research Center. As an advanced chemical propulsion system, AMBR uses nitrogen tetroxide oxidizer and hydrazine fuel to propel a spacecraft. Based on current research and development efforts, the technology shows great promise for increasing engine operation and engine lifespan, as well as lowering manufacturing costs. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The Cassini-Huygens spacecraft captured this view of Saturn in 2009. In order to send new rovers, probes, and observers to Mars, Jupiter, and Saturn, NASA is working with industry to develop propulsion technologies such as the Advanced Material Bipropellant Rocket (AMBR). \n                        \n                      \n                      In developing AMBR, ISPT has several goals: to decrease the time it takes for a spacecraft to travel to its destination, reduce the cost of making the propulsion system, and lessen the weight of the propulsion system. If goals like these are met, it could result in greater capabilities for in-space science investigations. For example, if the amount (and weight) of propellant required on a spacecraft is reduced, more scientific instruments (and weight) could be added to the spacecraft. \n                      To achieve AMBR’s maximum potential performance, the engine needed to be capable of operating at extremely high temperatures and pressure. To this end, ISPT required engine chambers made of iridium-coated rhenium (strong, high-temperature metallic elements) that allowed operation at temperatures close to 4,000 °F. In addition, ISPT needed an advanced manufacturing technique for better coating methods to increase the strength of the engine chamber without increasing the costs of fabricating the chamber.\n                      Partnership\n                      In 2006, NASA’s ISTP project partnered with NASA’s Marshall Space Flight Center and Aerojet through a NASA Research Announcement (NRA) to increase AMBR’s performance efficiency and to lower the fabrication cost for the iridium-coated rhenium combustion chamber. Aerojet subcontracted a company in Huntsville, Alabama, called Plasma Processes Inc. (PPI) to modify a state-of-the-art engine design so the chamber wall materials could operate at very high temperatures. \n                      While Aerojet defined the design details of the chamber configuration and worked with PPI to ensure the processes were in place to fabricate the chamber, the actual fabrication of the chamber was completed by PPI, using a process called EL-Form. Results from performance testing of the technology in 2008 and 2009 showed the propellant efficiency was higher than ever achieved for the hydrazine and nitrogen tetroxide oxidizer propellant combination. The iridium-coated rhenium chamber produced under the NRA set a hydrazine record for performance efficiency, which will mean a reduction in the propellant required to perform spacecraft maneuvers. It also had a 30-percent improvement on production costs. \n                      “EL-Form allows us to deposit a thicker iridium layer for improved oxidation protection. It also allows us to produce the rhenium layer with better consistency and properties than what they had been doing in the past. The iridium rhenium chambers were in use already, but the El-Form process allows us to be able to improve those materials—affecting the quality and the cost,” says Anatoliy Shchetkovskiy, EL-Form director for PPI.\n                      The iridium-coated rhenium combustion chamber fabricated using the EL-Form process addressed the needs of the ISTP project, as well as validated PPI’s process for making high-temperature materials for other applications. \n                      Benefits\n                      Compared to other coating processes, PPI’s EL-Form, or electroforming, process can reduce fabrication costs for iridium-coated rhenium material systems. Compared to traditional chemical vapor deposition processing techniques, the EL-Form process can produce thicker iridium layers for improved oxidation resistance, as well as perform multi-component processing. \n                      \n                        \n                        \n                          \n                        \n                        \n                          When NASA, Aerojet, and Plasma Processes Inc. tested AMBR, the results showed the chamber wall materials could withstand temperatures up to and exceeding 4,000 ˚F. The same materials are now being used for high-temperature applications such as small thrust chambers for satellites. \n                        \n                      \n                      PPI is the only supplier of the EL-Form process for electrodeposition of rhenium and other refractory metal and platinum group material coatings to graphite and metallic substrates. As demonstrated through testing with NASA, the EL-Form process makes components more capable of surviving high-pressure and high-temperature propulsion environments, with the resulting material having the capability to withstand steady-state temperatures up to and exceeding 4,000 °F. After validating the EL-Form process to fabricate high-temperature materials for NASA, PPI now uses the technique to make the same materials for other high temperature applications. \n                      For example, PPI used EL-Form to create a coating with the same metal combination as the one used in the AMBR chamber for small thrust chambers for satellites. “The customer used it for advanced propellant, and the in-flight tests show it was successful,” says Shchetkovskiy. \n                      In addition, the NASA-tested materials created by EL-Form have space propulsion rocket applications relevant to the commercial aerospace community, including Boeing, Honeywell, Alliant Techsystems Inc., and SpaceX. The U.S. Department of Defense, Navy, Air Force, and others are also using the high performance, low-cost iridium-coated rhenium material. \n                      As the development of AMBR continues, PPI and Aerojet continue to work with Glenn through a Small Business Innovation Research (SBIR) contract to improve the room-temperature yield strength of the iridium-lined rhenium combustion chambers. Such innovation could mean even more benefits for propulsion technology processes and materials in the future.\n                      EL-Form™ is a trademark of Plasma Processes Inc. \n                    \n                    \n                  \n                \n              \n              \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      In the future, the Planetary Science Division of NASA’s Science Mission Directorate hopes to use better-performing and lower-cost propulsion systems to send rovers, probes, and observers to places like Mars, Jupiter, and Saturn. For such purposes, a new propulsion technology called the Advanced Materials Bipropellant Rocket (AMBR) was developed under NASA’s In-Space Propulsion Technology (ISPT) project, located at Glenn Research Center. As an advanced chemical propulsion system, AMBR uses nitrogen tetroxide oxidizer and hydrazine fuel to propel a spacecraft. Based on current research and development efforts, the technology shows great promise for increasing engine operation and engine lifespan, as well as lowering manufacturing costs. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The Cassini-Huygens spacecraft captured this view of Saturn in 2009. In order to send new rovers, probes, and observers to Mars, Jupiter, and Saturn, NASA is working with industry to develop propulsion technologies such as the Advanced Material Bipropellant Rocket (AMBR). \n                        \n                      \n                      In developing AMBR, ISPT has several goals: to decrease the time it takes for a spacecraft to travel to its destination, reduce the cost of making the propulsion system, and lessen the weight of the propulsion system. If goals like these are met, it could result in greater capabilities for in-space science investigations. For example, if the amount (and weight) of propellant required on a spacecraft is reduced, more scientific instruments (and weight) could be added to the spacecraft. \n                      To achieve AMBR’s maximum potential performance, the engine needed to be capable of operating at extremely high temperatures and pressure. To this end, ISPT required engine chambers made of iridium-coated rhenium (strong, high-temperature metallic elements) that allowed operation at temperatures close to 4,000 °F. In addition, ISPT needed an advanced manufacturing technique for better coating methods to increase the strength of the engine chamber without increasing the costs of fabricating the chamber.\n                      Partnership\n                      In 2006, NASA’s ISTP project partnered with NASA’s Marshall Space Flight Center and Aerojet through a NASA Research Announcement (NRA) to increase AMBR’s performance efficiency and to lower the fabrication cost for the iridium-coated rhenium combustion chamber. Aerojet subcontracted a company in Huntsville, Alabama, called Plasma Processes Inc. (PPI) to modify a state-of-the-art engine design so the chamber wall materials could operate at very high temperatures. \n                      While Aerojet defined the design details of the chamber configuration and worked with PPI to ensure the processes were in place to fabricate the chamber, the actual fabrication of the chamber was completed by PPI, using a process called EL-Form. Results from performance testing of the technology in 2008 and 2009 showed the propellant efficiency was higher than ever achieved for the hydrazine and nitrogen tetroxide oxidizer propellant combination. The iridium-coated rhenium chamber produced under the NRA set a hydrazine record for performance efficiency, which will mean a reduction in the propellant required to perform spacecraft maneuvers. It also had a 30-percent improvement on production costs. \n                      “EL-Form allows us to deposit a thicker iridium layer for improved oxidation protection. It also allows us to produce the rhenium layer with better consistency and properties than what they had been doing in the past. The iridium rhenium chambers were in use already, but the El-Form process allows us to be able to improve those materials—affecting the quality and the cost,” says Anatoliy Shchetkovskiy, EL-Form director for PPI.\n                      The iridium-coated rhenium combustion chamber fabricated using the EL-Form process addressed the needs of the ISTP project, as well as validated PPI’s process for making high-temperature materials for other applications. \n                      Benefits\n                      Compared to other coating processes, PPI’s EL-Form, or electroforming, process can reduce fabrication costs for iridium-coated rhenium material systems. Compared to traditional chemical vapor deposition processing techniques, the EL-Form process can produce thicker iridium layers for improved oxidation resistance, as well as perform multi-component processing. \n                      \n                        \n                        \n                          \n                        \n                        \n                          When NASA, Aerojet, and Plasma Processes Inc. tested AMBR, the results showed the chamber wall materials could withstand temperatures up to and exceeding 4,000 ˚F. The same materials are now being used for high-temperature applications such as small thrust chambers for satellites. \n                        \n                      \n                      PPI is the only supplier of the EL-Form process for electrodeposition of rhenium and other refractory metal and platinum group material coatings to graphite and metallic substrates. As demonstrated through testing with NASA, the EL-Form process makes components more capable of surviving high-pressure and high-temperature propulsion environments, with the resulting material having the capability to withstand steady-state temperatures up to and exceeding 4,000 °F. After validating the EL-Form process to fabricate high-temperature materials for NASA, PPI now uses the technique to make the same materials for other high temperature applications. \n                      For example, PPI used EL-Form to create a coating with the same metal combination as the one used in the AMBR chamber for small thrust chambers for satellites. “The customer used it for advanced propellant, and the in-flight tests show it was successful,” says Shchetkovskiy. \n                      In addition, the NASA-tested materials created by EL-Form have space propulsion rocket applications relevant to the commercial aerospace community, including Boeing, Honeywell, Alliant Techsystems Inc., and SpaceX. The U.S. Department of Defense, Navy, Air Force, and others are also using the high performance, low-cost iridium-coated rhenium material. \n                      As the development of AMBR continues, PPI and Aerojet continue to work with Glenn through a Small Business Innovation Research (SBIR) contract to improve the room-temperature yield strength of the iridium-lined rhenium combustion chambers. Such innovation could mean even more benefits for propulsion technology processes and materials in the future.\n                      EL-Form™ is a trademark of Plasma Processes Inc. \n                    \n                    \n                  \n                \n              \n              \n            \n          \n        \n      \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      In the future, the Planetary Science Division of NASA’s Science Mission Directorate hopes to use better-performing and lower-cost propulsion systems to send rovers, probes, and observers to places like Mars, Jupiter, and Saturn. For such purposes, a new propulsion technology called the Advanced Materials Bipropellant Rocket (AMBR) was developed under NASA’s In-Space Propulsion Technology (ISPT) project, located at Glenn Research Center. As an advanced chemical propulsion system, AMBR uses nitrogen tetroxide oxidizer and hydrazine fuel to propel a spacecraft. Based on current research and development efforts, the technology shows great promise for increasing engine operation and engine lifespan, as well as lowering manufacturing costs. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The Cassini-Huygens spacecraft captured this view of Saturn in 2009. In order to send new rovers, probes, and observers to Mars, Jupiter, and Saturn, NASA is working with industry to develop propulsion technologies such as the Advanced Material Bipropellant Rocket (AMBR). \n                        \n                      \n                      In developing AMBR, ISPT has several goals: to decrease the time it takes for a spacecraft to travel to its destination, reduce the cost of making the propulsion system, and lessen the weight of the propulsion system. If goals like these are met, it could result in greater capabilities for in-space science investigations. For example, if the amount (and weight) of propellant required on a spacecraft is reduced, more scientific instruments (and weight) could be added to the spacecraft. \n                      To achieve AMBR’s maximum potential performance, the engine needed to be capable of operating at extremely high temperatures and pressure. To this end, ISPT required engine chambers made of iridium-coated rhenium (strong, high-temperature metallic elements) that allowed operation at temperatures close to 4,000 °F. In addition, ISPT needed an advanced manufacturing technique for better coating methods to increase the strength of the engine chamber without increasing the costs of fabricating the chamber.\n                      Partnership\n                      In 2006, NASA’s ISTP project partnered with NASA’s Marshall Space Flight Center and Aerojet through a NASA Research Announcement (NRA) to increase AMBR’s performance efficiency and to lower the fabrication cost for the iridium-coated rhenium combustion chamber. Aerojet subcontracted a company in Huntsville, Alabama, called Plasma Processes Inc. (PPI) to modify a state-of-the-art engine design so the chamber wall materials could operate at very high temperatures. \n                      While Aerojet defined the design details of the chamber configuration and worked with PPI to ensure the processes were in place to fabricate the chamber, the actual fabrication of the chamber was completed by PPI, using a process called EL-Form. Results from performance testing of the technology in 2008 and 2009 showed the propellant efficiency was higher than ever achieved for the hydrazine and nitrogen tetroxide oxidizer propellant combination. The iridium-coated rhenium chamber produced under the NRA set a hydrazine record for performance efficiency, which will mean a reduction in the propellant required to perform spacecraft maneuvers. It also had a 30-percent improvement on production costs. \n                      “EL-Form allows us to deposit a thicker iridium layer for improved oxidation protection. It also allows us to produce the rhenium layer with better consistency and properties than what they had been doing in the past. The iridium rhenium chambers were in use already, but the El-Form process allows us to be able to improve those materials—affecting the quality and the cost,” says Anatoliy Shchetkovskiy, EL-Form director for PPI.\n                      The iridium-coated rhenium combustion chamber fabricated using the EL-Form process addressed the needs of the ISTP project, as well as validated PPI’s process for making high-temperature materials for other applications. \n                      Benefits\n                      Compared to other coating processes, PPI’s EL-Form, or electroforming, process can reduce fabrication costs for iridium-coated rhenium material systems. Compared to traditional chemical vapor deposition processing techniques, the EL-Form process can produce thicker iridium layers for improved oxidation resistance, as well as perform multi-component processing. \n                      \n                        \n                        \n                          \n                        \n                        \n                          When NASA, Aerojet, and Plasma Processes Inc. tested AMBR, the results showed the chamber wall materials could withstand temperatures up to and exceeding 4,000 ˚F. The same materials are now being used for high-temperature applications such as small thrust chambers for satellites. \n                        \n                      \n                      PPI is the only supplier of the EL-Form process for electrodeposition of rhenium and other refractory metal and platinum group material coatings to graphite and metallic substrates. As demonstrated through testing with NASA, the EL-Form process makes components more capable of surviving high-pressure and high-temperature propulsion environments, with the resulting material having the capability to withstand steady-state temperatures up to and exceeding 4,000 °F. After validating the EL-Form process to fabricate high-temperature materials for NASA, PPI now uses the technique to make the same materials for other high temperature applications. \n                      For example, PPI used EL-Form to create a coating with the same metal combination as the one used in the AMBR chamber for small thrust chambers for satellites. “The customer used it for advanced propellant, and the in-flight tests show it was successful,” says Shchetkovskiy. \n                      In addition, the NASA-tested materials created by EL-Form have space propulsion rocket applications relevant to the commercial aerospace community, including Boeing, Honeywell, Alliant Techsystems Inc., and SpaceX. The U.S. Department of Defense, Navy, Air Force, and others are also using the high performance, low-cost iridium-coated rhenium material. \n                      As the development of AMBR continues, PPI and Aerojet continue to work with Glenn through a Small Business Innovation Research (SBIR) contract to improve the room-temperature yield strength of the iridium-lined rhenium combustion chambers. Such innovation could mean even more benefits for propulsion technology processes and materials in the future.\n                      EL-Form™ is a trademark of Plasma Processes Inc. \n                    \n                    \n                  \n                \n              \n              \n            \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      In the future, the Planetary Science Division of NASA’s Science Mission Directorate hopes to use better-performing and lower-cost propulsion systems to send rovers, probes, and observers to places like Mars, Jupiter, and Saturn. For such purposes, a new propulsion technology called the Advanced Materials Bipropellant Rocket (AMBR) was developed under NASA’s In-Space Propulsion Technology (ISPT) project, located at Glenn Research Center. As an advanced chemical propulsion system, AMBR uses nitrogen tetroxide oxidizer and hydrazine fuel to propel a spacecraft. Based on current research and development efforts, the technology shows great promise for increasing engine operation and engine lifespan, as well as lowering manufacturing costs. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The Cassini-Huygens spacecraft captured this view of Saturn in 2009. In order to send new rovers, probes, and observers to Mars, Jupiter, and Saturn, NASA is working with industry to develop propulsion technologies such as the Advanced Material Bipropellant Rocket (AMBR). \n                        \n                      \n                      In developing AMBR, ISPT has several goals: to decrease the time it takes for a spacecraft to travel to its destination, reduce the cost of making the propulsion system, and lessen the weight of the propulsion system. If goals like these are met, it could result in greater capabilities for in-space science investigations. For example, if the amount (and weight) of propellant required on a spacecraft is reduced, more scientific instruments (and weight) could be added to the spacecraft. \n                      To achieve AMBR’s maximum potential performance, the engine needed to be capable of operating at extremely high temperatures and pressure. To this end, ISPT required engine chambers made of iridium-coated rhenium (strong, high-temperature metallic elements) that allowed operation at temperatures close to 4,000 °F. In addition, ISPT needed an advanced manufacturing technique for better coating methods to increase the strength of the engine chamber without increasing the costs of fabricating the chamber.\n                      Partnership\n                      In 2006, NASA’s ISTP project partnered with NASA’s Marshall Space Flight Center and Aerojet through a NASA Research Announcement (NRA) to increase AMBR’s performance efficiency and to lower the fabrication cost for the iridium-coated rhenium combustion chamber. Aerojet subcontracted a company in Huntsville, Alabama, called Plasma Processes Inc. (PPI) to modify a state-of-the-art engine design so the chamber wall materials could operate at very high temperatures. \n                      While Aerojet defined the design details of the chamber configuration and worked with PPI to ensure the processes were in place to fabricate the chamber, the actual fabrication of the chamber was completed by PPI, using a process called EL-Form. Results from performance testing of the technology in 2008 and 2009 showed the propellant efficiency was higher than ever achieved for the hydrazine and nitrogen tetroxide oxidizer propellant combination. The iridium-coated rhenium chamber produced under the NRA set a hydrazine record for performance efficiency, which will mean a reduction in the propellant required to perform spacecraft maneuvers. It also had a 30-percent improvement on production costs. \n                      “EL-Form allows us to deposit a thicker iridium layer for improved oxidation protection. It also allows us to produce the rhenium layer with better consistency and properties than what they had been doing in the past. The iridium rhenium chambers were in use already, but the El-Form process allows us to be able to improve those materials—affecting the quality and the cost,” says Anatoliy Shchetkovskiy, EL-Form director for PPI.\n                      The iridium-coated rhenium combustion chamber fabricated using the EL-Form process addressed the needs of the ISTP project, as well as validated PPI’s process for making high-temperature materials for other applications. \n                      Benefits\n                      Compared to other coating processes, PPI’s EL-Form, or electroforming, process can reduce fabrication costs for iridium-coated rhenium material systems. Compared to traditional chemical vapor deposition processing techniques, the EL-Form process can produce thicker iridium layers for improved oxidation resistance, as well as perform multi-component processing. \n                      \n                        \n                        \n                          \n                        \n                        \n                          When NASA, Aerojet, and Plasma Processes Inc. tested AMBR, the results showed the chamber wall materials could withstand temperatures up to and exceeding 4,000 ˚F. The same materials are now being used for high-temperature applications such as small thrust chambers for satellites. \n                        \n                      \n                      PPI is the only supplier of the EL-Form process for electrodeposition of rhenium and other refractory metal and platinum group material coatings to graphite and metallic substrates. As demonstrated through testing with NASA, the EL-Form process makes components more capable of surviving high-pressure and high-temperature propulsion environments, with the resulting material having the capability to withstand steady-state temperatures up to and exceeding 4,000 °F. After validating the EL-Form process to fabricate high-temperature materials for NASA, PPI now uses the technique to make the same materials for other high temperature applications. \n                      For example, PPI used EL-Form to create a coating with the same metal combination as the one used in the AMBR chamber for small thrust chambers for satellites. “The customer used it for advanced propellant, and the in-flight tests show it was successful,” says Shchetkovskiy. \n                      In addition, the NASA-tested materials created by EL-Form have space propulsion rocket applications relevant to the commercial aerospace community, including Boeing, Honeywell, Alliant Techsystems Inc., and SpaceX. The U.S. Department of Defense, Navy, Air Force, and others are also using the high performance, low-cost iridium-coated rhenium material. \n                      As the development of AMBR continues, PPI and Aerojet continue to work with Glenn through a Small Business Innovation Research (SBIR) contract to improve the room-temperature yield strength of the iridium-lined rhenium combustion chambers. Such innovation could mean even more benefits for propulsion technology processes and materials in the future.\n                      EL-Form™ is a trademark of Plasma Processes Inc. \n                    \n                    \n                  \n                \n              \n              \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      In the future, the Planetary Science Division of NASA’s Science Mission Directorate hopes to use better-performing and lower-cost propulsion systems to send rovers, probes, and observers to places like Mars, Jupiter, and Saturn. For such purposes, a new propulsion technology called the Advanced Materials Bipropellant Rocket (AMBR) was developed under NASA’s In-Space Propulsion Technology (ISPT) project, located at Glenn Research Center. As an advanced chemical propulsion system, AMBR uses nitrogen tetroxide oxidizer and hydrazine fuel to propel a spacecraft. Based on current research and development efforts, the technology shows great promise for increasing engine operation and engine lifespan, as well as lowering manufacturing costs. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The Cassini-Huygens spacecraft captured this view of Saturn in 2009. In order to send new rovers, probes, and observers to Mars, Jupiter, and Saturn, NASA is working with industry to develop propulsion technologies such as the Advanced Material Bipropellant Rocket (AMBR). \n                        \n                      \n                      In developing AMBR, ISPT has several goals: to decrease the time it takes for a spacecraft to travel to its destination, reduce the cost of making the propulsion system, and lessen the weight of the propulsion system. If goals like these are met, it could result in greater capabilities for in-space science investigations. For example, if the amount (and weight) of propellant required on a spacecraft is reduced, more scientific instruments (and weight) could be added to the spacecraft. \n                      To achieve AMBR’s maximum potential performance, the engine needed to be capable of operating at extremely high temperatures and pressure. To this end, ISPT required engine chambers made of iridium-coated rhenium (strong, high-temperature metallic elements) that allowed operation at temperatures close to 4,000 °F. In addition, ISPT needed an advanced manufacturing technique for better coating methods to increase the strength of the engine chamber without increasing the costs of fabricating the chamber.\n                      Partnership\n                      In 2006, NASA’s ISTP project partnered with NASA’s Marshall Space Flight Center and Aerojet through a NASA Research Announcement (NRA) to increase AMBR’s performance efficiency and to lower the fabrication cost for the iridium-coated rhenium combustion chamber. Aerojet subcontracted a company in Huntsville, Alabama, called Plasma Processes Inc. (PPI) to modify a state-of-the-art engine design so the chamber wall materials could operate at very high temperatures. \n                      While Aerojet defined the design details of the chamber configuration and worked with PPI to ensure the processes were in place to fabricate the chamber, the actual fabrication of the chamber was completed by PPI, using a process called EL-Form. Results from performance testing of the technology in 2008 and 2009 showed the propellant efficiency was higher than ever achieved for the hydrazine and nitrogen tetroxide oxidizer propellant combination. The iridium-coated rhenium chamber produced under the NRA set a hydrazine record for performance efficiency, which will mean a reduction in the propellant required to perform spacecraft maneuvers. It also had a 30-percent improvement on production costs. \n                      “EL-Form allows us to deposit a thicker iridium layer for improved oxidation protection. It also allows us to produce the rhenium layer with better consistency and properties than what they had been doing in the past. The iridium rhenium chambers were in use already, but the El-Form process allows us to be able to improve those materials—affecting the quality and the cost,” says Anatoliy Shchetkovskiy, EL-Form director for PPI.\n                      The iridium-coated rhenium combustion chamber fabricated using the EL-Form process addressed the needs of the ISTP project, as well as validated PPI’s process for making high-temperature materials for other applications. \n                      Benefits\n                      Compared to other coating processes, PPI’s EL-Form, or electroforming, process can reduce fabrication costs for iridium-coated rhenium material systems. Compared to traditional chemical vapor deposition processing techniques, the EL-Form process can produce thicker iridium layers for improved oxidation resistance, as well as perform multi-component processing. \n                      \n                        \n                        \n                          \n                        \n                        \n                          When NASA, Aerojet, and Plasma Processes Inc. tested AMBR, the results showed the chamber wall materials could withstand temperatures up to and exceeding 4,000 ˚F. The same materials are now being used for high-temperature applications such as small thrust chambers for satellites. \n                        \n                      \n                      PPI is the only supplier of the EL-Form process for electrodeposition of rhenium and other refractory metal and platinum group material coatings to graphite and metallic substrates. As demonstrated through testing with NASA, the EL-Form process makes components more capable of surviving high-pressure and high-temperature propulsion environments, with the resulting material having the capability to withstand steady-state temperatures up to and exceeding 4,000 °F. After validating the EL-Form process to fabricate high-temperature materials for NASA, PPI now uses the technique to make the same materials for other high temperature applications. \n                      For example, PPI used EL-Form to create a coating with the same metal combination as the one used in the AMBR chamber for small thrust chambers for satellites. “The customer used it for advanced propellant, and the in-flight tests show it was successful,” says Shchetkovskiy. \n                      In addition, the NASA-tested materials created by EL-Form have space propulsion rocket applications relevant to the commercial aerospace community, including Boeing, Honeywell, Alliant Techsystems Inc., and SpaceX. The U.S. Department of Defense, Navy, Air Force, and others are also using the high performance, low-cost iridium-coated rhenium material. \n                      As the development of AMBR continues, PPI and Aerojet continue to work with Glenn through a Small Business Innovation Research (SBIR) contract to improve the room-temperature yield strength of the iridium-lined rhenium combustion chambers. Such innovation could mean even more benefits for propulsion technology processes and materials in the future.\n                      EL-Form™ is a trademark of Plasma Processes Inc. \n                    \n                    \n                  \n                \n              \n              \n                \n                  \n                    \n                      NASA Technology\n                      In the future, the Planetary Science Division of NASA’s Science Mission Directorate hopes to use better-performing and lower-cost propulsion systems to send rovers, probes, and observers to places like Mars, Jupiter, and Saturn. For such purposes, a new propulsion technology called the Advanced Materials Bipropellant Rocket (AMBR) was developed under NASA’s In-Space Propulsion Technology (ISPT) project, located at Glenn Research Center. As an advanced chemical propulsion system, AMBR uses nitrogen tetroxide oxidizer and hydrazine fuel to propel a spacecraft. Based on current research and development efforts, the technology shows great promise for increasing engine operation and engine lifespan, as well as lowering manufacturing costs. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The Cassini-Huygens spacecraft captured this view of Saturn in 2009. In order to send new rovers, probes, and observers to Mars, Jupiter, and Saturn, NASA is working with industry to develop propulsion technologies such as the Advanced Material Bipropellant Rocket (AMBR). \n                        \n                      \n                      In developing AMBR, ISPT has several goals: to decrease the time it takes for a spacecraft to travel to its destination, reduce the cost of making the propulsion system, and lessen the weight of the propulsion system. If goals like these are met, it could result in greater capabilities for in-space science investigations. For example, if the amount (and weight) of propellant required on a spacecraft is reduced, more scientific instruments (and weight) could be added to the spacecraft. \n                      To achieve AMBR’s maximum potential performance, the engine needed to be capable of operating at extremely high temperatures and pressure. To this end, ISPT required engine chambers made of iridium-coated rhenium (strong, high-temperature metallic elements) that allowed operation at temperatures close to 4,000 °F. In addition, ISPT needed an advanced manufacturing technique for better coating methods to increase the strength of the engine chamber without increasing the costs of fabricating the chamber.\n                      Partnership\n                      In 2006, NASA’s ISTP project partnered with NASA’s Marshall Space Flight Center and Aerojet through a NASA Research Announcement (NRA) to increase AMBR’s performance efficiency and to lower the fabrication cost for the iridium-coated rhenium combustion chamber. Aerojet subcontracted a company in Huntsville, Alabama, called Plasma Processes Inc. (PPI) to modify a state-of-the-art engine design so the chamber wall materials could operate at very high temperatures. \n                      While Aerojet defined the design details of the chamber configuration and worked with PPI to ensure the processes were in place to fabricate the chamber, the actual fabrication of the chamber was completed by PPI, using a process called EL-Form. Results from performance testing of the technology in 2008 and 2009 showed the propellant efficiency was higher than ever achieved for the hydrazine and nitrogen tetroxide oxidizer propellant combination. The iridium-coated rhenium chamber produced under the NRA set a hydrazine record for performance efficiency, which will mean a reduction in the propellant required to perform spacecraft maneuvers. It also had a 30-percent improvement on production costs. \n                      “EL-Form allows us to deposit a thicker iridium layer for improved oxidation protection. It also allows us to produce the rhenium layer with better consistency and properties than what they had been doing in the past. The iridium rhenium chambers were in use already, but the El-Form process allows us to be able to improve those materials—affecting the quality and the cost,” says Anatoliy Shchetkovskiy, EL-Form director for PPI.\n                      The iridium-coated rhenium combustion chamber fabricated using the EL-Form process addressed the needs of the ISTP project, as well as validated PPI’s process for making high-temperature materials for other applications. \n                      Benefits\n                      Compared to other coating processes, PPI’s EL-Form, or electroforming, process can reduce fabrication costs for iridium-coated rhenium material systems. Compared to traditional chemical vapor deposition processing techniques, the EL-Form process can produce thicker iridium layers for improved oxidation resistance, as well as perform multi-component processing. \n                      \n                        \n                        \n                          \n                        \n                        \n                          When NASA, Aerojet, and Plasma Processes Inc. tested AMBR, the results showed the chamber wall materials could withstand temperatures up to and exceeding 4,000 ˚F. The same materials are now being used for high-temperature applications such as small thrust chambers for satellites. \n                        \n                      \n                      PPI is the only supplier of the EL-Form process for electrodeposition of rhenium and other refractory metal and platinum group material coatings to graphite and metallic substrates. As demonstrated through testing with NASA, the EL-Form process makes components more capable of surviving high-pressure and high-temperature propulsion environments, with the resulting material having the capability to withstand steady-state temperatures up to and exceeding 4,000 °F. After validating the EL-Form process to fabricate high-temperature materials for NASA, PPI now uses the technique to make the same materials for other high temperature applications. \n                      For example, PPI used EL-Form to create a coating with the same metal combination as the one used in the AMBR chamber for small thrust chambers for satellites. “The customer used it for advanced propellant, and the in-flight tests show it was successful,” says Shchetkovskiy. \n                      In addition, the NASA-tested materials created by EL-Form have space propulsion rocket applications relevant to the commercial aerospace community, including Boeing, Honeywell, Alliant Techsystems Inc., and SpaceX. The U.S. Department of Defense, Navy, Air Force, and others are also using the high performance, low-cost iridium-coated rhenium material. \n                      As the development of AMBR continues, PPI and Aerojet continue to work with Glenn through a Small Business Innovation Research (SBIR) contract to improve the room-temperature yield strength of the iridium-lined rhenium combustion chambers. Such innovation could mean even more benefits for propulsion technology processes and materials in the future.\n                      EL-Form™ is a trademark of Plasma Processes Inc. \n                    \n                    \n                  \n                \n                  \n                    \n                      NASA Technology\n                      In the future, the Planetary Science Division of NASA’s Science Mission Directorate hopes to use better-performing and lower-cost propulsion systems to send rovers, probes, and observers to places like Mars, Jupiter, and Saturn. For such purposes, a new propulsion technology called the Advanced Materials Bipropellant Rocket (AMBR) was developed under NASA’s In-Space Propulsion Technology (ISPT) project, located at Glenn Research Center. As an advanced chemical propulsion system, AMBR uses nitrogen tetroxide oxidizer and hydrazine fuel to propel a spacecraft. Based on current research and development efforts, the technology shows great promise for increasing engine operation and engine lifespan, as well as lowering manufacturing costs. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The Cassini-Huygens spacecraft captured this view of Saturn in 2009. In order to send new rovers, probes, and observers to Mars, Jupiter, and Saturn, NASA is working with industry to develop propulsion technologies such as the Advanced Material Bipropellant Rocket (AMBR). \n                        \n                      \n                      In developing AMBR, ISPT has several goals: to decrease the time it takes for a spacecraft to travel to its destination, reduce the cost of making the propulsion system, and lessen the weight of the propulsion system. If goals like these are met, it could result in greater capabilities for in-space science investigations. For example, if the amount (and weight) of propellant required on a spacecraft is reduced, more scientific instruments (and weight) could be added to the spacecraft. \n                      To achieve AMBR’s maximum potential performance, the engine needed to be capable of operating at extremely high temperatures and pressure. To this end, ISPT required engine chambers made of iridium-coated rhenium (strong, high-temperature metallic elements) that allowed operation at temperatures close to 4,000 °F. In addition, ISPT needed an advanced manufacturing technique for better coating methods to increase the strength of the engine chamber without increasing the costs of fabricating the chamber.\n                      Partnership\n                      In 2006, NASA’s ISTP project partnered with NASA’s Marshall Space Flight Center and Aerojet through a NASA Research Announcement (NRA) to increase AMBR’s performance efficiency and to lower the fabrication cost for the iridium-coated rhenium combustion chamber. Aerojet subcontracted a company in Huntsville, Alabama, called Plasma Processes Inc. (PPI) to modify a state-of-the-art engine design so the chamber wall materials could operate at very high temperatures. \n                      While Aerojet defined the design details of the chamber configuration and worked with PPI to ensure the processes were in place to fabricate the chamber, the actual fabrication of the chamber was completed by PPI, using a process called EL-Form. Results from performance testing of the technology in 2008 and 2009 showed the propellant efficiency was higher than ever achieved for the hydrazine and nitrogen tetroxide oxidizer propellant combination. The iridium-coated rhenium chamber produced under the NRA set a hydrazine record for performance efficiency, which will mean a reduction in the propellant required to perform spacecraft maneuvers. It also had a 30-percent improvement on production costs. \n                      “EL-Form allows us to deposit a thicker iridium layer for improved oxidation protection. It also allows us to produce the rhenium layer with better consistency and properties than what they had been doing in the past. The iridium rhenium chambers were in use already, but the El-Form process allows us to be able to improve those materials—affecting the quality and the cost,” says Anatoliy Shchetkovskiy, EL-Form director for PPI.\n                      The iridium-coated rhenium combustion chamber fabricated using the EL-Form process addressed the needs of the ISTP project, as well as validated PPI’s process for making high-temperature materials for other applications. \n                      Benefits\n                      Compared to other coating processes, PPI’s EL-Form, or electroforming, process can reduce fabrication costs for iridium-coated rhenium material systems. Compared to traditional chemical vapor deposition processing techniques, the EL-Form process can produce thicker iridium layers for improved oxidation resistance, as well as perform multi-component processing. \n                      \n                        \n                        \n                          \n                        \n                        \n                          When NASA, Aerojet, and Plasma Processes Inc. tested AMBR, the results showed the chamber wall materials could withstand temperatures up to and exceeding 4,000 ˚F. The same materials are now being used for high-temperature applications such as small thrust chambers for satellites. \n                        \n                      \n                      PPI is the only supplier of the EL-Form process for electrodeposition of rhenium and other refractory metal and platinum group material coatings to graphite and metallic substrates. As demonstrated through testing with NASA, the EL-Form process makes components more capable of surviving high-pressure and high-temperature propulsion environments, with the resulting material having the capability to withstand steady-state temperatures up to and exceeding 4,000 °F. After validating the EL-Form process to fabricate high-temperature materials for NASA, PPI now uses the technique to make the same materials for other high temperature applications. \n                      For example, PPI used EL-Form to create a coating with the same metal combination as the one used in the AMBR chamber for small thrust chambers for satellites. “The customer used it for advanced propellant, and the in-flight tests show it was successful,” says Shchetkovskiy. \n                      In addition, the NASA-tested materials created by EL-Form have space propulsion rocket applications relevant to the commercial aerospace community, including Boeing, Honeywell, Alliant Techsystems Inc., and SpaceX. The U.S. Department of Defense, Navy, Air Force, and others are also using the high performance, low-cost iridium-coated rhenium material. \n                      As the development of AMBR continues, PPI and Aerojet continue to work with Glenn through a Small Business Innovation Research (SBIR) contract to improve the room-temperature yield strength of the iridium-lined rhenium combustion chambers. Such innovation could mean even more benefits for propulsion technology processes and materials in the future.\n                      EL-Form™ is a trademark of Plasma Processes Inc. \n                    \n                    \n                  \n                    \n                      NASA Technology\n                      In the future, the Planetary Science Division of NASA’s Science Mission Directorate hopes to use better-performing and lower-cost propulsion systems to send rovers, probes, and observers to places like Mars, Jupiter, and Saturn. For such purposes, a new propulsion technology called the Advanced Materials Bipropellant Rocket (AMBR) was developed under NASA’s In-Space Propulsion Technology (ISPT) project, located at Glenn Research Center. As an advanced chemical propulsion system, AMBR uses nitrogen tetroxide oxidizer and hydrazine fuel to propel a spacecraft. Based on current research and development efforts, the technology shows great promise for increasing engine operation and engine lifespan, as well as lowering manufacturing costs. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The Cassini-Huygens spacecraft captured this view of Saturn in 2009. In order to send new rovers, probes, and observers to Mars, Jupiter, and Saturn, NASA is working with industry to develop propulsion technologies such as the Advanced Material Bipropellant Rocket (AMBR). \n                        \n                      \n                      In developing AMBR, ISPT has several goals: to decrease the time it takes for a spacecraft to travel to its destination, reduce the cost of making the propulsion system, and lessen the weight of the propulsion system. If goals like these are met, it could result in greater capabilities for in-space science investigations. For example, if the amount (and weight) of propellant required on a spacecraft is reduced, more scientific instruments (and weight) could be added to the spacecraft. \n                      To achieve AMBR’s maximum potential performance, the engine needed to be capable of operating at extremely high temperatures and pressure. To this end, ISPT required engine chambers made of iridium-coated rhenium (strong, high-temperature metallic elements) that allowed operation at temperatures close to 4,000 °F. In addition, ISPT needed an advanced manufacturing technique for better coating methods to increase the strength of the engine chamber without increasing the costs of fabricating the chamber.\n                      Partnership\n                      In 2006, NASA’s ISTP project partnered with NASA’s Marshall Space Flight Center and Aerojet through a NASA Research Announcement (NRA) to increase AMBR’s performance efficiency and to lower the fabrication cost for the iridium-coated rhenium combustion chamber. Aerojet subcontracted a company in Huntsville, Alabama, called Plasma Processes Inc. (PPI) to modify a state-of-the-art engine design so the chamber wall materials could operate at very high temperatures. \n                      While Aerojet defined the design details of the chamber configuration and worked with PPI to ensure the processes were in place to fabricate the chamber, the actual fabrication of the chamber was completed by PPI, using a process called EL-Form. Results from performance testing of the technology in 2008 and 2009 showed the propellant efficiency was higher than ever achieved for the hydrazine and nitrogen tetroxide oxidizer propellant combination. The iridium-coated rhenium chamber produced under the NRA set a hydrazine record for performance efficiency, which will mean a reduction in the propellant required to perform spacecraft maneuvers. It also had a 30-percent improvement on production costs. \n                      “EL-Form allows us to deposit a thicker iridium layer for improved oxidation protection. It also allows us to produce the rhenium layer with better consistency and properties than what they had been doing in the past. The iridium rhenium chambers were in use already, but the El-Form process allows us to be able to improve those materials—affecting the quality and the cost,” says Anatoliy Shchetkovskiy, EL-Form director for PPI.\n                      The iridium-coated rhenium combustion chamber fabricated using the EL-Form process addressed the needs of the ISTP project, as well as validated PPI’s process for making high-temperature materials for other applications. \n                      Benefits\n                      Compared to other coating processes, PPI’s EL-Form, or electroforming, process can reduce fabrication costs for iridium-coated rhenium material systems. Compared to traditional chemical vapor deposition processing techniques, the EL-Form process can produce thicker iridium layers for improved oxidation resistance, as well as perform multi-component processing. \n                      \n                        \n                        \n                          \n                        \n                        \n                          When NASA, Aerojet, and Plasma Processes Inc. tested AMBR, the results showed the chamber wall materials could withstand temperatures up to and exceeding 4,000 ˚F. The same materials are now being used for high-temperature applications such as small thrust chambers for satellites. \n                        \n                      \n                      PPI is the only supplier of the EL-Form process for electrodeposition of rhenium and other refractory metal and platinum group material coatings to graphite and metallic substrates. As demonstrated through testing with NASA, the EL-Form process makes components more capable of surviving high-pressure and high-temperature propulsion environments, with the resulting material having the capability to withstand steady-state temperatures up to and exceeding 4,000 °F. After validating the EL-Form process to fabricate high-temperature materials for NASA, PPI now uses the technique to make the same materials for other high temperature applications. \n                      For example, PPI used EL-Form to create a coating with the same metal combination as the one used in the AMBR chamber for small thrust chambers for satellites. “The customer used it for advanced propellant, and the in-flight tests show it was successful,” says Shchetkovskiy. \n                      In addition, the NASA-tested materials created by EL-Form have space propulsion rocket applications relevant to the commercial aerospace community, including Boeing, Honeywell, Alliant Techsystems Inc., and SpaceX. The U.S. Department of Defense, Navy, Air Force, and others are also using the high performance, low-cost iridium-coated rhenium material. \n                      As the development of AMBR continues, PPI and Aerojet continue to work with Glenn through a Small Business Innovation Research (SBIR) contract to improve the room-temperature yield strength of the iridium-lined rhenium combustion chambers. Such innovation could mean even more benefits for propulsion technology processes and materials in the future.\n                      EL-Form™ is a trademark of Plasma Processes Inc. \n                    \n                    \n                      NASA Technology\n                      In the future, the Planetary Science Division of NASA’s Science Mission Directorate hopes to use better-performing and lower-cost propulsion systems to send rovers, probes, and observers to places like Mars, Jupiter, and Saturn. For such purposes, a new propulsion technology called the Advanced Materials Bipropellant Rocket (AMBR) was developed under NASA’s In-Space Propulsion Technology (ISPT) project, located at Glenn Research Center. As an advanced chemical propulsion system, AMBR uses nitrogen tetroxide oxidizer and hydrazine fuel to propel a spacecraft. Based on current research and development efforts, the technology shows great promise for increasing engine operation and engine lifespan, as well as lowering manufacturing costs. \n                      \n                        \n                        \n                          \n                        \n                        \n                          The Cassini-Huygens spacecraft captured this view of Saturn in 2009. In order to send new rovers, probes, and observers to Mars, Jupiter, and Saturn, NASA is working with industry to develop propulsion technologies such as the Advanced Material Bipropellant Rocket (AMBR). \n                        \n                      \n                      In developing AMBR, ISPT has several goals: to decrease the time it takes for a spacecraft to travel to its destination, reduce the cost of making the propulsion system, and lessen the weight of the propulsion system. If goals like these are met, it could result in greater capabilities for in-space science investigations. For example, if the amount (and weight) of propellant required on a spacecraft is reduced, more scientific instruments (and weight) could be added to the spacecraft. \n                      To achieve AMBR’s maximum potential performance, the engine needed to be capable of operating at extremely high temperatures and pressure. To this end, ISPT required engine chambers made of iridium-coated rhenium (strong, high-temperature metallic elements) that allowed operation at temperatures close to 4,000 °F. In addition, ISPT needed an advanced manufacturing technique for better coating methods to increase the strength of the engine chamber without increasing the costs of fabricating the chamber.\n                      Partnership\n                      In 2006, NASA’s ISTP project partnered with NASA’s Marshall Space Flight Center and Aerojet through a NASA Research Announcement (NRA) to increase AMBR’s performance efficiency and to lower the fabrication cost for the iridium-coated rhenium combustion chamber. Aerojet subcontracted a company in Huntsville, Alabama, called Plasma Processes Inc. (PPI) to modify a state-of-the-art engine design so the chamber wall materials could operate at very high temperatures. \n                      While Aerojet defined the design details of the chamber configuration and worked with PPI to ensure the processes were in place to fabricate the chamber, the actual fabrication of the chamber was completed by PPI, using a process called EL-Form. Results from performance testing of the technology in 2008 and 2009 showed the propellant efficiency was higher than ever achieved for the hydrazine and nitrogen tetroxide oxidizer propellant combination. The iridium-coated rhenium chamber produced under the NRA set a hydrazine record for performance efficiency, which will mean a reduction in the propellant required to perform spacecraft maneuvers. It also had a 30-percent improvement on production costs. \n                      “EL-Form allows us to deposit a thicker iridium layer for improved oxidation protection. It also allows us to produce the rhenium layer with better consistency and properties than what they had been doing in the past. The iridium rhenium chambers were in use already, but the El-Form process allows us to be able to improve those materials—affecting the quality and the cost,” says Anatoliy Shchetkovskiy, EL-Form director for PPI.\n                      The iridium-coated rhenium combustion chamber fabricated using the EL-Form process addressed the needs of the ISTP project, as well as validated PPI’s process for making high-temperature materials for other applications. \n                      Benefits\n                      Compared to other coating processes, PPI’s EL-Form, or electroforming, process can reduce fabrication costs for iridium-coated rhenium material systems. Compared to traditional chemical vapor deposition processing techniques, the EL-Form process can produce thicker iridium layers for improved oxidation resistance, as well as perform multi-component processing. \n                      \n                        \n                        \n                          \n                        \n                        \n                          When NASA, Aerojet, and Plasma Processes Inc. tested AMBR, the results showed the chamber wall materials could withstand temperatures up to and exceeding 4,000 ˚F. The same materials are now being used for high-temperature applications such as small thrust chambers for satellites. \n                        \n                      \n                      PPI is the only supplier of the EL-Form process for electrodeposition of rhenium and other refractory metal and platinum group material coatings to graphite and metallic substrates. As demonstrated through testing with NASA, the EL-Form process makes components more capable of surviving high-pressure and high-temperature propulsion environments, with the resulting material having the capability to withstand steady-state temperatures up to and exceeding 4,000 °F. After validating the EL-Form process to fabricate high-temperature materials for NASA, PPI now uses the technique to make the same materials for other high temperature applications. \n                      For example, PPI used EL-Form to create a coating with the same metal combination as the one used in the AMBR chamber for small thrust chambers for satellites. “The customer used it for advanced propellant, and the in-flight tests show it was successful,” says Shchetkovskiy. \n                      In addition, the NASA-tested materials created by EL-Form have space propulsion rocket applications relevant to the commercial aerospace community, including Boeing, Honeywell, Alliant Techsystems Inc., and SpaceX. The U.S. Department of Defense, Navy, Air Force, and others are also using the high performance, low-cost iridium-coated rhenium material. \n                      As the development of AMBR continues, PPI and Aerojet continue to work with Glenn through a Small Business Innovation Research (SBIR) contract to improve the room-temperature yield strength of the iridium-lined rhenium combustion chambers. Such innovation could mean even more benefits for propulsion technology processes and materials in the future.\n                      EL-Form™ is a trademark of Plasma Processes Inc. \n                    "},{"href":"http://spinoff.nasa.gov/Spinoff2011/ip_7.html","text":"High-Temperature Coatings Offer Energy Savings","image":"http://spinoff.nasa.gov/Spinoff2011/Images/ip_7a_opt.png","story":"\n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          In developing new materials to test on the X-33 reusable launch vehicle (artist’s concept shown here), Ames Research Center invented a thin material capable of withstanding high temperatures. It also exhibited good thermal shock, vibration, and acoustic performance. \n                        \n                      \n                      The U.S. X-Plane Program included the first-of-its-kind research in aerodynamics and astronautics with experimental vehicles, including the first aircraft to break the sound barrier; the first aircraft to fly in excess of 100,000, then 200,000, and then 300,000 feet; and the first aircraft to fly at three, four, five, and then six times the speed of sound. \n                      During the 1990s, NASA started developing a new thermal protection material to test on the X-33 and X-34 supersonic aircraft. The X-33 was intended to demonstrate the technologies needed for a new reusable launch vehicle and was projected to reach an altitude of approximately 50 miles and speeds of more than Mach 11. The X-34, a small, reusable technology demonstrator for a launch vehicle, was intended to reach an altitude of 250,000 feet and fly at speeds of Mach 8. \n                      As a result of its research and development efforts, NASA’s Ames Research Center invented the Protective Ceramic Coating Material (PCCM). Applied to a surface, the thin, lightweight coating could protect the material underneath from extreme temperatures. The capability of the technology came from its emissivity, which radiated heat away from the surface it covered, thereby decreasing the amount of heat transferred to the underlying material. PCCM not only increased the capability of materials to withstand higher temperatures, it also exhibited impressive thermal shock, vibration, and acoustic performance. In addition, it proved to be resistant to abrasion and mechanical damage and was also environmentally safe, due to it being water-based and containing no solvents. Even though funding for the X-33 and X-34 ended in 2001, PCCM continued on a path of innovation. \n                      Partnership\n                      Shortly after Ames made PCCM available for licensing, Emisshield Inc. (then Wessex Incorporated) in Blacksburg, Virginia, stumbled upon the technology, and according to John Olver, president and CEO of Emisshield, “After we looked it over, analyzed it, read about it, and checked on some of the references, we called Ames and said we’d like to license it. We wanted to know how they did that.” \n                      Olver and other representatives from Emisshield talked to the NASA inventors to learn more about PCCM, and in 1996, obtained a license for the technology. With assistance from the Center for Adhesion and Sealant Sciences at the Virginia Polytechnic Institute and State University (Virginia Tech), Emisshield performed extensive testing, research, and development of the coating. By 2001, the company had expanded its license agreement to include all applications except space and space vehicle applications. \n                      During the first few years, Emisshield made several changes to make PCCM more practical to use. One of the properties Emisshield adjusted was the shelf life of the material. “When you mixed it up, it set like concrete in about an hour. You couldn’t use it after that,” Olver says. Emisshield also modified PCCM so it would adhere to metal and was easy to apply with a spray gun. \n                      “As we progressed, we took the base license and advanced it into two new patents,” says Olver. “NASA said, ‘That’s what we intended for you to do, to license it, make it better, and commercialize it.’”\n                      Benefits\n                      Previously featured in Spinoff 2001 and Spinoff 2004, Emisshield provides its NASA-derived technology, also called Emisshield, in more than 20 different products. Each formulation is different based on the material it is being applied to as well as the temperature and conditions of the environment. “We are changing the surface properties of existing materials—metals, ceramics—to improve their performance,” says Olver. “It will work just about anywhere there is heat—from electricity to manufacturing glass and plastic bottles.”\n                      Available for use on new or existing substrates in any combustion process including metals, refractory (heat resistant material), ceramics, and high technology fabrics, Emisshield can provide significant savings for most energy consuming, producing, or related heat systems. According to its customers, Emisshield has permitted heat-driven industrial applications to experience up to a 15-percent energy savings, a 15-percent increase in production, more uniform heating, prolonged substrate life, and reduced downtime for maintenance. In fact, the company finds the harder a process is pushed, the greater the fuel savings and the faster the payback for using Emisshield.\n                      “Another thing that happens is that by improving combustion of gasses and fuels, products are made with less energy, and that reduces air emissions,” says Olver. All of this is done with a coating that is about as thin as a kitchen garbage bag. The coating can be applied to items at an Emisshield facility, or onsite at a customer’s facility. “It’s unique because it is so easy to install, even in the field and for applications that have extreme requirements. We can go out, clean the surface, and then apply the coating.”\n                      “We started the root system with NASA, then the trunk, and now we’re growing \n                        the branches. We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                        —John Olver, Emisshield Inc.                      \n                      In hydrocarbon and chemical processing, Emisshield can be used to coat the combustion chamber and process tubes of high temperature cracking units, as well as lower temperature process heaters. Emisshield is applied to the process tubes and refractory walls, a combination that generates an increase in energy savings and production. Like applications in the hydrocarbon and chemical processing industry, power generation can also see similar benefits while promoting better air emissions. Such applications include biomass boilers, waste incinerators, natural gas boilers, heat recovery steam generators, and burners. \n                      \n                        \n                        \n                          \n                        \n                        \n                          Emisshield Inc. licensed technology from NASA to incorporate into various formulations of coatings for high-temperature applications. The images above show the walls of a boiler before (left) and after (right) the NASA-derived coating was applied.\n                        \n                      \n                      For metal production, applications include reheat furnaces, bell annealing furnaces, walking beam furnaces, electric arc furnaces, and others. The increase in combustion allows for a quicker heat up and cool down \n                        in an intermittent furnace, which saves manufacturers time and money. Emisshield is also used in a variety of multipurpose kilns including intermittent kilns and continuous kilns. \n                      One of Emisshield’s most popular applications is in furnaces for making glass—everything from wine bottles to windshields. So far, the coating has been applied to 30 furnaces worldwide. “On these big glass furnaces, they are saving about 10 percent of their energy,” says Olver. “The payback for our clients making glass is always under a year.” \n                      As the company moves forward, it strives to penetrate new market areas. Recently, the company started focusing on introducing Emisshield in the food processing industry. The company is working to apply the coating on the walls of ovens, baking pans, and burners for commercial bread baking. “We see lots of opportunities in this market, and are hoping to push into it in the next few years,” says Olver. “Emisshield could even be applied to the grills that people use at home. There are a lot of potential applications.”\n                      The newest application, however, is for high solar absorptive materials for concentrated solar power generation stations. The company is currently working with an Israeli-U.S. company in this area.\n                      “We started the root system with NASA, then the trunk, and now we’re growing our branches,” says Olver. “We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                      Emisshield® is registered by Emisshield Inc.\n                    \n                    \n                  \n                \n              \n              \n            \n          \n        \n      \n    \n      \n        \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          In developing new materials to test on the X-33 reusable launch vehicle (artist’s concept shown here), Ames Research Center invented a thin material capable of withstanding high temperatures. It also exhibited good thermal shock, vibration, and acoustic performance. \n                        \n                      \n                      The U.S. X-Plane Program included the first-of-its-kind research in aerodynamics and astronautics with experimental vehicles, including the first aircraft to break the sound barrier; the first aircraft to fly in excess of 100,000, then 200,000, and then 300,000 feet; and the first aircraft to fly at three, four, five, and then six times the speed of sound. \n                      During the 1990s, NASA started developing a new thermal protection material to test on the X-33 and X-34 supersonic aircraft. The X-33 was intended to demonstrate the technologies needed for a new reusable launch vehicle and was projected to reach an altitude of approximately 50 miles and speeds of more than Mach 11. The X-34, a small, reusable technology demonstrator for a launch vehicle, was intended to reach an altitude of 250,000 feet and fly at speeds of Mach 8. \n                      As a result of its research and development efforts, NASA’s Ames Research Center invented the Protective Ceramic Coating Material (PCCM). Applied to a surface, the thin, lightweight coating could protect the material underneath from extreme temperatures. The capability of the technology came from its emissivity, which radiated heat away from the surface it covered, thereby decreasing the amount of heat transferred to the underlying material. PCCM not only increased the capability of materials to withstand higher temperatures, it also exhibited impressive thermal shock, vibration, and acoustic performance. In addition, it proved to be resistant to abrasion and mechanical damage and was also environmentally safe, due to it being water-based and containing no solvents. Even though funding for the X-33 and X-34 ended in 2001, PCCM continued on a path of innovation. \n                      Partnership\n                      Shortly after Ames made PCCM available for licensing, Emisshield Inc. (then Wessex Incorporated) in Blacksburg, Virginia, stumbled upon the technology, and according to John Olver, president and CEO of Emisshield, “After we looked it over, analyzed it, read about it, and checked on some of the references, we called Ames and said we’d like to license it. We wanted to know how they did that.” \n                      Olver and other representatives from Emisshield talked to the NASA inventors to learn more about PCCM, and in 1996, obtained a license for the technology. With assistance from the Center for Adhesion and Sealant Sciences at the Virginia Polytechnic Institute and State University (Virginia Tech), Emisshield performed extensive testing, research, and development of the coating. By 2001, the company had expanded its license agreement to include all applications except space and space vehicle applications. \n                      During the first few years, Emisshield made several changes to make PCCM more practical to use. One of the properties Emisshield adjusted was the shelf life of the material. “When you mixed it up, it set like concrete in about an hour. You couldn’t use it after that,” Olver says. Emisshield also modified PCCM so it would adhere to metal and was easy to apply with a spray gun. \n                      “As we progressed, we took the base license and advanced it into two new patents,” says Olver. “NASA said, ‘That’s what we intended for you to do, to license it, make it better, and commercialize it.’”\n                      Benefits\n                      Previously featured in Spinoff 2001 and Spinoff 2004, Emisshield provides its NASA-derived technology, also called Emisshield, in more than 20 different products. Each formulation is different based on the material it is being applied to as well as the temperature and conditions of the environment. “We are changing the surface properties of existing materials—metals, ceramics—to improve their performance,” says Olver. “It will work just about anywhere there is heat—from electricity to manufacturing glass and plastic bottles.”\n                      Available for use on new or existing substrates in any combustion process including metals, refractory (heat resistant material), ceramics, and high technology fabrics, Emisshield can provide significant savings for most energy consuming, producing, or related heat systems. According to its customers, Emisshield has permitted heat-driven industrial applications to experience up to a 15-percent energy savings, a 15-percent increase in production, more uniform heating, prolonged substrate life, and reduced downtime for maintenance. In fact, the company finds the harder a process is pushed, the greater the fuel savings and the faster the payback for using Emisshield.\n                      “Another thing that happens is that by improving combustion of gasses and fuels, products are made with less energy, and that reduces air emissions,” says Olver. All of this is done with a coating that is about as thin as a kitchen garbage bag. The coating can be applied to items at an Emisshield facility, or onsite at a customer’s facility. “It’s unique because it is so easy to install, even in the field and for applications that have extreme requirements. We can go out, clean the surface, and then apply the coating.”\n                      “We started the root system with NASA, then the trunk, and now we’re growing \n                        the branches. We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                        —John Olver, Emisshield Inc.                      \n                      In hydrocarbon and chemical processing, Emisshield can be used to coat the combustion chamber and process tubes of high temperature cracking units, as well as lower temperature process heaters. Emisshield is applied to the process tubes and refractory walls, a combination that generates an increase in energy savings and production. Like applications in the hydrocarbon and chemical processing industry, power generation can also see similar benefits while promoting better air emissions. Such applications include biomass boilers, waste incinerators, natural gas boilers, heat recovery steam generators, and burners. \n                      \n                        \n                        \n                          \n                        \n                        \n                          Emisshield Inc. licensed technology from NASA to incorporate into various formulations of coatings for high-temperature applications. The images above show the walls of a boiler before (left) and after (right) the NASA-derived coating was applied.\n                        \n                      \n                      For metal production, applications include reheat furnaces, bell annealing furnaces, walking beam furnaces, electric arc furnaces, and others. The increase in combustion allows for a quicker heat up and cool down \n                        in an intermittent furnace, which saves manufacturers time and money. Emisshield is also used in a variety of multipurpose kilns including intermittent kilns and continuous kilns. \n                      One of Emisshield’s most popular applications is in furnaces for making glass—everything from wine bottles to windshields. So far, the coating has been applied to 30 furnaces worldwide. “On these big glass furnaces, they are saving about 10 percent of their energy,” says Olver. “The payback for our clients making glass is always under a year.” \n                      As the company moves forward, it strives to penetrate new market areas. Recently, the company started focusing on introducing Emisshield in the food processing industry. The company is working to apply the coating on the walls of ovens, baking pans, and burners for commercial bread baking. “We see lots of opportunities in this market, and are hoping to push into it in the next few years,” says Olver. “Emisshield could even be applied to the grills that people use at home. There are a lot of potential applications.”\n                      The newest application, however, is for high solar absorptive materials for concentrated solar power generation stations. The company is currently working with an Israeli-U.S. company in this area.\n                      “We started the root system with NASA, then the trunk, and now we’re growing our branches,” says Olver. “We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                      Emisshield® is registered by Emisshield Inc.\n                    \n                    \n                  \n                \n              \n              \n            \n          \n        \n      \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          In developing new materials to test on the X-33 reusable launch vehicle (artist’s concept shown here), Ames Research Center invented a thin material capable of withstanding high temperatures. It also exhibited good thermal shock, vibration, and acoustic performance. \n                        \n                      \n                      The U.S. X-Plane Program included the first-of-its-kind research in aerodynamics and astronautics with experimental vehicles, including the first aircraft to break the sound barrier; the first aircraft to fly in excess of 100,000, then 200,000, and then 300,000 feet; and the first aircraft to fly at three, four, five, and then six times the speed of sound. \n                      During the 1990s, NASA started developing a new thermal protection material to test on the X-33 and X-34 supersonic aircraft. The X-33 was intended to demonstrate the technologies needed for a new reusable launch vehicle and was projected to reach an altitude of approximately 50 miles and speeds of more than Mach 11. The X-34, a small, reusable technology demonstrator for a launch vehicle, was intended to reach an altitude of 250,000 feet and fly at speeds of Mach 8. \n                      As a result of its research and development efforts, NASA’s Ames Research Center invented the Protective Ceramic Coating Material (PCCM). Applied to a surface, the thin, lightweight coating could protect the material underneath from extreme temperatures. The capability of the technology came from its emissivity, which radiated heat away from the surface it covered, thereby decreasing the amount of heat transferred to the underlying material. PCCM not only increased the capability of materials to withstand higher temperatures, it also exhibited impressive thermal shock, vibration, and acoustic performance. In addition, it proved to be resistant to abrasion and mechanical damage and was also environmentally safe, due to it being water-based and containing no solvents. Even though funding for the X-33 and X-34 ended in 2001, PCCM continued on a path of innovation. \n                      Partnership\n                      Shortly after Ames made PCCM available for licensing, Emisshield Inc. (then Wessex Incorporated) in Blacksburg, Virginia, stumbled upon the technology, and according to John Olver, president and CEO of Emisshield, “After we looked it over, analyzed it, read about it, and checked on some of the references, we called Ames and said we’d like to license it. We wanted to know how they did that.” \n                      Olver and other representatives from Emisshield talked to the NASA inventors to learn more about PCCM, and in 1996, obtained a license for the technology. With assistance from the Center for Adhesion and Sealant Sciences at the Virginia Polytechnic Institute and State University (Virginia Tech), Emisshield performed extensive testing, research, and development of the coating. By 2001, the company had expanded its license agreement to include all applications except space and space vehicle applications. \n                      During the first few years, Emisshield made several changes to make PCCM more practical to use. One of the properties Emisshield adjusted was the shelf life of the material. “When you mixed it up, it set like concrete in about an hour. You couldn’t use it after that,” Olver says. Emisshield also modified PCCM so it would adhere to metal and was easy to apply with a spray gun. \n                      “As we progressed, we took the base license and advanced it into two new patents,” says Olver. “NASA said, ‘That’s what we intended for you to do, to license it, make it better, and commercialize it.’”\n                      Benefits\n                      Previously featured in Spinoff 2001 and Spinoff 2004, Emisshield provides its NASA-derived technology, also called Emisshield, in more than 20 different products. Each formulation is different based on the material it is being applied to as well as the temperature and conditions of the environment. “We are changing the surface properties of existing materials—metals, ceramics—to improve their performance,” says Olver. “It will work just about anywhere there is heat—from electricity to manufacturing glass and plastic bottles.”\n                      Available for use on new or existing substrates in any combustion process including metals, refractory (heat resistant material), ceramics, and high technology fabrics, Emisshield can provide significant savings for most energy consuming, producing, or related heat systems. According to its customers, Emisshield has permitted heat-driven industrial applications to experience up to a 15-percent energy savings, a 15-percent increase in production, more uniform heating, prolonged substrate life, and reduced downtime for maintenance. In fact, the company finds the harder a process is pushed, the greater the fuel savings and the faster the payback for using Emisshield.\n                      “Another thing that happens is that by improving combustion of gasses and fuels, products are made with less energy, and that reduces air emissions,” says Olver. All of this is done with a coating that is about as thin as a kitchen garbage bag. The coating can be applied to items at an Emisshield facility, or onsite at a customer’s facility. “It’s unique because it is so easy to install, even in the field and for applications that have extreme requirements. We can go out, clean the surface, and then apply the coating.”\n                      “We started the root system with NASA, then the trunk, and now we’re growing \n                        the branches. We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                        —John Olver, Emisshield Inc.                      \n                      In hydrocarbon and chemical processing, Emisshield can be used to coat the combustion chamber and process tubes of high temperature cracking units, as well as lower temperature process heaters. Emisshield is applied to the process tubes and refractory walls, a combination that generates an increase in energy savings and production. Like applications in the hydrocarbon and chemical processing industry, power generation can also see similar benefits while promoting better air emissions. Such applications include biomass boilers, waste incinerators, natural gas boilers, heat recovery steam generators, and burners. \n                      \n                        \n                        \n                          \n                        \n                        \n                          Emisshield Inc. licensed technology from NASA to incorporate into various formulations of coatings for high-temperature applications. The images above show the walls of a boiler before (left) and after (right) the NASA-derived coating was applied.\n                        \n                      \n                      For metal production, applications include reheat furnaces, bell annealing furnaces, walking beam furnaces, electric arc furnaces, and others. The increase in combustion allows for a quicker heat up and cool down \n                        in an intermittent furnace, which saves manufacturers time and money. Emisshield is also used in a variety of multipurpose kilns including intermittent kilns and continuous kilns. \n                      One of Emisshield’s most popular applications is in furnaces for making glass—everything from wine bottles to windshields. So far, the coating has been applied to 30 furnaces worldwide. “On these big glass furnaces, they are saving about 10 percent of their energy,” says Olver. “The payback for our clients making glass is always under a year.” \n                      As the company moves forward, it strives to penetrate new market areas. Recently, the company started focusing on introducing Emisshield in the food processing industry. The company is working to apply the coating on the walls of ovens, baking pans, and burners for commercial bread baking. “We see lots of opportunities in this market, and are hoping to push into it in the next few years,” says Olver. “Emisshield could even be applied to the grills that people use at home. There are a lot of potential applications.”\n                      The newest application, however, is for high solar absorptive materials for concentrated solar power generation stations. The company is currently working with an Israeli-U.S. company in this area.\n                      “We started the root system with NASA, then the trunk, and now we’re growing our branches,” says Olver. “We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                      Emisshield® is registered by Emisshield Inc.\n                    \n                    \n                  \n                \n              \n              \n            \n          \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          In developing new materials to test on the X-33 reusable launch vehicle (artist’s concept shown here), Ames Research Center invented a thin material capable of withstanding high temperatures. It also exhibited good thermal shock, vibration, and acoustic performance. \n                        \n                      \n                      The U.S. X-Plane Program included the first-of-its-kind research in aerodynamics and astronautics with experimental vehicles, including the first aircraft to break the sound barrier; the first aircraft to fly in excess of 100,000, then 200,000, and then 300,000 feet; and the first aircraft to fly at three, four, five, and then six times the speed of sound. \n                      During the 1990s, NASA started developing a new thermal protection material to test on the X-33 and X-34 supersonic aircraft. The X-33 was intended to demonstrate the technologies needed for a new reusable launch vehicle and was projected to reach an altitude of approximately 50 miles and speeds of more than Mach 11. The X-34, a small, reusable technology demonstrator for a launch vehicle, was intended to reach an altitude of 250,000 feet and fly at speeds of Mach 8. \n                      As a result of its research and development efforts, NASA’s Ames Research Center invented the Protective Ceramic Coating Material (PCCM). Applied to a surface, the thin, lightweight coating could protect the material underneath from extreme temperatures. The capability of the technology came from its emissivity, which radiated heat away from the surface it covered, thereby decreasing the amount of heat transferred to the underlying material. PCCM not only increased the capability of materials to withstand higher temperatures, it also exhibited impressive thermal shock, vibration, and acoustic performance. In addition, it proved to be resistant to abrasion and mechanical damage and was also environmentally safe, due to it being water-based and containing no solvents. Even though funding for the X-33 and X-34 ended in 2001, PCCM continued on a path of innovation. \n                      Partnership\n                      Shortly after Ames made PCCM available for licensing, Emisshield Inc. (then Wessex Incorporated) in Blacksburg, Virginia, stumbled upon the technology, and according to John Olver, president and CEO of Emisshield, “After we looked it over, analyzed it, read about it, and checked on some of the references, we called Ames and said we’d like to license it. We wanted to know how they did that.” \n                      Olver and other representatives from Emisshield talked to the NASA inventors to learn more about PCCM, and in 1996, obtained a license for the technology. With assistance from the Center for Adhesion and Sealant Sciences at the Virginia Polytechnic Institute and State University (Virginia Tech), Emisshield performed extensive testing, research, and development of the coating. By 2001, the company had expanded its license agreement to include all applications except space and space vehicle applications. \n                      During the first few years, Emisshield made several changes to make PCCM more practical to use. One of the properties Emisshield adjusted was the shelf life of the material. “When you mixed it up, it set like concrete in about an hour. You couldn’t use it after that,” Olver says. Emisshield also modified PCCM so it would adhere to metal and was easy to apply with a spray gun. \n                      “As we progressed, we took the base license and advanced it into two new patents,” says Olver. “NASA said, ‘That’s what we intended for you to do, to license it, make it better, and commercialize it.’”\n                      Benefits\n                      Previously featured in Spinoff 2001 and Spinoff 2004, Emisshield provides its NASA-derived technology, also called Emisshield, in more than 20 different products. Each formulation is different based on the material it is being applied to as well as the temperature and conditions of the environment. “We are changing the surface properties of existing materials—metals, ceramics—to improve their performance,” says Olver. “It will work just about anywhere there is heat—from electricity to manufacturing glass and plastic bottles.”\n                      Available for use on new or existing substrates in any combustion process including metals, refractory (heat resistant material), ceramics, and high technology fabrics, Emisshield can provide significant savings for most energy consuming, producing, or related heat systems. According to its customers, Emisshield has permitted heat-driven industrial applications to experience up to a 15-percent energy savings, a 15-percent increase in production, more uniform heating, prolonged substrate life, and reduced downtime for maintenance. In fact, the company finds the harder a process is pushed, the greater the fuel savings and the faster the payback for using Emisshield.\n                      “Another thing that happens is that by improving combustion of gasses and fuels, products are made with less energy, and that reduces air emissions,” says Olver. All of this is done with a coating that is about as thin as a kitchen garbage bag. The coating can be applied to items at an Emisshield facility, or onsite at a customer’s facility. “It’s unique because it is so easy to install, even in the field and for applications that have extreme requirements. We can go out, clean the surface, and then apply the coating.”\n                      “We started the root system with NASA, then the trunk, and now we’re growing \n                        the branches. We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                        —John Olver, Emisshield Inc.                      \n                      In hydrocarbon and chemical processing, Emisshield can be used to coat the combustion chamber and process tubes of high temperature cracking units, as well as lower temperature process heaters. Emisshield is applied to the process tubes and refractory walls, a combination that generates an increase in energy savings and production. Like applications in the hydrocarbon and chemical processing industry, power generation can also see similar benefits while promoting better air emissions. Such applications include biomass boilers, waste incinerators, natural gas boilers, heat recovery steam generators, and burners. \n                      \n                        \n                        \n                          \n                        \n                        \n                          Emisshield Inc. licensed technology from NASA to incorporate into various formulations of coatings for high-temperature applications. The images above show the walls of a boiler before (left) and after (right) the NASA-derived coating was applied.\n                        \n                      \n                      For metal production, applications include reheat furnaces, bell annealing furnaces, walking beam furnaces, electric arc furnaces, and others. The increase in combustion allows for a quicker heat up and cool down \n                        in an intermittent furnace, which saves manufacturers time and money. Emisshield is also used in a variety of multipurpose kilns including intermittent kilns and continuous kilns. \n                      One of Emisshield’s most popular applications is in furnaces for making glass—everything from wine bottles to windshields. So far, the coating has been applied to 30 furnaces worldwide. “On these big glass furnaces, they are saving about 10 percent of their energy,” says Olver. “The payback for our clients making glass is always under a year.” \n                      As the company moves forward, it strives to penetrate new market areas. Recently, the company started focusing on introducing Emisshield in the food processing industry. The company is working to apply the coating on the walls of ovens, baking pans, and burners for commercial bread baking. “We see lots of opportunities in this market, and are hoping to push into it in the next few years,” says Olver. “Emisshield could even be applied to the grills that people use at home. There are a lot of potential applications.”\n                      The newest application, however, is for high solar absorptive materials for concentrated solar power generation stations. The company is currently working with an Israeli-U.S. company in this area.\n                      “We started the root system with NASA, then the trunk, and now we’re growing our branches,” says Olver. “We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                      Emisshield® is registered by Emisshield Inc.\n                    \n                    \n                  \n                \n              \n              \n            \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          In developing new materials to test on the X-33 reusable launch vehicle (artist’s concept shown here), Ames Research Center invented a thin material capable of withstanding high temperatures. It also exhibited good thermal shock, vibration, and acoustic performance. \n                        \n                      \n                      The U.S. X-Plane Program included the first-of-its-kind research in aerodynamics and astronautics with experimental vehicles, including the first aircraft to break the sound barrier; the first aircraft to fly in excess of 100,000, then 200,000, and then 300,000 feet; and the first aircraft to fly at three, four, five, and then six times the speed of sound. \n                      During the 1990s, NASA started developing a new thermal protection material to test on the X-33 and X-34 supersonic aircraft. The X-33 was intended to demonstrate the technologies needed for a new reusable launch vehicle and was projected to reach an altitude of approximately 50 miles and speeds of more than Mach 11. The X-34, a small, reusable technology demonstrator for a launch vehicle, was intended to reach an altitude of 250,000 feet and fly at speeds of Mach 8. \n                      As a result of its research and development efforts, NASA’s Ames Research Center invented the Protective Ceramic Coating Material (PCCM). Applied to a surface, the thin, lightweight coating could protect the material underneath from extreme temperatures. The capability of the technology came from its emissivity, which radiated heat away from the surface it covered, thereby decreasing the amount of heat transferred to the underlying material. PCCM not only increased the capability of materials to withstand higher temperatures, it also exhibited impressive thermal shock, vibration, and acoustic performance. In addition, it proved to be resistant to abrasion and mechanical damage and was also environmentally safe, due to it being water-based and containing no solvents. Even though funding for the X-33 and X-34 ended in 2001, PCCM continued on a path of innovation. \n                      Partnership\n                      Shortly after Ames made PCCM available for licensing, Emisshield Inc. (then Wessex Incorporated) in Blacksburg, Virginia, stumbled upon the technology, and according to John Olver, president and CEO of Emisshield, “After we looked it over, analyzed it, read about it, and checked on some of the references, we called Ames and said we’d like to license it. We wanted to know how they did that.” \n                      Olver and other representatives from Emisshield talked to the NASA inventors to learn more about PCCM, and in 1996, obtained a license for the technology. With assistance from the Center for Adhesion and Sealant Sciences at the Virginia Polytechnic Institute and State University (Virginia Tech), Emisshield performed extensive testing, research, and development of the coating. By 2001, the company had expanded its license agreement to include all applications except space and space vehicle applications. \n                      During the first few years, Emisshield made several changes to make PCCM more practical to use. One of the properties Emisshield adjusted was the shelf life of the material. “When you mixed it up, it set like concrete in about an hour. You couldn’t use it after that,” Olver says. Emisshield also modified PCCM so it would adhere to metal and was easy to apply with a spray gun. \n                      “As we progressed, we took the base license and advanced it into two new patents,” says Olver. “NASA said, ‘That’s what we intended for you to do, to license it, make it better, and commercialize it.’”\n                      Benefits\n                      Previously featured in Spinoff 2001 and Spinoff 2004, Emisshield provides its NASA-derived technology, also called Emisshield, in more than 20 different products. Each formulation is different based on the material it is being applied to as well as the temperature and conditions of the environment. “We are changing the surface properties of existing materials—metals, ceramics—to improve their performance,” says Olver. “It will work just about anywhere there is heat—from electricity to manufacturing glass and plastic bottles.”\n                      Available for use on new or existing substrates in any combustion process including metals, refractory (heat resistant material), ceramics, and high technology fabrics, Emisshield can provide significant savings for most energy consuming, producing, or related heat systems. According to its customers, Emisshield has permitted heat-driven industrial applications to experience up to a 15-percent energy savings, a 15-percent increase in production, more uniform heating, prolonged substrate life, and reduced downtime for maintenance. In fact, the company finds the harder a process is pushed, the greater the fuel savings and the faster the payback for using Emisshield.\n                      “Another thing that happens is that by improving combustion of gasses and fuels, products are made with less energy, and that reduces air emissions,” says Olver. All of this is done with a coating that is about as thin as a kitchen garbage bag. The coating can be applied to items at an Emisshield facility, or onsite at a customer’s facility. “It’s unique because it is so easy to install, even in the field and for applications that have extreme requirements. We can go out, clean the surface, and then apply the coating.”\n                      “We started the root system with NASA, then the trunk, and now we’re growing \n                        the branches. We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                        —John Olver, Emisshield Inc.                      \n                      In hydrocarbon and chemical processing, Emisshield can be used to coat the combustion chamber and process tubes of high temperature cracking units, as well as lower temperature process heaters. Emisshield is applied to the process tubes and refractory walls, a combination that generates an increase in energy savings and production. Like applications in the hydrocarbon and chemical processing industry, power generation can also see similar benefits while promoting better air emissions. Such applications include biomass boilers, waste incinerators, natural gas boilers, heat recovery steam generators, and burners. \n                      \n                        \n                        \n                          \n                        \n                        \n                          Emisshield Inc. licensed technology from NASA to incorporate into various formulations of coatings for high-temperature applications. The images above show the walls of a boiler before (left) and after (right) the NASA-derived coating was applied.\n                        \n                      \n                      For metal production, applications include reheat furnaces, bell annealing furnaces, walking beam furnaces, electric arc furnaces, and others. The increase in combustion allows for a quicker heat up and cool down \n                        in an intermittent furnace, which saves manufacturers time and money. Emisshield is also used in a variety of multipurpose kilns including intermittent kilns and continuous kilns. \n                      One of Emisshield’s most popular applications is in furnaces for making glass—everything from wine bottles to windshields. So far, the coating has been applied to 30 furnaces worldwide. “On these big glass furnaces, they are saving about 10 percent of their energy,” says Olver. “The payback for our clients making glass is always under a year.” \n                      As the company moves forward, it strives to penetrate new market areas. Recently, the company started focusing on introducing Emisshield in the food processing industry. The company is working to apply the coating on the walls of ovens, baking pans, and burners for commercial bread baking. “We see lots of opportunities in this market, and are hoping to push into it in the next few years,” says Olver. “Emisshield could even be applied to the grills that people use at home. There are a lot of potential applications.”\n                      The newest application, however, is for high solar absorptive materials for concentrated solar power generation stations. The company is currently working with an Israeli-U.S. company in this area.\n                      “We started the root system with NASA, then the trunk, and now we’re growing our branches,” says Olver. “We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                      Emisshield® is registered by Emisshield Inc.\n                    \n                    \n                  \n                \n              \n              \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          In developing new materials to test on the X-33 reusable launch vehicle (artist’s concept shown here), Ames Research Center invented a thin material capable of withstanding high temperatures. It also exhibited good thermal shock, vibration, and acoustic performance. \n                        \n                      \n                      The U.S. X-Plane Program included the first-of-its-kind research in aerodynamics and astronautics with experimental vehicles, including the first aircraft to break the sound barrier; the first aircraft to fly in excess of 100,000, then 200,000, and then 300,000 feet; and the first aircraft to fly at three, four, five, and then six times the speed of sound. \n                      During the 1990s, NASA started developing a new thermal protection material to test on the X-33 and X-34 supersonic aircraft. The X-33 was intended to demonstrate the technologies needed for a new reusable launch vehicle and was projected to reach an altitude of approximately 50 miles and speeds of more than Mach 11. The X-34, a small, reusable technology demonstrator for a launch vehicle, was intended to reach an altitude of 250,000 feet and fly at speeds of Mach 8. \n                      As a result of its research and development efforts, NASA’s Ames Research Center invented the Protective Ceramic Coating Material (PCCM). Applied to a surface, the thin, lightweight coating could protect the material underneath from extreme temperatures. The capability of the technology came from its emissivity, which radiated heat away from the surface it covered, thereby decreasing the amount of heat transferred to the underlying material. PCCM not only increased the capability of materials to withstand higher temperatures, it also exhibited impressive thermal shock, vibration, and acoustic performance. In addition, it proved to be resistant to abrasion and mechanical damage and was also environmentally safe, due to it being water-based and containing no solvents. Even though funding for the X-33 and X-34 ended in 2001, PCCM continued on a path of innovation. \n                      Partnership\n                      Shortly after Ames made PCCM available for licensing, Emisshield Inc. (then Wessex Incorporated) in Blacksburg, Virginia, stumbled upon the technology, and according to John Olver, president and CEO of Emisshield, “After we looked it over, analyzed it, read about it, and checked on some of the references, we called Ames and said we’d like to license it. We wanted to know how they did that.” \n                      Olver and other representatives from Emisshield talked to the NASA inventors to learn more about PCCM, and in 1996, obtained a license for the technology. With assistance from the Center for Adhesion and Sealant Sciences at the Virginia Polytechnic Institute and State University (Virginia Tech), Emisshield performed extensive testing, research, and development of the coating. By 2001, the company had expanded its license agreement to include all applications except space and space vehicle applications. \n                      During the first few years, Emisshield made several changes to make PCCM more practical to use. One of the properties Emisshield adjusted was the shelf life of the material. “When you mixed it up, it set like concrete in about an hour. You couldn’t use it after that,” Olver says. Emisshield also modified PCCM so it would adhere to metal and was easy to apply with a spray gun. \n                      “As we progressed, we took the base license and advanced it into two new patents,” says Olver. “NASA said, ‘That’s what we intended for you to do, to license it, make it better, and commercialize it.’”\n                      Benefits\n                      Previously featured in Spinoff 2001 and Spinoff 2004, Emisshield provides its NASA-derived technology, also called Emisshield, in more than 20 different products. Each formulation is different based on the material it is being applied to as well as the temperature and conditions of the environment. “We are changing the surface properties of existing materials—metals, ceramics—to improve their performance,” says Olver. “It will work just about anywhere there is heat—from electricity to manufacturing glass and plastic bottles.”\n                      Available for use on new or existing substrates in any combustion process including metals, refractory (heat resistant material), ceramics, and high technology fabrics, Emisshield can provide significant savings for most energy consuming, producing, or related heat systems. According to its customers, Emisshield has permitted heat-driven industrial applications to experience up to a 15-percent energy savings, a 15-percent increase in production, more uniform heating, prolonged substrate life, and reduced downtime for maintenance. In fact, the company finds the harder a process is pushed, the greater the fuel savings and the faster the payback for using Emisshield.\n                      “Another thing that happens is that by improving combustion of gasses and fuels, products are made with less energy, and that reduces air emissions,” says Olver. All of this is done with a coating that is about as thin as a kitchen garbage bag. The coating can be applied to items at an Emisshield facility, or onsite at a customer’s facility. “It’s unique because it is so easy to install, even in the field and for applications that have extreme requirements. We can go out, clean the surface, and then apply the coating.”\n                      “We started the root system with NASA, then the trunk, and now we’re growing \n                        the branches. We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                        —John Olver, Emisshield Inc.                      \n                      In hydrocarbon and chemical processing, Emisshield can be used to coat the combustion chamber and process tubes of high temperature cracking units, as well as lower temperature process heaters. Emisshield is applied to the process tubes and refractory walls, a combination that generates an increase in energy savings and production. Like applications in the hydrocarbon and chemical processing industry, power generation can also see similar benefits while promoting better air emissions. Such applications include biomass boilers, waste incinerators, natural gas boilers, heat recovery steam generators, and burners. \n                      \n                        \n                        \n                          \n                        \n                        \n                          Emisshield Inc. licensed technology from NASA to incorporate into various formulations of coatings for high-temperature applications. The images above show the walls of a boiler before (left) and after (right) the NASA-derived coating was applied.\n                        \n                      \n                      For metal production, applications include reheat furnaces, bell annealing furnaces, walking beam furnaces, electric arc furnaces, and others. The increase in combustion allows for a quicker heat up and cool down \n                        in an intermittent furnace, which saves manufacturers time and money. Emisshield is also used in a variety of multipurpose kilns including intermittent kilns and continuous kilns. \n                      One of Emisshield’s most popular applications is in furnaces for making glass—everything from wine bottles to windshields. So far, the coating has been applied to 30 furnaces worldwide. “On these big glass furnaces, they are saving about 10 percent of their energy,” says Olver. “The payback for our clients making glass is always under a year.” \n                      As the company moves forward, it strives to penetrate new market areas. Recently, the company started focusing on introducing Emisshield in the food processing industry. The company is working to apply the coating on the walls of ovens, baking pans, and burners for commercial bread baking. “We see lots of opportunities in this market, and are hoping to push into it in the next few years,” says Olver. “Emisshield could even be applied to the grills that people use at home. There are a lot of potential applications.”\n                      The newest application, however, is for high solar absorptive materials for concentrated solar power generation stations. The company is currently working with an Israeli-U.S. company in this area.\n                      “We started the root system with NASA, then the trunk, and now we’re growing our branches,” says Olver. “We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                      Emisshield® is registered by Emisshield Inc.\n                    \n                    \n                  \n                \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          In developing new materials to test on the X-33 reusable launch vehicle (artist’s concept shown here), Ames Research Center invented a thin material capable of withstanding high temperatures. It also exhibited good thermal shock, vibration, and acoustic performance. \n                        \n                      \n                      The U.S. X-Plane Program included the first-of-its-kind research in aerodynamics and astronautics with experimental vehicles, including the first aircraft to break the sound barrier; the first aircraft to fly in excess of 100,000, then 200,000, and then 300,000 feet; and the first aircraft to fly at three, four, five, and then six times the speed of sound. \n                      During the 1990s, NASA started developing a new thermal protection material to test on the X-33 and X-34 supersonic aircraft. The X-33 was intended to demonstrate the technologies needed for a new reusable launch vehicle and was projected to reach an altitude of approximately 50 miles and speeds of more than Mach 11. The X-34, a small, reusable technology demonstrator for a launch vehicle, was intended to reach an altitude of 250,000 feet and fly at speeds of Mach 8. \n                      As a result of its research and development efforts, NASA’s Ames Research Center invented the Protective Ceramic Coating Material (PCCM). Applied to a surface, the thin, lightweight coating could protect the material underneath from extreme temperatures. The capability of the technology came from its emissivity, which radiated heat away from the surface it covered, thereby decreasing the amount of heat transferred to the underlying material. PCCM not only increased the capability of materials to withstand higher temperatures, it also exhibited impressive thermal shock, vibration, and acoustic performance. In addition, it proved to be resistant to abrasion and mechanical damage and was also environmentally safe, due to it being water-based and containing no solvents. Even though funding for the X-33 and X-34 ended in 2001, PCCM continued on a path of innovation. \n                      Partnership\n                      Shortly after Ames made PCCM available for licensing, Emisshield Inc. (then Wessex Incorporated) in Blacksburg, Virginia, stumbled upon the technology, and according to John Olver, president and CEO of Emisshield, “After we looked it over, analyzed it, read about it, and checked on some of the references, we called Ames and said we’d like to license it. We wanted to know how they did that.” \n                      Olver and other representatives from Emisshield talked to the NASA inventors to learn more about PCCM, and in 1996, obtained a license for the technology. With assistance from the Center for Adhesion and Sealant Sciences at the Virginia Polytechnic Institute and State University (Virginia Tech), Emisshield performed extensive testing, research, and development of the coating. By 2001, the company had expanded its license agreement to include all applications except space and space vehicle applications. \n                      During the first few years, Emisshield made several changes to make PCCM more practical to use. One of the properties Emisshield adjusted was the shelf life of the material. “When you mixed it up, it set like concrete in about an hour. You couldn’t use it after that,” Olver says. Emisshield also modified PCCM so it would adhere to metal and was easy to apply with a spray gun. \n                      “As we progressed, we took the base license and advanced it into two new patents,” says Olver. “NASA said, ‘That’s what we intended for you to do, to license it, make it better, and commercialize it.’”\n                      Benefits\n                      Previously featured in Spinoff 2001 and Spinoff 2004, Emisshield provides its NASA-derived technology, also called Emisshield, in more than 20 different products. Each formulation is different based on the material it is being applied to as well as the temperature and conditions of the environment. “We are changing the surface properties of existing materials—metals, ceramics—to improve their performance,” says Olver. “It will work just about anywhere there is heat—from electricity to manufacturing glass and plastic bottles.”\n                      Available for use on new or existing substrates in any combustion process including metals, refractory (heat resistant material), ceramics, and high technology fabrics, Emisshield can provide significant savings for most energy consuming, producing, or related heat systems. According to its customers, Emisshield has permitted heat-driven industrial applications to experience up to a 15-percent energy savings, a 15-percent increase in production, more uniform heating, prolonged substrate life, and reduced downtime for maintenance. In fact, the company finds the harder a process is pushed, the greater the fuel savings and the faster the payback for using Emisshield.\n                      “Another thing that happens is that by improving combustion of gasses and fuels, products are made with less energy, and that reduces air emissions,” says Olver. All of this is done with a coating that is about as thin as a kitchen garbage bag. The coating can be applied to items at an Emisshield facility, or onsite at a customer’s facility. “It’s unique because it is so easy to install, even in the field and for applications that have extreme requirements. We can go out, clean the surface, and then apply the coating.”\n                      “We started the root system with NASA, then the trunk, and now we’re growing \n                        the branches. We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                        —John Olver, Emisshield Inc.                      \n                      In hydrocarbon and chemical processing, Emisshield can be used to coat the combustion chamber and process tubes of high temperature cracking units, as well as lower temperature process heaters. Emisshield is applied to the process tubes and refractory walls, a combination that generates an increase in energy savings and production. Like applications in the hydrocarbon and chemical processing industry, power generation can also see similar benefits while promoting better air emissions. Such applications include biomass boilers, waste incinerators, natural gas boilers, heat recovery steam generators, and burners. \n                      \n                        \n                        \n                          \n                        \n                        \n                          Emisshield Inc. licensed technology from NASA to incorporate into various formulations of coatings for high-temperature applications. The images above show the walls of a boiler before (left) and after (right) the NASA-derived coating was applied.\n                        \n                      \n                      For metal production, applications include reheat furnaces, bell annealing furnaces, walking beam furnaces, electric arc furnaces, and others. The increase in combustion allows for a quicker heat up and cool down \n                        in an intermittent furnace, which saves manufacturers time and money. Emisshield is also used in a variety of multipurpose kilns including intermittent kilns and continuous kilns. \n                      One of Emisshield’s most popular applications is in furnaces for making glass—everything from wine bottles to windshields. So far, the coating has been applied to 30 furnaces worldwide. “On these big glass furnaces, they are saving about 10 percent of their energy,” says Olver. “The payback for our clients making glass is always under a year.” \n                      As the company moves forward, it strives to penetrate new market areas. Recently, the company started focusing on introducing Emisshield in the food processing industry. The company is working to apply the coating on the walls of ovens, baking pans, and burners for commercial bread baking. “We see lots of opportunities in this market, and are hoping to push into it in the next few years,” says Olver. “Emisshield could even be applied to the grills that people use at home. There are a lot of potential applications.”\n                      The newest application, however, is for high solar absorptive materials for concentrated solar power generation stations. The company is currently working with an Israeli-U.S. company in this area.\n                      “We started the root system with NASA, then the trunk, and now we’re growing our branches,” says Olver. “We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                      Emisshield® is registered by Emisshield Inc.\n                    \n                    \n                  \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          In developing new materials to test on the X-33 reusable launch vehicle (artist’s concept shown here), Ames Research Center invented a thin material capable of withstanding high temperatures. It also exhibited good thermal shock, vibration, and acoustic performance. \n                        \n                      \n                      The U.S. X-Plane Program included the first-of-its-kind research in aerodynamics and astronautics with experimental vehicles, including the first aircraft to break the sound barrier; the first aircraft to fly in excess of 100,000, then 200,000, and then 300,000 feet; and the first aircraft to fly at three, four, five, and then six times the speed of sound. \n                      During the 1990s, NASA started developing a new thermal protection material to test on the X-33 and X-34 supersonic aircraft. The X-33 was intended to demonstrate the technologies needed for a new reusable launch vehicle and was projected to reach an altitude of approximately 50 miles and speeds of more than Mach 11. The X-34, a small, reusable technology demonstrator for a launch vehicle, was intended to reach an altitude of 250,000 feet and fly at speeds of Mach 8. \n                      As a result of its research and development efforts, NASA’s Ames Research Center invented the Protective Ceramic Coating Material (PCCM). Applied to a surface, the thin, lightweight coating could protect the material underneath from extreme temperatures. The capability of the technology came from its emissivity, which radiated heat away from the surface it covered, thereby decreasing the amount of heat transferred to the underlying material. PCCM not only increased the capability of materials to withstand higher temperatures, it also exhibited impressive thermal shock, vibration, and acoustic performance. In addition, it proved to be resistant to abrasion and mechanical damage and was also environmentally safe, due to it being water-based and containing no solvents. Even though funding for the X-33 and X-34 ended in 2001, PCCM continued on a path of innovation. \n                      Partnership\n                      Shortly after Ames made PCCM available for licensing, Emisshield Inc. (then Wessex Incorporated) in Blacksburg, Virginia, stumbled upon the technology, and according to John Olver, president and CEO of Emisshield, “After we looked it over, analyzed it, read about it, and checked on some of the references, we called Ames and said we’d like to license it. We wanted to know how they did that.” \n                      Olver and other representatives from Emisshield talked to the NASA inventors to learn more about PCCM, and in 1996, obtained a license for the technology. With assistance from the Center for Adhesion and Sealant Sciences at the Virginia Polytechnic Institute and State University (Virginia Tech), Emisshield performed extensive testing, research, and development of the coating. By 2001, the company had expanded its license agreement to include all applications except space and space vehicle applications. \n                      During the first few years, Emisshield made several changes to make PCCM more practical to use. One of the properties Emisshield adjusted was the shelf life of the material. “When you mixed it up, it set like concrete in about an hour. You couldn’t use it after that,” Olver says. Emisshield also modified PCCM so it would adhere to metal and was easy to apply with a spray gun. \n                      “As we progressed, we took the base license and advanced it into two new patents,” says Olver. “NASA said, ‘That’s what we intended for you to do, to license it, make it better, and commercialize it.’”\n                      Benefits\n                      Previously featured in Spinoff 2001 and Spinoff 2004, Emisshield provides its NASA-derived technology, also called Emisshield, in more than 20 different products. Each formulation is different based on the material it is being applied to as well as the temperature and conditions of the environment. “We are changing the surface properties of existing materials—metals, ceramics—to improve their performance,” says Olver. “It will work just about anywhere there is heat—from electricity to manufacturing glass and plastic bottles.”\n                      Available for use on new or existing substrates in any combustion process including metals, refractory (heat resistant material), ceramics, and high technology fabrics, Emisshield can provide significant savings for most energy consuming, producing, or related heat systems. According to its customers, Emisshield has permitted heat-driven industrial applications to experience up to a 15-percent energy savings, a 15-percent increase in production, more uniform heating, prolonged substrate life, and reduced downtime for maintenance. In fact, the company finds the harder a process is pushed, the greater the fuel savings and the faster the payback for using Emisshield.\n                      “Another thing that happens is that by improving combustion of gasses and fuels, products are made with less energy, and that reduces air emissions,” says Olver. All of this is done with a coating that is about as thin as a kitchen garbage bag. The coating can be applied to items at an Emisshield facility, or onsite at a customer’s facility. “It’s unique because it is so easy to install, even in the field and for applications that have extreme requirements. We can go out, clean the surface, and then apply the coating.”\n                      “We started the root system with NASA, then the trunk, and now we’re growing \n                        the branches. We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                        —John Olver, Emisshield Inc.                      \n                      In hydrocarbon and chemical processing, Emisshield can be used to coat the combustion chamber and process tubes of high temperature cracking units, as well as lower temperature process heaters. Emisshield is applied to the process tubes and refractory walls, a combination that generates an increase in energy savings and production. Like applications in the hydrocarbon and chemical processing industry, power generation can also see similar benefits while promoting better air emissions. Such applications include biomass boilers, waste incinerators, natural gas boilers, heat recovery steam generators, and burners. \n                      \n                        \n                        \n                          \n                        \n                        \n                          Emisshield Inc. licensed technology from NASA to incorporate into various formulations of coatings for high-temperature applications. The images above show the walls of a boiler before (left) and after (right) the NASA-derived coating was applied.\n                        \n                      \n                      For metal production, applications include reheat furnaces, bell annealing furnaces, walking beam furnaces, electric arc furnaces, and others. The increase in combustion allows for a quicker heat up and cool down \n                        in an intermittent furnace, which saves manufacturers time and money. Emisshield is also used in a variety of multipurpose kilns including intermittent kilns and continuous kilns. \n                      One of Emisshield’s most popular applications is in furnaces for making glass—everything from wine bottles to windshields. So far, the coating has been applied to 30 furnaces worldwide. “On these big glass furnaces, they are saving about 10 percent of their energy,” says Olver. “The payback for our clients making glass is always under a year.” \n                      As the company moves forward, it strives to penetrate new market areas. Recently, the company started focusing on introducing Emisshield in the food processing industry. The company is working to apply the coating on the walls of ovens, baking pans, and burners for commercial bread baking. “We see lots of opportunities in this market, and are hoping to push into it in the next few years,” says Olver. “Emisshield could even be applied to the grills that people use at home. There are a lot of potential applications.”\n                      The newest application, however, is for high solar absorptive materials for concentrated solar power generation stations. The company is currently working with an Israeli-U.S. company in this area.\n                      “We started the root system with NASA, then the trunk, and now we’re growing our branches,” says Olver. “We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                      Emisshield® is registered by Emisshield Inc.\n                    \n                    \n                      NASA Technology\n                      \n                        \n                        \n                          \n                        \n                        \n                          In developing new materials to test on the X-33 reusable launch vehicle (artist’s concept shown here), Ames Research Center invented a thin material capable of withstanding high temperatures. It also exhibited good thermal shock, vibration, and acoustic performance. \n                        \n                      \n                      The U.S. X-Plane Program included the first-of-its-kind research in aerodynamics and astronautics with experimental vehicles, including the first aircraft to break the sound barrier; the first aircraft to fly in excess of 100,000, then 200,000, and then 300,000 feet; and the first aircraft to fly at three, four, five, and then six times the speed of sound. \n                      During the 1990s, NASA started developing a new thermal protection material to test on the X-33 and X-34 supersonic aircraft. The X-33 was intended to demonstrate the technologies needed for a new reusable launch vehicle and was projected to reach an altitude of approximately 50 miles and speeds of more than Mach 11. The X-34, a small, reusable technology demonstrator for a launch vehicle, was intended to reach an altitude of 250,000 feet and fly at speeds of Mach 8. \n                      As a result of its research and development efforts, NASA’s Ames Research Center invented the Protective Ceramic Coating Material (PCCM). Applied to a surface, the thin, lightweight coating could protect the material underneath from extreme temperatures. The capability of the technology came from its emissivity, which radiated heat away from the surface it covered, thereby decreasing the amount of heat transferred to the underlying material. PCCM not only increased the capability of materials to withstand higher temperatures, it also exhibited impressive thermal shock, vibration, and acoustic performance. In addition, it proved to be resistant to abrasion and mechanical damage and was also environmentally safe, due to it being water-based and containing no solvents. Even though funding for the X-33 and X-34 ended in 2001, PCCM continued on a path of innovation. \n                      Partnership\n                      Shortly after Ames made PCCM available for licensing, Emisshield Inc. (then Wessex Incorporated) in Blacksburg, Virginia, stumbled upon the technology, and according to John Olver, president and CEO of Emisshield, “After we looked it over, analyzed it, read about it, and checked on some of the references, we called Ames and said we’d like to license it. We wanted to know how they did that.” \n                      Olver and other representatives from Emisshield talked to the NASA inventors to learn more about PCCM, and in 1996, obtained a license for the technology. With assistance from the Center for Adhesion and Sealant Sciences at the Virginia Polytechnic Institute and State University (Virginia Tech), Emisshield performed extensive testing, research, and development of the coating. By 2001, the company had expanded its license agreement to include all applications except space and space vehicle applications. \n                      During the first few years, Emisshield made several changes to make PCCM more practical to use. One of the properties Emisshield adjusted was the shelf life of the material. “When you mixed it up, it set like concrete in about an hour. You couldn’t use it after that,” Olver says. Emisshield also modified PCCM so it would adhere to metal and was easy to apply with a spray gun. \n                      “As we progressed, we took the base license and advanced it into two new patents,” says Olver. “NASA said, ‘That’s what we intended for you to do, to license it, make it better, and commercialize it.’”\n                      Benefits\n                      Previously featured in Spinoff 2001 and Spinoff 2004, Emisshield provides its NASA-derived technology, also called Emisshield, in more than 20 different products. Each formulation is different based on the material it is being applied to as well as the temperature and conditions of the environment. “We are changing the surface properties of existing materials—metals, ceramics—to improve their performance,” says Olver. “It will work just about anywhere there is heat—from electricity to manufacturing glass and plastic bottles.”\n                      Available for use on new or existing substrates in any combustion process including metals, refractory (heat resistant material), ceramics, and high technology fabrics, Emisshield can provide significant savings for most energy consuming, producing, or related heat systems. According to its customers, Emisshield has permitted heat-driven industrial applications to experience up to a 15-percent energy savings, a 15-percent increase in production, more uniform heating, prolonged substrate life, and reduced downtime for maintenance. In fact, the company finds the harder a process is pushed, the greater the fuel savings and the faster the payback for using Emisshield.\n                      “Another thing that happens is that by improving combustion of gasses and fuels, products are made with less energy, and that reduces air emissions,” says Olver. All of this is done with a coating that is about as thin as a kitchen garbage bag. The coating can be applied to items at an Emisshield facility, or onsite at a customer’s facility. “It’s unique because it is so easy to install, even in the field and for applications that have extreme requirements. We can go out, clean the surface, and then apply the coating.”\n                      “We started the root system with NASA, then the trunk, and now we’re growing \n                        the branches. We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                        —John Olver, Emisshield Inc.                      \n                      In hydrocarbon and chemical processing, Emisshield can be used to coat the combustion chamber and process tubes of high temperature cracking units, as well as lower temperature process heaters. Emisshield is applied to the process tubes and refractory walls, a combination that generates an increase in energy savings and production. Like applications in the hydrocarbon and chemical processing industry, power generation can also see similar benefits while promoting better air emissions. Such applications include biomass boilers, waste incinerators, natural gas boilers, heat recovery steam generators, and burners. \n                      \n                        \n                        \n                          \n                        \n                        \n                          Emisshield Inc. licensed technology from NASA to incorporate into various formulations of coatings for high-temperature applications. The images above show the walls of a boiler before (left) and after (right) the NASA-derived coating was applied.\n                        \n                      \n                      For metal production, applications include reheat furnaces, bell annealing furnaces, walking beam furnaces, electric arc furnaces, and others. The increase in combustion allows for a quicker heat up and cool down \n                        in an intermittent furnace, which saves manufacturers time and money. Emisshield is also used in a variety of multipurpose kilns including intermittent kilns and continuous kilns. \n                      One of Emisshield’s most popular applications is in furnaces for making glass—everything from wine bottles to windshields. So far, the coating has been applied to 30 furnaces worldwide. “On these big glass furnaces, they are saving about 10 percent of their energy,” says Olver. “The payback for our clients making glass is always under a year.” \n                      As the company moves forward, it strives to penetrate new market areas. Recently, the company started focusing on introducing Emisshield in the food processing industry. The company is working to apply the coating on the walls of ovens, baking pans, and burners for commercial bread baking. “We see lots of opportunities in this market, and are hoping to push into it in the next few years,” says Olver. “Emisshield could even be applied to the grills that people use at home. There are a lot of potential applications.”\n                      The newest application, however, is for high solar absorptive materials for concentrated solar power generation stations. The company is currently working with an Israeli-U.S. company in this area.\n                      “We started the root system with NASA, then the trunk, and now we’re growing our branches,” says Olver. “We wouldn’t be here if it weren’t for technology transfer from NASA.”\n                      Emisshield® is registered by Emisshield Inc.\n                    "}]